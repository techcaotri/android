{"./":{"url":"./","title":"Introduction","keywords":"","body":"1. Introduction1. Introduction This page collects many of the interesting articles in Android, Live555 and Flutter programming. "},"Graphical Android - Zygote, System Server startup analysis.html":{"url":"Graphical Android - Zygote, System Server startup analysis.html","title":"Graphical Android - Zygote, System Server startup analysis","keywords":"","body":"1. Graphical Android - Zygote, System Server startup analysis2. 1. App_Process3. 2. AndroidRuntime4. 3. ZygoteInit5. 4. System Server startup process6. 5. Fork7. 6. After work8. Summary1. Graphical Android - Zygote, System Server startup analysis Graphical Android - Zygote, System Server startup analysis 1. App_Process 2. AndroidRuntime 3. ZygoteInit 4. System Server startup process 5. Fork 6. After work Summary Init is the starting point for all Linux programs, and Zygote is on Android, just as its English meaning is the 'incubation pool' of all Java programs (known to the brothers who have played with the Star Wars). Can be seen with ps output \\>adb shell ps \\| grep -E 'init\\|926' root 1 0 656 372 00000000 0805d546 S /init root 926 1 685724 43832 ffffffff b76801e0 S zygote system 1018 926 795924 62720 ffffffff b767fff6 S system_server u0_a6 1241 926 717704 39252 ffffffff b76819eb S com.android.systemui u0_a37 1325 926 698280 29024 ffffffff b76819eb S com.android.inputmethod.latin radio 1349 926 711284 30116 ffffffff b76819eb S com.android.phone u0_a7 1357 926 720792 41444 ffffffff b76819eb S com.android.launcher u0_a5 1523 926 703576 26416 ffffffff b76819eb S com.android.providers.calendar u0_a25 1672 926 693716 21328 ffffffff b76819eb S com.android.musicfx u0_a17 2040 926 716888 33992 ffffffff b76819eb S android.process.acore u0_a21 2436 926 716060 23904 ffffffff b76819eb S com.android.calendar Init is the parent process of zygote, and system_server and all other applications ending in com.xxx are from zygote fork. This article will illustrate the startup process of Zygote, system server and android application by means of a diagram (with a small amount of code). Less nonsense, open two big pictures to open our Zygote tour. The first picture is the structure diagram of all the classes related to Zygote, and the other is the flow chart started by Zygote. According to the figure, we decompose the startup process of Zygote according to the serial number in Figure 1. 2. 1. App_Process APP_Process: An application that launches zygote and other Java programs. The code is located in frameworks/base/cmds/app_process/app_main.cpp, specified in init.rc. \\#init.rc service zygote /system/bin/app_process -Xzygote /system/bin --zygote --start-system-server code show as below ... else if (strcmp(arg, \"--zygote\") == 0) { zygote = true; niceName = \"zygote\"; } else if (strcmp(arg, \"--start-system-server\") == 0) { startSystemServer = true; } else if (strcmp(arg, \"--application\") == 0) { application = true; } ... if (zygote) { runtime.start(\"com.android.internal.os.ZygoteInit\", startSystemServer ? \"start-system-server\" : \"\"); } else if (className) { // Remainder of args get passed to startup class main() runtime.mClassName = className; ... runtime.start(\"com.android.internal.os.RuntimeInit\", application ? \"application\" : \"tool\"); } else { } As you can see, there are three application types defined in app_process: 1. Zygote: com.android.internal.os.ZygoteInit 2. System Server, not started separately, but started by Zygote 3. Other Java programs that specify the class name, such as the commonly used am. /system/bin/am is actually a shell program, its real implementation is exec app_process \\$base/bin com.android.commands.am.Am \"\\$\\@\" These Java applications are all started with AppRuntime.start(className). As you can see from the first big picture, AppRuntime is a subclass of AndroidRuntime. It mainly implements several callback functions, and the start() method is implemented in the AndroidRuntime method class. What is AnroidRuntime? We will start right away. It should be noted that Zygote is not the first program launched by Init. It can be seen from the PID. Before it, the important System Daemon (background process) implemented by Native may be up first, such as ServiceManager (service DNS service). 3. 2. AndroidRuntime First of all, what is Runtime? Take a look at several explanations given by the wiki: Run time (program lifecycle phase)), the period during which a computer program is executing Runtime library, a program library designed to implement functions built into a programming language I tend to refer to the latter here and see a further explanation: In computer programming, a runtime library is the API used by a compiler to invoke some of the behaviors of a runtime system. The runtime system implements the execution model and other fundamental behaviors of a programming language. The compiler inserts calls to the runtime library into the executable binary. During execution (run time)) of that computer program, execution of those calls to the runtime library cause communication between the application and theruntime system. This often includes functions for input and output, or for memory management. The generalization is that Runtime is the base library that supports the running of the program, it is bound to the language. such as: C Runtime: It is C standard lib, which is what we often say libc. (Interestingly, the wiki will automatically redirect the \"C runtime\" to the \"C Standard Library\"). Java Runtime: Again, the wiki redirects it to the \"Java Virtual Machine\", which of course includes the Java support library (.jar). AndroidRuntime: Obviously, it is the runtime environment required to run the Android app. This environment includes the following: Dalvik VM: Android Java VM, which explains running Java programs in Dex format. Each process runs a virtual machine (what is running a virtual machine? To put it bluntly, it is some C code, constantly interpreting the Dex format Bytecode, converting them to Machine code, and then executing, Of course, most Java virtual machines now support JIT, which means that bytecode may have been converted to machine code before running, which greatly improves performance. A common understanding in the past is that Java programs are static than C, C++, etc. The compiled language is slow, but with the intervention and development of JIT, this is completely a past tense. The dynamic operation of JIT allows the virtual machine to optimize the generation of machine code according to the runtime environment. In some cases, Java can even It runs faster than C/C++ and has platform-independent features, which is one of the reasons why Java is so popular today.) Android's Java class libraries, mostly from Apache Hamony, open source Java API implementations, such as java.lang, java.util, java.net. But removed AWT, Swing and other components. JNI: Interface between C and Java intermodulation. Libc: Android also has a lot of C code, naturally, libc, note that Android's libc is called bionic C. OK, then let's first take a look at how AndroidRuntime is built. The above figure shows the general flow of Zygote startup. The entry is AndroidRuntime.start(). There are two ways to start depending on the parameters passed in. One is \"com.android.internal.os.RuntimeInit\", the other is \" com.android.internal.os.ZygoteInit\", corresponding to the two classes RuntimeInit and ZygoteInit, which are represented by green and pink respectively. The main difference between the two classes is the Java side. It is obvious that ZygoteInit does a lot more than RuntimeInit, such as \"preload\", \"gc\" and so on. But on the Native side, they all do the same thing, startVM() and startReg(), let's start here. As you can see from the class diagram, JavaVM and JNIEnv are the only two levels between the link between AndroidRuntim and Dalvik VM. It hides the implementation details in Dalvik. In fact, it is two function pointer structures that provide access to native code. The interface of the Java resource. JNIEnv is relative to the thread. The pointer to JNIEnv can finally correspond to the Thread structure inside Dalvik VM. All calls are completed in this structure context. The JavaVM corresponds to DVMGlobal, a process-only structure. It internally maintains a thread queue threadList, which stores each Thread structure object, as well as a list of objects of various states, and a structure that stores the GC, etc. . This article can't go deeper, just a brief introduction. JavaVM and JNIENV Struct _JavaVM { const struct JNIInvokeInterface* functions; // function pointer of C #if defined(__cplusplus) ... jint GetEnv(void** env, jint version) { return functions->GetEnv(this, env, version); } #endif /*__cplusplus*/ }; struct JNIInvokeInterface { void* reserved0; ... jint (*DestroyJavaVM)(JavaVM*); jint (*AttachCurrentThread)(JavaVM*, JNIEnv**, void*); jint (*DetachCurrentThread)(JavaVM*); jint (*GetEnv)(JavaVM*, void**, jint); jint (*AttachCurrentThreadAsDaemon)(JavaVM*, JNIEnv**, void*); }; The most common interface inside is GetEnv(), which returns a JNIEnv object corresponding to each DVM thread. The definition of JNIEnv is very long. Interested students can find it in Jni.h. Here we only see how this object gets static jint GetEnv(JavaVM* vm, void** env, jint version) { Thread* self = dvmThreadSelf() ; //Get the current thread object. If (version JNI_VERSION_1_6) { Return JNI_EVERSION ; } //Check the version number, Android 4.3 corresponds to 1.6 ... *env = (void*) dvmGetThreadJNIEnv(self) ; //It's very simple, see the bottom line dvmChangeStatus(self, THREAD_NATIVE) ; return (*env ! = NULL) ? JNI_OK : JNI_EDETACHED ; } INLINE JNIEnv* dvmGetThreadJNIEnv(Thread* self) { return self->jniEnv; } Very simple, the original is to read from the structure object of the current thread, it seems that there is no JavaVM, why is the parameter passed in? I don't know, maybe Google is reserved for future expansion? But no matter what, to get the call to GetEnv, you still need JavaVM. Students who want to write JNI code in the future can refer to the following code to see how to get JavaVM and JniENV. JNIEnv * AndroidRuntime :: getJNIEnv () { JNIEnv * env; JavaVM* vm = AndroidRuntime::getJavaVM(); assert(vm != NULL); if (vm->GetEnv((void**) &env, JNI_VERSION_1_4) != JNI_OK) return NULL; return env; } At this point, we know that JavaVM and JNIEnv are native (C/C++) code for intermodulation with Java code, and that must be the Java virtual machine and the corresponding Java application on the Java side. What is the Java virtual machine in the end, how is it created? The answer starts with the AndroidRuntime::startVM() function. startVM startVM () int AndroidRuntime :: startVm (JavaVM ** pJavaVM, JNIEnv ** pEnv) { property_get(\"dalvik.vm.checkjni\", propBuf, \"\"); ... initArgs.version = JNI_VERSION_1_4; ... //Create a VM and return JavaVM and JniEnv, pEnv corresponds to the current thread. If (JNI_CreateJavaVM(pJavaVM, pEnv, &initArgs) funcTable = & gInvokeInterface; / / initialization function pointer pVM->envList = NULL; ... gDvmJni.jniVm = (JavaVM* ) pVM; //The JavaVM that the native code contacts is just JniVm. JNIEnvExt * pEnv = (JNIEnvExt* ) dvmCreateJNIEnv(NULL); //Create JNIEnv, because the next virtual machine initialization needs to access C/C++ implementation /* 开始初始化. */ gDvm.initializing = true; std::string status = dvmStartup(argc, argv.get(), args->ignoreUnrecognized, (JNIEnv*)pEnv); gDvm.initializing = false; dvmChangeStatus(NULL, THREAD_NATIVE); *p_env = (JNIEnv*) pEnv; *p_vm = (JavaVM*) pVM; return JNI_OK; std::string dvmStartup(int argc, const char* const argv[], bool ignoreUnrecognized, JNIEnv* pEnv) { /* * Check input and prepare initialization parameters */ int cc = processOptions(argc, argv, ignoreUnrecognized); ... /* The actual initialization begins, initializes each internal module, and creates a series of threads */ if (! dvmAllocTrackerStartup()) { return \" dvmAllocTrackerStartup failed \" ; } if (!dvmGcStartup()) { return \"dvmGcStartup failed\"; } if (!dvmThreadStartup()) { return \"dvmThreadStartup failed\"; } if (!dvmInlineNativeStartup()) { return \"dvmInlineNativeStartup\"; } if (!dvmRegisterMapStartup()) { return \"dvmRegisterMapStartup failed\"; } if (!dvmInstanceofStartup()) { return \"dvmInstanceofStartup failed\"; } if (!dvmClassStartup()) { return \"dvmClassStartup failed\"; } if (!dvmNativeStartup()) { return \"dvmNativeStartup failed\"; } if (!dvmInternalNativeStartup()) { return \"dvmInternalNativeStartup failed\"; } if (!dvmJniStartup()) { return \"dvmJniStartup failed\"; } if (!dvmProfilingStartup()) { return \"dvmProfilingStartup failed\"; } if (!dvmInitClass(gDvm.classJavaLangClass)) { return \"couldn't initialized java.lang.Class\"; } if (!registerSystemNatives(pEnv)) { return \"couldn't register system natives\"; } if (!dvmCreateStockExceptions()) { return \"dvmCreateStockExceptions failed\"; } if (!dvmPrepMainThread()) { return \"dvmPrepMainThread failed\"; } if (dvmReferenceTableEntries(&dvmThreadSelf()->internalLocalRefTable) != 0) { ALOGW(\"Warning: tracked references remain post-initialization\"); dvmDumpReferenceTable(&dvmThreadSelf()->internalLocalRefTable, \"MAIN\"); } if (!dvmDebuggerStartup()) { return \"dvmDebuggerStartup failed\"; } if (!dvmGcStartupClasses()) { return \"dvmGcStartupClasses failed\"; } if (gDvm.zygote) { if (!initZygote()) { return \"initZygote failed\"; } } else { if (!dvmInitAfterZygote()) { return \"dvmInitAfterZygote failed\"; } } return \"\"; } There are too many details about the startup of the Java virtual machine that cannot be expanded here. Here we only need to know that it does the following things: Read a series of startup parameters from the property. Create and initialize the structure global object (per process) gDVM, and corresponding to JavaVM and JNIEnv internal structure JavaVMExt, JNIEnvExt. Initialize the java virtual machine and create a virtual machine thread. \"ps -t\", you can find that each Android application has the following threads > U0_a46 1284 1281 714900 57896 20 0 0 0 fg ffffffff 00000000 S GC //Garbage > Collection > u0_a46 1285 1281 714900 57896 20 0 0 0 fg ffffffff 00000000 S Signal Catcher > U0_a46 1286 1281 714900 57896 20 0 0 0 fg ffffffff 00000000 S JDWP //Java > debugging > u0_a46 1287 1281 714900 57896 20 0 0 0 fg ffffffff 00000000 S Compiler //JIT > u0_a46 1288 1281 714900 57896 20 0 0 0 fg ffffffff 00000000 S > ReferenceQueueD > u0_a46 1289 1281 714900 57896 20 0 0 0 fg ffffffff 00000000 S > FinalizerDaemon //Finalizer监护 > u0_a46 1290 1281 714900 57896 20 0 0 0 fg ffffffff 00000000 S > FinalizerWatchd // Register the JNI of the system through which the Java program accesses the underlying resources. loadJniLibrary(\"javacore\"); loadJniLibrary(\"nativehelper\"); Make final preparations for the startup of Zygote, including setting the SID/UID, and mounting the file system. Return the JavaVM to the Native code so that it can access the Java interface up. In addition to the system's JNI interface (\"javacore\", \"nativehelper\"), the android framework also has a large number of Native implementations, and Android will do all of these interfaces one-time through start_reg(). startReg () int AndroidRuntime::startReg(JNIEnv* env){ androidSetCreateThreadFunc((android_create_thread_fn) javaCreateThreadEtc); // Create threads that the JVM can access must pass through a specific interface. Env -> PushLocalFrame( 200 ); if (register_jni_procs(gRegJNI, NELEM(gRegJNI), env) PopLocalFrame(NULL); return -1; } env->PopLocalFrame(NULL); return 0; } The Android native layer has two ways to create a Thread: #threads.cpp status_t Thread::run(const char* name, int32_t priority, size_t stack) { ... if (mCanCallJava) { res = createThreadEtc(_threadLoop, this, name, priority, stack, &mThread); } else { res = androidCreateRawThreadEtc(_threadLoop,this, name, priority, stack, &mThread); } ... } The difference between them is whether they can call Java-side functions. The normal thread is a simple wrapper around pthread_create. int androidCreateRawThreadEtc(android_thread_func_t entryFunction, void *userData, const char* threadName, int32_t threadPriority, size_t threadStackSize, android_thread_id_t *threadId) { ... int result = pthread_create(&thread, &attr,android_pthread_entry)entryFunction, userData); ... } The thread that can access the Java side needs to be bound with the JVM. The following is the concrete implementation function. #AndroidRuntime.cpp int AndroidRuntime::javaCreateThreadEtc( android_thread_func_t entryFunction, void* userData, const char* threadName, int32_t threadPriority, size_t threadStackSize, android_thread_id_t* threadId) { Args[ 0 ] = ( void *) entryFunction; // Precedent entryFunc in args[0] args[ 1 ] = userData; args[2] = (void*) strdup(threadName); result =AndroidCreateRawThreadEtc(AndroidRuntime::javaThreadShell, args, threadName, threadPriority, threadStackSize, threadId); //entryFunc变成javaThreadShell. return result; } int AndroidRuntime::javaThreadShell(void* args) { void* start = ((void**)args)[0]; void* userData = ((void **)args)[1]; char* name = (char*) ((void **)args)[2]; // we own this storage JNIEnv* env; /* 跟 VM 绑定 */ if (javaAttachThread(name, &env) != JNI_OK) return -1; /* Run the real 'entryFunc' */ result = (* (android_thread_func_t) start)(userData); /* unhook us */ javaDetachThread (); ... return result; } What does attachVM() do? The space is limited and cannot be expanded. Here you only need to know the following points: There is a Java virtual machine in a process. There are many threads inside the Java virtual machine, such as the GC listed above, FinalizeDaemon, and user-created threads. Each Java thread maintains a JNIEnvExt object that holds a pointer to the DVM internal Thread object. That is, all calls from native to Java will reference this object. All threads created by the JVM will be recorded inside the VM, but currently, we have not entered the Java world. The locally created thread VM is naturally unknown, so we need to notify the VM to create the corresponding internal data structure through attach. Take a look at the code below, you know, in fact, one of the important things that Attach() does is to create thread and JNIEnvExt. bool dvmAttachCurrentThread(const JavaVMAttachArgs* pArgs, bool isDaemon) { Thread* self = NULL; ... self = allocThread(gDvm.stackSize); ... self->jniEnv = dvmCreateJNIEnv(self); ... gDvm.threadList->next = self; ... threadObj = dvmAllocObject(gDvm.classJavaLangThread, ALLOC_DEFAULT); vmThreadObj = dvmAllocObject(gDvm.classJavaLangVMThread, ALLOC_DEFAULT); ... self->threadObj = threadObj; ... } When you are finished, you will start registering the local JNI interface function - register_jni_procs(). This function is actually a traversal call to a global array gRegJni[]. This array expansion can get the following results. static const RegJNIRec gRegJNI[] = { {register_android_debug_JNITest}, {register_com_android_internal_os_RuntimeInit}. ... } Each register_xxx is a function pointer int jniRegisterNativeMethods( C_JNIEnv* env, const char* className, const JNINativeMethod* gMethods, int numMethods); What happens to RegisterNativeMethods inside the VM? Again, you only need to know the following points: gRegJni [] Ok, after a lot of hard work, the Android runtime environment is ready, let's review what the AndroidRuntime initialization has done. Created Dalvik VM. Get Native access to Java's two interface objects, JavaVM and JNIENV. Registered a batch (see gRegJni[]) native interface to the VM. These operations are relatively time-consuming tasks. If each process does the same work, it will affect the startup speed. This is why we need to create Android applications through Zygote, because the Linux fork copy_on_write mechanism allows the child processes to Mapping these initialized memory spaces directly into their own process space does not require repetitive work, which increases the speed at which applications can be launched. Can it be that the Android system only needs a basic runtime environment? The answer is obviously No. AndriodRuntime only provides the basic support of the language level, we need to quickly incubate and run the application on a multi-tasking, multi-user graphical operating system. This is Zygote, which is why in Figure 2, ZygoteInit does more than RuntimeInit. Then, let us really enter the world of Zygote. 4. 3. ZygoteInit When the VM is ready, you can run the Java code. The system will enter the Java world for the first time. Remember the parameters of Runtime.start() that are set in app_main.cpp. That is the Java class we want to run. . Android supports two classes as a starting point, one is ' com.android.internal.os.ZygoteInit ', and the other is 'com.android.internal.os.RuntimeInit'. In addition, a ZygoteInit() static method is defined in the Runtime_Init class. It is created when Zygote creates a new application process, which does the same thing as the main() function of the RuntimeInit class: redirectLogStreams(): Redirects System.out and System.err output to Android's Log system (defined in android.util.Log). commonInit(): Initializes the system properties. The most important point is to set up a handler for the uncaught exception. When the code has any unknown exceptions, it will execute it. The classmates who have debugged the Android code often see \"** * FATAL EXCEPTION IN SYSTEM PROCESS\" Printed here: Runtime_init.java ... Thread.setDefaultUncaughtExceptionHandler(new UncaughtHandler()); ... private static class UncaughtHandler implements Thread.UncaughtExceptionHandler { public void uncaughtException(Thread t, Throwable e) { try { // Don't re-enter -- avoid infinite loops if crash-reporting crashes. if (mCrashing) return; mCrashing = true; if (mApplicationObject == null) { Slog.e(TAG, \"*** FATAL EXCEPTION IN SYSTEM PROCESS: \" + t.getName(), e); } else { Slog.e(TAG, \"FATAL EXCEPTION: \" + t.getName(), e); } ActivityManagerNative.getDefault().handleApplicationCrash( mApplicationObject, new ApplicationErrorReport.CrashInfo(e)); } catch (Throwable t2) { ... } finally { Process.killProcess(Process.myPid()); System.exit(10); } } } Next, RuntimeInit::main() and RuntimeInit::ZygoteInit() call nativeFinishInit() and nativeZygoteInit() respectively, and then start to part ways. RuntimeInit's nativeFinishInit() will eventually call the onStarted() function in app_main.cpp. , which calls the main() function of the Java class, and then ends the process exit. virtual void onStarted() { sp proc = ProcessState::self(); proc->startThreadPool(); AndroidRuntime * ar = AndroidRuntime :: getRuntime (); ar->callMain(mClassName, mClass, mArgC, mArgV); IPCThreadState::self()->stopProcess(); } RuntimeInit::ZygoteInit() will be transferred to onZygoteInit() of app_main.cpp virtual void onZygoteInit() { // Re-enable tracing now that we're no longer in Zygote. atrace_set_tracing_enabled(true); sp proc = ProcessState::self(); proc->startThreadPool(); } It just starts a ThreadPool, and the rest of the work goes back to the Java side and is done by RuntimeInit::applicationInit(). So, we might as well understand RuntimeInit::main(), RuntimeInit::ZygoteInit(), ZygoteInit::main(), RuntimeInit's main() method provides a standard Java program runtime, and RuntimeInit's ZygoteInit() It is the method of closing the Android application. It is called when Zygote creates a new application process. This part of the code is implemented in the ZygoteInit class. In addition to the differences described above, the ZygoteInit class has done a few more things, let us analyze them one by one. registerZygoteSocket(); startSystemServer(); runSelectLoopMode(); RegisterZygoteSocket() In fact, the simple thing to do is to initialize the socket of the server (that is, Zygote). It is worth mentioning that the socket type used here is LocalSocket, which is a package of Android's Local Socket for Linux. Local Socket is a Socket-based interprocess communication method provided by Linux. For the server, the only difference is that bind to a local file descriptor (fd) instead of an IP address and port number. In many places in Android, Local Socket is used to communicate between processes. Search init.rc, you will see many such statements: socket adbd stream 660 system system socket vold stream 0660 root mount socket netd stream 0660 root system socket dnsproxyd stream 0660 root inet socket mdns stream 0660 root system socket rild stream 660 root radio socket rild-debug stream 660 radio system socket zygote stream 660 root system socket installd stream 600 system system socket racoon stream 600 system system socket mtpd stream 600 system system socket dumpstate stream 0660 shell log socket mdnsd stream 0660 mdnsr inet When init resolves to such a statement, it will do a few things: Call create_socket() (system/core/init/util.c), create a Socket fd, and put this fd with a file (/dev/socket/xxx, xxx is the name listed above, for example, zygote) Bind, set the relevant users, groups and permissions according to the definition in init.rc. Finally return this fd. Register the socket name (with the 'ANDROIDSOCKET' prefix) (such as zygote) and fd into the environment variable of the init process, so that all other processes (all processes are init subprocesses) can be obtained by getenv(name) To this fd. ZygoteInit completes the configuration of the Socket Server side with the following code: private static final String ANDROID_SOCKET_ENV = \"ANDROID_SOCKET_zygote\"; private static void registerZygoteSocket() { String env = System.getenv(ANDROID_SOCKET_ENV); fileDesc = Integer.parseInt(env); ... sServerSocket = new LocalServerSocket( createFileDescriptor(fileDesc)); ... } After the server is created, the corresponding client connection request can be made. As we mentioned earlier, AndroidRuntime a series of complex initialization work can help the child process to simplify the process through fork. Yes, Zygote creates a Socket server to respond to this fork request. Who is the request? Who is the child process of Zygote fork? The answer is ActivityManagerService and Android Application. What is the process like this? The answer is in the startup process of Andriod System Server. Preload Preload() does two things: static void preload() { preloadClasses(); preloadResources(); } This is the two most time-consuming things in the Android startup process. preloadClassess loads all classes defined by preloaded-classes in framework.jar into memory. Preloaded-classes can be found in framework/base after compiling Android. The preloadResources loads the system's Resource (not the resource defined in the user apk) into memory. The resource is preloaded into the Zygoted process address space. All fork children will share this space without reloading, which greatly reduces the application startup time, but in turn increases the system startup time. System startup can be accelerated by adjusting the number of preload classes and resources. GC static void gc () { final VMRuntime runtime = VMRuntime.getRuntime (); System.gc(); runtime.runFinalizationSync(); System.gc(); runtime.runFinalizationSync(); System.gc(); runtime.runFinalizationSync(); } Why did you adjust System.gc() and runFinalizationSync() three times? This is because the gc() call simply tells the VM to do garbage collection, whether to recycle, and when to recycle it. GC recycling has a complex state machine control that allows as many resources as possible to be recycled through multiple calls. Gc() must be completed before the fork (the next StartSystemServer will have a fork operation), so that the child process that will be copied in the future will have as little garbage memory as possible. Start SystemServer Think of the zygote parameter in init.rc, \"--start-system-server\", System Server is the first Java process of Zygote fork, this process is very important, because they have a lot of system threads, provide all cores System service, we can use 'ps -t |grep \\' to see which threads are there, exclude the several Java virtual machine threads listed above, and system 1176 1163 774376 51144 00000000 b76c4ab6 S SensorService system 1177 1163 774376 51144 00000000 b76c49eb S er.ServerThread system 1178 1163 774376 51144 00000000 b76c49eb S UI system 1179 1163 774376 51144 00000000 b76c49eb S WindowManager system 1180 1163 774376 51144 00000000 b76c49eb S ActivityManager system 1182 1163 774376 51144 00000000 b76c4d69 S ProcessStats system 1183 1163 774376 51144 00000000 b76c2bb6 S FileObserver system 1184 1163 774376 51144 00000000 b76c49eb S PackageManager system 1185 1163 774376 51144 00000000 b76c49eb S AccountManagerS system 1187 1163 774376 51144 00000000 b76c49eb S PackageMonitor system 1188 1163 774376 51144 00000000 b76c4ab6 S UEventObserver system 1189 1163 774376 51144 00000000 b76c4d69 S BatteryUpdateTi system 1190 1163 774376 51144 00000000 b76c49eb S PowerManagerSer system 1191 1163 774376 51144 00000000 b76c2ff6 S AlarmManager system 1192 1163 774376 51144 00000000 b76c4d69 S SoundPool system 1193 1163 774376 51144 00000000 b76c4d69 S SoundPoolThread system 1194 1163 774376 51144 00000000 b76c49eb S InputDispatcher system 1195 1163 774376 51144 00000000 b76c49eb S InputReader system 1196 1163 774376 51144 00000000 b76c49eb S BluetoothManage system 1197 1163 774376 51144 00000000 b76c49eb S MountService system 1198 1163 774376 51144 00000000 b76c4483 S VoldConnector system 1199 1163 774376 51144 00000000 b76c49eb S CallbackHandler system 1201 1163 774376 51144 00000000 b76c4483 S NetdConnector system 1202 1163 774376 51144 00000000 b76c49eb S CallbackHandler system 1203 1163 774376 51144 00000000 b76c49eb S NetworkStats system 1204 1163 774376 51144 00000000 b76c49eb S NetworkPolicy system 1205 1163 774376 51144 00000000 b76c49eb S WifiP2pService system 1206 1163 774376 51144 00000000 b76c49eb S WifiStateMachin system 1207 1163 774376 51144 00000000 b76c49eb S WifiService system 1208 1163 774376 51144 00000000 b76c49eb S ConnectivitySer system 1214 1163 774376 51144 00000000 b76c49eb S WifiManager system 1215 1163 774376 51144 00000000 b76c49eb S Tethering system 1216 1163 774376 51144 00000000 b76c49eb S CaptivePortalTr system 1217 1163 774376 51144 00000000 b76c49eb S WifiWatchdogSta system 1218 1163 774376 51144 00000000 b76c49eb S NsdService system 1219 1163 774376 51144 00000000 b76c4483 S mDnsConnector system 1220 1163 774376 51144 00000000 b76c49eb S CallbackHandler system 1227 1163 774376 51144 00000000 b76c49eb S SyncHandlerThre system 1228 1163 774376 51144 00000000 b76c49eb S AudioService system 1229 1163 774376 51144 00000000 b76c49eb S backup system 1233 1163 774376 51144 00000000 b76c49eb S AppWidgetServic system 1240 1163 774376 51144 00000000 b76c4d69 S AsyncTask #1 system 1244 1163 774376 51144 00000000 b76c42a3 S Thread-64 system 1284 1163 774376 51144 00000000 b76c4d69 S AsyncTask #2 system 1316 1163 774376 51144 00000000 b76c2bb6 S UsbService host system 1319 1163 774376 51144 00000000 b76c4d69 S watchdog system 1330 1163 774376 51144 00000000 b76c49eb S LocationManager system 1336 1163 774376 51144 00000000 b76c2ff6 S Binder_3 system 1348 1163 774376 51144 00000000 b76c49eb S CountryDetector system 1354 1163 774376 51144 00000000 b76c49eb S NetworkTimeUpda system 1360 1163 774376 51144 00000000 b76c2ff6 S Binder_4 system 1391 1163 774376 51144 00000000 b76c2ff6 S Binder_5 system 1395 1163 774376 51144 00000000 b76c2ff6 S Binder_6 system 1397 1163 774376 51144 00000000 b76c2ff6 S Binder_7 system 1516 1163 774376 51144 00000000 b76c4d69 S SoundPool system 1517 1163 774376 51144 00000000 b76c4d69 S SoundPoolThread system 1692 1163 774376 51144 00000000 b76c4d69 S AsyncTask #3 system 1694 1163 774376 51144 00000000 b76c4d69 S AsyncTask #4 system 1695 1163 774376 51144 00000000 b76c4d69 S AsyncTask #5 system 1791 1163 774376 51144 00000000 b76c4d69 S pool-1-thread-1 system 2758 1163 774376 51144 00000000 b76c4d69 S AudioTrack system 2829 1163 774376 51144 00000000 b76c49eb S KeyguardWidgetP See the famous WindowManager, ActivityManager? By the way, they are all running in the process of system_server. There are also a number of \"Binder-x\" threads that are created by individual services in response to an application remotely invoking a request. In addition, there are many internal threads, such as \"UI thread\", \"InputReader\", \"InputDispatch\", etc. We will analyze these modules in subsequent articles. In this article, we only care about how System Server is created. 5. 4. System Server startup process There are a lot of code in this process, involving many classes. We use a sequence diagram to describe this process. The different colors in the diagram represent running in different threads. 1. ZygoteInit fork A new process, this process is the SystemServer process. 2. The child process that forks out starts initialization in handleSystemServerProcess . The initialization is divided into two steps, one is done in native, and the other part (mostly) is done in Java. The native side works in AppRuntime (subclass of AndroidRuntime)::onZygoteInit(). One thing to do is to start a Thread, which is the main thread of SystemServer (the leftmost pink square), which is responsible for receiving and sending to other processes. The Binder calls the request. code show as below void ProcessState::spawnPooledThread(bool isMain) { if (mThreadPoolStarted) { String8 name = makeBinderThreadName(); //“Binder_1\" sp t = new PoolThread(isMain); t->run(name.string()); } } virtual bool threadLoop() { IPCThreadState::self()->joinThreadPool(mIsMain); //blocking knows that the Binder driver wakes up return false; } 3. After nativeZygoteInit() is completed, the Java layer is initialized. This process is long and complicated. We divide it into many steps. The initialization entry is SystemServer's main() function, which calls Native's Init1(). Init1 is implemented in com_android_server_SystemServer.cpp, and the final call to the function is system_init(). The implementation of system_init() is as follows: extern \"C\" status_t system_init() { sp proc(ProcessState::self()); sp sm = defaultServiceManager(); sm->asBinder()->linkToDeath(grim, grim.get(), 0); property_get(\"system_init.startsurfaceflinger\", propBuf, \"1\"); if (strcmp(propBuf, \"1\") == 0) { // Start the SurfaceFlinger SurfaceFlinger::instantiate(); //初始化 SurfaceFlinger android_vt = 7; } property_get(\"system_init.startsensorservice\", propBuf, \"1\"); if (strcmp(propBuf, \"1\") == 0) { // Start the sensor service SensorService::instantiate(); // 初始化SensorService. } ALOGI(\"System server: starting Android runtime.\\n\"); AndroidRuntime* runtime = AndroidRuntime::getRuntime(); JNIEnv* env = runtime->getJNIEnv(); ... jclass clazz = env->FindClass(\"com/android/server/SystemServer\"); jmethodID methodId = env->GetStaticMethodID(clazz, \"init2\", \"()V\"); ... env->CallStaticVoidMethod(clazz, methodId); ProcessState::self()->startThreadPool(); IPCThreadState::self()->joinThreadPool(); return NO_ERROR; } Some points to note: A. SurfaceFlinger Service can be run in the System_Server process, or it can be run in a separate process. If it is the latter, you need to add \"setprop system_init.startsurfaceflinger=1\" to init.rc and ensure that service surfaceflinger is not \"disable\". ” B. init2 is implemented in System_Server.java, which we will cover in detail later. 4. system_init() Finally, join_threadpool() suspends the current thread and waits for the request from the binder. The name of this thread is \"Binder_1\". For the internal mechanism of service and binder, please refer to the article http://www.cnblogs.com/samchen2009/p/3316001.html 5. init2: At this point, the native initialization of the system server is completed, and it is back to the Java side. Here, many very important system services will be started. These jobs will start in a new thread with the thread name \"android.server.ServerThread\", see the green bar below. In ServerThread, SystemServer first creates two threads, UI thread and WindowManager thread. See the orange and peach bars in the figure. The handles of these two threads will be passed to some Service constructors, and some startup work will be done. Distribute to these two Threads. Each Thread finally enters the wait loop. Here, Android's Looper mechanism is used. Looper and Handler are the in-process messaging and processing mechanism of Android. We will be in the article http://www.cnblogs.com/samchen2009/p In detail, /3316004.html , here, we only need to know that Looper sleeps in a thread waiting for messages in the message queue, and then processes the message in a specific Handler. In other words, specify something to be processed in a thread. 6. Next, System Server will start a series of services, the most important of which is Acitivity Manager and Window Manager. As you can see from the figure, Activity Manager has a Looper Thread, AThread. Please pay attention to the difference between Binder Thread and Looper, we will have a special article to introduce them later. A lot of the combination of Binder and Looper is used in Android. One of the important reasons is to solve the complex synchronization problem in multi-threading. Through a Looper and corresponding Message queue, you can serialize Binder calls of different processes in the future without Need to maintain complex and problem-prone locks. Similar to WindowManager, his Handler Thread is one of the two Handler threads created in the initial stage of the System server we just mentioned, WMThread. His Binder thread will be specified by Kernel's Binder Driver. In addition to the ActivityManager Service and WindowManager Service, there are many other services that are started one after another. They are not detailed here. You only need to know a few steps required for a Service to start: 1. Initialize the Service object to get the IBinder object. 2. Start the background thread and enter Loop to wait. 3. Register yourself to the Service Manager and let other processes get the IBinder objects that are required to be called remotely by name. 7. There is no doubt that there are dependencies between so many services. For example, the ActivityManager Service cannot start an application until the WindowManager Service is initialized. How do you control these priorities? This is done by the System server's startup thread (the green bar in the image below) through the SystemReady() interface. Each system service must implement a SystemReady() interface that, when called, indicates that the system is OK, and the service can access (directly or indirectly) resources of other services. The last service to be tuned is the ActivyManager Service. AM's SystemReady() is done in another thread via Runnable, and the arrow below the comment 8 in the figure below. The thing to do in this Runnable is to start an application that is currently at the top level - resumeTopActivityLocked(). Generally speaking, this is what we often call 'HOME'. Of course, you can specify other applications as Startup applications, such as GoogleTV, can use the TV application as a launcher, so that users can see the program directly after launching, similar to the set-top box at home. In addition, the ActivityManager Service also broadcasts the BOOT_COMPLETED event to the entire system. In general, the background service of many applications can be monitored and started by registering the Receiver of this Event. The code to start Home is as follows boolean startHomeActivityLocked(int userId) { ... Intent intent = new Intent(...); ... intent.addCategory(Intent.CATEGORY_HOME); ... mMainStack.startActivityLocked(null, intent, null, aInfo,null, null, 0, 0, 0, null, 0, null, false, null); ... } 8. Android application startup is more complicated, we will study the details of ActivityManager in a special chapter. Here, we only need to know that ActivityStack is the stack that currently runs Activity, and resumeTopActivityLocked() finds the one to start from. (In the beginning, the stack was empty because we needed to push 'Home' to the stack via moveTaskFromFrontLocked().) If the application has never been launched, we need to create a process for it via AcitivyManagerService. note! The process is not created by the ActivityManager, don't forget, we mentioned Zygote is the incubator of all Android applications, right, the ActivityManager just informs Zygote to create. This communication is implemented in Process.java, the specific code is as follows: static LocalSocket sZygoteSocket; private static ProcessStartResult zygoteSendArgsAndGetResult(ArrayList args) throws ZygoteStartFailedEx { openZygoteSocketIfNeeded(); try { ... sZygoteWriter.write(arg); } ... sZygoteWriter.flush(); // wait after sending ... result.pid = sZygoteInputStream.readInt(); ... return result; } sZygoteSocket = null ; } } At this point, the startup of System Server has been completed, and the startup of Zygote has been completed. Next we introduce the only thing in the life of the Zygote process and clone itself. 6. 5. Fork Before Process.java sends a fork request, Zygote is ready for the server side, which we have covered in the previous Zygote Init chapter. Here we briefly analyze the processing of the request received by the Zygote Server. The code is in runSelectLoop() of ZygoteInit.java, private static void runSelectLoop() throws MethodAndArgsCaller { ArrayList fds = new ArrayList(); ArrayList peers = new ArrayList(); FileDescriptor [] fdArray = new FileDescriptor [4 ]; fds.add(sServerSocket.getFileDescriptor()); peers.add(null); While ( true ) { /* Doing the GC before the fork child process instead of doing it yourself in each child process can improve efficiency, but it can't be done every time because GC is still time consuming. */ if (loopCount boolean runOnce() throws ZygoteInit.MethodAndArgsCaller { ... try { args = readArgumentList(); descriptors = mSocket.getAncillaryFileDescriptors(); } catch (IOException ex) { ... } FileDescriptor childPipeFd = null; FileDescriptor serverPipeFd = null; /* if (parsedArgs.runtimeInit && parsedArgs.invokeWith != null) { FileDescriptor[] pipeFds = Libcore.os.pipe(); childPipeFd = pipeFds[1]; serverPipeFd = pipeFds[0]; ZygoteInit.setCloseOnExec(serverPipeFd, true); } try { parsedArgs = new Arguments(args); applyUidSecurityPolicy(parsedArgs, peer, peerSecurityContext); ... pid = Zygote.forkAndSpecialize(parsedArgs.uid,parsedArgs.gid, parsedArgs.gids,parsedArgs.debugFlags, rlimits, parsedArgs.mountExternal, parsedArgs.seInfo,parsedArgs.niceName); } catch (IOException ex) { ... } Try { if (pid == 0 ) { // child process, release serverPedFd = null for serverFd ; handleChildProc(parsedArgs, descriptors, childPipeFd, newStderr); } else { //The parent process releases the PipeFd of the unused child process IoUtils.closeQuietly(childPipeFd); childPipeFd = null; return handleParentProc(pid, descriptors, serverPipeFd, parsedArgs); } } finally { IoUtils.closeQuietly(childPipeFd); IoUtils.closeQuietly(serverPipeFd); } } The launch of the Android app is done in handleChildProc: private void handleChildProc(Arguments parsedArgs, FileDescriptor[] descriptors, FileDescriptor pipeFd, PrintStream newStderr) throws ZygoteInit.MethodAndArgsCaller { closeSocket (); / / does not require the server socket ZygoteInit.closeServerSocket (); ... If (parsedArgs.runtimeInit) { //All from Process.java is true if (parsedArgs.invokeWith != null ) { WrapperInit.execApplication(parsedArgs.invokeWith, parsedArgs.niceName, parsedArgs.targetSdkVersion, pipeFd, parsedArgs.remainingArgs); // Start the command line program } else { RuntimeInit.zygoteInit(parsedArgs.targetSdkVersion, parsedArgs.remainingArgs); // Almost all applications start this way } } else { ... if (parsedArgs.invokeWith != null) { WrapperInit.execStandalone(parsedArgs.invokeWith, parsedArgs.classpath, className, mainArgs); } else { ... try { ZygoteInit.invokeStaticMain(cloader, className, mainArgs); } catch (RuntimeException ex) { ... } } } } Here is the RuntimeInit.ZygoteInit(), which is the same as startSystemServer, and finally invokeStaticMain(,\"\"android.app.ActivityThread\",); invokeStatickMain() function is implemented static void invokeStaticMain(ClassLoader loader,String className, String[] argv) throws zygoteInit.MethodAndArgsCaller { ... throw new ZygoteInit.MethodAndArgsCaller(m, argv); } Careful readers may ask a few questions: Why not directly call the corresponding Java function, but through an exception? MethodAndArgsCaller. Here Android cleverly uses some of the design features of Java Exception. One of the great features of Execption is that when an exception occurs or throws, it can be traced back from the call stack from where the error occurred until the code segment that caught the exception is found. The code to catch the exception is as follows public static void main(String argv[]) { ... try { runSelectLoop (); closeServerSocket(); } catch (MethodAndArgsCaller caller) { Caller.run(); //The real entry is here. } catch (RuntimeException ex) { ... } } Now you understand why you always see the following call stack in the dumpstate file. ... at java.lang.reflect.Method.invokeNative(Native Method) at java.lang.reflect.Method.invoke(Method.java:511) at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:793) at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:560) at dalvik.system.NativeStart.main(Native Method) Why do all applications start with \"android.app.ActivityThread\"? Leave a foreshadowing here, we will introduce the entire process of Android Activity from startup to display at http://www.cnblogs.com/samchen2009/p/3315993.html. Once the application is launched, Zygote has to go back to sleep and wait for a new application launch request. 7. 6. After work Isn't it after this, Zygote's work has become very easy, can you raise a good year? Unfortunately, in modern society, which parent can raise the child and leave it alone? Especially for the eldest son who has a heavy social responsibility like the Sytem Server, parents still have to help. Here, Zygote will silently stare at his eldest son in the background. Once he discovers that System Server has been hanged, he will recycle it, then kill himself and start a new life again, which is a pity for the parents. This implementation is in the code: dalvik/vm/native/dalvik_system_zygote.cpp, static void Dalvik_dalvik_system_Zygote_forkSystemServer( const u4* args, JValue* pResult){ ... pid_t pid; pid = forkAndSpecializeCommon(args, true); ... if (pid > 0) { int status; gDvm.systemServerPid = pid; /* WNOHANG will cause waitpid to return immediately, just to prevent the above system from crashing before the assignment statement is completed */ if (waitpid(pid, &status, WNOHANG) == pid) { ALOGE(\"System server process %d has died. Restarting Zygote!\", pid); kill(getpid(), SIGKILL); } } RETURN_INT(pid); } /* Real processing is here */ static void sigchldHandler( int s) { ... pid_t pid; int status; ... while ((pid = waitpid(-1, &status, WNOHANG)) > 0) { ... if (pid == gDvm.systemServerPid) { ... kill(getpid(), SIGKILL); } } ... } static void Dalvik_dalvik_system_Zygote_fork(const u4* args, JValue* pResult) { pid_t pid; ... setSignalHandler(); //signalHandler Register here ... pid = fork(); ... RETURN_INT(pid); } On Unix-like systems, the parent process must wait for the child process to exit with waitpid, otherwise the child process will become a \"Zombie\" process, not only the system resources will leak, but the system will crash (no system server, all Android applications are Can not run). But waitpid() is a blocking function (except for the WNOHANG parameter), so the usual practice is to do non-blocking processing in the signal handler, because the system will issue a SIGCHID signal when each child exits. Zygote will kill himself, the father is dead, all the apps are not orphaned? No, because the system will automatically generate a SIGHUP signal to all child processes after the parent process is killed. The default processing of this signal is to kill itself and exit the current process. However, some background processes (Daemon) can ignore this signal by setting the SIG_IGN parameter, so that it can continue to run in the background. 8. Summary The startup process of Zygote and System Server is finally finished. Let's revisit this process with the complete class diagram above. init runs app_process according to init.rc and carries the '--zygote' and '--startSystemServer' parameters. JavaVM will be started in AndroidRuntime.cpp::start() and all system-related JNI interfaces will be registered. For the first time into the Java world, run the ZygoteInit.java::main() function to initialize Zygote. Zygote and create the server side of the Socket. Then fork a new process and initialize SystemServer in the new process. Before Fork, Zygote is a commonly used Java class library for preload, as well as the system's resources, while GC() cleans up the memory space, eliminating the need for duplicate work for the child process. SystemServer initializes all system services, including ActivityManager and WindowManager, which are prerequisites for the application to run. At the same time, Zygote listens to the server Socket and waits for a new application to start the request. After the ActivityManager is ready, look for the system's \"Startup\" Application and send the request to Zygote. After Zygote receives the request, the fork will issue a new process. Zygote listens for and processes the SIGCHID signal from SystemServer and kills itself as soon as System Server crashes. Init will restart Zygote. "},"Android Permissions - Android Runtime Permission.html":{"url":"Android Permissions - Android Runtime Permission.html","title":"Android Permissions - Android Runtime Permission","keywords":"","body":"1. Android Runtime Permission1.1. Foreword:1.2. Runtime permission forward compatibility1.3. Use of system permissions1.4. Use of permissions:1.5. Permission level:1.6. Automatic adjustment of permissions:1.7. Authorization level classification:1.8. Special permissions:1.9. Dangerous Permission:1.10. Permission group:1.11. Use rights1.12. Check permission status:1.13. request for access:1.14. Prompt the user why you need:1.15. About automatic authorization:1.16. Permission flags:1.17. Allow permissions:1.18. Prohibited permissions:1. Android Runtime Permission Column: android source code analysis Copyright statement: This article is the original article of the blogger, please be sure to indicate the author and the original link. Https://blog.csdn.net/jingerppp/article/details/80194908 Android Runtime Permission Foreword: Runtime permission forward compatibility Use of system permissions Use of permissions: Permission level: Automatic adjustment of permissions: Authorization level classification: Special permissions: Dangerous Permission: Permission group: Use rights Check permission status: request for access: Prompt the user why you need: About automatic authorization: Permission flags: Allow permissions: Prohibited permissions: 1.1. Foreword: There are some drawbacks to permission management before Android 6.0: The permission system will only be asked once during installation, and the user can optionally grant application-related permissions. But once installed, the application will access everything within the privilege without the user's knowledge. Prior to Android 6.0, the permissions were called install time permission. After the application was installed, the user could not modify the authorization of the permission, nor allowed the individual authorization and revocation of the permission. The Android app permissions mode in Android 6.0 and higher is designed to make permissions easier to understand, more useful, and more secure. This mode moves Android apps that require dangerous permissions from install-time permissions mode to runtime permissions mode: Permissions for installation (Android 5.1 and lower, or application target SDK is 22 or lower). Users grant dangerous permissions to apps when they install or update apps. OEM/operators can pre-install pre-authorized applications without notifying users. Runtime permissions (Android 6.0 and higher, or application target SDK 23 or higher). The user grants dangerous permissions to the app while the app is running. The app decides when to apply for permissions (for example, when an app launches or when a user accesses a particular feature), but must allow the user to grant/deny access to the app to access a specific permission group. OEMs/operators can pre-install applications, but may not grant permissions in advance. 1.2. Runtime permission forward compatibility If the application before M is installed on M or higher, the permission will be installed before the old mode management, which is the install time permission model. It should be noted that on the M system, the user can authorize and revoke the permission in the settings. The application software may crash if there is no corresponding permission. If the application after M is installed on a version before M, the permission has no runtime, and the previous install time permission will be installed. 1.3. Use of system permissions 1.4. Use of permissions: The basic Android app does not associate permissions by default, which means it can't perform any actions that adversely affect the user experience or any data on the device. To take advantage of protected device features, you must include one or more \\ tags in your app manifest (AndroidManifest.xml). For example, an app that needs to monitor incoming SMS messages should specify: ... 1.5. Permission level: These permissions are automatically granted if your app lists normal permissions in its manifest (that is, permissions that do not pose a significant risk to user privacy or device operations). If your app lists dangerous permissions in its manifest (that is, permissions that may affect user privacy or the normal operation of the device), the system will ask the user to explicitly grant those permissions. The way Android makes requests depends on the system version, which is the target of the app: If the device is running Android 6.0 (API level 23) or higher and the targetSdkVersion of the app is 23 or higher, the app requests permissions from the user at runtime. Users can call permissions at any time, so the application needs to check if it has the required permissions each time it runs. For more information on requesting permissions in an app, see the Using System Permissions Training Guide. If the device is running Android 5.1 (API level 22) or lower and the targetSdkVersion of the app is 22 or lower, the user is asked to grant permissions when the user installs the app. If you add a new privilege to a newer app version, the user will be asked to grant it when the app is updated. Once users install an app, the only way they can revoke permissions is to uninstall the app. Often, a privilege failure causes a SecurityException to be thrown back into the app. But there is no guarantee that every place will be like this. For example, the sendBroadcast(Intent) method checks for permissions when data is passed to each recipient, and after the method call returns, you won't receive an exception even if the permissions fail. However, in almost all cases, permission failures are logged to the system log. See Manifest.permission for permissions provided by the Android system. In addition, any application can define and enforce its own permissions, so this is not an exhaustive list of all possible permissions. It is possible to implement specific permissions in multiple locations during program execution: Prevents the app from performing certain functions when the system is called. Prevents the app from launching activities from other apps when the activity is started. Control who can receive your broadcast and send a broadcast to you when sending and receiving broadcasts. When accessing and manipulating content providers. Bind to a service or start a service. 1.6. Automatic adjustment of permissions: Over time, new restrictions may be added to the platform, and to use a specific API, your app may have to request permissions that were not previously needed. Because existing apps assume that they have access to these API apps at will, Android may apply new permission requests to the app manifest to avoid breaking the app on the new platform version. Android will determine if the app requires permission based on the value provided by the targetSdkVersion property. If the value is lower than the version in which the permission was added, Android will add the permission. For example, WRITE_EXTERNAL_STORAGE permission was added to API level 4 to restrict access to shared storage. If your targetSdkVersion is 3 or lower, this permission will be added to apps on the updated Android version device. To avoid this and remove the default permissions you don't need, always update targetSdkVersion to the highest version. The permissions added by each version can be viewed in the Build.VERSION_CODES document. 1.7. Authorization level classification: The hierarchical classification mentioned here is actually the attribute in the permission: android:protectionLevel Divided into several categories: Normal, Dangerous, Signature, SigatureOrSystem Normal Permission refers to the permissions of the data and resources other than the app's sandbox (each process has a separate sandbox). These permissions generally do not pose a risk to the user's private information. For example, setting Time zone permissions (SET_TIME_ZONE). For such permissions, the system will automatically assign it after the app is applied. Dangerous Permission refers to behavioral rights that may pose a risk to the user's private information or may affect the user's data. For example, read the user's contacts. For Dangerous Permission, the app must display the permission of the user to use it. The Runtime Permission mechanism is for this kind of dangerous permission. Signature permission: A permission requester can only use the permission if it is signed with the same certificate as [Permission Identifier]. If the certificates match, the system automatically grants these permissions without notification or requesting users. SignatureOrSystem: The SDK version 23 was called \" signature|privileged\" before . In addition to the above Signature Permission, this type of permission includes permissions that are only given to applications within the Android System Image. Android does not recommend the app to use this class, because Signature Permission can meet most of the requirements, regardless of whether the app is built in the System Image. 1.8. Special permissions: The above describes the meaning of the attribute android:protectionLevel in the permission, there are some special permissions, these permissions are more sensitive, must be specially treated when used. SYSTEM_ALERT_WINDOW And WRITE_SETTINGS this is the more sensitive permissions. For example WRITE_SETTINGS: The official explanation is as follows: Note: If the app targets API level 23 or higher, the app user must explicitly grant this permission to the app through a permission management screen. The app requests the user's approval by sending an intent with action ACTION_MANAGE_WRITE_SETTINGS. The app can check whether it has this authorization by calling Settings.System.canWrite(). 1.9. Dangerous Permission: Android 6.0 and later requires dangerous permissions to use runtime permissions mode. Dangerous privilege is a higher-risk privilege (such as READ_CALENDAR) that allows an authoritative app to access user private data or gain control of a device that can adversely affect users. To see a list of dangerous permissions, run the following command: adb shell pm list permissions -g -d Android 6.0 and later does not change the behavior of general permissions (all non-dangerous permissions including general, system, and signed permissions). Regular permissions are lower-risk permissions (such as SET_WALLPAPER), which allow applications that request authorization to access quarantined application-level features with minimal risk to other applications, systems, or users. In Android 5.1 and earlier, when the app is installed, the app is automatically granted general permissions to the app that is requesting authorization, and there is no need to prompt the user for approval. 1.10. Permission group: All dangerous Android system permissions belong to the permission group. If the device is running Android 6.0 (API level 23) and the targetSdkVersion of the app is 23 or higher, the following behavior occurs when the user requests dangerous permissions: If the app requests the dangerous permissions listed in its manifest, and the app does not currently have any permissions in the permissions group, the user will be presented with a dialog box describing the permission groups that the app will access. The dialog does not describe the specific permissions within the group. For example, if an application requests READ_CONTACTS permission, the system dialog only describes the contact information that the application needs to access the device. If the user approves, the app will be granted permission to the app. If an app requests a dangerous privilege listed in its manifest, and the app already has another dangerous privilege in the same privilege group, the privilege is granted immediately without any interaction with the user. For example, if an application has requested and was granted READ_CONTACTS permission, then it WRITE_CONTACTS, the system will grant the permission immediately . Any permission can belong to a permission group, including normal permissions and application-defined permissions. However, the permission group only affects the user experience when the permissions are dangerous. A permission group with normal permissions can be ignored. If the device is running Android 5.1 (API level 22) or lower and the targetSdkVersion of the app is 22 or lower, the user is asked to grant permissions during installation. Again, the system only tells the user what permissions group the application needs, without telling the specific permissions. (Note that in the domestic CTA, these group permissions must be subdivided) Permission Table Permission Group Permissions CALENDAR READ_CALENDAR WRITE_CALENDAR CALL_LOG READ_CALL_LOG WRITE_CALL_LOG PROCESS_OUTGOING_CALLS CAMERA CAMERA CONTACTS READ_CONTACTS WRITE_CONTACTS GET_ACCOUNTS LOCATION ACCESS_FINE_LOCATION ACCESS_COARSE_LOCATION MICROPHONE RECORD_AUDIO PHONE READ_PHONE_STATE READ_PHONE_NUMBERS CALL_PHONE ANSWER_PHONE_CALLS ADD_VOICEMAIL USE_SIP SENSORS BODY_SENSORS SMS SEND_SMS RECEIVE_SMS READ_SMS RECEIVE_WAP_PUSH RECEIVE_MMS STORAGE READ_EXTERNAL_STORAGE WRITE_EXTERNAL_STORAGE 1.11. Use rights 1.12. Check permission status: // Check if a uid and pid have permission // If you return PackageManager#PERMISSION_GRANTED, the permission has been allowed // If you return PackageManager#PERMISSION_DENIED, this permission is not allowed public int checkPermission(String permission, int pid, int uid) // Same as checkPermission, which is provided to the current process call public int checkCallingPermission(String permission) // Same as checkPermission, the difference between this and checkCallingPermission is that there is no need to determine if the caller is the current process. public int checkCallingOrSelfPermission(String permission) // Same as checkPermission, mainly when a return is not PackageManager.PERMISSION_GRANTED will throw a SecurityException public void enforcePermission(String permission, int pid, int uid, String message) //With enforcePermission public void enforceCallingPermission(String permission, String message) //With enforcePermission public void enforceCallingOrSelfPermission(String permission, String message) Detailed source code can see ContextImpl.java It should be noted that there is still a lot to go before switching to PMS: public int checkPermission(String permission, int pid, int uid, IBinder callerToken) { if (permission == null) { //The passed permission cannot be null throw new IllegalArgumentException(\"permission is null\"); } try { return ActivityManager.getService().checkPermissionWithToken(//详细看AMS permission, pid, uid, callerToken); } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } } 1.13. request for access: public final void requestPermissions(@NonNull String[] permissions, int requestCode) { if (requestCode = 0\"); } if (mHasCurrentPermissionsRequest) { Log.w(TAG, \"Can reqeust only one set of permissions at a time\"); // Dispatch the callback with empty arrays which means a cancellation. onRequestPermissionsResult(requestCode, new String[0], new int[0]); return; } Intent intent = getPackageManager().buildRequestPermissionsIntent(permissions); startActivityForResult(REQUEST_PERMISSIONS_WHO_PREFIX, intent, requestCode, null); mHasCurrentPermissionsRequest = true; } Call this function, the system will call up a dialog box to prompt the user whether to give the appropriate permissions. After the user allows or denies the corresponding permission, the app's onRequestPermissionsResult(int, String[], int[]) will be called, telling the app that the corresponding permission is authorized or denied. Detailed code can be seen in Activity.java, here you need to pay attention to: 1, requestCode is used to match, but must be non-negative 2, buildRequestPermissionsIntent Note the function here, here is the invoke place where the dialog box needs to pop up during the request permission. public Intent buildRequestPermissionsIntent(@NonNull String[] permissions) { if (ArrayUtils.isEmpty(permissions)) { throw new IllegalArgumentException(\"permission cannot be null or empty\"); } Intent intent = new Intent(ACTION_REQUEST_PERMISSIONS); //Note the Action here intent.putExtra(EXTRA_REQUEST_PERMISSIONS_NAMES, permissions); //Extra passed the permission name intent.setPackage(getPermissionControllerPackageName());//Note that the system directly specifies the packageName return intent; } Here in build intent, the system will have a place to receive, look at the GrantPermissionsActivity in PackageIntaller ( click here for details, https://blog.csdn.net/shift_wwx/article/details/80263467): 3, onRequestPermissionResult There are 3 ways to trigger, here is one, and the other is through: private void dispatchRequestPermissionsResult(int requestCode, Intent data) { mHasCurrentPermissionsRequest = false; // If the package installer crashed we may have not data - best effort. String[] permissions = (data != null) ? data.getStringArrayExtra( PackageManager.EXTRA_REQUEST_PERMISSIONS_NAMES) : new String[0]; final int[] grantResults = (data != null) ? data.getIntArrayExtra( PackageManager.EXTRA_REQUEST_PERMISSIONS_RESULTS) : new int[0]; onRequestPermissionsResult(requestCode, permissions, grantResults); } private void dispatchRequestPermissionsResultToFragment(int requestCode, Intent data, Fragment fragment) { // If the package installer crashed we may have not data - best effort. String[] permissions = (data != null) ? data.getStringArrayExtra( PackageManager.EXTRA_REQUEST_PERMISSIONS_NAMES) : new String[0]; final int[] grantResults = (data != null) ? data.getIntArrayExtra( PackageManager.EXTRA_REQUEST_PERMISSIONS_RESULTS) : new int[0]; fragment.onRequestPermissionsResult(requestCode, permissions, grantResults); } 1.14. Prompt the user why you need: /** * Gets whether you should show UI with rationale for requesting a permission. * You should do this only if you do not have the permission and the context in * which the permission is requested does not clearly communicate to the user * what would be the benefit from granting this permission. * * For example, if you write a camera app, requesting the camera permission * would be expected by the user and no rationale for why it is requested is * needed. If however, the app needs location for tagging photos then a non-tech * savvy user may wonder how location is related to taking photos. In this case * you may choose to show UI with rationale of requesting this permission. * * * @param permission A permission your app wants to request. * @return Whether you can show permission rationale UI. * * @see #checkSelfPermission(String) * @see #requestPermissions(String[], int) * @see #onRequestPermissionsResult(int, String[], int[]) */ public boolean shouldShowRequestPermissionRationale(@NonNull String permission) { return getPackageManager().shouldShowRequestPermissionRationale(permission); } Returns true If the app previously requested this permission, but the user refused, the permission can still be requested at this time. Returns false if the previous user refused to grant this permission and the \"Don't ask again\" option was selected in the system dialog. Returns false if the device policy prevents the app from having this privilege. This is usually set in the DevicePolicyManager. The first time after the application is installed, it will return false directly. The first time the permission is requested, the user rejects it. The next time shouldShowRequestPermissionRationale() returns true, this time can show some instructions on why this permission is needed; The second time the permission is requested, the user rejects and selects the option \"No longer alert\": shouldShowRequestPermissionRationale() returns false; The system's system settings prohibit the current application from obtaining authorization for this permission, and shouldShowRequestPermissionRationale() returns false; 1.15. About automatic authorization: App with PRIVATE_FLAG_PRIVILEGED & FLAG_PERSISTENT flag will be automatically authorized. The system default base app will be automatically given the corresponding permission. For example, the default phone book app will automatically have the CONTACT related permission. Automatic authorization is implemented by the function grantDefaultPermissions() \\@DefaultPermissionGrantPolicy.Java. This function is called when system ready and when creating a new user. The DefaultPermissionGrantPolicy.java file is a new class added to M in the PMS to implement the related functions of automatic authorization. 1.16. Permission flags: PackageManager.FLAG_PERMISSION_USER_SET: The permissions are set by the user. The application can also request PackageManager.FLAG_PERMISSION_USER_FIXED at runtime . The permissions are set by the user, but the application can no longer request this permission (users check \"never ask again\"). PackageManager.FLAG_PERMISSION_POLICY_FIXED: The permissions set by device policy cannot be modified by both user and app. PackageManager.FLAG_PERMISSION_REVOKE_ON_UPGRADE: If the permission is marked with this flag, it means that the permission of the deny after the app is upgraded will still be deny. This flag will be used in the following cases. Applicable to the previous version of the L app, installed on the M device, if its dangerous permission is revoked, such as through the permission management in the settings or device policy settings, then the APP is upgraded to apply to the new permission of M After the mode, the permission is still revoked after the upgrade. That is, the dangerous permission is revoked after the upgrade, and is still revoked after the upgrade. PackageManager.FLAG_PERMISSION_SYSTEM_FIXED: The automatic authorization permission obtained by the system app. PackageManager.FLAG_PERMISSION_GRANTED_BY_DEFAULT: The default system basic function app gets the auto-authorization permission. PackageManager.FLAG_PERMISSION_REVIEW_REQUIRED: A permission review is required before the app runs 1.17. Allow permissions: public void grantRuntimePermission(String packageName, String name, final int userId) { grantRuntimePermission(packageName, name, userId, false /* Only if not fixed by policy */); } Detailed source code, you can see the specific implementation of the PMS, or another blog 1.18. Prohibited permissions: @Override public void revokeRuntimePermission(String packageName, String name, int userId) { revokeRuntimePermission(packageName, name, userId, false /* Only if not fixed by policy */); } After reading the grantRuntimePermission specification, the code for revokeRuntimePermission is much simpler. The final result is to modify the mGranted property in PermissionStates and write its properties to runtime-permissions.xml. "},"Android Permissions - Android grantRuntimePermission Detailed.html":{"url":"Android Permissions - Android grantRuntimePermission Detailed.html","title":"Android Permissions - Android grantRuntimePermission Detailed","keywords":"","body":"1. Android grantRuntimePermission Detailed1.1. Foreword:1.2. Call method:1. Android grantRuntimePermission Detailed Column: android source code analysis Copyright statement: This article is the original article of the blogger, please be sure to indicate the author and the original link. Https://blog.csdn.net/jingerppp/article/details/80249595 Android grantRuntimePermission Detailed Foreword: Call method: 1.1. Foreword: Runtime Permission appears after Android M (see Android Runtime permission for details ), and the previous ones are called install time permission. After the Activity requestPermissions, the user will be prompted whether to allow the dialog. When the selection is allowed, the grantRuntimePermission will be triggered. This blog post is mainly to analyze the whole process of this function. 1.2. Call method: Called through the interface inside PackageManger @SystemApi @RequiresPermission(android.Manifest.permission.GRANT_RUNTIME_PERMISSIONS) public abstract void grantRuntimePermission(@NonNull String packageName, @NonNull String permissionName, @NonNull UserHandle user); Note that here is the system api, third-party applications can not get this interface, it limits the need to request permission through the request permission. Finally called into the PMS: @Override public void grantRuntimePermission(String packageName, String name, final int userId) { grantRuntimePermission(packageName, name, userId, false /* Only if not fixed by policy */); } private void grantRuntimePermission(String packageName, String name, final int userId, boolean overridePolicy) { if (!sUserManager.exists(userId)) {//Confirm that the user id exists Log.e(TAG, \"No such user:\" + userId); return; } final int callingUid = Binder.getCallingUid();//determine the uid of the calling app mContext.enforceCallingOrSelfPermission(//need to register the GRANT_RUNTIME_PERMISSIONS permission on the app side, otherwise it will throw an exception android.Manifest.permission.GRANT_RUNTIME_PERMISSIONS, \"grantRuntimePermission\"); enforceCrossUserPermission(callingUid, userId,//​​requires INTERACT_ACROSS_USERS_FULL permission, also throws exception true /* requireFullPermission */, true /* checkShell */, \"grantRuntimePermission\"); final int uid; final PackageSetting ps; synchronized (mPackages) { final PackageParser.Package pkg = mPackages.get(packageName);//packageName correctness if (pkg == null) { throw new IllegalArgumentException(\"Unknown package: \" + packageName); } final BasePermission bp = mSettings.mPermissions.get(name);//permission name correctness if (bp == null) { throw new IllegalArgumentException(\"Unknown permission: \" + name); } ps = (PackageSetting) pkg.mExtras; if (ps == null || filterAppAccessLPr(ps, callingUid, userId)) { throw new IllegalArgumentException(\"Unknown package: \" + packageName); } enforceDeclaredAsUsedAndRuntimeOrDevelopmentPermission(pkg, bp);//app registers the permission to AndroidManifest //and the permission is Runtime or development permission // If a permission review is required for legacy apps we represent // their permissions as always granted runtime ones since we need // to keep the review required permission flag per user while an // install permission's state is shared across all users. if (mPermissionReviewRequired //does not handle legacy apps && pkg.applicationInfo.targetSdkVersion Mainly pay attention to 3 places: permissionsState.grantRuntimePermission(bp, userId):public int grantRuntimePermission(BasePermission permission, int userId) { enforceValidUserId(userId); if (userId == UserHandle.USER_ALL) {//This operation cannot be for all users, only for the current user. return PERMISSION_OPERATION_FAILURE; } return grantPermission(permission, userId); } private int grantPermission(BasePermission permission, int userId) { if (hasPermission(permission.name, userId)) {//confirm whether it has been granted return PERMISSION_OPERATION_FAILURE; } final boolean hasGids = !ArrayUtils.isEmpty(permission.computeGids(userId)); final int[] oldGids = hasGids ? computeGids(userId) : NO_GIDS; PermissionData permissionData = ensurePermissionData(permission); if (!permissionData.grant(userId)) {//This is the end point, modify the mGranted property of PermissionState in PermissionData return PERMISSION_OPERATION_FAILURE; } if (hasGids) { final int[] newGids = computeGids(userId); if (oldGids.length != newGids.length) { return PERMISSION_OPERATION_SUCCESS_GIDS_CHANGED; } } return PERMISSION_OPERATION_SUCCESS; } mOnPermissionChangeListeners.onPermissionsChanged(uid):private void handleOnPermissionsChanged(int uid) { final int count = mPermissionListeners.beginBroadcast(); try { for (int i = 0; i Register the callback of I OnPermissionsChangeListener with the client, indicating that the grant succeeded. mSettings.writeRuntimePermissionsForUserLPr(userId, false):public void writeRuntimePermissionsForUserLPr(int userId, boolean sync) { if (sync) { mRuntimePermissionsPersistence.writePermissionsForUserSyncLPr(userId); } else { mRuntimePermissionsPersistence.writePermissionsForUserAsyncLPr(userId); } } public void writePermissionsForUserAsyncLPr(int userId) { final long currentTimeMillis = SystemClock.uptimeMillis(); if (mWriteScheduled.get(userId)) { mHandler.removeMessages(userId); // If enough time passed, write without holding off anymore. final long lastNotWrittenMutationTimeMillis = mLastNotWrittenMutationTimesMillis .get(userId); final long timeSinceLastNotWrittenMutationMillis = currentTimeMillis - lastNotWrittenMutationTimeMillis; if (timeSinceLastNotWrittenMutationMillis >= MAX_WRITE_PERMISSIONS_DELAY_MILLIS) { mHandler.obtainMessage(userId).sendToTarget(); return; } // Hold off a bit more as settings are frequently changing. final long maxDelayMillis = Math.max(lastNotWrittenMutationTimeMillis + MAX_WRITE_PERMISSIONS_DELAY_MILLIS - currentTimeMillis, 0); final long writeDelayMillis = Math.min(WRITE_PERMISSIONS_DELAY_MILLIS, maxDelayMillis); Message message = mHandler.obtainMessage(userId); mHandler.sendMessageDelayed(message, writeDelayMillis); } else { mLastNotWrittenMutationTimesMillis.put(userId, currentTimeMillis); Message message = mHandler.obtainMessage(userId); mHandler.sendMessageDelayed(message, WRITE_PERMISSIONS_DELAY_MILLIS); mWriteScheduled.put(userId, true); } } This function is mainly asynchronous processing. Firstly, it confirms whether mWriteScheduled is processing userId. If it is not added, it will send a message after 200ms to start processing. If it is already processed, calculate the most suitable delay processing, it can be seen that the system gives the most operation. The length is 2 seconds. Finally, it will be handled in the handleMessage in the mHandler: @Override public void handleMessage(Message message) { final int userId = message.what; Runnable callback = (Runnable) message.obj; writePermissionsSync(userId); if (callback != null) { callback.run(); } } Whichever is synchronous asynchronously, the final call is still writePermissionSync: private void writePermissionsSync(int userId) { AtomicFile destination = new AtomicFile(getUserRuntimePermissionsFile(userId)); ArrayMap> permissionsForPackage = new ArrayMap<>(); ArrayMap> permissionsForSharedUser = new ArrayMap<>(); synchronized (mLock) { mWriteScheduled.delete(userId); final int packageCount = mPackages.size(); for (int i = 0; i permissionsStates = permissionsState .getRuntimePermissionStates(userId); if (!permissionsStates.isEmpty()) { permissionsForPackage.put(packageName, permissionsStates); } } } final int sharedUserCount = mSharedUsers.size(); for (int i = 0; i permissionsStates = permissionsState .getRuntimePermissionStates(userId); if (!permissionsStates.isEmpty()) { permissionsForSharedUser.put(sharedUserName, permissionsStates); } } } FileOutputStream out = null; try { out = destination.startWrite(); XmlSerializer serializer = Xml.newSerializer(); serializer.setOutput(out, StandardCharsets.UTF_8.name()); serializer.setFeature( \"http://xmlpull.org/v1/doc/features.html#indent-output\", true); serializer.startDocument(null, true); serializer.startTag(null, TAG_RUNTIME_PERMISSIONS); String fingerprint = mFingerprints.get(userId); if (fingerprint != null) { serializer.attribute(null, ATTR_FINGERPRINT, fingerprint); } final int packageCount = permissionsForPackage.size(); for (int i = 0; i permissionStates = permissionsForPackage.valueAt(i); serializer.startTag(null, TAG_PACKAGE); serializer.attribute(null, ATTR_NAME, packageName); writePermissions(serializer, permissionStates); serializer.endTag(null, TAG_PACKAGE); } final int sharedUserCount = permissionsForSharedUser.size(); for (int i = 0; i permissionStates = permissionsForSharedUser.valueAt(i); serializer.startTag(null, TAG_SHARED_USER); serializer.attribute(null, ATTR_NAME, packageName); writePermissions(serializer, permissionStates); serializer.endTag(null, TAG_SHARED_USER); } serializer.endTag(null, TAG_RUNTIME_PERMISSIONS); // Now any restored permission grants that are waiting for the apps // in question to be installed. These are stored as per-package // TAG_RESTORED_RUNTIME_PERMISSIONS blocks, each containing some // number of individual permission grant entities. if (mRestoredUserGrants.get(userId) != null) { ArrayMap> restoredGrants = mRestoredUserGrants.get(userId); if (restoredGrants != null) { final int pkgCount = restoredGrants.size(); for (int i = 0; i pkgGrants = restoredGrants.valueAt(i); if (pkgGrants != null && pkgGrants.size() > 0) { final String pkgName = restoredGrants.keyAt(i); serializer.startTag(null, TAG_RESTORED_RUNTIME_PERMISSIONS); serializer.attribute(null, ATTR_PACKAGE_NAME, pkgName); final int N = pkgGrants.size(); for (int z = 0; z Inside is the corresponding runtime permission stored in runtime-permissions.xml, mainly to store the mGranted attribute and mFlags attribute in the previously saved PermissionStates here: private void writePermissions(XmlSerializer serializer, List permissionStates) throws IOException { for (PermissionState permissionState : permissionStates) { serializer.startTag(null, TAG_ITEM); serializer.attribute(null, ATTR_NAME,permissionState.getName()); serializer.attribute(null, ATTR_GRANTED, String.valueOf(permissionState.isGranted())); serializer.attribute(null, ATTR_FLAGS, Integer.toHexString(permissionState.getFlags())); serializer.endTag(null, TAG_ITEM); } } The final xml is as follows (see /data/system/users/0/runtime-permissions.xml for details): "},"Android Permissions - Android GrantPermissionsActivity Detailed.html":{"url":"Android Permissions - Android GrantPermissionsActivity Detailed.html","title":"Android Permissions - Android GrantPermissionsActivity Detailed","keywords":"","body":"1. Android GrantPermissionsActivity Detailed1.1. The meaning of existence:1.2. Analysis source code:1.2.1. 1. RequestedPermissions1.2.2. 2. GrantPermissionsViewHandlerImpl1.2.3. 3. setContentView(mViewHandler.createView());1.2.4. 4. mAppPermissions1.2.5. 5. showNextPermissionGroupGrantRequest1.2.6. 6. onClick1.2.7. 7. onPermissionGrantResult1.3. to sum up:1. Android GrantPermissionsActivity Detailed Column: android source code analysis Copyright statement: This article is the original article of the blogger, please be sure to indicate the author and the original link. Https://blog.csdn.net/jingerppp/article/details/80263467 Android GrantPermissionsActivity Detailed The meaning of existence: Analysis source code: 1. RequestedPermissions 2. GrantPermissionsViewHandlerImpl 3. setContentView(mViewHandler.createView()); 4. mAppPermissions 5. showNextPermissionGroupGrantRequest 6. onClick 7. onPermissionGrantResult to sum up: 1.1. The meaning of existence: After Android 6.0 (SDK > 22) strict control of Runtime Permission, open Runtime permission in third-party applications The system needs to remind the user. Under normal circumstances, the default permission of Runtime permission is denied. The application needs to obtain the application and it is necessary to apply. When the request is made, a prompt box for interacting with the user will pop up, and these are the meanings of GrantPermissionActivity. . Let's take a look at the information registered with GrantPermissionsActivity: First look at the place where this Activity is registered, triggered when the action is android.content.pm.action.REQUEST_PERMISSIONS. Let's look at requestPermissions in Activity.java: public final void requestPermissions(@NonNull String[] permissions, int requestCode) { if (requestCode = 0\"); } if (mHasCurrentPermissionsRequest) { Log.w(TAG, \"Can reqeust only one set of permissions at a time\"); // Dispatch the callback with empty arrays which means a cancellation. onRequestPermissionsResult(requestCode, new String[0], new int[0]); return; } Intent intent = getPackageManager().buildRequestPermissionsIntent(permissions); startActivityForResult(REQUEST_PERMISSIONS_WHO_PREFIX, intent, requestCode, null); mHasCurrentPermissionsRequest = true; } Where buildRequestPermissionsIntent is used to create the required intent: public Intent buildRequestPermissionsIntent(@NonNull String[] permissions) { if (ArrayUtils.isEmpty(permissions)) { throw new IllegalArgumentException(\"permission cannot be null or empty\"); } Intent intent = new Intent(ACTION_REQUEST_PERMISSIONS); intent.putExtra(EXTRA_REQUEST_PERMISSIONS_NAMES, permissions); intent.setPackage(getPermissionControllerPackageName()); return intent; } The first action is the action required by the GrantPermissionsActivity. This intent will also bring in the permission of the request. The most important thing is to specify the package pointed to by the intent as the PackageInstaller. At this point, we know that the GrantPermissionsActivity exists to handle requestPermissions. 1.2. Analysis source code: Detailed source code can be seen: packages/apps/PackageInstaller/src/com/android/packageinstaller/permission/ui/GrantPermissionsActivity.java Mainly biased towards the control of the UI logic, here are a few important parts: 1.2.1. 1. RequestedPermissions This is passed through the extra of the intent, the name of the extra is PackageManager.EXTRA_REQUEST_PERMISSIONS_NAMES mRequestedPermissions = getIntent().getStringArrayExtra( PackageManager.EXTRA_REQUEST_PERMISSIONS_NAMES); 1.2.2. 2. GrantPermissionsViewHandlerImpl This is an important class for updating the activity UI. mViewHandler = new com.android.packageinstaller.permission.ui.handheld .GrantPermissionsViewHandlerImpl(this, getCallingPackage()) .setResultListener(this); 1.2.3. 3. setContentView(mViewHandler.createView()); Acitivity displays the View from createView in GrantPermissionsViewHandlerImpl. 1.2.4. 4. mAppPermissions mAppPermissions = new AppPermissions(this, callingPackageInfo, null, false, new Runnable() { @Override public void run() { setResultAndFinish(); } }); This AppPermissions is actually the statistics of all the group permissions owned by a single application. private final ArrayList mGroups = new ArrayList<>(); 1.2.5. 5. showNextPermissionGroupGrantRequest Read the group related information of the request and update the UI with mViewHandler.updateUi. mViewHandler.updateUi(groupState.mGroup.getName(), groupCount, currentIndex, Icon.createWithResource(resources, icon), message, groupState.mGroup.isUserSet()); 1.2.6. 6. onClick public void onClick(View view) { switch (view.getId()) { case R.id.permission_allow_button: if (mResultListener != null) { view.performAccessibilityAction( AccessibilityNodeInfo.ACTION_CLEAR_ACCESSIBILITY_FOCUS, null); mResultListener.onPermissionGrantResult(mGroupName, true, false); } break; case R.id.permission_deny_button: mAllowButton.setEnabled(true); if (mResultListener != null) { view.performAccessibilityAction( AccessibilityNodeInfo.ACTION_CLEAR_ACCESSIBILITY_FOCUS, null); mResultListener.onPermissionGrantResult(mGroupName, false, AppPermissionGroup.isStrictOpEnable() ? false : mShowDonNotAsk && mDoNotAskCheckbox.isChecked()); } break; case R.id.permission_more_info_button: Intent intent = new Intent(Intent.ACTION_MANAGE_APP_PERMISSIONS); intent.putExtra(Intent.EXTRA_PACKAGE_NAME, mAppPackageName); intent.putExtra(ManagePermissionsActivity.EXTRA_ALL_PERMISSIONS, true); mActivity.startActivity(intent); break; case R.id.do_not_ask_checkbox: mAllowButton.setEnabled(!mDoNotAskCheckbox.isChecked()); break; } } The click event of the prompt is handled here in GrantPermissionsViewHandlerImpl and finally returned to the GrantPermissionsActivity via callback. 1.2.7. 7. onPermissionGrantResult public void onPermissionGrantResult(String name, boolean granted, boolean doNotAskAgain) { GroupState groupState = mRequestGrantPermissionGroups.get(name); if (groupState.mGroup != null) { if (granted) { groupState.mGroup.grantRuntimePermissions(doNotAskAgain, groupState.affectedPermissions); groupState.mState = GroupState.STATE_ALLOWED; } else { if (!AppPermissionGroup.isStrictOpEnable()) { groupState.mGroup.revokeRuntimePermissions(doNotAskAgain, groupState.affectedPermissions); } groupState.mState = GroupState.STATE_DENIED; int numRequestedPermissions = mRequestedPermissions.length; for (int i = 0; i The callback here comes back from GrantPermissionsViewHandlerImpl and determines whether to execute grant or revoke. 1.3. to sum up: In fact, the core idea is to interact with the user when requesting, and a prompt box pops up. The CTA is also required. One question is that if a third-party application directly calls the check permission and grants permission without going through the request, there may be no interaction. Detailed can look at the android grantRuntimePermission, https://blog.csdn.net/shift_wwx/article/details/80249595 . "},"Android Permissions - AppOps control for Normal permission.html":{"url":"Android Permissions - AppOps control for Normal permission.html","title":"Android Permissions - AppOps control for Normal permission","keywords":"","body":"1. AppOps control for Normal permission1.1. Foreword:1.2. for example:1.3. BT enable：1.4. AppOpsManager.noteOp:1.5. Management of NFC enable:1. AppOps control for Normal permission Personal classification: android ------ security and permissions Column: android source code analysis Copyright statement: This article is the original article of the blogger, please be sure to indicate the author and the original link. Https://blog.csdn.net/jingerppp/article/details/80360676 AppOps control for Normal permission Foreword: for example: BT enable： AppOpsManager.noteOp: Management of NFC enable: 1.1. Foreword: The previous blog posts ( Android Runtime Permission , android grantRuntimePermission , Android GrantPermissionsActivity Detailed explanation ) mainly analyzes the control flow of Runtime permission. For Runtime permission, the user will be prompted when the application requires the corresponding permissions. The CTA requires that BT, WLAN, NFC, etc. also need to give corresponding prompts, so these permissions also need separate control. This article analyzes the Normal permission or intall time permission to control the process separately after android M. 1.2. for example: Here we use Bluetooth to illustrate, Bluetooth's permission is as follows: If you need to enable/disable Bluetooth control, you must apply for this permission, but this permission level is normal, not runtime permission, and cannot be managed by grantRuntimePermission or invokeRuntimePermission in PMS. For this normal permission, we can manage it with AppOps. 1.3. BT enable： Let's first look at how BT enable/disable is implemented. framework/base/core/java/android/bluetooth/BluetoothAdapter.java： public boolean enableBLE() { if (!isBleScanAlwaysAvailable()) return false; try { String packageName = ActivityThread.currentPackageName(); mManagerService.updateBleAppCount(mToken, true, packageName); if (isLeEnabled()) { if (DBG) Log.d(TAG, \"enableBLE(): Bluetooth already enabled\"); return true; } if (DBG) Log.d(TAG, \"enableBLE(): Calling enable\"); return mManagerService.enable(packageName); } catch (RemoteException e) { Log.e(TAG, \"\", e); } return false; } Here is the switch entry that provides the user enable, which will eventually be called to IBluetoothManager.enable: class BluetoothManagerService extends IBluetoothManager.Stub {} public boolean enable(String packageName) throws RemoteException { final int callingUid = Binder.getCallingUid(); final boolean callerSystem = UserHandle.getAppId(callingUid) == Process.SYSTEM_UID; if (isBluetoothDisallowed()) { if (DBG) { Slog.d(TAG,\"enable(): not enabling - bluetooth disallowed\"); } return false; } if (!callerSystem) { if (!checkIfCallerIsForegroundUser()) { Slog.w(TAG, \"enable(): not allowed for non-active and non system user\"); return false; } mContext.enforceCallingOrSelfPermission(BLUETOOTH_ADMIN_PERM, \"Need BLUETOOTH ADMIN permission\"); if (!isEnabled() && mPermissionReviewRequired && startConsentUiIfNeeded(packageName, callingUid, BluetoothAdapter.ACTION_REQUEST_ENABLE)) { return false; } } ... ... } We control through AppOps, just need to add a dialog confirmation before the enable implementation. AppOpsManager mAppOpsManager = mContext.getSystemService(AppOpsManager.class); String packages = mContext.getPackageManager().getNameForUid(Binder.getCallingUid()); if ((Binder.getCallingUid() >= Process.FIRST_APPLICATION_UID) && (packages.indexOf(\"android.uid.systemui\") != 0) && (packages.indexOf(\"android.uid.system\") != 0)) { int result = mAppOpsManager.noteOp(AppOpsManager.OP_BLUETOOTH_ADMIN, Binder.getCallingUid(), packages); if (result == AppOpsManager.MODE_IGNORED) { return false; } } AppOps's noteOp interface confirms whether the current permission is allowed or disabled. The return values ​​are AppOpsManager.MODE_ALLOWED and AppOpsManager.MODE_IGNORED. 1.4. AppOpsManager.noteOp: public int noteOp(int op, int uid, String packageName) { try { int mode = mService.noteOperation(op, uid, packageName); if (mode == MODE_ERRORED) { throw new SecurityException(buildSecurityExceptionMsg(op, uid, packageName)); } return mode; } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } } Of course there is also an interface: public int noteOpNoThrow(int op, int uid, String packageName) { try { return mService.noteOperation(op, uid, packageName); } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } } Obviously, a distinction is made as to whether the return value MODE_ERRORED is an exception reminder. But the final call to the noteOperation interface in AppOpsService is: public int noteOpNoThrow(int op, int uid, String packageName) { try { return mService.noteOperation(op, uid, packageName); } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } } The source code for noteOperationUnchecked is not given here. We can see that it will eventually be called here to confirm whether this permission will be allowed or disabled in the app. According to the requirements of the CTA, we can give the user dialog prompt here and let the user choose whether to open it. The source code of the specific dialog relates to the company's confidentiality agreement, which is not given, but welcome to communicate. 1.5. Management of NFC enable: According to BT's experience, NFC can be controlled in the same way: private boolean isNfcAllowed() { AppOpsManager mAppOpsManager = mContext.getSystemService(AppOpsManager.class); String packages = mContext.getPackageManager().getNameForUid(Binder.getCallingUid()); if ((Binder.getCallingUid() >= Process.FIRST_APPLICATION_UID) && (packages.indexOf(\"android.uid.systemui\") != 0) && (packages.indexOf(\"android.uid.system\") != 0)) { int result = mAppOpsManager.noteOp(AppOpsManager.OP_NFC, Binder.getCallingUid(), packages); if (result == AppOpsManager.MODE_IGNORED) { return false; } } return true; } The main thing is that the logic control of OP_BLUETOOTH_ADMIN and OP_NFC needs to be controlled in AppOpsManager. "},"Android Permissions - Android native permission control process.html":{"url":"Android Permissions - Android native permission control process.html","title":"Android Permissions - Android native permission control process","keywords":"","body":"1. Android native permission control process1.1. Related articles:1.2. Foreword:1. Android native permission control process May 31, 2018 09:52:57 private kitchen reading number: 271 Copyright statement: This article is the original article of the blogger, please be sure to indicate the author and the original link. Https://blog.csdn.net/jingerppp/article/details/80519212 Android native permission control process Related articles: Foreword: 1.1. Related articles: Android Runtime Permission, https://blog.csdn.net/jingerppp/article/details/80194908 Android grantRuntimePermission Detailed, https://blog.csdn.net/jingerppp/article/details/80249595 Android GrantPermissionsActivity Detailed, https://blog.csdn.net/jingerppp/article/details/80263467 AppOps control for Normal permission, https://blog.csdn.net/jingerppp/article/details/80360676 1.2. Foreword: In the Android Runtime Permission detailed explanation , the difference between permission and Android 6.0 is explained in detail. For M, the application can be controlled by a series of interfaces such as checkPermission and requestPermission, but the application before M can not see such an interface. Open will directly call the interface, such as Camera, which will directly call the open interface. So how do we control these permissions? In the system after M, the native interface will check whether the permission corresponding to the function is changed by the interface of checkPermission. For example, Camera will check the android.permission.CAMERA permission. This blog post is the control flow of the system to the permission native interface after analyzing M. Source code analysis: First look at IServiceManager.h: namespace android { // ---------------------------------------------------------------------- class IServiceManager : public IInterface { ... ... }; sp defaultServiceManager(); template status_t getService(const String16& name, sp* outService) { const sp sm = defaultServiceManager(); if (sm != NULL) { *outService = interface_cast(sm->getService(name)); if ((*outService) != NULL) return NO_ERROR; } return NAME_NOT_FOUND; } bool checkCallingPermission(const String16& permission); bool checkCallingPermission(const String16& permission, int32_t* outPid, int32_t* outUid); bool checkPermission(const String16& permission, pid_t pid, uid_t uid); }; // namespace android 1, the first namespace is android, so some places call the interface here through the interface android::checkPermission For example, in PermissionCache.cpp: bool PermissionCache::checkPermission( const String16& permission, pid_t pid, uid_t uid) { if ((uid == 0) || (pid == getpid())) { // root and ourselves is always okay return true; } PermissionCache& pc(PermissionCache::getInstance()); bool granted = false; if (pc.check(&granted, permission, uid) != NO_ERROR) { nsecs_t t = -systemTime(); granted = android::checkPermission(permission, pid, uid); t += systemTime(); ALOGD(\"checking %s for uid=%d => %s (%d us)\", String8(permission).string(), uid, granted?\"granted\":\"denied\", (int)ns2us(t)); pc.cache(permission, uid, granted); } return granted; 2, the first reason to look at IServiceManager.h is because it provides a lot of public interfaces in android space, such as defaultServiceManager (), getService (), checkPermission () The final checkPermission() implementation is in IServiceManger.cpp: bool checkPermission(const String16& permission, pid_t pid, uid_t uid) { sp pc; gDefaultServiceManagerLock.lock(); pc = gPermissionController; gDefaultServiceManagerLock.unlock(); int64_t startTime = 0; while (true) { if (pc != NULL) { bool res = pc->checkPermission(permission, pid, uid); ... } ... } ... } Call checkPermission() via IPermissionController Look at IPermissionController.h: class IPermissionController : public IInterface { public: DECLARE_META_INTERFACE(PermissionController) virtual bool checkPermission(const String16& permission, int32_t pid, int32_t uid) = 0; virtual void getPackagesForUid(const uid_t uid, Vector &packages) = 0; virtual bool isRuntimePermission(const String16& permission) = 0; enum { CHECK_PERMISSION_TRANSACTION = IBinder::FIRST_CALL_TRANSACTION, GET_PACKAGES_FOR_UID_TRANSACTION = IBinder::FIRST_CALL_TRANSACTION + 1, IS_RUNTIME_PERMISSION_TRANSACTION = IBinder::FIRST_CALL_TRANSACTION + 2 }; }; class BnPermissionController : public BnInterface { public: virtual status_t onTransact( uint32_t code, const Parcel& data, Parcel* reply, uint32_t flags = 0); }; The place to implement depends on the place of BnPermissionController. From the perspective of the whole project, native will start a native service with permission. See framework/native/services/nativeperms/nativeperms.cpp for details: class PermissionService : public android::os::BnPermissionController { public: ::android::binder::Status checkPermission( const ::android::String16& permission, int32_t pid, int32_t uid, bool* _aidl_return) { (void)permission; (void)pid; (void)uid; *_aidl_return = true; return binder::Status::ok(); } Look at the android.os.IPermissionController in Java, first look at aidl, package android.os; /** @hide */ interface IPermissionController { boolean checkPermission(String permission, int pid, int uid); String[] getPackagesForUid(int uid); boolean isRuntimePermission(String permission); } Follow this aidl to know its service side, in ActivityManagerService.java, public void setSystemProcess() { try { ServiceManager.addService(Context.ACTIVITY_SERVICE, this, true); ServiceManager.addService(ProcessStats.SERVICE_NAME, mProcessStats); ServiceManager.addService(\"meminfo\", new MemBinder(this)); ServiceManager.addService(\"gfxinfo\", new GraphicsBinder(this)); ServiceManager.addService(\"dbinfo\", new DbBinder(this)); if (MONITOR_CPU_USAGE) { ServiceManager.addService(\"cpuinfo\", new CpuBinder(this)); } ServiceManager.addService(\"permission\", new PermissionController(this));//这里添加permission 的service ServiceManager.addService(\"processinfo\", new ProcessInfoService(this)); Then there is the service side: static class PermissionController extends IPermissionController.Stub { ActivityManagerService mActivityManagerService; PermissionController(ActivityManagerService activityManagerService) { mActivityManagerService = activityManagerService; } @Override public boolean checkPermission(String permission, int pid, int uid) { return mActivityManagerService.checkPermission(permission, pid, uid) == PackageManager.PERMISSION_GRANTED; } then: @Override public int checkPermission(String permission, int pid, int uid) { if (permission == null) { return PackageManager.PERMISSION_DENIED; } return checkComponentPermission(permission, pid, uid, -1, true); } then: int checkComponentPermission(String permission, int pid, int uid, int owningUid, boolean exported) { if (pid == MY_PID) { return PackageManager.PERMISSION_GRANTED; } return ActivityManager.checkComponentPermission(permission, uid, owningUid, exported); } then: public static int checkComponentPermission(String permission, int uid, int owningUid, boolean exported) { ... ... try { return AppGlobals.getPackageManager() .checkUidPermission(permission, uid); } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } } Eventually, the checkUidPermission in the PMS will be transferred to complete the final confirmation. The source code here is basically a logical problem, and you don't need to explain it in detail. If you have any questions, you can communicate at any time. The source code of checkUidPermission is not posted here, you can see the android grantRuntimePermission in detail. In fact, the most important is the mPermissions in PermissionsState. If the grant is granted, then there will be such a permission. If it is revoke, then there will be no such permission. Of course, for apps before M, the default is definitely granted. This blog post mainly analyzes the native check process. As for the CTA, the app also needs to pop up a dialog box to prompt the user to see another blog post. application permissions after android M M before application permissions and control . "},"Android Permissions - The difference between setUidMode and setMode in AppOps.html":{"url":"Android Permissions - The difference between setUidMode and setMode in AppOps.html","title":"Android Permissions - The difference between setUidMode and setMode in AppOps","keywords":"","body":"1. The difference between setUidMode and setMode in AppOps1.1. related resources:1.2. Foreword:1.3. Source code analysis:1.4. setUidMode()：1.5. setMode()：1.6. checkOperation()：1. The difference between setUidMode and setMode in AppOps Personal classification: android ------ security and permissions Copyright statement: This article is the original article of the blogger, please be sure to indicate the author and the original link. Https://blog.csdn.net/jingerppp/article/details/80674651 The difference between setUidMode and setMode in AppOps related resources: Foreword: Source code analysis: setUidMode()： setMode()： checkOperation()： 1.1. related resources: Android Runtime Permission, https://blog.csdn.net/jingerppp/article/details/80194908 Android grantRuntimePermission Detailed, https://blog.csdn.net/jingerppp/article/details/80249595 Android GrantPermissionsActivity Detailed, https://blog.csdn.net/jingerppp/article/details/80263467 AppOps control for Normal permission, https://blog.csdn.net/jingerppp/article/details/80360676 Android native permission control process, https://blog.csdn.net/jingerppp/article/details/80519212 The difference between setUidMode and setMode in AppOps, https://blog.csdn.net/jingerppp/article/details/80674651 Application permissions before android M and application permissions after M, https://blog.csdn.net/jingerppp/article/details/80674768 1.2. Foreword: Recently, I have encountered setUidMode and setMode functions in AppOps during the processing of privilege processing and M before android M. The android source application uses setUidMode, but if it is used to distinguish permissions management, I think This is not very suitable, here is a summary, look forward to the great God's advice! 1.3. Source code analysis: 1.4. setUidMode()： @Override public void setUidMode(int code, int uid, int mode) { if (Binder.getCallingPid() != Process.myPid()) { mContext.enforcePermission(android.Manifest.permission.UPDATE_APP_OPS_STATS, Binder.getCallingPid(), Binder.getCallingUid(), null); } verifyIncomingOp(code); code = AppOpsManager.opToSwitch(code); //找到switch 之后的op code synchronized (this) { final int defaultMode = AppOpsManager.opToDefaultMode(code);//找到default mode UidState uidState = getUidStateLocked(uid, false); //找到UidState if (uidState == null) { if (mode == defaultMode) { return; } uidState = new UidState(uid); uidState.opModes = new SparseIntArray(); uidState.opModes.put(code, mode); mUidStates.put(uid, uidState); scheduleWriteLocked(); } else if (uidState.opModes == null) { if (mode != defaultMode) { uidState.opModes = new SparseIntArray(); uidState.opModes.put(code, mode); scheduleWriteLocked(); } } else { if (uidState.opModes.get(code) == mode) { return; } if (mode == defaultMode) { //如果恢复到default mode，那么UidState中的opModes delete掉 uidState.opModes.delete(code); if (uidState.opModes.size() Here is mainly UidState: private static final class UidState { public final int uid; public ArrayMap pkgOps; public SparseIntArray opModes; public UidState(int uid) { this.uid = uid; } public void clear() { pkgOps = null; opModes = null; } public boolean isDefault() { return (pkgOps == null || pkgOps.isEmpty()) && (opModes == null || opModes.size() 1, store uid 2, for the same uid different pkg corresponding Ops stored in pkgOps There are two sources for this pkgOps: Read the file appops.xml when booting (the path is passed in when appOps is initialized in AMS) When the new app accesses mode(noteOperation) The mode corresponding to op is stored in OpModes, where the non-default mode is stored. 1.5. setMode()： public void setMode(int code, int uid, String packageName, int mode) { if (Binder.getCallingPid() != Process.myPid()) { mContext.enforcePermission(android.Manifest.permission.UPDATE_APP_OPS_STATS, Binder.getCallingPid(), Binder.getCallingUid(), null); } verifyIncomingOp(code); ArrayList repCbs = null; code = AppOpsManager.opToSwitch(code); //找到switch 之后的code synchronized (this) { UidState uidState = getUidStateLocked(uid, false); //这里好像是多余的 Op op = getOpLocked(code, uid, packageName, true); //找到Op if (op != null) { if (op.mode != mode) { //mode 发生变化 op.mode = mode; ArraySet cbs = mOpModeWatchers.get(code); if (cbs != null) { if (repCbs == null) { repCbs = new ArrayList<>(); } repCbs.addAll(cbs); } cbs = mPackageModeWatchers.get(packageName); if (cbs != null) { if (repCbs == null) { repCbs = new ArrayList<>(); } repCbs.addAll(cbs); } if (mode == AppOpsManager.opToDefaultMode(op.op)) { //如果mode 变为default mode // If going into the default mode, prune this op // if there is nothing else interesting in it. pruneOp(op, uid, packageName); } scheduleFastWriteLocked(); //快速记忆，需要10s等待 } } } ... ... //callback 回调 } Looking at getOpLocked(), as mentioned in setUidMode, pkgOps in UidState is also added in the same form. private Op getOpLocked(int code, int uid, String packageName, boolean edit) { Ops ops = getOpsRawLocked(uid, packageName, edit); if (ops == null) { return null; } return getOpLocked(ops, code, edit); } This function is: Create UidState (if there is no UidState corresponding to uid) Create Ops pkgOps in UidState added Create Op Re-storing appops.xml (this takes 30 minutes) Let's see when mode is called default mode: private void pruneOp(Op op, int uid, String packageName) { if (op.time == 0 && op.rejectTime == 0) { Ops ops = getOpsRawLocked(uid, packageName, false); if (ops != null) { ops.remove(op.op); if (ops.size() pkgOps = uidState.pkgOps; if (pkgOps != null) { pkgOps.remove(ops.packageName); if (pkgOps.isEmpty()) { uidState.pkgOps = null; } if (uidState.isDefault()) { mUidStates.remove(uid); } } } } } } This generally refers to the absence of noteOperation, op.time and op.rejectTime are 0, will remove all relevant parts of ops, pkgOps. 1.6. checkOperation()： public int checkOperation(int code, int uid, String packageName) { verifyIncomingUid(uid); verifyIncomingOp(code); String resolvedPackageName = resolvePackageName(uid, packageName); if (resolvedPackageName == null) { return AppOpsManager.MODE_IGNORED; } synchronized (this) { if (isOpRestrictedLocked(uid, code, resolvedPackageName)) { return AppOpsManager.MODE_IGNORED; } code = AppOpsManager.opToSwitch(code); UidState uidState = getUidStateLocked(uid, false); if (uidState != null && uidState.opModes != null && uidState.opModes.indexOfKey(code) >= 0) { return uidState.opModes.get(code); } Op op = getOpLocked(code, uid, resolvedPackageName, false); if (op == null) { return AppOpsManager.opToDefaultMode(code); } return op.mode; } } The reason for the difference between setUidMode and setMode is mainly checkOperation(). At the beginning, the mode is confirmed in UidState first, and if it is not, it will be confirmed in Op. As mentioned above, if you use setUidMode, it usually corresponds to the same package with uid, and then mode is removed from opModes when mode is default. When the mode set is default, it will definitely look up in Op. At this time, if it is a separate package, if the Op is not updated after setUidMode, the wrong mode return may occur. So under normal circumstances, if you are using a separate package, you can use setMode directly. "},"Android Permissions - Application permissions before android M and application permissions after M.html":{"url":"Android Permissions - Application permissions before android M and application permissions after M.html","title":"Android Permissions - Application permissions before android M and application permissions after M","keywords":"","body":"1. Application permissions before android M and application permissions after M1.1. Reprinted to indicate the source:1.2. related resources:1.3. Foreword:1.4. Source code analysis:1.5. First look at startActivity:1.6. Finally, it will call startActivity in ActivityStarter:1.7. 1. mService.checkPermission(START_ANY_ACTIVITY, callingPid, callingUid);1.8. 2. getComponentRestrictionForCallingPackage()1.9. 3. getActionRestrictionForCallingPackage()1.10. to sum up:1.11. Dialog prompt1. Application permissions before android M and application permissions after M Personal classification: android ------ security and permissions Copyright statement: This article is the original article of the blogger, please be sure to indicate the author and the original link. Https://blog.csdn.net/jingerppp/article/details/80674768 Application permissions before android M and application permissions after M Reprinted to indicate the source: related resources: Foreword: Source code analysis: First look at startActivity: Finally, it will call startActivity in ActivityStarter: 1. mService.checkPermission(START_ANY_ACTIVITY, callingPid, callingUid); 2. getComponentRestrictionForCallingPackage() 3. getActionRestrictionForCallingPackage() to sum up: Dialog prompt 1.1. Reprinted to indicate the source: https://blog.csdn.net/shift_wwx/article/details/80674768 1.2. related resources: Android Runtime Permission, https://blog.csdn.net/jingerppp/article/details/80194908 Android grantRuntimePermission Detailed, https://blog.csdn.net/jingerppp/article/details/80249595 Android GrantPermissionsActivity Detailed, https://blog.csdn.net/jingerppp/article/details/80263467 AppOps control for Normal permission, https://blog.csdn.net/jingerppp/article/details/80360676 Android native permission control process, https://blog.csdn.net/jingerppp/article/details/80519212 The difference between setUidMode and setMode in AppOps, https://blog.csdn.net/jingerppp/article/details/80674651 1.3. Foreword: Recently, the process of permission control, from the Android Runtime Permission detailed understanding, the android system is not the same process for the control of permissions after M. For the apk before M, of course, there is no interface in the system after M, such as checkPermission. In the application after M, the interface of checkPermission is used to confirm whether the permission is granted. The application before M cannot use checkPermission. The system adds this part of the process control to AppOps. This article mainly analyzes the process of pre-M app permission control reservation in M ​​system through source code. 1.4. Source code analysis: For the permission control after M, you can see the Android Runtime Permission. 1.5. First look at startActivity: @Override public final int startActivity(IApplicationThread caller, String callingPackage, Intent intent, String resolvedType, IBinder resultTo, String resultWho, int requestCode, int startFlags, ProfilerInfo profilerInfo, Bundle bOptions) { return startActivityAsUser(caller, callingPackage, intent, resolvedType, resultTo, resultWho, requestCode, startFlags, profilerInfo, bOptions, UserHandle.getCallingUserId()); } Then startActivityAsUser will be called, and the following process source code will not be posted (occupied space). 1.6. Finally, it will call startActivity in ActivityStarter: /** DO NOT call this method directly. Use {@link #startActivityLocked} instead. */ private int startActivity(IApplicationThread caller, Intent intent, Intent ephemeralIntent, String resolvedType, ActivityInfo aInfo, ResolveInfo rInfo, IVoiceInteractionSession voiceSession, IVoiceInteractor voiceInteractor, IBinder resultTo, String resultWho, int requestCode, int callingPid, int callingUid, String callingPackage, int realCallingPid, int realCallingUid, int startFlags, ActivityOptions options, boolean ignoreTargetSecurity, boolean componentSpecified, ActivityRecord[] outActivity, TaskRecord inTask) { ... ... boolean abort = !mSupervisor.checkStartAnyActivityPermission(intent, aInfo, resultWho, requestCode, callingPid, callingUid, callingPackage, ignoreTargetSecurity, callerApp, resultRecord, resultStack, options); abort |= !mService.mIntentFirewall.checkStartActivity(intent, callingUid, callingPid, resolvedType, aInfo.applicationInfo); ... ... } Here, you will be granted access to any activity that is started, to confirm whether you want to abort, which is generally allowed for applications after M, which will be explained later. Then look at checkStartAnyActivityPermission: boolean checkStartAnyActivityPermission(Intent intent, ActivityInfo aInfo, String resultWho, int requestCode, int callingPid, int callingUid, String callingPackage, boolean ignoreTargetSecurity, ProcessRecord callerApp, ActivityRecord resultRecord, ActivityStack resultStack, ActivityOptions options) { final int startAnyPerm = mService.checkPermission(START_ANY_ACTIVITY, callingPid, callingUid); //check step 1 if (startAnyPerm == PERMISSION_GRANTED) { return true; } final int componentRestriction = getComponentRestrictionForCallingPackage( aInfo, callingPackage, callingPid, callingUid, ignoreTargetSecurity); //check step 2 final int actionRestriction = getActionRestrictionForCallingPackage( intent.getAction(), callingPackage, callingPid, callingUid); //check step 3 if (componentRestriction == ACTIVITY_RESTRICTION_PERMISSION || actionRestriction == ACTIVITY_RESTRICTION_PERMISSION) { if (resultRecord != null) { resultStack.sendActivityResultLocked(-1, resultRecord, resultWho, requestCode, Activity.RESULT_CANCELED, null); } final String msg; if (actionRestriction == ACTIVITY_RESTRICTION_PERMISSION) { msg = \"Permission Denial: starting \" + intent.toString() + \" from \" + callerApp + \" (pid=\" + callingPid + \", uid=\" + callingUid + \")\" + \" with revoked permission \" + ACTION_TO_RUNTIME_PERMISSION.get(intent.getAction()); } else if (!aInfo.exported) { msg = \"Permission Denial: starting \" + intent.toString() + \" from \" + callerApp + \" (pid=\" + callingPid + \", uid=\" + callingUid + \")\" + \" not exported from uid \" + aInfo.applicationInfo.uid; } else { msg = \"Permission Denial: starting \" + intent.toString() + \" from \" + callerApp + \" (pid=\" + callingPid + \", uid=\" + callingUid + \")\" + \" requires \" + aInfo.permission; } Slog.w(TAG, msg); throw new SecurityException(msg); //throw an exception for denied state } if (actionRestriction == ACTIVITY_RESTRICTION_APPOP) { final String message = \"Appop Denial: starting \" + intent.toString() + \" from \" + callerApp + \" (pid=\" + callingPid + \", uid=\" + callingUid + \")\" + \" requires \" + AppOpsManager.permissionToOp( ACTION_TO_RUNTIME_PERMISSION.get(intent.getAction())); Slog.w(TAG, message); return false; } else if (componentRestriction == ACTIVITY_RESTRICTION_APPOP) { final String message = \"Appop Denial: starting \" + intent.toString() + \" from \" + callerApp + \" (pid=\" + callingPid + \", uid=\" + callingUid + \")\" + \" requires appop \" + AppOpsManager.permissionToOp(aInfo.permission); Slog.w(TAG, message); return false; } if (options != null) { if (options.getLaunchTaskId() != INVALID_STACK_ID) { final int startInTaskPerm = mService.checkPermission(START_TASKS_FROM_RECENTS, callingPid, callingUid); if (startInTaskPerm == PERMISSION_DENIED) { final String msg = \"Permission Denial: starting \" + intent.toString() + \" from \" + callerApp + \" (pid=\" + callingPid + \", uid=\" + callingUid + \") with launchTaskId=\" + options.getLaunchTaskId(); Slog.w(TAG, msg); throw new SecurityException(msg); } } // Check if someone tries to launch an activity on a private display with a different // owner. final int launchDisplayId = options.getLaunchDisplayId(); if (launchDisplayId != INVALID_DISPLAY && !isCallerAllowedToLaunchOnDisplay(callingPid, callingUid, launchDisplayId, aInfo)) { final String msg = \"Permission Denial: starting \" + intent.toString() + \" from \" + callerApp + \" (pid=\" + callingPid + \", uid=\" + callingUid + \") with launchDisplayId=\" + launchDisplayId; Slog.w(TAG, msg); throw new SecurityException(msg); } } return true; } This code is relatively simple, through three check functions, to determine whether the state is normal, abnormally will directly give a securityException, so that the return state of the check must be normal. 1.7. 1. mService.checkPermission(START_ANY_ACTIVITY, callingPid, callingUid); Note that the permissions here are START_ANY_ACTIVITY: An application that registers this permission can start any activity. If there is this permission, then other rights management will be ineffective. 1.8. 2. getComponentRestrictionForCallingPackage() private int getComponentRestrictionForCallingPackage(ActivityInfo activityInfo, String callingPackage, int callingPid, int callingUid, boolean ignoreTargetSecurity) { if (!ignoreTargetSecurity && mService.checkComponentPermission(activityInfo.permission, callingPid, callingUid, activityInfo.applicationInfo.uid, activityInfo.exported) == PERMISSION_DENIED) { return ACTIVITY_RESTRICTION_PERMISSION; } if (activityInfo.permission == null) { return ACTIVITY_RESTRICTION_NONE; } final int opCode = AppOpsManager.permissionToOpCode(activityInfo.permission); if (opCode == AppOpsManager.OP_NONE) { return ACTIVITY_RESTRICTION_NONE; } if (mService.mAppOpsService.noteOperation(opCode, callingUid, callingPackage) != AppOpsManager.MODE_ALLOWED) { if (!ignoreTargetSecurity) { return ACTIVITY_RESTRICTION_APPOP; } } return ACTIVITY_RESTRICTION_NONE; } The first step is to check through the checkPermission interface after M. If you can't pass it here, you definitely don't need to go to AppOps. Here you can see that for the given permissions, such as PHONE_CALLS, it will go through the operation of noteOperation, regardless of whether it is before or after M, the only difference may be the logic control inside. If it is not here, it will give the return of ACTIVITY_RESTRICTION_APPOP. The future processing logic is not much to say here, the code is very clear. 1.9. 3. getActionRestrictionForCallingPackage() private int getActionRestrictionForCallingPackage(String action, String callingPackage, int callingPid, int callingUid) { if (action == null) { return ACTIVITY_RESTRICTION_NONE; } String permission = ACTION_TO_RUNTIME_PERMISSION.get(action); if (permission == null) { return ACTIVITY_RESTRICTION_NONE; } final PackageInfo packageInfo; try { packageInfo = mService.mContext.getPackageManager() .getPackageInfo(callingPackage, PackageManager.GET_PERMISSIONS); } catch (PackageManager.NameNotFoundException e) { Slog.i(TAG, \"Cannot find package info for \" + callingPackage); return ACTIVITY_RESTRICTION_NONE; } if (!ArrayUtils.contains(packageInfo.requestedPermissions, permission)) { return ACTIVITY_RESTRICTION_NONE; } if (mService.checkPermission(permission, callingPid, callingUid) == PERMISSION_DENIED) { return ACTIVITY_RESTRICTION_PERMISSION; } final int opCode = AppOpsManager.permissionToOpCode(permission); if (opCode == AppOpsManager.OP_NONE) { return ACTIVITY_RESTRICTION_NONE; } if (mService.mAppOpsService.noteOperation(opCode, callingUid, callingPackage) != AppOpsManager.MODE_ALLOWED) { return ACTIVITY_RESTRICTION_APPOP; } return ACTIVITY_RESTRICTION_NONE; } Here is the action to confirm the permission, and then continue the M through the interface checkPermission and AppOps after the permission. 1.10. to sum up: Here is just a list of the control process for the rights management of the system after android M in startActivity. For the application before M, the general checkPemission is granted. As for the default value, you can see the PMS or leave a message if you want to know. If you want permission control for the pre-M application, and do not change the original system control process, you can only control it in AppOps. Of course, in addition to the startActivity control control here, there are other, such as ContentProvider. @Override public int update(String callingPkg, Uri uri, ContentValues values, String selection, String[] selectionArgs) { validateIncomingUri(uri); uri = maybeGetUriWithoutUserId(uri); if (enforceWritePermission(callingPkg, uri, null) != AppOpsManager.MODE_ALLOWED) { return 0; } final String original = setCallingPackage(callingPkg); try { return ContentProvider.this.update(uri, values, selection, selectionArgs); } finally { setCallingPackage(original); } } 1.11. Dialog prompt Through the android GrantPermissionsActivity detailed , there will be a dialog box popping up in the application after M, then the application box prompt before M can only be controlled in AppOps (previously controlled in the checkPermission in AMS, but found a bunch of deadlocks, modified Code is finally posted). For some reason, only a portion of the code is posted here: if (uidState.opModes != null && uidState.opModes.indexOfKey(switchCode) >= 0) { final int uidMode = uidState.opModes.get(switchCode); if (uidMode != AppOpsManager.MODE_ALLOWED) { if (DEBUG) Log.d(TAG, \"noteOperation: (uidState)reject #\" + op.mode + \" for code \" + switchCode + \" (\" + code + \") uid \" + uid + \" package \" + packageName); op.rejectTime = System.currentTimeMillis(); final Op switchOp = switchCode != code ? getOpLocked(ops, switchCode, true) : op; req = enforcePermission(code, uid, packageName, switchOp); if (req == null) return uidMode; isAllowed = false; } } private PermissionDialogReq enforcePermission(int code, int uid, String packageName, Op op) { if (!isStrictOpEnable() || !isStrictCodeValid(code) || Looper.myLooper() == mLooper || op.mode != AppOpsManager.MODE_NOTED) return null; return askOperationLocked(code, uid, packageName, op); } private boolean isStrictCodeValid(int code) { return code == AppOpsManager.OP_CHANGE_WIFI_STATE || code == AppOpsManager.OP_BLUETOOTH_ADMIN || code == AppOpsManager.OP_NFC || code == AppOpsManager.OP_SEND_MMS || isRuntimePermission(code); } /** * added by wj, just adjust the permission is runtime permission or not * for the application whose SDK version is less than M. */ private boolean isRuntimePermission(int code) { String permName = AppOpsManager.opToPermission(code); PermissionInfo permissionInfo; try { permissionInfo = mContext.getPackageManager().getPermissionInfo(permName, 0); } catch (PackageManager.NameNotFoundException e) { return false; } return (permissionInfo.protectionLevel & PermissionInfo.PROTECTION_MASK_BASE) == PermissionInfo.PROTECTION_DANGEROUS; } Based on this, create a custom dialog and complete the implementation. The MODE here adds a NOTED to the original ALLOWED and IGNORED, indicating that it is prompted every time. Additional: public boolean noteRuntimePermissions(boolean fixedByTheUser, String[] filterPermissions) { final int uid = mPackageInfo.applicationInfo.uid; // We toggle permissions only to apps that support runtime // permissions, otherwise we toggle the app op corresponding // to the permission if the permission is granted to the app. for (Permission permission : mPermissions.values()) { if (filterPermissions != null && !ArrayUtils.contains(filterPermissions, permission.getName())) { continue; } if (mAppSupportsRuntimePermissions && mIsRuntimePermission && !mIsSendMMS) { // Do not touch permissions fixed by the system. if (permission.isSystemFixed()) { return false; } if (permission.hasAppOp() && !permission.isAppOpNoted()) { permission.setAppOpMode(AppOpsManager.MODE_NOTE); // Disable the app op. mAppOps.setMode(permission.getOp(), uid, mPackageInfo.packageName, AppOpsManager.MODE_NOTE); } // Grant the permission if needed. if (!permission.isGranted()) { permission.setGranted(true); mPackageManager.grantRuntimePermission(mPackageInfo.packageName, permission.getName(), mUserHandle); } // Update the permission flags. if (!fixedByTheUser) { // Now the apps can ask for the permission as the user // no longer has it fixed in a denied state. if (permission.isUserFixed() || permission.isUserSet()) { permission.setUserFixed(false); permission.setUserSet(false); mPackageManager.updatePermissionFlags(permission.getName(), mPackageInfo.packageName, PackageManager.FLAG_PERMISSION_USER_FIXED | PackageManager.FLAG_PERMISSION_USER_SET, 0, mUserHandle); } } } else { // Legacy apps cannot have a not granted permission but just in case. if (!permission.isGranted()) { continue; } int killUid = -1; int mask = 0; // If the permissions has no corresponding app op, then it is a // third-party one and we do not offer toggling of such permissions. if (permission.hasAppOp()) { if (!permission.isAppOpNoted()) { permission.setAppOpMode(AppOpsManager.MODE_NOTE); // Enable the app op. mAppOps.setMode(permission.getOp(), uid, mPackageInfo.packageName, AppOpsManager.MODE_NOTE); } // Mark that the permission should not be be granted on upgrade // when the app begins supporting runtime permissions. if (permission.shouldRevokeOnUpgrade()) { permission.setRevokeOnUpgrade(false); mask |= PackageManager.FLAG_PERMISSION_REVOKE_ON_UPGRADE; } } // Granting a permission explicitly means the user already // reviewed it so clear the review flag on every grant. if (permission.isReviewRequired()) { permission.resetReviewRequired(); mask |= PackageManager.FLAG_PERMISSION_REVIEW_REQUIRED; } if (mask != 0) { mPackageManager.updatePermissionFlags(permission.getName(), mPackageInfo.packageName, mask, 0, mUserHandle); } if (killUid != -1) { mActivityManager.killUid(killUid, KILL_REASON_APP_OP_CHANGE); } } } return true; } AMS checkPermission join processing process (a deadlock will occur, use M system source can be) /** * added by wj, check permission of application which the target sdk is less than the one of M and * the protection level of permission is dangerous. * @return 0 or 1 indicates the permission has handled by AppOps. */ private final Object aLock = new Object(); private int checkPermissionForAppOps(String permission, int uid) { PermissionInfo info = null; try { info = mContext.getPackageManager().getPermissionInfo(permission, 0); } catch (PackageManager.NameNotFoundException e) { //ignore } //At first, the permission is dangerous. if (info == null || ((info.protectionLevel & PermissionInfo.PROTECTION_MASK_BASE) != PermissionInfo.PROTECTION_DANGEROUS)) return -1; String pkgName = null; try { pkgName = AppGlobals.getPackageManager().getNameForUid(uid); } catch (RemoteException e) { //ignore } Slog.d(TAG, \"checkPermissionForAppOps, permission = \" + permission + \", uid = \" + uid + \", packageName = \" + pkgName); if (pkgName == null) return -1; ApplicationInfo ai = null; try { ai = mContext.getPackageManager().getApplicationInfo(pkgName, 0); } catch (PackageManager.NameNotFoundException e) { //ignore } if (ai == null || ai.targetSdkVersion >= Build.VERSION_CODES.M) return -1; Slog.d(TAG, \"checkPermissionForAppOps, targetSdkVersion = \" + ai.targetSdkVersion); synchronized(aLock) { AppOpsManager mAppOpsManager = mContext.getSystemService(AppOpsManager.class); int tUid = Binder.getCallingUid() >= uid ? Binder.getCallingUid() : uid;//get application uid but not the one from native if ((tUid >= Process.FIRST_APPLICATION_UID) && (pkgName.indexOf(\"android.uid.systemui\") != 0) && (pkgName.indexOf(\"android.uid.system\") != 0)) { int result = mAppOpsManager.noteOp(AppOpsManager.permissionToOp(permission), tUid, pkgName); return result; } } return -1; } after joining the MODE_NOTED interface permission control selection interface dialog box prompt interface "},"Android Permissions - Provider permissions detailed.html":{"url":"Android Permissions - Provider permissions detailed.html","title":"Android Permissions - Provider permissions detailed","keywords":"","body":"1. Provider permissions detailed1.1. source:1.2. Foreword:1.3. Example:1.4. Source code analysis:1.5. in conclusion:1.6. Example conclusion:1. Provider permissions detailed Copyright statement: This article is the original article of the blogger, please be sure to indicate the author and the original link. Https://blog.csdn.net/jingerppp/article/details/82108549 Provider permissions detailed source: Foreword: Example: Source code analysis: in conclusion: Example conclusion: 1.1. source: https://blog.csdn.net/shift_wwx/article/details/82108549 1.2. Foreword: There is a blog post \" Android Basics Summary: ContentProvider \" that explains the basics of the provider. For the resolution of the provider in AndroidManifest.xml, you can see the blog post \" How to parse APK with android PMS \". This article mainly analyzes the provider permissions. If the provider is used by another program, you need to set the export property to true, and you need to set the readPermission and writePermission. Of course, for the FileProvider that appears after SDK 22, this is another case. This article will use the source code to analyze the Provider's permissions management in detail. This article is based on the version Android O. 1.3. Example: Before the occurrence of an exception log, this article combines this example for parsing. --------- beginning of crash 08-24 18:14:43.989 E/AndroidRuntime( 2366): FATAL EXCEPTION: main 08-24 18:14:43.989 E/AndroidRuntime( 2366): Process: com.android.messaging, PID: 2366 08-24 18:14:43.989 E/AndroidRuntime( 2366): java.lang.SecurityException: UID 10098 does not have permission to content://com.android.dialer.files/my_cache/my_cache/%2B12543365555_08-11-18_0442AM.amr [user 0] 08-24 18:14:43.989 E/AndroidRuntime( 2366): at android.os.Parcel.readException(Parcel.java:2005) 08-24 18:14:43.989 E/AndroidRuntime( 2366): at android.os.Parcel.readException(Parcel.java:1951) 08-24 18:14:43.989 E/AndroidRuntime( 2366): at android.app.IActivityManager$Stub$Proxy.startActivity(IActivityManager.java:4352) 08-24 18:14:43.989 E/AndroidRuntime( 2366): at android.app.Instrumentation.execStartActivity(Instrumentation.java:1613) 08-24 18:14:43.989 E/AndroidRuntime( 2366): at android.app.Activity.startActivityForResult(Activity.java:4501) 08-24 18:14:43.989 E/AndroidRuntime( 2366): at android.app.Activity.startActivityForResult(Activity.java:4459) 08-24 18:14:43.989 E/AndroidRuntime( 2366): at android.app.Activity.startActivity(Activity.java:4820) 08-24 18:14:43.989 E/AndroidRuntime( 2366): at android.app.Activity.startActivity(Activity.java:4788) 08-24 18:14:43.989 E/AndroidRuntime( 2366): at com.android.messaging.ui.Q.wT(SourceFile:200) 08-24 18:14:43.989 E/AndroidRuntime( 2366): at com.android.messaging.ui.conversationlist.ShareIntentActivity.pR(SourceFile:179) 08-24 18:14:43.989 E/AndroidRuntime( 2366): at com.android.messaging.ui.conversationlist.o.onClick(SourceFile:98) 08-24 18:14:43.989 E/AndroidRuntime( 2366): at com.android.internal.app.AlertController$ButtonHandler.handleMessage(AlertController.java:166) 08-24 18:14:43.989 E/AndroidRuntime( 2366): at android.os.Handler.dispatchMessage(Handler.java:106) 08-24 18:14:43.989 E/AndroidRuntime( 2366): at android.os.Looper.loop(Looper.java:164) 08-24 18:14:43.989 E/AndroidRuntime( 2366): at android.app.ActivityThread.main(ActivityThread.java:6518) 08-24 18:14:43.989 E/AndroidRuntime( 2366): at java.lang.reflect.Method.invoke(Native Method) 08-24 18:14:43.989 E/AndroidRuntime( 2366): at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:438) 08-24 18:14:43.989 E/AndroidRuntime( 2366): at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:807) 08-24 18:14:43.989 D/RecurrenceRule( 599): Resolving using anchor 2018-08-24T18:14:43.989+08:00[Asia/Shanghai] Log prompts that a process with a uid of 10098 does not have permission to use a provider. 1.4. Source code analysis: The debug function startActivity() will eventually be called into AMS, and the stack will be printed below: 08-24 18:14:43.946 E/ActivityManager( 599): WJ Stack:java.lang.Throwable 08-24 18:14:43.946 E/ActivityManager( 599): at com.android.server.am.ActivityManagerService.checkGrantUriPermissionLocked(ActivityManagerService.java:8975) 08-24 18:14:43.946 E/ActivityManager( 599): at com.android.server.am.ActivityManagerService.checkGrantUriPermissionFromIntentLocked(ActivityManagerService.java:9264) 08-24 18:14:43.946 E/ActivityManager( 599): at com.android.server.am.ActivityManagerService.grantUriPermissionFromIntentLocked(ActivityManagerService.java:9304) 08-24 18:14:43.946 E/ActivityManager( 599): at com.android.server.am.ActivityStarter.startActivityUnchecked(ActivityStarter.java:1203) 08-24 18:14:43.946 E/ActivityManager( 599): at com.android.server.am.ActivityStarter.startActivity(ActivityStarter.java:1000) 08-24 18:14:43.946 E/ActivityManager( 599): at com.android.server.am.ActivityStarter.startActivity(ActivityStarter.java:577) 08-24 18:14:43.946 E/ActivityManager( 599): at com.android.server.am.ActivityStarter.startActivityLocked(ActivityStarter.java:283) 08-24 18:14:43.946 E/ActivityManager( 599): at com.android.server.am.ActivityStarter.startActivityMayWait(ActivityStarter.java:822) 08-24 18:14:43.946 E/ActivityManager( 599): at com.android.server.am.ActivityManagerService.startActivityAsUser(ActivityManagerService.java:4616) 08-24 18:14:43.946 E/ActivityManager( 599): at com.android.server.am.ActivityManagerService.startActivity(ActivityManagerService.java:4603) 08-24 18:14:43.946 E/ActivityManager( 599): at android.app.IActivityManager$Stub.onTransact(IActivityManager.java:121) 08-24 18:14:43.946 E/ActivityManager( 599): at com.android.server.am.ActivityManagerService.onTransact(ActivityManagerService.java:2971) 08-24 18:14:43.946 E/ActivityManager( 599): at android.os.Binder.execTransact(Binder.java:697) GrantUriPermissionFromIntentLocked() is called in AMS: void grantUriPermissionFromIntentLocked(int callingUid, String targetPkg, Intent intent, UriPermissionOwner owner, int targetUserId) { NeededUriGrants needed = checkGrantUriPermissionFromIntentLocked(callingUid, targetPkg, intent, intent != null ? intent.getFlags() : 0, null, targetUserId); if (needed == null) { return; } grantUriPermissionUncheckedFromIntentLocked(needed, owner); } Here the parameters intent, targetPkg, owner, targetUserId are all passed in by ActivityStarter. The final function will call checkGrantUriPermissionLocked(), which is the core function of the permission processing. In fact, the AMS needs to determine the Uri permission for the application. A public interface function checkGrantUriPermission() is provided separately. Through the code, the function will eventually call checkGrantUriPermissionLocked(). public int checkGrantUriPermission(int callingUid, String targetPkg, Uri uri, final int modeFlags, int userId) { enforceNotIsolatedCaller(\"checkGrantUriPermission\"); synchronized(this) { return checkGrantUriPermissionLocked(callingUid, targetPkg, new GrantUri(userId, uri, false), modeFlags, -1); } } Look at the function checkGrantUriPermissionLocked(): int checkGrantUriPermissionLocked(int callingUid, String targetPkg, GrantUri grantUri, final int modeFlags, int lastTargetUid) { // 要求Intent 的flags 设为FLAG_GRANT_READ_URI_PERMISSION 或FLAG_GRANT_WRITE_URI_PERMISSION if (!Intent.isAccessUriMode(modeFlags)) { return -1; } ... ... // 要求scheme 是content if (!ContentResolver.SCHEME_CONTENT.equals(grantUri.uri.getScheme())) { if (DEBUG_URI_PERMISSION) Slog.v(TAG_URI_PERMISSION, \"Can't grant URI permission for non-content URI: \" + grantUri); return -1; } // Bail early if system is trying to hand out permissions directly; it // must always grant permissions on behalf of someone explicit. final int callingAppId = UserHandle.getAppId(callingUid); if ((callingAppId == SYSTEM_UID) || (callingAppId == ROOT_UID)) { if (\"com.android.settings.files\".equals(grantUri.uri.getAuthority())) { // Exempted authority for cropping user photos in Settings app } else { Slog.w(TAG, \"For security reasons, the system cannot issue a Uri permission\" + \" grant to \" + grantUri + \"; use startActivityAsCaller() instead\"); return -1; } } ... ... // 确定targetUid 是否有该permission if (targetUid >= 0) { // First... does the target actually need this permission? if (checkHoldingPermissionsLocked(pm, pi, grantUri, targetUid, modeFlags)) { // No need to grant the target this permission. if (DEBUG_URI_PERMISSION) Slog.v(TAG_URI_PERMISSION, \"Target \" + targetPkg + \" already has full permission to \" + grantUri); return -1; } } ... ... /* There is a special cross user grant if: * - The target is on another user. * - Apps on the current user can access the uri without any uid permissions. * In this case, we grant a uri permission, even if the ContentProvider does not normally * grant uri permissions. */ boolean specialCrossUserGrant = UserHandle.getUserId(targetUid) != grantUri.sourceUserId && checkHoldingPermissionsInternalLocked(pm, pi, grantUri, callingUid, modeFlags, false /*without considering the uid permissions*/); // Second... is the provider allowing granting of URI permissions? if (!specialCrossUserGrant) { if (!pi.grantUriPermissions) { throw new SecurityException(\"Provider \" + pi.packageName + \"/\" + pi.name + \" does not allow granting of Uri permissions (uri \" + grantUri + \")\"); } if (pi.uriPermissionPatterns != null) { final int N = pi.uriPermissionPatterns.length; boolean allowed = false; for (int i=0; i Intent requirements of flags set FLAG_GRANT_READ_URI_PERMISSION, FLAG_GRANT_WRITE_URI_PERMISSIONotherwise no deal Ask Uri's scheme to be content, otherwise it will not be processed. If the provider's grantUriPermissions property is true, then the grant-uri-permission is confirmed, see the grant-uri-permission document in detail. The checkHoldingPermissionsLocked() function determines the required basic permissions of the Provider. See below for details. checkUriPermissionLocked() When checking fail above, it will further confirm whether it has been previously granted in the provider. See below for details. First look at checkHoldingPermissionsLocked(): private final boolean checkHoldingPermissionsLocked( IPackageManager pm, ProviderInfo pi, GrantUri grantUri, int uid, final int modeFlags) { if (DEBUG_URI_PERMISSION) Slog.v(TAG_URI_PERMISSION, \"checkHoldingPermissionsLocked: uri=\" + grantUri + \" uid=\" + uid); if (UserHandle.getUserId(uid) != grantUri.sourceUserId) { if (ActivityManager.checkComponentPermission(INTERACT_ACROSS_USERS, uid, -1, true) != PERMISSION_GRANTED) { return false; } } Slog.v(TAG_URI_PERMISSION, \"enter checkHoldingPermissionsInternalLocked\"); return checkHoldingPermissionsInternalLocked(pm, pi, grantUri, uid, modeFlags, true); } For multiple users, you need to first check the INTERACT_ACROSS_USERS permission, then call checkHoldingPermissionsInternalLocked(): private final boolean checkHoldingPermissionsInternalLocked(IPackageManager pm, ProviderInfo pi, GrantUri grantUri, int uid, final int modeFlags, boolean considerUidPermissions) { if (pi.applicationInfo.uid == uid) { return true; } else if (!pi.exported) { return false; } boolean readMet = (modeFlags & Intent.FLAG_GRANT_READ_URI_PERMISSION) == 0; boolean writeMet = (modeFlags & Intent.FLAG_GRANT_WRITE_URI_PERMISSION) == 0; try { // check if target holds top-level permissions if (!readMet && pi.readPermission != null && considerUidPermissions && (pm.checkUidPermission(pi.readPermission, uid) == PERMISSION_GRANTED)) { readMet = true; } if (!writeMet && pi.writePermission != null && considerUidPermissions && (pm.checkUidPermission(pi.writePermission, uid) == PERMISSION_GRANTED)) { writeMet = true; } // track if unprotected read/write is allowed; any denied // below removes this ability boolean allowDefaultRead = pi.readPermission == null; boolean allowDefaultWrite = pi.writePermission == null; // check if target holds any that match uri final PathPermission[] pps = pi.pathPermissions; if (pps != null) { final String path = grantUri.uri.getPath(); int i = pps.length; while (i > 0 && (!readMet || !writeMet)) { i--; PathPermission pp = pps[i]; if (pp.match(path)) { if (!readMet) { final String pprperm = pp.getReadPermission(); if (DEBUG_URI_PERMISSION) Slog.v(TAG_URI_PERMISSION, \"Checking read perm for \" + pprperm + \" for \" + pp.getPath() + \": match=\" + pp.match(path) + \" check=\" + pm.checkUidPermission(pprperm, uid)); if (pprperm != null) { if (considerUidPermissions && pm.checkUidPermission(pprperm, uid) == PERMISSION_GRANTED) { readMet = true; } else { allowDefaultRead = false; } } } if (!writeMet) { final String ppwperm = pp.getWritePermission(); if (DEBUG_URI_PERMISSION) Slog.v(TAG_URI_PERMISSION, \"Checking write perm \" + ppwperm + \" for \" + pp.getPath() + \": match=\" + pp.match(path) + \" check=\" + pm.checkUidPermission(ppwperm, uid)); if (ppwperm != null) { if (considerUidPermissions && pm.checkUidPermission(ppwperm, uid) == PERMISSION_GRANTED) { writeMet = true; } else { allowDefaultWrite = false; } } } } } } // grant unprotected read/write, if not blocked by // above if (allowDefaultRead) readMet = true; if (allowDefaultWrite) writeMet = true; } catch (RemoteException e) { return false; } return readMet && writeMet; } When the application uid and provider uid are the same, check passes If the exported attribute of the provider is false, check does not pass directly. When the exported property of the provider is true, in order to protect the provider, it is sometimes necessary to add read permission and write permission. If the provider sets these two permissions, the application needs to guarantee these two permissions when used. The code will pass the function checkUidPermission(). Of course, if the provider does not add protection for these two permissions, the system considers both read and write are allowed, such as code: if (allowDefaultRead) readMet = true; if (allowDefaultWrite) writeMet = true; 1.5. in conclusion: If you want checkHoldingPermissionsLocked() to pass, you must satisfy one of the following points: The applied uid is the same as the provider uid The provider's exported is set to true, and the application must have both read permission and write permission. If the provider does not add this protection, the application has these two permissions by default. The second case is special. If it is a FileProvider then exported must be false, the code is as follows: (see the FileProvider documentation for details ) public void attachInfo(Context context, ProviderInfo info) { super.attachInfo(context, info); // Sanity check our security if (info.exported) { throw new SecurityException(\"Provider must not be exported\"); } if (!info.grantUriPermissions) { throw new SecurityException(\"Provider must grant uri permissions\"); } mStrategy = getPathStrategy(context, info.authority); } The checkGrantUriPermissionLocked () function above knows that we can finally check if one of the two conditions is met: checkHoldingPermissionsLocked() function can check pass checkUriPermissionLocked () function can check pass The check process of checkHoldingPermissionsLocked() is parsed above, and the conclusions behind the function are detailed. For the FileProvider is special, the exported attribute must be false, the function check must be fail, if the function check, only need to ensure that the checkUriPermissionLocked () function can check pass, that is, even if the provider's exported attribute value is false, It is also possible to check the pass. Let's parse the checkUriPermissionLocked() function in detail: private final boolean checkUriPermissionLocked(GrantUri grantUri, int uid, final int modeFlags) { final boolean persistable = (modeFlags & Intent.FLAG_GRANT_PERSISTABLE_URI_PERMISSION) != 0; final int minStrength = persistable ? UriPermission.STRENGTH_PERSISTABLE : UriPermission.STRENGTH_OWNED; // Root gets to do everything. if (uid == 0) { return true; } final ArrayMap perms = mGrantedUriPermissions.get(uid); if (perms == null) return false; // First look for exact match final UriPermission exactPerm = perms.get(grantUri); if (exactPerm != null && exactPerm.getStrength(modeFlags) >= minStrength) { return true; } // No exact match, look for prefixes final int N = perms.size(); for (int i = 0; i = minStrength) { return true; } } return false; The function mainly confirms whether mGrantedUriPermissions has a corresponding uid ArrayMap, which means that you must create such an ArrayMap and add it to mGrantedUriPermissions. private final SparseArray> mGrantedUriPermissions = new SparseArray>(); And this mGrantedUriPermissions is created in the function findOrCreateUriPermissionLocked(): private UriPermission findOrCreateUriPermissionLocked(String sourcePkg, String targetPkg, int targetUid, GrantUri grantUri) { ArrayMap targetUris = mGrantedUriPermissions.get(targetUid); if (targetUris == null) { targetUris = Maps.newArrayMap(); mGrantedUriPermissions.put(targetUid, targetUris); } UriPermission perm = targetUris.get(grantUri); if (perm == null) { perm = new UriPermission(sourcePkg, targetPkg, targetUid, grantUri); targetUris.put(grantUri, perm); } return perm; } In fact , you can know from the FileProvider documentation that there are two options for general grant uri permission: via the interface grantUriPermission() Call the method Context.grantUriPermission(package, Uri, mode_flags)) for the content:// Uri, using the desired mode flags. This grants temporary access permission for the content URI to the specified package, according to the value of the the mode_flags parameter, which you can set toFLAG_GRANT_READ_URI_PERMISSION, FLAG_GRANT_WRITE_URI_PERMISSION or both. The permission remains in effect until you revoke it by calling revokeUriPermission() or until the device reboots. Intent Configuration Put the content URI in an Intent by calling setData(). Next, call the method Intent.setFlags() with either FLAG_GRANT_READ_URI_PERMISSION orFLAG_GRANT_WRITE_URI_PERMISSION or both. Finally, send the Intent to another app. Most often, you do this by calling setResult(). Permissions granted in an Intent remain in effect while the stack of the receiving Activity is active. When the stack finishes, the permissions are automatically removed. Permissions granted to one Activity in a client app are automatically extended to other components of that app. 1.6. Example conclusion: The exception problem that appears in the instance should be Android's own problem. When sharing the SMS, the SMS itself starts an Activity, which causes the targetUid and callingUid of the checkHoldingPermissionsLocked() to be the uid of the SMS itself. Finally, the check can not pass. In the first startActivity will enter checkGrantUriPermissionLocked (), but encountered conditions to filter out, we need to modify the filter to make it: if ((callingAppId == SYSTEM_UID) || (callingAppId == ROOT_UID)) { if (\"com.android.settings.files\".equals(grantUri.uri.getAuthority())) { // Exempted authority for cropping user photos in Settings app } else { Slog.w(TAG, \"For security reasons, the system cannot issue a Uri permission\" + \" grant to \" + grantUri + \"; use startActivityAsCaller() instead\"); return -1; } } In fact, through the code you can see that the Android source also has a special filter for com.android.settings.files. We only need to refer to this. references: https://developer.android.com/guide/topics/manifest/provider-element https://developer.android.com/guide/topics/manifest/grant-uri-permission-element https://developer.android.com/reference/android/support/v4/content/FileProvider#SpecifyFiles "},"Android OTA - Android OTA upgrade principle and process analysis 1.html":{"url":"Android OTA - Android OTA upgrade principle and process analysis 1.html","title":"Android OTA - Android OTA upgrade principle and process analysis 1","keywords":"","body":"1. Android OTA upgrade principle and process analysis (1) --production of update.zip package1.1. 1. the directory structure of update.zip package1.2. 2. update.zip package directory structure.1.3. 3. Analysis of the generation process of Android upgrade package update.zip1.4. 4. Android OTA incremental package update.zip generation1. Android OTA upgrade principle and process analysis (1) --production of update.zip package July 04, 2016 09:54:21 blast - Bevis reading number: 1072 tags: otamore Personal Category: Android-OTA Android OTA upgrade principle and process analysis (2) --- update.zip differential package problem solving Reprinted from: http://blog.chinaunix.net/uid-22028566-id-3533848.html Android OTA upgrade principle and process analysis (1) --production of update.zip package 1. the directory structure of update.zip package 2. update.zip package directory structure. 3. Analysis of the generation process of Android upgrade package update.zip 4. Android OTA incremental package update.zip generation This and future pages will understand how the Recovery mode service works in the Android system by analyzing the update.zip package in the specific Android system upgrade process. Let's start with the creation of the update.zip package, then the startup mode analysis of the Android system, how Recovery works, how to choose system update from our upper layer to restart the Recovery service, and how to handle the update.zip package in the Recovery service. Upgraded, a series of questions about how our installation script updater-script is parsed and executed. The Android source code used in the analysis process is gingerbread0919 (standard on the tcc88xx development board), and the test development board is tcc88xx. This is the document summarized in the work. Of course, I have referenced a lot of content on the Internet. If there is a similarity, it is a coincidence. There are also many unresolved problems in the analysis process. I hope that everyone will advise you. 1.1. 1. the directory structure of update.zip package \\|----boot.img \\|----system/ \\|----recovery/ \\`\\|----recovery-from-boot.p \\`\\|---- Etc/ \\`\\|----install-recovery.sh \\|---META-INF/ \\`\\|CERT.RSA \\`\\|CERT.SF \\`\\|MANIFEST.MF \\`\\|----com/ \\`\\|---- Google/ \\`\\|----android/ \\`\\|----update-binary \\`\\|----updater-script \\`\\|----android/ \\`\\|----metadata 1.2. 2. update.zip package directory structure. The above is the standard directory structure of the update.zip package we created with the command make otapackage. boot.img is the file needed to update the boot partition. This boot.img mainly includes kernel+ramdisk. The contents of the system/ directory will be placed in the system partition of the system after the upgrade. Mainly used to update some applications of the system or some libraries that the application will use. You can copy all the files in the Android source code compilation out/target/product/tcc8800/system/ to this directory instead. Recovery-directory recovery-from-boot.p is the patch of boot.img and recovery.img, mainly used to update the recovery partition, where install-recovery.sh in the etc/ directory is the update script. update-binary is a binary file, equivalent to a script interpreter, able to identify the operation described in the updater-script. This file is generated after the Android source code is compiled out/target/product/tcc8800/system bin/updater, and the updater can be renamed to update-binary. The name of the file in the specific update package is determined by the value of the macro ASSUMED_UPDATE_BINARY_NAME in bootable/recovery/install.c in the source code. updater-script: This file is a script file that describes the update process. We can write this script to suit our specific needs, depending on the situation. The file name is determined by the value of the macro SCRIPT_NAME in the bootable/recovery/updater/updater.c file in the source code. The metadata file is metadata describing device information and environment variables. It mainly includes some compile options, signature public key, timestamp and device model. we can also add the userdata directory in the package to update the user data part of the system. This part will be stored in the /data directory of the system after the update. update.zip package signature: update.zip update package needs to be signed after the completion of the production, otherwise there will be an error message when the upgrade fails. And the signature uses an encrypted public key that is consistent with the target board. The specific path generated by the encryption of the public key and the three files needed for encryption after the Android source code is compiled is: out/host/linux-x86/framework/signapk.jar build/target/product/security/testkey.x509.pem build/target/product/security/testkey.pk8 。 The update.zip package we created with the command make otapackage is already signed. If you do the update.zip package yourself, you must manually sign it. The specific encryption method: $ java –jar gingerbread/out/host/linux/framework/signapk.jar –w gingerbread/build/target/product/security/testkey.x509.pem gingerbread/build/target/product/security/testkey .pk8 update.zip update_signed.zip The above command is executed in the path where the update.zip package is located, where the reference to the signapk.jar testkey.x509.pem and testkey.pk8 files uses an absolute path. Update.zip is the package we have already made, and the update_signed.zip package is the signed package that was generated after the command was executed. MANIFEST.MF: This manifest file defines the data related to the composition of the package. A mainfest.xml file similar to an Android app. CERT.RSA: A signature block file associated with a signature file that stores the public signature used to sign the JAR file. CERT.SF: This is the signature file of the JAR file, where the prefix CERT represents the signer. In addition, in the specific upgrade, the update.zip package will be roughly divided into three steps: 1 Check whether the SF file matches the RSA file. 2 Verify that MANIFEST.MF is consistent with the digest in the signature file. 3 The files in the inspection package are consistent with those described in MANIFEST. 1.3. 3. Analysis of the generation process of Android upgrade package update.zip There are two ways to make the update.zip package, namely manual creation and command generation. The first type of manual production : manually create the directory we need according to the directory structure of update.zip. Then copy the corresponding file to the appropriate directory, for example, we add an application to the system. You can copy the newly added application to our newly created update/system/app/ (the system directory is the system directory generated after copying the compiled source code). After packaging and signing, copy it to the SD card and you can use it. This method has not been tested successfully in the actual tcc8800 development board. The signature part did not pass and may be related to a specific development board. The second method of production : command production. The Android source code system provides us with the command to make the update.zip brush package, namely make otapackage. This command is executed after the source code is compiled and in the root directory of the source. Specific operation mode: execute in the source root directory ①\\$ . build/envsetup.sh。 ②\\$ lunch Then select the configuration you need (eg 17). ③\\$ make otapackage。 After compiling the source code, it is best to perform the above steps 1 and 2 to prevent the execution of 3 when the error message is not found. After the command is executed, the upgrade package is located at out/target/product/full_tcc8800_evm_target_files-eng.mumu.20120309.111059.zip. Rename the package to update.zip and copy it to the SD card for use. This approach (ie full upgrade) has been tested successfully in the tcc8800 development board. Use the make otapackage command to generate a process analysis of update.zip. Executing the make otapackage command in the source root directory to generate the update.zip package is mainly divided into two steps. The first step is to compile and generate an update original package (zip format) according to the Makefile. The second step is to run a python script and take the zip package prepared in the previous step as input, and finally generate the upgrade package we need. The two processes are further analyzed below. The first step : compile the Makefile. The location of the corresponding Makefile is: build/core/Makefile.Starting with the 884 lines of the file (tcc8800, gingerbread0919), a zip package will be generated, which will be used to make the OTA package or filesystem image. First paste the corresponding Makefile in this section as follows: # ----------------------------------------------------------------- # A zip of the directories that map to the target filesystem. # This zip can be used to create an OTA package or filesystem image # as a post-build step. # name := $(TARGET_PRODUCT) ifeq ($(TARGET_BUILD_TYPE),debug) name := $(name)_debug endif name := $(name)-target_files-$(FILE_NAME_TAG) intermediates := $(call intermediates-dir-for,PACKAGING,target_files) BUILT_TARGET_FILES_PACKAGE := $(intermediates)/$(name).zip $(BUILT_TARGET_FILES_PACKAGE): intermediates := $(intermediates) $(BUILT_TARGET_FILES_PACKAGE): \\ zip_root := $(intermediates)/$(name) # $(1): Directory to copy # $(2): Location to copy it to # The \"ls -A\" is to prevent \"acp s/* d\" from failing if s is empty. define package_files-copy-root if [ -d \"$(strip $(1))\" -a \"$(ls -A $(1))\" ]; then \\ mkdir -p $(2) && \\ $(ACP) -rd $(strip $(1))/* $(2); \\ be endef built_ota_tools: = \\ $(call intermediates-dir-for,EXECUTABLES,applypatch)/applypatch \\ $(call intermediates-dir-for,EXECUTABLES,applypatch_static)/applypatch_static \\ $(call intermediates-dir-for,EXECUTABLES,check_prereq)/check_prereq \\ $(call intermediates-dir-for,EXECUTABLES,updater)/updater $(BUILT_TARGET_FILES_PACKAGE): PRIVATE_OTA_TOOLS := $(built_ota_tools) $(BUILT_TARGET_FILES_PACKAGE): PRIVATE_RECOVERY_API_VERSION := $(RECOVERY_API_VERSION) ifeq ($(TARGET_RELEASETOOLS_EXTENSIONS),) # default to common dir for device vendor $(BUILT_TARGET_FILES_PACKAGE): tool_extensions := $(TARGET_DEVICE_DIR)/../common else $(BUILT_TARGET_FILES_PACKAGE): tool_extensions := $(TARGET_RELEASETOOLS_EXTENSIONS) endif # Depending on the various images guarantees that the underlying # directories are up-to-date. $(BUILT_TARGET_FILES_PACKAGE): \\ $(INSTALLED_BOOTIMAGE_TARGET) \\ $(INSTALLED_RADIOIMAGE_TARGET) \\ $(INSTALLED_RECOVERYIMAGE_TARGET) \\ $(INSTALLED_SYSTEMIMAGE) \\ $(INSTALLED_USERDATAIMAGE_TARGET) \\ $(INSTALLED_ANDROID_INFO_TXT_TARGET) \\ $ (built_ota_tools) \\ $(APKCERTS_FILE) \\ $(HOST_OUT_EXECUTABLES)/fs_config \\ | $(ACP) @echo \"Package target files: $@\" $(hide) rm -rf $@ $(zip_root) $(hide) mkdir -p $(dir $@) $(zip_root) @# Components of the recovery image $(hide) mkdir -p $(zip_root)/RECOVERY $(hide) $(call package_files-copy-root, \\ $(TARGET_RECOVERY_ROOT_OUT),$(zip_root)/RECOVERY/RAMDISK) ifdef INSTALLED_KERNEL_TARGET $(hide) $(ACP) $(INSTALLED_KERNEL_TARGET) $(zip_root)/RECOVERY/kernel endif ifdef INSTALLED_2NDBOOTLOADER_TARGET $(hide) $(ACP) \\ $(INSTALLED_2NDBOOTLOADER_TARGET) $(zip_root)/RECOVERY/second endif ifdef BOARD_KERNEL_CMDLINE $(hide) echo \"$(BOARD_KERNEL_CMDLINE)\" > $(zip_root)/RECOVERY/cmdline endif ifdef BOARD_KERNEL_BASE $(hide) echo \"$(BOARD_KERNEL_BASE)\" > $(zip_root)/RECOVERY/base endif ifdef BOARD_KERNEL_PAGESIZE $(hide) echo \"$(BOARD_KERNEL_PAGESIZE)\" > $(zip_root)/RECOVERY/pagesize endif @# Components of the boot image $(hide) mkdir -p $(zip_root)/BOOT $(hide) $(call package_files-copy-root, \\ $(TARGET_ROOT_OUT),$(zip_root)/BOOT/RAMDISK) ifdef INSTALLED_KERNEL_TARGET $(hide) $(ACP) $(INSTALLED_KERNEL_TARGET) $(zip_root)/BOOT/kernel endif ifdef INSTALLED_2NDBOOTLOADER_TARGET $(hide) $(ACP) \\ $(INSTALLED_2NDBOOTLOADER_TARGET) $(zip_root)/BOOT/second endif ifdef BOARD_KERNEL_CMDLINE $(hide) echo \"$(BOARD_KERNEL_CMDLINE)\" > $(zip_root)/BOOT/cmdline endif ifdef BOARD_KERNEL_BASE $(hide) echo \"$(BOARD_KERNEL_BASE)\" > $(zip_root)/BOOT/base endif ifdef BOARD_KERNEL_PAGESIZE $(hide) echo \"$(BOARD_KERNEL_PAGESIZE)\" > $(zip_root)/BOOT/pagesize endif $(hide) $(foreach t,$(INSTALLED_RADIOIMAGE_TARGET),\\ mkdir -p $(zip_root)/RADIO; \\ $(ACP) $(t) $(zip_root)/RADIO/$(notdir $(t));) @# Contents of the system image $(hide) $(call package_files-copy-root, \\ $(SYSTEMIMAGE_SOURCE_DIR),$(zip_root)/SYSTEM) @# Contents of the data image $(hide) $(call package_files-copy-root, \\ $(TARGET_OUT_DATA),$(zip_root)/DATA) @# Extra contents of the OTA package $(hide) mkdir -p $(zip_root)/OTA/bin $(hide) $(ACP) $(INSTALLED_ANDROID_INFO_TXT_TARGET) $(zip_root)/OTA/ $(hide) $(ACP) $(PRIVATE_OTA_TOOLS) $(zip_root)/OTA/bin/ @# Files that do not end up in any images, but are necessary to @# build them. $(hide) mkdir -p $(zip_root)/META $(hide) $(ACP) $(APKCERTS_FILE) $(zip_root)/META/apkcerts.txt $(hide) echo \"$(PRODUCT_OTA_PUBLIC_KEYS)\" > $(zip_root)/META/otakeys.txt $(hide) echo \"recovery_api_version=$(PRIVATE_RECOVERY_API_VERSION)\" > $(zip_root)/META/misc_info.txt ifdef BOARD_FLASH_BLOCK_SIZE $(hide) echo \"blocksize=$(BOARD_FLASH_BLOCK_SIZE)\" >> $(zip_root)/META/misc_info.txt endif ifdef BOARD_BOOTIMAGE_PARTITION_SIZE $(hide) echo \"boot_size=$(BOARD_BOOTIMAGE_PARTITION_SIZE)\" >> $(zip_root)/META/misc_info.txt endif ifdef BOARD_RECOVERYIMAGE_PARTITION_SIZE $(hide) echo \"recovery_size=$(BOARD_RECOVERYIMAGE_PARTITION_SIZE)\" >> $(zip_root)/META/misc_info.txt endif ifdef BOARD_SYSTEMIMAGE_PARTITION_SIZE $(hide) echo \"system_size=$(BOARD_SYSTEMIMAGE_PARTITION_SIZE)\" >> $(zip_root)/META/misc_info.txt endif ifdef BOARD_USERDATAIMAGE_PARTITION_SIZE $(hide) echo \"userdata_size=$(BOARD_USERDATAIMAGE_PARTITION_SIZE)\" >> $(zip_root)/META/misc_info.txt endif $(hide) echo \"tool_extensions=$(tool_extensions)\" >> $(zip_root)/META/misc_info.txt ifdef mkyaffs2_extra_flags $(hide) echo \"mkyaffs2_extra_flags=$(mkyaffs2_extra_flags)\" >> $(zip_root)/META/misc_info.txt endif @# Zip everything up, preserving symlinks $(hide) (cd $(zip_root) && zip -qry ../$(notdir $@) .) @# Run fs_config on all the system files in the zip, and save the output $(hide) zipinfo -1 $@ | awk -F/ 'BEGIN { OFS=\"/\" } /^SYSTEM\\// {$1 = \"system\"; print}' | $(HOST_OUT_EXECUTABLES)/fs_config > $(zip_root)/META/filesystem_config.txt $(hide) (cd $(zip_root) && zip -q ../$(notdir $@) META/filesystem_config.txt) target-files-package: $(BUILT_TARGET_FILES_PACKAGE) ifneq ($(TARGET_SIMULATOR),true) ifneq ($(TARGET_PRODUCT),sdk) ifneq ($(TARGET_DEVICE),generic) ifneq ($(TARGET_NO_KERNEL),true) ifneq ($(recovery_fstab),) According to the Makefile above, you can analyze the generation process of this package: First create a root_zip root directory, and then create the following other directories in this directory. Create a RECOVERY directory and populate the contents of the directory, including the kernel image and the image of the recovery root file system. This directory is ultimately used to generate recovery.img. Create and populate the BOOT directory. Contains kernel and cmdline and pagesize size, etc., which is ultimately used to generate boot.img. Fill the SYSTEM directory with the system image. Fill the data image with DATA. Additional content needed to generate the OTA package. It mainly includes some bin commands. Create a META directory and add some text files to the directory, such as apkcerts.txt (describe the authentication certificate used by the apk file), misc_info.txt (describe the block size of the flash memory and the partitions of boot, recovery, system, userdata, etc.) Size information). Use the reserved connection option to compress the root_zip directory we obtained above. Use fs_config (build/tools/fs_config) to configure the permissions of all system files (system/subdirectories, files) in the above zip package. Fs_config contains a header file #include \"private/android_filesystem_config.h\". In this header file, the permissions and owners of each file in the system directory are set in a hard-coded manner. After the configuration is completed, the configured information is output to META/filesystem_config.txt as text. And once again zip into the original package we ultimately need. The second step : The above zip package is just the original package generated during the compilation process. This original zip package has two functions in the actual compilation process, one is used to generate the OTA update upgrade package, and the other is used to generate the system image. In the compilation process, if the OTA update upgrade package is generated, it will be called (the specific location is in lines 1037 to 1058 of the Makefile). A Python script named ota_from_target_files is located at /build/tools/releasetools/ota_from_target_files. The function of this script is to take the zip original package generated in the first step as input, and finally generate the available OTA upgrade zip package. Below we analyze the process of using this script to generate the final OTA upgrade package. (a) First look at the help documentation at the beginning of this script. code show as below: #!/usr/bin/env python # # Copyright (C) 2008 The Android Open Source Project # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. \"\"\" Given a target-files zipfile, produces an OTA package that installs that build. An incremental OTA is produced if -i is given, otherwise a full OTA is produced. Usage: ota_from_target_files [flags] input_target_files output_ota_package -b (--board_config) Deprecated. -k (--package_key) Key to use to sign the package (default is \"build/target/product/security/testkey\"). -i (--incremental_from) Generate an incremental OTA using the given target-files zip as the starting build. -w (--wipe_user_data) Generate an OTA package that will wipe the user data partition when installed. -n (--no_prereq) Omit the timestamp prereq check normally included at the top of the build scripts (used for developer OTA packages which legitimately need to go back and forth). -e (--extra_script) Insert the contents of file at the end of the update script. \"\"\" Let's briefly translate their use and the role of the options. Usage: ota_from_target_files [flags] input_target_files output_ota_package -b Obsolete. -k used by the -k signature -i Use this option when generating incremental OTA packages. We will use this option later to generate the OTA delta package. -w Whether to clear the userdata partition- n Whether to check the timestamp during the upgrade, the default is to check, that is, by default, it can only be upgraded based on the old version. -e Is there an extra run script - the format required to generate the script (updater-script) during the execution process. There are currently two types, amend and edify. A different interpreter will be used for the upgrade of the previous two versions. By default, scripts of both formats are generated at the same time. -p defines the path to some executable files used by the script. -s defines the path to the extra run script. -x defines the key-value pairs that may be used by additional running scripts. -v executes the executed command during execution. -h command help (b) Below we analyze how the ota_from_target_files python script generates the final zip package. Let me first post the code for this script as follows: import sys if sys.hexversion > sys.stderr, \"Python 2.4 or newer is required.\" sys.exit(1) import copy import errno import the import re import sha import subprocess import tempfile import time import zipfile import common import edify_generator OPTIONS = common.OPTIONS OPTIONS.package_key = \"build/target/product/security/testkey\" OPTIONS.incremental_source = None OPTIONS.require_verbatim = set() OPTIONS.prohibit_verbatim = set((\"system/build.prop\",)) OPTIONS.patch_threshold = 0.95 OPTIONS.wipe_user_data = False OPTIONS.omit_prereq = False OPTIONS.extra_script = None OPTIONS.worker_threads = 3 def MostPopularKey(d, default): \"\"\"Given a dict, return the key corresponding to the largest value. Returns 'default' if the dict is empty.\"\"\" x = [(v, k) for (k, v) in d.iteritems()] if not x: return default x.sort() return x[-1][1] def IsSymlink(info): \"\"\"Return true if the zipfile.ZipInfo object passed in represents a symlink.\"\"\" return (info.external_attr >> 16) == 0120777 class Item: \"\"\"Items represent the metadata (user, group, mode) of files and directories in the system image.\"\"\" ITEMS = {} def __init__(self, name, dir=False): self.name = name self.uid = None self.gid = None self.mode = None self .dir = dir if name: self.parent = Item.Get(os.path.dirname(name), dir=True) self.parent.children.append(self) else: self.parent = None if you: self.children = [] def Dump(self, indent=0): if self.uid is not None: print \"%s%s %d %d %o\" % (\" \"*indent, self.name, self.uid, self.gid, self.mode) else: print \"%s%s %s %s %s\" % (\" \"*indent, self.name, self.uid, self.gid, self.mode) if self .dir: print \"%s%s\" % (\" \"*indent, self.descendants) print \"%s%s\" % (\" \"*indent, self.best_subtree) for i in self.children: i.Dump(indent=indent+1) @classmethod def Get(cls, name, dir=False): if name not in cls.ITEMS: cls.ITEMS[name] = Item(name, dir=dir) return cls.ITEMS[name] @classmethod def GetMetadata(cls, input_zip): try: # See if the target_files contains a record of what the uid, # gid, and mode is supposed to be. output = input_zip.read(\"META/filesystem_config.txt\") except KeyError: # Run the external 'fs_config' program to determine the desired # uid, gid, and mode for every Item object. Note this uses the # one in the client now, which might not be the same as the one # used when this target_files was built. p = common.Run([\"fs_config\"], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE) suffix = { False: \"\", True: \"/\" } input = \"\".join([\"%s%s\\n\" % (i.name, suffix[i.dir]) for i in cls.ITEMS.itervalues() if i.name]) output, error = p.communicate(input) assert not error for line in output.split(\"\\n\"): if not line: continue name, uid, gid, mode = line.split() i = cls.ITEMS.get(name, None) if i is not None: i.uid = int (uid) i.gid = you (wealth) i.mode = int(mode, 8) if i.dir: i.children.sort(key=lambda i: i.name) # set metadata for the files generated by this script. i = cls.ITEMS.get(\"system/recovery-from-boot.p\", None) if i: i.uid, i.gid, i.mode = 0, 0, 0644 i = cls.ITEMS.get(\"system/etc/install-recovery.sh\", None) if i: i.uid, i.gid, i.mode = 0, 0, 0544 def CountChildMetadata(self): \"\"\"Count up the (uid, gid, mode) tuples for all children and determine the best strategy for using set_perm_recursive and set_perm to correctly chown/chmod all the files to their desired values. Recursively calls itself for all descendants. Returns a dict of {(uid, gid, dmode, fmode): count} counting up all descendants of this node. (dmode or fmode may be None.) Also sets the best_subtree of each directory Item to the (uid, gid, dmode, fmode) tuple that will match the most descendants of that Item. \"\"\" assert self .dir d = self.descendants = {(self.uid, self.gid, self.mode, None): 1} for i in self.children: if i.dir: for k, v in i.CountChildMetadata().iteritems(): d[k] = d.get(k, 0) + v else: k = (i.uid, i.gid, None, i.mode) d[k] = d.get(k, 0) + 1 # Find the (uid, gid, dmode, fmode) tuple that matches the most # descendants. # First, find the (uid, gid) pair that matches the most # descendants. and = {} for (uid, gid, _, _), count in d.iteritems(): and [(uid, gid)] = ug.get ((uid, gid), 0 ) + count and = MostPopularKey (and, ( 0 , 0 )) # Now find the dmode and fmode that match the most descendants # with that (uid, gid), and choose those. best_dmode = (0, 0755) best_fmode = (0, 0644) for k, count in d.iteritems(): if k [: 2 ]! = and: continue if k[2] is not None and count >= best_dmode[0]: best_dmode = (count, k[2]) if k[3] is not None and count >= best_fmode[0]: best_fmode = (count, k[3]) self.best_subtree = ug + (best_dmode[1], best_fmode[1]) return d def SetPermissions ( self , script): \"\"\"Append set_perm/set_perm_recursive commands to 'script' to set all permissions, users, and groups for the tree of files rooted at 'self'.\"\"\" self.CountChildMetadata() def recurse(item, current): # current is the (uid, gid, dmode, fmode) tuple that the current # item (and all its children) have already been set to. We only # need to issue set_perm/set_perm_recursive commands if we're # supposed to be something different. if item.dir: if current != item.best_subtree: script.SetPermissionsRecursive(\"/\"+item.name, *item.best_subtree) current = item.best_subtree if item.uid != current[0] or item.gid != current[1] or \\ item.mode != current[2]: script.SetPermissions(\"/\"+item.name, item.uid, item.gid, item.mode) for i in item.children: recurse(i, current) else: if item.uid != current[0] or item.gid != current[1] or \\ item.mode != current[3]: script.SetPermissions(\"/\"+item.name, item.uid, item.gid, item.mode) recurse(self, (-1, -1, -1, -1)) def CopySystemFiles(input_zip, output_zip=None, substitute=None): \"\"\"Copies files underneath system/ in the input zip to the output zip. Populates the Item class with their metadata, and returns a list of symlinks. output_zip may be None, in which case the copy is skipped (but the other side effects still happen). substitute is an optional dict of {output filename: contents} to be output instead of certain input files. \"\"\" symlinks = [] for info in input_zip.infolist(): if info.filename.startswith(\"SYSTEM/\"): basefilename = info.filename[7:] if IsSymlink(info): symlinks.append((input_zip.read(info.filename), \"/system/\" + basefilename)) else: info2 = copy.copy(info) fn = info2.filename = \"system/\" + basefilename if substitute and fn in substitute and substitute[fn] is None: continue if output_zip is not None: if substitute and fn in substitute: data = substitute[fn] else: data = input_zip.read(info.filename) output_zip.writestr(info2, data) if fn.endswith(\"/\"): Item.Get(fn[:-1], dir=True) else: Item.Get(fn, dir=False) symlinks.sort() return symlinks def SignOutput(temp_zip_name, output_zip_name): key_passwords = common.GetKeyPasswords([OPTIONS.package_key]) pw = key_passwords[OPTIONS.package_key] common.SignFile(temp_zip_name, output_zip_name, OPTIONS.package_key, pw, whole_file=True) def AppendAssertions(script, input_zip): device = GetBuildProp(\"ro.product.device\", input_zip) script.AssertDevice(device) def MakeRecoveryPatch(output_zip, recovery_img, boot_img): \"\"\"Generate a binary patch that creates the recovery image starting with the boot image. (Most of the space in these images is just the kernel, which is identical for the two, so the resulting patch should be efficient.) Add it to the output zip, along with a shell script that is run from init.rc on first boot to actually do the patching and install the new recovery image. recovery_img and boot_img should be File objects for the corresponding images. Returns an Item for the shell script, which must be made executable. \"\"\" d = common.Difference(recovery_img, boot_img) _, _, patch = d.ComputePatch() common.ZipWriteStr(output_zip, \"recovery/recovery-from-boot.p\", patch) Item.Get(\"system/recovery-from-boot.p\", dir=False) boot_type, boot_device = common.GetTypeAndDevice(\"/boot\", OPTIONS.info_dict) recovery_type, recovery_device = common.GetTypeAndDevice(\"/recovery\", OPTIONS.info_dict) # Images with different content will have a different first page, so # we check to see if this recovery has already been installed by # testing just the first 2k. HEADER_SIZE = 2048 header_sha1 = sha.sha(recovery_img.data[:HEADER_SIZE]).hexdigest() sh = \"\"\"#!/system/bin/sh if ! applypatch -c %(recovery_type)s:%(recovery_device)s:%(header_size)d:%(header_sha1)s; then log -t recovery \"Installing new recovery image\" applypatch %(boot_type)s:%(boot_device)s:%(boot_size)d:%(boot_sha1)s %(recovery_type)s:%(recovery_device)s %(recovery_sha1)s %(recovery_size)d %(boot_sha1)s:/system/recovery-from-boot.p else log -t recovery \"Recovery image already installed\" be \"\"\" % { 'boot_size': boot_img.size, 'boot_sha1': boot_img.sha1, 'header_size': HEADER_SIZE, 'header_sha1': header_sha1, 'recovery_size': recovery_img.size, 'recovery_sha1': recovery_img.sha1, 'boot_type': boot_type, 'boot_device': boot_device, 'recovery_type': recovery_type, 'recovery_device': recovery_device, } common.ZipWriteStr(output_zip, \"recovery/etc/install-recovery.sh\", sh) return Item.Get(\"system/etc/install-recovery.sh\", dir=False) def WriteFullOTAPackage(input_zip, output_zip): # TODO: how to determine this? We don't know what version it will # be installed on top of. For now, we expect the API just won't # change very often. script = edify_generator.EdifyGenerator(3, OPTIONS.info_dict) metadata = {\"post-build\": GetBuildProp(\"ro.build.fingerprint\", input_zip), \"pre-device\": GetBuildProp(\"ro.product.device\", input_zip), \"post-timestamp\": GetBuildProp(\"ro.build.date.utc\", input_zip), } device_specific = common.DeviceSpecificParams( input_zip=input_zip, input_version=OPTIONS.info_dict[\"recovery_api_version\"], output_zip=output_zip, script=script, input_tmp=OPTIONS.input_tmp, metadata=metadata, info_dict=OPTIONS.info_dict) if not OPTIONS.omit_prereq: ts = GetBuildProp(\"ro.build.date.utc\", input_zip) script.AssertOlderBuild(ts) AppendAssertions(script, input_zip) device_specific.FullOTA_Assertions() script.ShowProgress(0.5, 0) if OPTIONS.wipe_user_data: script.FormatPartition(\"/data\") script.FormatPartition(\"/system\") script.Mount(\"/system\") script.UnpackPackageDir(\"recovery\", \"/system\") script.UnpackPackageDir(\"system\", \"/system\") symlinks = CopySystemFiles(input_zip, output_zip) script.MakeSymlinks(symlinks) boot_img = common.File(\"boot.img\", common.BuildBootableImage( os.path.join(OPTIONS.input_tmp, \"BOOT\"))) recovery_img = common.File(\"recovery.img\", common.BuildBootableImage( os.path.join(OPTIONS.input_tmp, \"RECOVERY\"))) MakeRecoveryPatch(output_zip, recovery_img, boot_img) Item.GetMetadata(input_zip) Item.Get(\"system\").SetPermissions(script) common.CheckSize(boot_img.data, \"boot.img\", OPTIONS.info_dict) common.ZipWriteStr(output_zip, \"boot.img\", boot_img.data) script.ShowProgress(0.2, 0) script.ShowProgress(0.2, 10) script.WriteRawImage(\"/boot\", \"boot.img\") script.ShowProgress(0.1, 0) device_specific.FullOTA_InstallEnd() if OPTIONS.extra_script is not None: script.AppendExtra(OPTIONS.extra_script) script.UnmountAll() script.AddToZip(input_zip, output_zip) WriteMetadata(metadata, output_zip) def WriteMetadata(metadata, output_zip): common.ZipWriteStr(output_zip, \"META-INF/com/android/metadata\", \"\".join([\"%s=%s\\n\" % kv for kv in sorted(metadata.iteritems())])) def LoadSystemFiles(z): \"\"\"Load all the files from SYSTEM/... in a given target-files ZipFile, and return a dict of {filename: File object}.\"\"\" out = {} for info in z.infolist(): if info.filename.startswith(\"SYSTEM/\") and not IsSymlink(info): fn = \"system/\" + info.filename[7:] data = z.read(info.filename) out[fn] = common.File(fn, data) return out def GetBuildProp(property, z): \"\"\"Return the fingerprint of the build of a given target-files ZipFile object.\"\"\" bp = z.read(\"SYSTEM/build.prop\") if not property: return bp m = re.search(re.escape(property) + r\"=(.*)\\n\", bp) if not m: raise common.ExternalError(\"couldn't find %s in build.prop\" % (property,)) return m.group(1).strip() def WriteIncrementalOTAPackage(target_zip, source_zip, output_zip): source_version = OPTIONS.source_info_dict[\"recovery_api_version\"] target_version = OPTIONS.target_info_dict[\"recovery_api_version\"] if source_version == 0: print (\"WARNING: generating edify script for a source that \" \"can't install it.\") script = edify_generator.EdifyGenerator(source_version, OPTIONS.info_dict) metadata = {\"pre-device\": GetBuildProp(\"ro.product.device\", source_zip), \"post-timestamp\": GetBuildProp(\"ro.build.date.utc\", target_zip), } device_specific = common.DeviceSpecificParams( source_zip=source_zip, source_version=source_version, target_zip=target_zip, target_version=target_version, output_zip=output_zip, script=script, metadata=metadata, info_dict=OPTIONS.info_dict) print \"Loading target...\" target_data = LoadSystemFiles(target_zip) print \"Loading source...\" source_data = LoadSystemFiles(source_zip) verbatim_targets = [] patch_list = [] diffs = [] largest_source_size = 0 for fn in sorted(target_data.keys()): tf = target_data[fn] assert fn == tf.name sf = source_data.get(fn, None) if sf is None or fn in OPTIONS.require_verbatim: # This file should be included verbatim if fn in OPTIONS.prohibit_verbatim: raise common.ExternalError(\"\\\"%s\\\" must be sent verbatim\" % (fn,)) print \"send\", fn, \"verbatim\" tf.AddToZip(output_zip) verbatim_targets.append((fn, tf.size)) elif tf.sha1 != sf.sha1: # File is different; consider sending as a patch diffs.append(common.Difference(tf, sf)) else: # Target file identical to source. pass common.ComputeDifferences(diffs) for diff in diffs: tf, sf, d = diff.GetPatch() if d is None or len(d) > tf.size * OPTIONS.patch_threshold: # patch is almost as big as the file; don't bother patching tf.AddToZip(output_zip) verbatim_targets.append((tf.name, tf.size)) else: common.ZipWriteStr(output_zip, \"patch/\" + tf.name + \".p\", d) patch_list.append((tf.name, tf, sf, tf.size, sha.sha(d).hexdigest())) largest_source_size = max(largest_source_size, sf.size) source_fp = GetBuildProp(\"ro.build.fingerprint\", source_zip) target_fp = GetBuildProp(\"ro.build.fingerprint\", target_zip) metadata[\"pre-build\"] = source_fp metadata[\"post-build\"] = target_fp script.Mount(\"/system\") script.AssertSomeFingerprint(source_fp, target_fp) source_boot = common.File(\"/tmp/boot.img\", common.BuildBootableImage( os.path.join(OPTIONS.source_tmp, \"BOOT\"))) target_boot = common.File(\"/tmp/boot.img\", common.BuildBootableImage( os.path.join(OPTIONS.target_tmp, \"BOOT\"))) updating_boot = (source_boot.data != target_boot.data) source_recovery = common.File(\"system/recovery.img\", common.BuildBootableImage( os.path.join(OPTIONS.source_tmp, \"RECOVERY\"))) target_recovery = common.File(\"system/recovery.img\", common.BuildBootableImage( os.path.join(OPTIONS.target_tmp, \"RECOVERY\"))) updating_recovery = (source_recovery.data != target_recovery.data) # Here's how we divide up the progress bar: # 0.1 for verifying the start state (PatchCheck calls) # 0.8 for applying patches (ApplyPatch calls) # 0.1 for unpacking verbatim files, symlinking, and doing the # device-specific commands. AppendAssertions(script, target_zip) device_specific.IncrementalOTA_Assertions() script.Print(\"Verifying current system...\") script.ShowProgress(0.1, 0) total_verify_size = float(sum([i[2].size for i in patch_list]) + 1) if updating_boot: total_verify_size += source_boot.size so_far = 0 for fn, tf, sf, size, patch_sha in patch_list: script.PatchCheck(\"/\"+fn, tf.sha1, sf.sha1) so_far += sf.size script.SetProgress(so_far / total_verify_size) if updating_boot: d = common.Difference(target_boot, source_boot) _, _, d = d.ComputePatch() print \"boot target: %d source: %d diff: %d\" % ( target_boot.size, source_boot.size, len(d)) common.ZipWriteStr(output_zip, \"patch/boot.img.p\", d) boot_type, boot_device = common.GetTypeAndDevice(\"/boot\", OPTIONS.info_dict) script.PatchCheck(\"%s:%s:%d:%s:%d:%s\" % (boot_type, boot_device, source_boot.size, source_boot.sha1, target_boot.size, target_boot.sha1)) so_far += source_boot.size script.SetProgress(so_far / total_verify_size) if patch_list or updating_recovery or updating_boot: script.CacheFreeSpaceCheck(largest_source_size) device_specific.IncrementalOTA_VerifyEnd() script.Comment(\"---- start making changes here ----\") if OPTIONS.wipe_user_data: script.Print(\"Erasing user data...\") script.FormatPartition(\"/data\") script.Print(\"Removing unneeded files...\") script.DeleteFiles([\"/\"+i[0] for i in verbatim_targets] + [\"/\"+i for i in sorted(source_data) if i not in target_data] + [\"/system/recovery.img\"]) script.ShowProgress(0.8, 0) total_patch_size = float(sum([i[1].size for i in patch_list]) + 1) if updating_boot: total_patch_size += target_boot.size so_far = 0 script.Print(\"Patching system files...\") for fn, tf, sf, size, _ in patch_list: script.ApplyPatch(\"/\"+fn, \"-\", tf.size, tf.sha1, sf.sha1, \"patch/\"+fn+\".p\") so_far += tf.size script.SetProgress(so_far / total_patch_size) if updating_boot: # Produce the boot image by applying a patch to the current # contents of the boot partition, and write it back to the # partition. script.Print(\"Patching boot image...\") script.ApplyPatch(\"%s:%s:%d:%s:%d:%s\" % (boot_type, boot_device, source_boot.size, source_boot.sha1, target_boot.size, target_boot.sha1), \"-\", target_boot.size, target_boot.sha1, source_boot.sha1, \"patch/boot.img.p\") so_far += target_boot.size script.SetProgress(so_far / total_patch_size) print \"boot image changed; including.\" else: print \"boot image unchanged; skipping.\" if updating_recovery: # Is it better to generate recovery as a patch from the current # boot image, or from the previous recovery image? For large # updates with significant kernel changes, probably the former. # For small updates where the kernel hasn't changed, almost # certainly the latter. We pick the first option. Future # complicated schemes may let us effectively use both. # # A wacky possibility: as long as there is room in the boot # partition, include the binaries and image files from recovery in # the boot image (though not in the ramdisk) so they can be used # as fodder for constructing the recovery image. MakeRecoveryPatch(output_zip, target_recovery, target_boot) script.DeleteFiles([\"/system/recovery-from-boot.p\", \"/system/etc/install-recovery.sh\"]) print \"recovery image changed; including as patch from boot.\" else: print \"recovery image unchanged; skipping.\" script.ShowProgress(0.1, 10) target_symlinks = CopySystemFiles(target_zip, None) target_symlinks_d = dict([(i[1], i[0]) for i in target_symlinks]) temp_script = script.MakeTemporary() Item.GetMetadata(target_zip) Item.Get(\"system\").SetPermissions(temp_script) # Note that this call will mess up the tree of Items, so make sure # we're done with it. source_symlinks = CopySystemFiles(source_zip, None) source_symlinks_d = dict([(i[1], i[0]) for i in source_symlinks]) # Delete all the symlinks in source that aren't in target. This # needs to happen before verbatim files are unpacked, in case a # symlink in the source is replaced by a real file in the target. to_delete = [] for dest, link in source_symlinks: if link not in target_symlinks_d: to_delete.append(link) script.DeleteFiles(to_delete) if verbatim_targets: script.Print(\"Unpacking new files...\") script.UnpackPackageDir(\"system\", \"/system\") if updating_recovery: script.Print(\"Unpacking new recovery...\") script.UnpackPackageDir(\"recovery\", \"/system\") script.Print(\"Symlinks and permissions...\") # Create all the symlinks that don't already exist, or point to # somewhere different than what we want. Delete each symlink before # creating it, since the 'symlink' command won't overwrite. to_create = [] for dest, link in target_symlinks: if link in source_symlinks_d: if dest != source_symlinks_d[link]: to_create.append((dest, link)) else: to_create.append((dest, link)) script.DeleteFiles([i[1] for i in to_create]) script.MakeSymlinks(to_create) # Now that the symlinks are created, we can set all the # permissions. script.AppendScript(temp_script) # Do device-specific installation (eg, write radio image). device_specific.IncrementalOTA_InstallEnd() if OPTIONS.extra_script is not None: scirpt.AppendExtra(OPTIONS.extra_script) script.AddToZip(target_zip, output_zip) WriteMetadata(metadata, output_zip) def main(argv): def option_handler(o, a): if o in (\"-b\", \"--board_config\"): pass # deprecated elif o in (\"-k\", \"--package_key\"): OPTIONS.package_key = a elif o in (\"-i\", \"--incremental_from\"): OPTIONS.incremental_source = a elif o in (\"-w\", \"--wipe_user_data\"): OPTIONS.wipe_user_data = True elif o in (\"-n\", \"--no_prereq\"): OPTIONS.omit_prereq = True elif o in (\"-e\", \"--extra_script\"): OPTIONS.extra_script = a elif o in (\"--worker_threads\"): OPTIONS.worker_threads = int(a) else: return False return True args = common.ParseOptions(argv, __doc__, extra_opts=\"b:k:i:d:wne:\", extra_long_opts=[\"board_config=\", \"package_key=\", \"incremental_from=\", \"wipe_user_data\", \"no_prereq\", \"extra_script=\", \"worker_threads=\"], extra_option_handler=option_handler) if len(args) != 2: common.Usage(__doc__) sys.exit(1) if OPTIONS.extra_script is not None: OPTIONS.extra_script = open(OPTIONS.extra_script).read() print \"unzipping target target-files...\" OPTIONS.input_tmp = common.UnzipTemp(args[0]) OPTIONS.target_tmp = OPTIONS.input_tmp input_zip = zipfile.ZipFile(args[0], \"r\") OPTIONS.info_dict = common.LoadInfoDict(input_zip) if OPTIONS.verbose: print \"--- target info ---\" common.DumpInfoDict(OPTIONS.info_dict) if OPTIONS.device_specific is None: OPTIONS.device_specific = OPTIONS.info_dict.get(\"tool_extensions\", None) if OPTIONS.device_specific is not None: OPTIONS.device_specific = os.path.normpath(OPTIONS.device_specific) print \"using device-specific extensions in\", OPTIONS.device_specific if OPTIONS.package_key: temp_zip_file = tempfile.NamedTemporaryFile() output_zip = zipfile.ZipFile(temp_zip_file, \"w\", compression=zipfile.ZIP_DEFLATED) else: output_zip = zipfile.ZipFile(args[1], \"w\", compression=zipfile.ZIP_DEFLATED) if OPTIONS.incremental_source is None: WriteFullOTAPackage(input_zip, output_zip) else: print \"unzipping source target-files...\" OPTIONS.source_tmp = common.UnzipTemp(OPTIONS.incremental_source) source_zip = zipfile.ZipFile(OPTIONS.incremental_source, \"r\") OPTIONS.target_info_dict = OPTIONS.info_dict OPTIONS.source_info_dict = common.LoadInfoDict(source_zip) if OPTIONS.verbose: print \"--- source info ---\" common.DumpInfoDict(OPTIONS.source_info_dict) WriteIncrementalOTAPackage(input_zip, source_zip, output_zip) output_zip.close() if OPTIONS.package_key: SignOutput(temp_zip_file.name, args[1]) temp_zip_file.close() common.Cleanup() print \"done.\" if __name__ == '__main__': try: common.CloseInheritedPipes() main(sys.argv[1:]) except common.ExternalError, e: print print \" ERROR: %s\" % (e,) print sys.exit(1) The main function main is the entry function of python. Let's look at the main function. Let's take a look at the flow in the main function (the last script) to know the execution of the script. At the beginning of the main function, first save the user-set option option into the OPTIONS variable, which is a class in python. Then it is judged whether there are any additional scripts, and if so, it is read into the OPTIONS variable. Unzip the input zip package, which is the original zip package we generated above. Then determine if device-specific extensions are used, and if they are used, they are read into the OPTIONS variable. Determine whether to sign, and then determine whether there is an incremental source of new content, and if so, decompress the incremental source package into a temporary variable (source_zip). Since then, all the preparations have been completed, and the most important function in the script, WriteFullOTAPackage(input_zip,output_zip), will be called. The processing of the WriteFullOTAPackage function is to get the generator of the script first. The default format is edify. Then get the metadata metadata, which comes from some environment variables of Android. Then get the device configuration parameters such as the version of the api function. Then determine if the timestamp is ignored. After the WriteFullOTAPackage function has finished preparing, it will start to generate the upgrade script file (updater-script). After generating the script file, write the metadata metadata obtained in the previous step to the output package out_zip. A complete update.zip upgrade package is now available. The generated location is: out/target/product/tcc8800/full_tcc8800_evm-ota-eng.mumu.20120315.155326.zip. Copy the upgrade package to the SD card and you can use it to upgrade. 1.4. 4. Android OTA incremental package update.zip generation The update.zip upgrade package generated in the above process is an upgrade package for all systems. The size is more than 80M. For mobile phone users, the traffic used to upgrade is very large. And in the actual upgrade, we only hope to be able to upgrade the part of our changes. This requires an incremental package to upgrade. The process of generating an incremental package also requires the participation of ota_from_target_files.py mentioned above. The following is the process of making an update.zip delta package. In the source root directory, execute the following command in turn: \\$ build/envsetup.sh \\$ lunch Select 17 \\$ make \\$ make otapackage After executing the above command, we will generate our first system upgrade package under out/target/product/tcc8800/ . Let's name it A.zip Modify the parts we need to change in the source code, such as modifying the kernel configuration, adding new drivers, and so on. Execute the above command again after modification. A second update.zip upgrade package generated by us will be generated. Name it B.zip. In the above we looked at the help of the ota_from_target_files.py script, where the option -i is used to generate the differential delta package. The usage is based on the above A.zip and B.zip packages as input and the update.zip package as output. The generated update.zip is the last incremental package we need. The specific use is: copy the above two packages to the source root directory, and then execute the following command. \\$ ./build/tools/releasetools/ota_from_target_files -i A.zip B.zip update.zip An error that did not find recovery_api_version occurred when executing the above command. The reason is that if you use the option i when executing the above script, WriteIncrementalOTAPackage will be called to search for misc_info.txt from the META directory in the A and B packages to read the value of recovery_api_version. However, there is no such directory in the update.zip package generated when executing the make otapackage command. At this point we need to use the original zip package generated by the make otapackage. The location of this package is in the out/target/product/tcc8800/ obj /PACKAGING/target_files_intermediates/ directory . It is the intermediate production after the command make otapackage, which is the most original upgrade package. We rename the generated packages of the two compilations to A.zip and B.zip respectively, and copy them to the SD card root directory to execute the above commands repeatedly: \\$ ./build/tools/releasetools/ota_form_target_files -i A.zip B.zip update.zip When the above command is about to be executed, IncrementalOTAInstallEnd will be called at _device/telechips/common/releasetools.py, and RADIO/bootloader.img in the package will be read in this function. There is no such directory and bootloader.img in the package. So the execution failed and the corresponding update.zip could not be generated. May be related to our unmodified bootloader. This issue has been resolved in the next blog. In the next article, explain the reasons for the failure to make incremental packages and the solution. "},"Android OTA - Android OTA upgrade principle and process analysis 2.html":{"url":"Android OTA - Android OTA upgrade principle and process analysis 2.html","title":"Android OTA - Android OTA upgrade principle and process analysis 2","keywords":"","body":"1. Android OTA upgrade principle and process analysis (2) -- update.zip differential package problem solving1.1. Android1. Android OTA upgrade principle and process analysis (2) -- update.zip differential package problem solving July 04, 2016 09:37:43 blast - Bevis reading number: 885 tags: ota Personal Category: Android-OTA Reprinted from: http://blog.chinaunix.net/uid-22028566-id-3533849.html Android OTA upgrade principle and process analysis (2) -- update.zip differential package problem solving Android ---- start making changes here ---- 1.1. Android OTA upgrade principle and process analysis (1)--production of update.zip package The problem that occurred when generating the differential package mentioned at the end of the previous article has been solved. Due to the recent busy schedule, the time between them is longer, so a single column prompts everyone. This problem is actually a problem in the source code, you may have succeeded in production, but my problem is indeed a problem in the source code, I do not know if it is a bug, the following will be specifically analyzed! First, the solution to generate OTA incremental package failure At the end of the previous article, using the ota_from_target_files script to make the update.zip delta package failed. We first posted the error . An error occurred while reading RADIO/bootloader.img in input_zip at the end of this script, indicating that there is no input_zip attribute in the DeviceSpecifiParams object. Let's start by looking up the calling function that has the error in the script. The place where the error occurred is the device_specific.IncrementalOTA_InstallEnd() in the WriteIncrementalOTAPackage (line 443), which is located at the end of WriteIncrementalOTAPackage(). Further tracking source discovery, this is a callback function, his specific implementation method is located in the source / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / The following is an analysis of the role of this function. The two functions in the releasetools.py script, FullOTA_InstallEnd() and IncrementalOTA_InstallEnd(), are used to read the RADIO/bootloader.img file from the input package and write it to the output package. At the same time, the script is executed when the bootloader.img is installed. That part of the order. Just one is to directly write the bootloader.img image in the input package to the output package. One is to compare whether the bootloader.img in target_zip and source_zip is different (when the option -i is used to generate the differential package), then the new image will be compared. Write to the output package. Let's post the specific implementation of this function (located in /device/telechips/common/releasetools.py): Our actual situation is that there is no bootloader.img image file in the RADIO directory when the command make otapackage is generated (because this part of the update has been blocked). However, in this function, there is an error handling for the case where the bootloader.img file is not read from the package, that is, it is returned. So we have to find the cause of the problem from the actual errors that have occurred. The real mistakes are: Target_bootloader=info.input_zip.read(\"RADIO/bootloader.img\"). The reason for the error is: AttributeError: 'DeviceSpecificParams' object has no attribute 'input_zip', prompting us that the DeviceSpecificParams object does not have the input_zip attribute. The option -i was used when making the difference package with the ota_from_target_files script, and only three parameters were used in this case, namely target_zip, source_zip, out_zip. The error is target_bootloader=info.input_zip_read(\"RADIO/bootloader.img\"), which uses input_zip. We have to wonder if this place is used incorrectly, but instead use info.target_zip.read().The following can confirm our guess. From the ota_from_target_files script, the WriteFullOTAPackage() and WriteIncrementalOTAPackage functions (which are used to generate all-inclusive and differential packages, respectively) can be found that device_specific is assigned at the beginning of their section. The parameters corresponding to WriteFullOTAPackage() are input_zip and out_zip, and WriteIncrementalOTAPackage corresponds to target_zip, source_zip, out_zip. We can look at the specific implementation of this part in the WriteIncrementalOTAPackage function: As you can see from the figure above, the WriteIncrementalOTAPackage function does use target_zip instead of input_zip when initializing the DeviceSpecificParams object. In the releasetools.py script, info.input_zip.read() is used, so the DeviceSpecificParams object does not have the input_zip attribute. From this we found the problem (is this a bug in the source code?). The releasetools.py script in the IncrementalOTA_InstallEnd(info) function in target_bootloader=info.input_zip. Read(\"RADIO/bootloader.img\") is: target_bootloader=info.target_zip.read(\"RADIO/bootloader.img\"), and then re-execute the Make Differential Packets command mentioned above. The generated differential package update.zip is generated. Second, the update test of the differential package update.zip In the above-mentioned difference package script command, the principle of generating a differential packet is to output the different part of the second parameter (source_zip) to the third parameter (output_zip) with reference to the first parameter (target_zip). The order of target_zip and source_zip is different, and the generated differential packets will also be different. In the actual test process, our incremental package is to delete an application that was added before (added when using the update.zip package upgrade), and other parts such as the kernel have not changed, so the generated differential package is very simple. Only META-INF this folder. The main difference is reflected in the updater-script script, where #----start make changes here----the latter part is the part that makes the change, the main script command is: delete(\"/system/ App/CheckUpdateAll.apk\" , \"/system/recovery.img\"); it will remove the CheckUpdateAll.apk app when it is updated. For your reference, the upgrade script for this differential package is posted, and the corresponding fully upgraded script has been posted in the ninth article : Mount(\"yaffs2\", \"MTD\", \"system\", \"/system\"); Assert(file_getprop(\"/system/build.prop\", \"ro.build.fingerprint\") == \"telechips/full_tcc8800_evm/tcc8800:2.3.5/GRJ90/eng.mumu.20120309.100232:eng/test-keys\" || File_getprop(\"/system/build.prop\", \"ro.build.fingerprint\") == \"telechips/full_tcc8800_evm/tcc8800:2.3.5/GRJ90/eng.mumu.20120309.100232:eng/test-keys\"); Assert(getprop(\"ro.product.device\") == \"tcc8800\" || Getprop(\"ro.build.product\") == \"tcc8800\"); Ui_print(\"Verifying current system...\"); Show_progress(0.100000, 0); # ---- start making changes here ---- Ui_print(\"Removing unneeded files...\"); Delete(\"/system/app/CheckUpdateAll.apk\", \"/system/recovery.img\"); Show_progress(0.800000, 0); Ui_print(\"Patching system files...\"); Show_progress(0.100000, 10); Ui_print(\"Symlinks and permissions...\"); Set_perm_recursive(0, 0, 0755, 0644, \"/system\"); Set_perm_recursive(0, 2000, 0755, 0755, \"/system/bin\"); Set_perm(0, 3003, 02750, \"/system/bin/netcfg\"); Set_perm(0, 3004, 02755, \"/system/bin/ping\"); Set_perm(0, 2000, 06750, \"/system/bin/run-as\"); Set_perm_recursive(1002, 1002, 0755, 0440, \"/system/etc/bluetooth\"); Set_perm(0, 0, 0755, \"/system/etc/bluetooth\"); Set_perm(1000, 1000, 0640, \"/system/etc/bluetooth/auto_pairing.conf\"); Set_perm(3002, 3002, 0444, \"/system/etc/bluetooth/blacklist.conf\"); Set_perm(1002, 1002, 0440, \"/system/etc/dbus.conf\"); Set_perm(1014, 2000, 0550, \"/system/etc/dhcpcd/dhcpcd-run-hooks\"); Set_perm(0, 2000, 0550, \"/system/etc/init.goldfish.sh\"); Set_perm_recursive(0, 0, 0755, 0555, \"/system/etc/ppp\"); Set_perm_recursive(0, 2000, 0755, 0755, \"/system/xbin\"); Set_perm(0, 0, 06755, \"/system/xbin/librank\"); Set_perm(0, 0, 06755, \"/system/xbin/procmem\"); Set_perm(0, 0, 06755, \"/system/xbin/procrank\"); Set_perm(0, 0, 06755, \"/system/xbin/su\"); Set_perm(0, 0, 06755, \"/system/xbin/tcpdump\"); Unmount(\"/system\"); When doing the update test, we should base on the target_zip system, that is, the development board system before the update is the system upgraded with the target_zip package. Otherwise, the update will fail, because the device and the timestamp and other information (the part of the updater-script script at the beginning) will be read from the corresponding directory of the system during the update, and the next step will be installed after the matching is correct. After all the preparations are completed, put the differential package we made into the SD card and perform the update in Settings-->About Phone-->System Update-->Installed From SDCARD. After the final update is complete and restarted, we will find that the previous CheckUpdateAll.apk was successfully deleted, and you're done! At this point, the update.zip package and its corresponding differential package have finally been successfully created. The following article begins to analyze the process of the update.zip package produced in the actual update! "},"Android OTA - Android OTA upgrade principle and process analysis 3.html":{"url":"Android OTA - Android OTA upgrade principle and process analysis 3.html","title":"Android OTA - Android OTA upgrade principle and process analysis 3","keywords":"","body":"1. Android OTA upgrade principle and process analysis (3) --- three startup modes of Android system1.1. (1) MAGIC KEY (combination key):1.2. (2) Normal start:1. Android OTA upgrade principle and process analysis (3) --- three startup modes of Android system July 04, 2016 09:38:51 Blast - Bevis Reads: 450 Tags: ota Personal Category: Android-OTA Android OTA upgrade principle and process analysis (3) --- three startup modes of Android system Reprinted from: http://blog.chinaunix.net/uid-22028566-id-3533851.html Android OTA upgrade principle and process analysis (3) --- three startup modes of Android system (1) MAGIC KEY (combination key): (2) Normal start: The following pages begin to analyze the process that we have in the update of the update.zip package generated in the last two pages, and analyze how each part works according to the source code. First, the system updates the update.zip package in two ways From the previous document, we learned how to make an update.zip upgrade package for upgrading the system. There are two ways for Android to get the update.zip package when upgrading the system. One is offline upgrade, that is, manually copy the upgrade package to the SD card (or NAND), and select to upgrade from the SD card through settings-->About phone-->System Update-->. The other is an online upgrade, which is OTA Install (over the air). The user downloads the upgrade package online to the local and then updates. The update.zip package in this way is generally downloaded to the /CACHE partition of the system. Regardless of where the upgrade package is placed, it will be restarted and enter Recovery mode when using update.zip update, then start the recovery service (/sbin/recovery) to install our update.zip package. To do this, we must understand how Recovery mode works and how to enter Recovery mode when the Android system restarts instead of other modes (such as normal mode). Second, the three startup modes in the Android system First of all, we need to understand several working modes that the Android system may enter after it starts. First look at the picture below: From the above figure, we can see that the Android system may enter the following modes: 1.1. (1) MAGIC KEY (combination key): That is, the user enters different working modes by pressing the combination key after starting, and there are two specific types: power + vol-: If the user presses the power + vol- key at the beginning of the boot, it will enter the bootloader mode and further enter the fastboot mode. power + vol+: If the user presses the power + vol+ key combination at the beginning of the startup , the system will directly enter the Recovery mode. When entering Recovery mode in this way, the system will enter a simple UI (using the minii) interface to prompt the user for further operations. Several options are available in the tcc8800 development board: \"reboot system now\" \"apply update from sdcard\" \"wipe data/factory reset\" \"wipe cache partition\" 1.2. (2) Normal start: If the user does not press any combination key during the startup process, the bootloader will read the Bootloader Control Block (BCB) located in the MISC partition. It is a structure that holds the start command command. According to different commands, the system can enter three different startup modes. Let's take a look at the definition of this structure. Struct bootloader_message{ Char command[32]; //Store different startup commands Char status[32]; //update-radio or update-hboot completes the execution result Char recovery[1024]; //Store the commands in /cache/recovery/command }; Let's first look at the possible values ​​of command, others will be analyzed in detail later. There are two possible values ​​for command, and the three startup modes are distinguished from the null value (ie, no command). When 1. command==\"boot-recovery\", the system will enter Recovery mode. The Recovery service will perform the corresponding operations according to the commands in /cache/recovery/command (for example, upgrade update.zip or erase cache, data, etc.). When 2. command==\"update-radia\" or \"update-hboot\", the system will enter the update firmware (update bootloader), which is completed by the bootloader. When 3. command is empty, there is no command, the system will enter the normal startup, and finally enter the main system (main system). This is the most common startup process. The entry of different startup modes of the Android system is triggered under different situations. When we upgrade our update.zip from the SD card, we will enter the Recovery mode, one of which is: the system crashes, or the command line Entering the startup command will also enter Recovery or other startup mode. In order to understand how our update.zip package is updated in Recovery mode and restarted to the main system, we also need to analyze how Recovery mode works in Android. The next one begins with a look at how the specific Recovery model works and how it plays an important role in the update. "},"Android OTA - Android OTA upgrade principle and process analysis 4.html":{"url":"Android OTA - Android OTA upgrade principle and process analysis 4.html","title":"Android OTA - Android OTA upgrade principle and process analysis 4","keywords":"","body":"1. Android OTA upgrade principle and process analysis (4) --Android system Recovery mode works1.1. 1. The three parts of the Recovery mode1.2. 2. Two communication interfaces in Recovery mode1.2.1. (a) Through the three files in the CACHE partition:1.2.2. (b) Through the BCB (Bootloader Control Block):1.3. 3. how to restart from the Main System and enter the Recovery mode1. Android OTA upgrade principle and process analysis (4) --Android system Recovery mode works July 04, 2016 09:39:45 blast - Bevis reading number: 461 Tags: ota Personal Category: Android-OTA Android OTA upgrade principle and process analysis (4) --- Android system Recovery mode works Reprinted from: http://blog.chinaunix.net/uid-22028566-id-3533853.html Android OTA upgrade principle and process analysis (4) --Android system Recovery mode works 1. The three parts of the Recovery mode 2. Two communication interfaces in Recovery mode (a) Through the three files in the CACHE partition: (b) Through the BCB (Bootloader Control Block): 3. how to restart from the Main System and enter the Recovery mode How to reset from the main system to the Recovery mode when using the update.zip package, how to determine what to do after entering the Recovery mode, and how to get the command sent by the main system to the Recovery service, solve this series of problems. It is done through close communication between different parts of the entire software platform. To do this, we must understand how Recovery mode works so that we know how our update.zip package stepped into Recovery and finally reached the main system. 1.1. 1. The three parts of the Recovery mode The work of Recovery requires the cooperation of the entire software platform. From the perspective of communication architecture, there are three main parts. MainSystem: The normal startup mode mentioned above (no command in BCB) is the system started by boot.img, the normal working mode of Android. When updating, our upper layer operation in this mode is to use OTA or upgrade the update.zip package from the SD card. Before rebooting into Recovery mode, a command is written to BCB to tell bootloader to enter Recovery mode after reboot. Recovery: After the system enters Recovery mode, it will load the Recovery partition, which contains recovery.img (same as boot.img, including the standard kernel and root file system). After entering this mode, the main operation is to run the Recovery service (/sbin/recovery) to do the corresponding operations (restart, upgrade update.zip, erase cache partition, etc.). Bootloader: In addition to the normal load boot system, the message to the Main system and Recovery is obtained by reading the MISC partition (BCB). 1.2. 2. Two communication interfaces in Recovery mode The communication between the above three entities in the Recovery service is indispensable, and they have the following two communication interfaces with each other. 1.2.1. (a) Through the three files in the CACHE partition: Recovery communicates with the mian system through three files in the /cache/recovery/ directory. details as follows /cache/recovery/command: This file holds the command line that the Main system passes to Recovery. Each line is a command that supports several combinations. --send_intent=anystring //write the text out to recovery/intent At the end of Recovery, pass the defined intent string as a parameter in the finish_recovery function and write it to /cache/recovery/intent --update_package=root:path //verify install an OTA package file Main system When this command is written, it means the system needs to be upgraded. After entering the Recovery mode, the commands in the file are read and written into the BCB. Then perform the corresponding update update.zip package operation. --wipe_data //erase user data(and cache), then reboot. Erase user data. The cache partition must be erased when erasing the data partition. --wipe_cache //wipe cache(but not user data), then reboot. Erase the cache partition. /cache/recovery/log: The log printing of the Recovery mode at work. During the recovery service run, stdout and stderr will be relocated to /tmp/recovery.log and will be dumped to /cache/recovery/log for recovery before the recovery exits. /cache/recovery/intent: The information that Recovery passes to the Main system. The effect is unknown. 1.2.2. (b) Through the BCB (Bootloader Control Block): BCB is the communication interface between bootloader and Recovery, and also the communication interface between Bootloader and Main system. The MISC partition stored in the flash occupies three pages, which itself is a structure. The specific members and members have the following meanings: Struct bootloader_message{ Char command[32]; Char status[32]; Char recovery[1024]; }; command member: its possible value we have analyzed above, that is, when we want to restart into Recovery mode, it will update the value of this member. In addition, when the recovery is completed after the successful update, the value of this member will be cleared to prevent the Recover mode from being entered again during the restart. status: After completing the corresponding update, the bootloader will write the execution result to this field. recovery: Can be written by the Main System or written by the Recovery service program.The content format of the file is: \"recovery\\\\n \\\\\\n \\\" The file stores a string that must start with recovery\\n, otherwise all content fields of this field will be ignored. The part after \"recovery\\n\" is the command supported by /cache/recovery/command. It can be understood as a backup of command operations during the Recovery operation. The process of Recovery is as follows: first read BCB and then read /cache/recovery/command, then rewrite the two back to BCB, so that before entering the Main system, ensure that the operation is executed. Before entering the Main system after the operation, Recovery will clear the command domain and recovery domain of the BCB, so that it will not enter the Recovery mode after the restart. 1.3. 3. how to restart from the Main System and enter the Recovery mode Let's first look at how the above three parts communicate. Let's look at the following picture: We only look at how the Main System enters the Recovery mode. Other communications are detailed later. Start with the Main System. When we upgrade using the update.zip package on the Main System, the system will reboot and enter Recovery mode. Before the system restarts, we can see that the Main System will write a boot-recovery (pink line) to the command field in the BCB to tell the bootloader to enter the recovery mode after rebooting. This step is a must. As for whether the Main System writes values ​​to the recovery domain, we are not sure about this in the source code. Even so, after rebooting into Recovery mode, the bootloader will read the value from /cache/recovery/command and put it into the recovery domain of BCB. The Main System will definitely write the operation commands that Recovery will take to /cache/recovery/command before restarting. At this point, we probably know that when the upper layer uses the update.zip upgrade, the main system tells the system after the restart to enter the Recovery mode, and what kind of operation is done in the Recovery mode. The next one begins the analysis of the first phase, that is, when we upgrade with the update.zip package in the upper layer, how does the Main System restart and enter the details of the Recovery service? "},"Android OTA - Android OTA upgrade principle and process analysis 5.html":{"url":"Android OTA - Android OTA upgrade principle and process analysis 5.html","title":"Android OTA - Android OTA upgrade principle and process analysis 5","keywords":"","body":"1. Android OTA upgrade principle and process analysis (5) --- update.zip package from the upper layer into the Recovery service1.1. 1. From System Update to Reboot1.2. 2. From reboot to Recovery service1. Android OTA upgrade principle and process analysis (5) --- update.zip package from the upper layer into the Recovery service July 04, 2016 09:40:52 Blast - Bevis Reads: 391 Tags: ota Personal Category: Android-OTA Android system Recovery works using update.zip upgrade process analysis (5) --- update.zip package from the upper layer into the Recovery service Reprinted from: http://blog.chinaunix.net/uid-22028566-id-3533854.html Android OTA upgrade principle and process analysis (5) --- update.zip package from the upper layer into the Recovery service 1. From System Update to Reboot 2. From reboot to Recovery service At the beginning of the article, we mentioned that there are two sources of update.zip package, one is OTA online download (generally downloaded to /CACHE partition), one is manually copied to the SD card. Either way, the update.zip package is not processed before entering the Recovery mode. Just tell the Recovery service the path to the zip package before restarting (by writing the --update_package= CACHE:some_filename.zip or --update_package=SDCARD:update.zip command to /cache/recovery/command). Here we assume that the update.zip package has been created and copied to the SD card, and upgraded by Settings-->About Phone-->System Update-->Installed From SDCARD. Our test development board is TCC8800, the Android source code used is gingerbread0919, and the source code upgraded in this way is located under gingerbread/device/telechips/ common/apps/TelechipsSystemUpdater/src/com/telechips/android/systemupdater/. Below we specifically analyze this upgrade method, how our update.zip stepped into the Recovery mode from the upper layer. 1.1. 1. From System Update to Reboot When we select Settings-->About Phone-->System Update-->Installed From SDCARD, a dialog box will pop up, indicating whether the update.zip package is updated now, we are tracking from this place. The source code for this dialog is SystemUpdateInstallDialog.java. In the listen event of the mNowButton button, mService.rebootAndUpdate(new File(mFile)) is called. This mService is an instance of SystemUpdateService. The source file for this class is SystemUpdateService.java. The argument to this function is a file. It is definitely our update.zip package.We can confirm this conjecture. mFile value: In the ServiceConnection in SystemUpdateInstallDialog.java we can see that the value of this mFile has two sources. Source 1: One source of mFile is whether this immediately updates the value of the previous Activity accepted by the \"file\" tag. This Activity is SystemUpdate.java. It is a PreferenceActivity type. The value passed to the next Activity is defined in its onPreferenceChange function, which is based on our different choices. If we chose to install from the SD card before, then the passed \"file\" value is \"/sdcard/update.zip\". If you choose to install from NAND, the corresponding value is \"/nand/update.zip\". Source 2: Another source is obtained from mService.getInstallFile(). We can further trace that the value obtained by the above function is \"/cache\"+ mUpdateFileURL.getFile(); this is the corresponding file path after OTA online download. Regardless of the source of the parameter mFile, we can find that in the listen event of the mNowButton button, the entire file, that is, our update.zip package, is passed as a parameter to rebootAndUpdate(). rebootAndUpdate: In this function, the Main System is ready to restart. Continue tracking will find that a new thread is created in the rebootAndUpdate function in SystemUpdateService.java. The last call in this thread is RecoverySystem.installPackage(mContext,mFile), and our update.zip package is also passed in. RecoverySystem class: The path of the source code of the RecoverySystem class is: gingerbread0919/frameworks/base/core/java/android/os/RecoverySystem.java. We are concerned with the installPackage(Context context, FilepackageFile) function. This function first obtains the absolute path filename of the package file based on the package file we passed. Then put it into arg=“--update_package=”+filename. It will eventually be written to the BCB. This is the operation that the Recovery service will perform after rebooting into Recovery mode. It is passed to the function bootCommand(context, arg). bootCommand (): In this function is the preparation of the Main System before the restart. The main thing is to do the following: First create the /cache/recovery/ directory, delete the backup of the command and log (may not exist) files in this directory in the sqlite database. Then write the arg command from step 4 above to the /cache/recovery/command file. The next step is to really restart. Let's take a look at what is done in the restart function reboot. pm.reboot(): Get PowerManager (power management) and get its system services before rebooting. Then the pm.reboot(\"recovery\") function is called. He is the reboot function in /gingerbread0919/bionic/libc/unistd/reboot.c. This function is actually a system call, ie __reboot(LINUX_REBOOT_MAGIC1, LINUX_REBOOT_MAGIC2, mode, NULL); from this function we can see that the first two parameters represent our combination key, and mode is the \"recovery\" we passed over. Further tracking goes to the assembly code, we can not directly see its specific implementation details. But what is certain is that this function only passes the \"recovery\" parameter, and then writes \"boot-recovery\" to the command field of the BCB block of the MISC partition. This way the bootloader knows to enter the Recovery mode after the reboot. Here we are not sure whether the Main System has operated on the BCB recovery domain before restarting. In fact, it is not important to update the recovery domain of BCB before restarting. After entering the Recovery service, Recovery will automatically read the operation to be performed in /cache/recovery/command and then write to the recovery domain of BCB. At this point, the Main System starts to reboot and enters Recovery mode. The most essential thing that Main System does before this is two things. One is to write \"boot-recovery\" to the command field of BCB, and the second is --update_package=/cache/update.zip\" or \"--update_package =/sdcard/update.zip\" is written to the /cache/recovery/command file. The following sections will restart and enter the Recovery service. 1.2. 2. From reboot to Recovery service This process we have already mentioned above (cf. the first figure) has already been said. Starting from the bootloader, if there is no key combination pressed, the command field of the BCB block is read from the MISC partition (the \"boot-recovery\" has been written in the main system). Then start in Recovery mode. Unlike normal startup, the image loaded in Recovery mode is recovery.img. This image is similar to boot.img and includes the standard kernel and root file system. It is then similar to a normal boot system, starting the kernel and then starting the file system. /init is executed after entering the file system. The init configuration file is /init.rc. This configuration file comes from bootable/ recovery/etc/init.rc. Looking at this file we can see that it does something very simple: 1. Set environment variables. 2. establish an etc connection. 3. create a new directory, spare. 4. mount /tmp for the memory file system tmpfs 5. Start the recovery (/sbin/recovery) service. 6. start the adbd service (for debugging). The most important thing here is of course the recovery service. We will complete our upgrade work in the Recovery service. We will analyze the details of the process of the Recovery service in detail in the next article. "},"Android OTA - Android OTA upgrade principle and process analysis 6.html":{"url":"Android OTA - Android OTA upgrade principle and process analysis 6.html","title":"Android OTA - Android OTA upgrade principle and process analysis 6","keywords":"","body":"1. Android OTA upgrade principle and process analysis (6)---Recovery service process details1.1. 1. Recovery's three types of services:1.2. 2. The general process of the Recovery service:1. Android OTA upgrade principle and process analysis (6)---Recovery service process details July 04, 2016 09:42:23 Blast - Bevis reading number: 364 Tags: ota Personal Category: Android-OTA Android system Recovery works using update.zip upgrade process analysis (six)---Recovery service process details Reprinted from: http://blog.chinaunix.net/uid-22028566-id-3533855.html Android OTA upgrade principle and process analysis (6)---Recovery service process details 1. Recovery's three types of services: 2. The general process of the Recovery service: The Recovery service is undoubtedly the most central part of the Recovery startup model. It does all the work of Recovery mode. The source files for the Recovery program are located at: /gingerbread0919/bootable/recovery/recovery.c. 1.1. 1. Recovery's three types of services: Let's take a look at a large section of the comments at the beginning of this source file, which will help us understand the main features of the Recovery service. code show as below: /* * The recovery tool communicates with the main system through /cache files. * /cache/recovery/command - INPUT - command line for tool, one arg per line * /cache/recovery/log - OUTPUT - combined log file from recovery run(s) * /cache/recovery/intent - OUTPUT - intent that was passed in * * The arguments which may be supplied in the recovery.command file: * --send_intent=anystring - write the text out to recovery.intent * --update_package=path - verify install an OTA package file * --wipe_data - erase user data (and cache), then reboot * --wipe_cache - wipe cache (but not user data), then reboot * --set_encrypted_filesystem=on|off - enables / diasables encrypted fs * * After completing, we remove /cache/recovery/command and reboot. * Arguments may also be supplied in the bootloader control block (BCB). * These important scenarios must be safely restartable at any point: * * FACTORY RESET * 1. user selects \"factory reset\" * 2. main system writes \"--wipe_data\" to /cache/recovery/command * 3. main system reboots into recovery * 4. get_args() writes BCB with \"boot-recovery\" and \"--wipe_data\" * -- after this, rebooting will restart the erase -- * 5. erase_volume() reformats /data * 6. erase_volume() reformats /cache * 7. finish_recovery() erases BCB * -- after this, rebooting will restart the main system -- * 8. main() calls reboot() to boot main system * * OTA INSTALL * 1. main system downloads OTA package to /cache/some-filename.zip * 2. main system writes \"--update_package=/cache/some-filename.zip\" * 3. main system reboots into recovery * 4. get_args() writes BCB with \"boot-recovery\" and \"--update_package=...\" * -- after this, rebooting will attempt to reinstall the update -- * 5. install_package() attempts to install the update * NOTE: the package install must itself be restartable from any point * 6. finish_recovery() erases BCB * -- after this, rebooting will (try to) restart the main system -- * 7. ** if install failed ** * 7a. prompt_and_wait() shows an error icon and waits for the user * 7b; the user reboots (pulling the battery, etc) into the main system * 8. main() calls maybe_install_firmware_update() * ** if the update contained radio/hboot firmware **: * 8a. m_i_f_u() writes BCB with \"boot-recovery\" and \"--wipe_cache\" * -- after this, rebooting will reformat cache & restart main system -- * 8b. m_i_f_u() writes firmware image into raw cache partition * 8c. m_i_f_u() writes BCB with \"update-radio/hboot\" and \"--wipe_cache\" * -- after this, rebooting will attempt to reinstall firmware -- * 8d. bootloader tries to flash firmware * 8e. bootloader writes BCB with \"boot-recovery\" (keeping \"--wipe_cache\") * -- after this, rebooting will reformat cache & restart main system -- * 8f. erase_volume() reformats /cache * 8g. finish_recovery() erases BCB * -- after this, rebooting will (try to) restart the main system -- * 9. main() calls reboot() to boot main system * * SECURE FILE SYSTEMS ENABLE/DISABLE * 1. user selects \"enable encrypted file systems\" * 2. main system writes \"--set_encrypted_filesystems=on|off\" to * /cache/recovery/command * 3. main system reboots into recovery * 4. get_args() writes BCB with \"boot-recovery\" and * \"--set_encrypted_filesystems=on|off\" * -- after this, rebooting will restart the transition -- * 5. read_encrypted_fs_info() retrieves encrypted file systems settings from /data * Settings include: property to specify the Encrypted FS istatus and * FS encryption key if enabled (not yet implemented) * 6. erase_volume() reformats /data * 7. erase_volume() reformats /cache * 8. restore_encrypted_fs_info() writes required encrypted file systems settings to /data * Settings include: property to specify the Encrypted FS status and * FS encryption key if enabled (not yet implemented) * 9. finish_recovery() erases BCB * -- after this, rebooting will restart the main system -- * 10. main() calls reboot() to boot main system */ From the comments we can see that there are three main types of Recovery services: FACTORY RESET, restore factory settings. OTA INSTALL, our update.zip package upgrade. ENCRYPTED FILE SYSTEM ENABLE/DISABLE, enables/disables the encrypted file system. The specific workflow of each type of service is detailed in the notes. We will explain the workflow of OTA INSTALL in detail below. The approximate processes of these three types of services are common, but different operations and different operational details. Let's look at the general flow of the Recovery service. 1.2. 2. The general process of the Recovery service: Here we take the OTA INSTALL process as an example for specific analysis. And start from the call process diagram of the relevant function, as shown below: We follow the flowchart analysis and start with the main function of recovery.c: ui_init(): The Recovery service uses a simple ui (miniui) system based on framebuffer. This function simply initializes it. In the process of the Recovery service, it is mainly used to display a background image (installation or installation failure) and a progress bar (for displaying progress). In addition, two threads are started, one for processing the progress bar display (progress_thread) and the other for responding to the user's button (input_thread). get_arg(): This function mainly does the work of get_arg() in the above figure going down to parse arg/v. We look at the process one by one. get_bootloader_message(): The main job is to read the BCB data block from the MISC partition into a temporary variable according to the partition's file format type (mtd or emmc). Then start to determine whether the Recovery service has a parameter with the command line (/sbin/recovery, which is not according to the existing logic), if not, read the recovery domain from the BCB. If the read fails, it is read from /cache/recovery/command and then. Thus the recovery field in the temporary variable of this BCB is updated. Before the temporary variable of this BCB is written back to the real BCB, the command field of the updated BCB temporary variable is \"boot-recovery\". The purpose of this is that if the upgrade fails (for example, if the upgrade is not completed, the system will be powered off), the system will enter Recovery mode after the restart, until the upgrade is completed. After each domain of this BCB temporary variable is updated, use set_bootloader_message() to write back to the real BCB block. This process can be summarized with a simple diagram, which is clearer: parserargc/argv: parsing we get the parameters. Register the parsed command (register_update_command), in the following operation, it will judge step by step according to the value parsed in this step, and then perform the corresponding operation. if (update_package): Determines whether update_package has a value. If it is, it indicates that the update package needs to be upgraded. At this time, install_package() is called (that is, the second phase of red in the figure). In this step you will be done installing the actual upgrade package. This is the most complex and the most essential part of upgrading the update.zip package. We analyze this process in detail in the next section. In order to understand the framework of the Recovery service from a macro perspective, we will skip this step first, assuming that the installation is complete. We then go down and see how Recovery will end the service step by step after the installation is complete and reboot to the new main system. if(wipe_data/wipe_cache): This step is actually two steps. In the source code, it is first judged whether to erase the data partition (user data part), and then judge whether to erase the cache partition. It is worth noting that the erase partition must be erased when erasing the data partition. The data partition may not be erased in the case where only the cache partition is erased. maybe_install_firmware_update(): This function is called if the upgrade package contains an update to /radio/hboot firmware. Check the source code to find out that there is this process in the annotation (OTA INSTALL). However, this function is not shown in the main function. It has not yet been discovered exactly where it is handled. But the process is the same as the one above. That is, 1 first writes the \"boot-recovery\" and \"-wipe_cache\" to the BCB and then formats the cache partition, and then writes the firmware image to the original cache partition. 2 Write the commands \"update-radio/hboot\" and \"-wipe_cache\" to the BCB, then start reinstalling the firmware and refreshing the firmware. 3 will then enter the end of the illustration, namely finish_recovery(). prompt_and_wait(): This function is called in a judgment. The implication is that if the installation fails (update.zip package error or verification signature failed), then wait for the user's input processing (such as through the key combination reboot, etc.). finish_recovery(): This is the only way for Recovery to close and enter the Main System. The general process is as follows: Pass the contents of the intent (string) as a parameter into the finish_recovery. If there is an intent to tell the Main System, write it to /cache/recovery/intent. The role of this intent is still unknown. Copy the log (/tmp/recovery.log) of the Recovery service in the memory file system to the cache (/cache/recovery/log) partition to tell what happened to the Main System after the restart. Erase the contents of the BCB data block in the MISC partition, so that after the system restarts, it does not enter the Recovery mode but enters the updated main system. Delete the /cache/recovery/command file. This step is also very important, because the bootloader will automatically retrieve this file after rebooting, and will enter Recovery mode if it is not deleted. The principle has been clearly stated above. reboot(): This is a system call. In this step Recovery completes its service restart and enters the Main System. This restart is the same as the function that restarts the call to Recovery mode in the main system, but the direction is different. So the parameters are different. Check the source code to find that its restart mode is RB_AUTOBOOT. This is a system macro. At this point, we have a general understanding of the entire process framework of the Recovery service. The following is the second phase of upgrading the update.zip package and the core of the Recovery service. That is the branch of red 2 in our legend. We will explain this part in detail in the next article, the install_package function, the core part of the Recovery service. "},"Android OTA - Android OTA upgrade principle and process analysis 7.html":{"url":"Android OTA - Android OTA upgrade principle and process analysis 7.html","title":"Android OTA - Android OTA upgrade principle and process analysis 7","keywords":"","body":"1. Android OTA upgrade principle and process analysis (7)---Recovery service core install_package function1.1. 1. The core of the Recovery service install_package (upgrade update.zip specific)1.2. 2. Let's analyze this process along with the above flow chart and source code:1. Android OTA upgrade principle and process analysis (7)---Recovery service core install_package function July 04, 2016 09:43:20 blast - Bevis reading number: 477 Tags: ota Personal Category: Android-OTA Android system Recovery works using update.zip upgrade process analysis (seven) --- Recovery service core install_package function Reprinted from: http://blog.chinaunix.net/uid-22028566-id-3533856.html Android OTA upgrade principle and process analysis (7)---Recovery service core install_package function 1. The core of the Recovery service install_package (upgrade update.zip specific) 2. Let's analyze this process along with the above flow chart and source code: 1.1. 1. The core of the Recovery service install_package (upgrade update.zip specific) Unlike wipe_data and wipe_cache in the Recovery service, install_package() is a unique part of the upgrade update.zip and is the core part. At this point, we really started to process our update.zip package. Let's start analyzing this part. Or look at the legend first: The source files for this part are located at: /gingerbread0919/bootable/recovery/install.c. This is a source file without the main function, or the source code is posted as follows: /* * Copyright (C) 2007 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the \"License\"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ #include #include #include #include #include #include #include #include \"common.h\" #include \"install.h\" #include \"mincrypt/rsa.h\" #include \"minui/minui.h\" #include \"minzip/SysUtil.h\" #include \"minzip/Zip.h\" #include \"mtdutils/mounts.h\" #include \"mtdutils/mtdutils.h\" #include \"roots.h\" #include \"verifier.h\" #define ASSUMED_UPDATE_BINARY_NAME \"META-INF/com/google/android/update-binary\" #define PUBLIC_KEYS_FILE \"/res/keys\" // If the package contains an update binary, extract it and run it. static int try_update_binary(const char *path, ZipArchive *zip) { const ZipEntry* binary_entry = mzFindZipEntry(zip, ASSUMED_UPDATE_BINARY_NAME); if (binary_entry == NULL) { mzCloseZipArchive(zip); return INSTALL_CORRUPT; } char* binary = \"/tmp/update_binary\"; unlink(binary); int fd = creat(binary, 0755); if (fd // fill up the next part of of the progress bar // over seconds. If is zero, use // set_progress commands to manually control the // progress of this segment of the bar // // set_progress // should be between 0.0 and 1.0; sets the // progress bar within the segment defined by the most // recent progress command. // // firmware // arrange to install the contents of in the // given partition on reboot. // // (API v2: may start with \"PACKAGE:\" to // indicate taking a file from the OTA package.) // // (API v3: this command no longer exists.) // // ui_print // display on the screen. // // - the name of the package zip file. // char** args = malloc(sizeof(char*) * 5); args[0] = binary; args[1] = EXPAND(RECOVERY_API_VERSION); // defined in Android.mk args[2] = malloc(10); sprintf(args[2], \"%d\", pipefd[1]); args[3] = (char*)path; args[4] = NULL; pid_t pid = fork(); if (pid == 0) { close(pipefd[0]); execv(binary, args); fprintf(stdout, \"E:Can't run %s (%s)\\n\", binary, strerror(errno)); _exit(-1); } close(pipefd[1]); char buffer[1024]; FILE* from_child = fdopen(pipefd[0], \"r\"); while (fgets(buffer, sizeof(buffer), from_child) != NULL) { char* command = strtok(buffer, \" \\n\"); if (command == NULL) { continue; } else if (strcmp(command, \"progress\") == 0) { char* fraction_s = strtok(NULL, \" \\n\"); char* seconds_s = strtok(NULL, \" \\n\"); float fraction = strtof(fraction_s, NULL); int seconds = strtol(seconds_s, NULL, 10); ui_show_progress(fraction * (1-VERIFICATION_PROGRESS_FRACTION), seconds); } else if (strcmp(command, \"set_progress\") == 0) { char* fraction_s = strtok(NULL, \" \\n\"); float fraction = strtof(fraction_s, NULL); ui_set_progress(fraction); } else if (strcmp(command, \"ui_print\") == 0) { char* str = strtok(NULL, \"\\n\"); if (str) { ui_print(\"%s\", str); } else { ui_print(\"\\n\"); } } else { LOGE(\"unknown command [%s]\\n\", command); } } fclose(from_child); int status; waitpid(pid, &status, 0); if (!WIFEXITED(status) || WEXITSTATUS(status) != 0) { LOGE(\"Error in %s\\n(Status %d)\\n\", path, WEXITSTATUS(status)); return INSTALL_ERROR; } return INSTALL_SUCCESS; } // Reads a file containing one or more public keys as produced by // DumpPublicKey: this is an RSAPublicKey struct as it would appear // as a C source literal, eg: // // \"{64,0xc926ad21,{1795090719,...,-695002876},{-857949815,...,1175080310}}\" // // (Note that the braces and commas in this example are actual // characters the parser expects to find in the file; the ellipses // indicate more numbers omitted from this example.) // // The file may contain multiple keys in this format, separated by // commas. The last key must not be followed by a comma. // // Returns NULL if the file failed to parse, or if it contain zero keys. static RSAPublicKey* load_keys(const char* filename, int* numKeys) { RSAPublicKey* out = NULL; * numKeys = 0; FILE* f = fopen(filename, \"r\"); if (f == NULL) { LOGE(\"opening %s: %s\\n\", filename, strerror(errno)); goto exit; } int i; bool done = false; while (!done) { ++ * numKeys; out = realloc(out, *numKeys * sizeof(RSAPublicKey)); RSAPublicKey* key = out + (*numKeys - 1); if (fscanf(f, \" { %i , 0x%x , { %u\", &(key->len), &(key->n0inv), &(key->n[0])) != 3) { goto exit; } if (key->len != RSANUMWORDS) { LOGE(\"key length (%d) does not match expected size\\n\", key->len); goto exit; } for (i = 1; i len; ++i) { if (fscanf(f, \" , %u\", &(key->n[i])) != 1) goto exit; } if (fscanf(f, \" } , { %u\", &(key->rr[0])) != 1) goto exit; for (i = 1; i len; ++i) { if (fscanf(f, \" , %u\", &(key->rr[i])) != 1) goto exit; } fscanf(f, \" } } \"); // if the line ends in a comma, this file has more keys. switch (fgetc(f)) { case ',': // more keys to come. break; case EOF: done = true; break; default: LOGE(\"unexpected character between keys\\n\"); goto exit; } } fclose(f); return out; exit: if (f) fclose(f); free(out); * numKeys = 0; return NULL; } int install_package(const char *path) { ui_set_background(BACKGROUND_ICON_INSTALLING); ui_print(\"Finding update package...\\n\"); ui_show_indeterminate_progress(); LOGI(\"Update location: %s\\n\", path); if (ensure_path_mounted(path) != 0) { LOGE(\"Can't mount %s\\n\", path); return INSTALL_CORRUPT; } ui_print(\"Opening update package...\\n\"); int numKeys; RSAPublicKey* loadedKeys = load_keys(PUBLIC_KEYS_FILE, &numKeys); if (loadedKeys == NULL) { LOGE(\"Failed to load keys\\n\"); return INSTALL_CORRUPT; } LOGI(\"%d key(s) loaded from %s\\n\", numKeys, PUBLIC_KEYS_FILE); // Give verification half the progress bar... ui_print(\"Verifying update package...\\n\"); ui_show_progress( VERIFICATION_PROGRESS_FRACTION, VERIFICATION_PROGRESS_TIME); int err; err = verify_file(path, loadedKeys, numKeys); free(loadedKeys); LOGI(\"verify_file returned %d\\n\", err); if (err != VERIFY_SUCCESS) { LOGE(\"signature verification failed\\n\"); return INSTALL_CORRUPT; } /* Try to open the package. */ ZipArchive zip; err = mzOpenZipArchive(path, &zip); if (err != 0) { LOGE(\"Can't open %s\\n(%s)\\n\", path, err != -1 ? strerror(err) : \"bad\"); return INSTALL_CORRUPT; } /* Verify and install the contents of the package. */ ui_print(\"Installing update...\\n\"); return try_update_binary(path, &zip); } 1.2. 2. Let's analyze this process along with the above flow chart and source code: ensure_path_mount (): First determine whether the partition where the updated update.zip package path is mounted. If not, mount it first. load_keys(): Load the public key source file with the path at /res/keys. This file is in the root file system of the Recovery image. verify_file(): Signature verification of the upgrade package update.zip package. mzOpenZipArchive(): Open the upgrade package and copy the relevant information into a temporary ZipArchinve variable. This step did not extract our update.zip package. try_update_binary(): In this function, it is the place to upgrade our update.zip. This function first copies the update_binary file to the /tmp/update_binary of the memory file system based on the zip package information we obtained in the previous step and the absolute path of the upgrade package. For later use. pipe(): Creates a pipe for communication between the following child process and the parent process. fork(): Create a child process. The child process is mainly responsible for executing binary (execv(binary, args), that is, executing our installation command script), and the parent process is responsible for accepting the commands sent by the child process to update the ui display (displaying the current progress). Child-to-parent communication depends on pipes. Among them, after creating a child process, the parent process has two effects. One is to update the UI display by accepting commands sent by the child process through the pipeline. The second is to wait for the child process to exit and return INSTALL SUCCESS. The sub-process sends the following commands while parsing the execution script: progress : Sets the progress bar according to the second parameter secs (seconds). set_progress : Set the progress bar directly, and the value of frac is between 0.0 and 0.1. firmware : Used when upgrading firmware, it is no longer used in API V3. ui_print : Display the string on the screen, which is the print update process. The role of execv (binary, args) is to execute the binary program. The essence of this program is to parse and execute the commands in the updater-script script in the update.zip package. As a result, the Recovery service enters the process of actually installing the update.zip package. The next article continues to analyze the process of parsing and executing the updater-script using update-binary. "},"Android OTA - Android OTA upgrade principle and process analysis 8.html":{"url":"Android OTA - Android OTA upgrade principle and process analysis 8.html","title":"Android OTA - Android OTA upgrade principle and process analysis 8","keywords":"","body":"1. Android OTA upgrade principle and process analysis (8) --- upgrade program update_binary implementation process1.1. 1. update_binary execution process analysis1.2. 2. Through the above source code to analyze the implementation process of this program:1. Android OTA upgrade principle and process analysis (8) --- upgrade program update_binary implementation process July 04, 2016 09:44:07 Blast - Bevis reading number: 441 Tags: ota Personal Category: Android-OTA Android OTA upgrade principle and process analysis (eight) --- upgrade program update_binary implementation process Reprinted from: http://blog.chinaunix.net/uid-22028566-id-3533857.html Android OTA upgrade principle and process analysis (8) --- upgrade program update_binary implementation process 1. update_binary execution process analysis 2. Through the above source code to analyze the implementation process of this program: 1.1. 1. update_binary execution process analysis The binary executed by the child process in the previous page is actually the update-binary in the update.zip package. We also said in the above, the Recovery service in this part of the work is to copy the package update-binary to the /tmp/update_binary in the memory file system, and then execute. The source code of the update_binary program is located at gingerbread0919/bootable/recovery/updater/updater.c. The source code is as follows: /* * Copyright (C) 2009 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the \"License\"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ #include #include #include #include \"edify/expr.h\" #include \"updater.h\" #include \"install.h\" #include \"minzip/Zip.h\" // Generated by the makefile, this function defines the // RegisterDeviceExtensions() function, which calls all the // registration functions for device-specific extensions. #include \"register.inc\" // Where in the package we expect to find the edify script to execute. // (Note it's \"updateR-script\", not the older \"update-script\".) #define SCRIPT_NAME \"META-INF/com/google/android/updater-script\" int main(int argc, char** argv) { // Various things log information to stdout or stderr more or less // at random. The log file makes more sense if buffering is // turned off so things appear in the right order. setbuf(stdout, NULL); setbuf(stderr, NULL); if (argc != 4) { fprintf(stderr, \"unexpected number of arguments (%d)\\n\", argc); return 1; } char* version = argv[1]; if ((version[0] != '1' && version[0] != '2' && version[0] != '3') || version[1] != '\\0') { // We support version 1, 2, or 3. fprintf(stderr, \"wrong updater binary API; expected 1, 2, or 3; \" \"got %s\\n\", argv[1]); return 2; } // Set up the pipe for sending commands back to the parent process. int fd = atoi(argv[2]); FILE* cmd_pipe = fdopen(fd, \"wb\"); setlinebuf(cmd_pipe); // Extract the script from the package. char* package_data = argv[3]; ZipArchive za; int err; err = mzOpenZipArchive(package_data, &za); if (err != 0) { fprintf(stderr, \"failed to open package %s: %s\\n\", package_data, strerror(err)); return 3; } const ZipEntry* script_entry = mzFindZipEntry(&za, SCRIPT_NAME); if (script_entry == NULL) { fprintf(stderr, \"failed to find %s in %s\\n\", SCRIPT_NAME, package_data); return 4; } char* script = malloc(script_entry->uncompLen+1); if (!mzReadZipEntry(&za, script_entry, script, script_entry->uncompLen)) { fprintf(stderr, \"failed to read script from package\\n\"); return 5; } script[script_entry->uncompLen] = '\\0'; // Configure edify's functions. RegisterBuiltins(); RegisterInstallFunctions(); RegisterDeviceExtensions(); FinishRegistration(); // Parse the script. Expr* root; int error_count = 0; yy_scan_string(script); int error = yyparse(&root, &error_count); if (error != 0 || error_count > 0) { fprintf(stderr, \"%d parse errors\\n\", error_count); return 6; } // Evaluate the parsed script. UpdaterInfo updater_info; updater_info.cmd_pipe = cmd_pipe; updater_info.package_zip = &za; updater_info.version = atoi(version); State state; state.cookie = &updater_info; state.script = script; state.errmsg = NULL; char* result = Evaluate(&state, root); if (result == NULL) { if (state.errmsg == NULL) { fprintf(stderr, \"script aborted (no error message)\\n\"); fprintf(cmd_pipe, \"ui_print script aborted (no error message)\\n\"); } else { fprintf(stderr, \"script aborted: %s\\n\", state.errmsg); char* line = strtok(state.errmsg, \"\\n\"); while (line) { fprintf(cmd_pipe, \"ui_print %s\\n\", line); line = strtok(NULL, \"\\n\"); } fprintf(cmd_pipe, \"ui_print\\n\"); } free(state.errmsg); return 7; } else { fprintf(stderr, \"script result was [%s]\\n\", result); free(result); } if (updater_info.package_zip) { mzCloseZipArchive(updater_info.package_zip); } free(script); return 0; } 1.2. 2. Through the above source code to analyze the implementation process of this program: function parameters and version check: The current updater binary API supports version numbers 1, 2, and 3. Get the pipeline and open: Write a command to the pipeline during the execution of this program to notify its parent process to update the UI display according to the command. Read the updater-script script: Read the updater-script script from the update.zip package into a piece of dynamic memory for later execution. Configure edify's functions: The statement processing function in the registration script, that is, the function that recognizes the commands in the script. Mainly have the following categories RegisterBuiltins(): Registers statements in the control flow, such as ifelse, assert, abort, stdout, etc. RegisterInstallFunctions(): Install the required function functions during the actual installation, such as mount, format, set_progress, set_perm, and so on. RegisterDeviceExtensions(): Additional additions related to the device, there is no implementation in the source code. FinishRegistration(): End registration. Parse the script: Call the yy* library function to parse the script and store the parsed content in a Python class of Expr type . The main functions are yy_scan_string() and yyparse(). Execution script: The core function is Evaluate(), which calls other callback functions, and these callback functions will call Evaluate to parse different script fragments to implement a simple script interpreter. error message prompt: Finally, according to the return value of Evaluate () after execution, give some print information. This implementation is very simple, the main function is Evaluate. It is responsible for the script commands that ultimately perform the parsing. The command during the installation process is updater-script. The next section will introduce the syntax in the updater-script script and the execution flow of this script in the specific upgrade. "},"Android OTA - Android OTA upgrade principle and process analysis 9.html":{"url":"Android OTA - Android OTA upgrade principle and process analysis 9.html","title":"Android OTA - Android OTA upgrade principle and process analysis 9","keywords":"","body":"1. Android OTA upgrade principle and process analysis (9)---updater-script script syntax introduction and execution process1.1. 1. update-script script syntax introduction:1.2. 2. The updater-script script execution process analysis:1.3. 3. Summary1. Android OTA upgrade principle and process analysis (9)---updater-script script syntax introduction and execution process July 04, 2016 09:45:10 blast - Bevis reading number: 493 Tags: ota Personal Category: Android-OTA Android system Recovery works using update.zip upgrade process analysis (9)---updater-script script syntax introduction and execution process Reprinted from: http://blog.csdn.net/mu0206mu/article/details/7465603 At present, the update-script script format is edify. What is the difference between it and amend? We will not discuss it. We only analyze the main syntax and the flow control of the script. 1.1. 1. update-script script syntax introduction: We follow the generated script to see the syntax that is mainly involved. assert(condition): If the condition parameter evaluates to False, the script execution is stopped, otherwise the script is executed. show_progress(frac,sec): frac indicates the value of the progress of the progress, and sec indicates the total number of seconds of the entire process. Mainly used to display the progress bar on the UI. format (fstype, partitiontype, location): fs_type, file system type, the value is generally \"yaffs2\" or \"ext4\". Partition_type, partition type, generally takes the value \"MTD\" or \"EMMC\". Mainly used for formatting to the specified file system. For example, the following: format(\"yaffs2\", \"MTD\", \"system\"). mount(fstype, partitiontype, location, mount_point): The first two parameters are the same as above, the device to be mounted by the location, and the mount_point mount point. Role: Mount a file system to the specified mount point. package_extract_dir(srcpath, destinationpath): src_path, the directory to be extracted, destination_path target directory. Role: From the upgrade package, extract the directory to the specified location. Example: package_extract_dir(\"system\",\"/system\"). symlink (target, src1, src2, ..., srcN): target, string type, is the target of the symbolic link. SrcX represents the target point of the symbolic link to be created. Example: symlink (\"toolbox\", \"/system/bin/ps\"), establish a pointer to the toolbox symbol /system/bin/ps, it is worth noting that the existing symbol is broken before the new symbolic link is established. connection. set_perm(uid,gid,mode,file1,file2,...,fileN): The role is to set the permissions of a single file or a series of files, at least one file must be specified. set_perm_recursive(uid,gid,mode,dir1,dir2,...,dirN): Same as above, but here also changes the permissions of one or more directories and their files. package_extract_file(srcfilepath, desfilepaht): srcfile_path, the file to be extracted, desfile_path, to extract the target location of the file. Example: package_extract_file(\"boot.img\",\"/tmp/boot.img\") Copy the boot.img file from the upgrade package to /tmp in the memory file system. write_raw_image(src-image, partition): src-image source image file, partition, target partition. Role: Write the image to the target partition. Example: write_raw_image(\"/tmp/boot.img\",\"boot\") writes the boot.img image to the boot partition of the system. getprop(key): Get the corresponding attribute information by specifying the value of the key. Example: getprop(\"ro.product.device\") gets the property value of ro.product.device. 1.2. 2. The updater-script script execution process analysis: First look at the upgrade script generated by the command make otapackage during the test process as follows: assert(!less_than_int(1331176658, getprop(\"ro.build.date.utc\"))); assert(getprop(\"ro.product.device\") == \"tcc8800\" || getprop(\"ro.build.product\") == \"tcc8800\"); show_progress(0.500000, 0); format(\"yaffs2\", \"MTD\", \"system\"); mount(\"yaffs2\", \"MTD\", \"system\", \"/system\"); package_extract_dir(\"recovery\", \"/system\"); package_extract_dir(\"system\", \"/system\"); symlink(\"busybox\", \"/system/bin/cp\", \"/system/bin/grep\", \"/system/bin/tar\", \"/system/bin/unzip\", \"/system/bin/vi\"); symlink(\"toolbox\", \"/system/bin/cat\", \"/system/bin/chmod\", \"/system/bin/chown\", \"/system/bin/cmp\", \"/system/bin/date\", \"/system/bin/dd\", \"/system/bin/df\", \"/system/bin/dmesg\", \"/system/bin/getevent\", \"/system/bin/getprop\", \"/system/bin/hd\", \"/system/bin/id\", \"/system/bin/ifconfig\", \"/system/bin/iftop\", \"/system/bin/insmod\", \"/system/bin/ioctl\", \"/system/bin/ionice\", \"/system/bin/kill\", \"/system/bin/ln\", \"/system/bin/log\", \"/system/bin/ls\", \"/system/bin/lsmod\", \"/system/bin/lsof\", \"/system/bin/mkdir\", \"/system/bin/mount\", \"/system/bin/mv\", \"/system/bin/nandread\", \"/system/bin/netstat\", \"/system/bin/newfs_msdos\", \"/system/bin/notify\", \"/system/bin/printenv\", \"/system/bin/ps\", \"/system/bin/reboot\", \"/system/bin/renice\", \"/system/bin/rm\", \"/system/bin/rmdir\", \"/system/bin/rmmod\", \"/system/bin/route\", \"/system/bin/schedtop\", \"/system/bin/sendevent\", \"/system/bin/setconsole\", \"/system/bin/setprop\", \"/system/bin/sleep\", \"/system/bin/smd\", \"/system/bin/start\", \"/system/bin/stop\", \"/system/bin/sync\", \"/system/bin/top\", \"/system/bin/umount\", \"/system/bin/uptime\", \"/system/bin/vmstat\", \"/system/bin/watchprops\", \"/system/bin/wipe\"); set_perm_recursive(0, 0, 0755, 0644, \"/system\"); set_perm_recursive(0, 2000, 0755, 0755, \"/system/bin\"); set_perm(0, 3003, 02750, \"/system/bin/netcfg\"); set_perm(0, 3004, 02755, \"/system/bin/ping\"); set_perm(0, 2000, 06750, \"/system/bin/run-as\"); set_perm_recursive(1002, 1002, 0755, 0440, \"/system/etc/bluetooth\"); set_perm(0, 0, 0755, \"/system/etc/bluetooth\"); set_perm(1000, 1000, 0640, \"/system/etc/bluetooth/auto_pairing.conf\"); set_perm(3002, 3002, 0444, \"/system/etc/bluetooth/blacklist.conf\"); set_perm(1002, 1002, 0440, \"/system/etc/dbus.conf\"); set_perm(1014, 2000, 0550, \"/system/etc/dhcpcd/dhcpcd-run-hooks\"); set_perm(0, 2000, 0550, \"/system/etc/init.goldfish.sh\"); set_perm(0, 0, 0544, \"/system/etc/install-recovery.sh\"); set_perm_recursive(0, 0, 0755, 0555, \"/system/etc/ppp\"); set_perm_recursive(0, 2000, 0755, 0755, \"/system/xbin\"); set_perm(0, 0, 06755, \"/system/xbin/librank\"); set_perm(0, 0, 06755, \"/system/xbin/procmem\"); set_perm(0, 0, 06755, \"/system/xbin/procrank\"); set_perm(0, 0, 06755, \"/system/xbin/su\"); set_perm(0, 0, 06755, \"/system/xbin/tcpdump\"); show_progress(0.200000, 0); show_progress(0.200000, 10); assert(package_extract_file(\"boot.img\", \"/tmp/boot.img\"), write_raw_image(\"/tmp/boot.img\", \"boot\"), delete(\"/tmp/boot.img\")); show_progress(0.100000, 0); unmount(\"/system\"); The following analysis of the execution of this script: Compare timestamp: Terminate the execution of the script if the upgrade package is older. Matching device information: If the current device information is inconsistent, the execution of the script is stopped. Display progress bar: If the above two steps match, the upgrade progress bar will be displayed. Format the system partition and mount it. Extract the recovery and package contents in the package to the /system of the system. Create a symbolic link for the command file under /system/bin/. Set the /system/ directory and the properties of the file. Extract the boot.img from the package to /tmp/boot.img. Write the /tmp/boot.img image file to the boot partition. After uninstalling /system. The above is the syntax in the updater-script script and the specific process of its execution. By analyzing its execution process, we can find that during the execution process, the upgrade package is not extracted to another place, but what needs to be extracted. It is worth noting that when extracting the contents of the recovery and system directories, they are placed under /system/. Nothing in the update.zip package was removed or changed during the operation. After the actual update is complete, our update.zip package does exist in its original location. 1.3. 3. Summary The above nine articles focus on one of the Recovery modes in the Android system, that is, the process that we have done in the update.zip package when the system is updated. The core part is how the Recovery service works. The other two FACTORY RESET, ENCRYPTED FILE SYSTEM ENABLE/DISABLE are connected to OTA INSTALL. The point is to understand how the Recovery service works. In addition, a detailed analysis of its upgrade process, for our actual upgrade, we can make corresponding modifications according to our needs. Inadequacies, please do not hesitate! "},"Android PMS - Explore the Android PMS service.html":{"url":"Android PMS - Explore the Android PMS service.html","title":"Android PMS - Explore the Android PMS service","keywords":"","body":"1. Explore the Android PMS service1.1. Pm use1.2. Package name information query1.3. Privilege information query1.4. Test package1.5. Package path1.6. System hardware characteristics1.7. Device dependent java library1.8. Dump package information1.9. Install and uninstall apk1.10. Clear application data1.11. Disable and enable system apps1.12. Hide and restore apps1.13. Set up and view the app's installation location1.14. View current system user information1. Explore the Android PMS service Android core service Android underlying development Explore the Android PMS service Pm use Package name information query Privilege information query Test package Package path System hardware characteristics Device dependent java library Dump package information Install and uninstall apk Clear application data Disable and enable system apps Hide and restore apps Set up and view the app's installation location View current system user information In the Android system, PackageManagerService is abbreviated as PMS, which is mainly responsible for the installation, uninstallation, optimization and query of various APKs. In the Android system, the pm tool is a display command of the PMS. By understanding the use of pm, you can understand what specific functions PMS provides, and thus help us understand and analyze the source implementation of PMS. 1.1. Pm use Use the adb shell command to enter the terminal of the Android device. The pm tool is in /system/bin, so you can use it directly: Pm 1.2. Package name information query Pm list packages [options] [FILTER] Prints the package name of all installed apps. If file filtering is set, the value shows the content containing the filtered text. parameter: -f displays the file location of each package -d Use filters to display only package names for disabled apps -e Use filters to display only the package names of available apps -s Use filters to display only the package name of the system application -3 Use filters to display only package names for third-party applications -i View the installer of the app 1.3. Privilege information query Print all known permission groups Pm list permission-groups Print permission: Pm list permissions [options] [GROUP] parameter: g List permissions by group -f print all information -s short summary -d only dangerous list of permissions -u Only users with permissions will see list user-defined permissions After Android 6.0, allow authorization and cancellation permissions: Pm grant Pm revoke Authorization and cancellation are for the permissions of the application in the APK. That is, there is no permission to apply in the APK, there is no way to add it through this command. 1.4. Test package Pm list instrumentation parameter List all instrumentation test packages without parameters -f lists the location of the apk file Target_package lists the test packages for an app 1.5. Package path Pm path package_name 1.6. System hardware characteristics Pm list features 1.7. Device dependent java library Pm list libraries 1.8. Dump package information Pm dump package_name 1.9. Install and uninstall apk Install apk Pm install [-lrtsfd] [-i PACKAGE] [PATH] Adb install is actually a wrapper call to pm install. parameter: -l lock application -r Reinstall the app and keep the app data -t allows test apk to be installed -i INSTALLER_PACKAGE_NAME specifies the package name of the installation package -s install to sd card -f install into system built-in storage (default installation location) -d Allows downgrade installation (same application low level for advanced) -g Grants all permissions listed in the application manifest (only available on 6.0 systems) Uninstall apk: Pm uninstall [options] Parameters: -k Unloads the application and keeps the data and cache (all if you don't add -k) 1.10. Clear application data Pm clear package_name 1.11. Disable and enable system apps Pm enable Make the package or component available Pm disenable Makes the package or component unavailable (you can't find the application directly) Pm disenable-user [options] Makes package or component unavailable (it shows disabled 1.12. Hide and restore apps Pm hide PACKAGE_OR_COMPONENT Pm unhide PACKAGE_OR_COMPONENT The hidden app becomes invisible in app management and the desktop icon disappears 1.13. Set up and view the app's installation location Pm set-install-location parameter package_name Pm get-install-location package_name Parameters: 0: Auto - Let the system determine the best position 1: Internal storage - Storage installed on internal devices 2: External storage - Installed on external media 1.14. View current system user information Pm list users The apk can be installed under a certain user, so that the apk can be displayed and used only when switching to the user. "},"Android PMS - Some rules of the PMS runtime.html":{"url":"Android PMS - Some rules of the PMS runtime.html","title":"Android PMS - Some rules of the PMS runtime","keywords":"","body":"1. Some rules of the PMS runtime1.1. APK file path1.1.1. /system/priv-app1.1.2. /system/app1.1.3. /vendor/app1.1.4. /oem/app1.1.5. /data/app1.2. How to install APK1.2.1. System application installation1.2.2. Download apk from the app store that comes with the device1.2.3. ADB command installation1.3. Third-party application installation1.4. Apk data storage location1.4.1. /data/app1.4.2. /data/data/1.5. PMS configuration file1.6. System hardware features and permissions1.7. Multi-user management1.8. Dynamic management of permissions1. Some rules of the PMS runtime Android core service Android underlying development Some rules of the PMS runtime APK file path /system/priv-app /system/app /vendor/app /oem/app /data/app How to install APK System application installation Download apk from the app store that comes with the device ADB command installation Third-party application installation Apk data storage location /data/app /data/data/ PMS configuration file System hardware features and permissions Multi-user management Dynamic management of permissions The previous introduction of how to use the pm command reflects the functions provided by the PMS from the side. Then before you really analyze the source code, you should also understand some of the default rules of the PMS. This article mainly introduces the directories and files related to PMS, and the rules for PMS to operate them. 1.1. APK file path APKs fall into two main categories: System comes with APK User Installed Third Party APK For the APK that comes with the system, you can find it from the following path: 1.1.1. /system/priv-app This path stores some of the underlying applications of the system, such as Setting, systemUI, and so on. The app in this directory has higher system permissions and if you want to use Android:protectionLevel=signatureOrSystem Then the app must be placed in the priv-app directory. 1.1.2. /system/app The system app permissions stored in this directory are relatively low, and when you have root privileges, it is possible to uninstall these apps. 1.1.3. /vendor/app This directory stores the vendor's app. 1.1.4. /oem/app This directory stores oem-specific apps. 1.1.5. /data/app User-installed third-party app When the PMS is started, the apks in these directories are also parsed one by one in the above order. 1.2. How to install APK 1.2.1. System application installation When the PMS is started, there is no installation interface. 1.2.2. Download apk from the app store that comes with the device After downloading the APK, call the Packagemanager interface to install, there is no installation interface. 1.2.3. ADB command installation The adb command is actually installed via the pm command, and there is no installation interface. 1.3. Third-party application installation Installed through the APK file in the SD card, there is an installation interface, and the interface of the installation and uninstallation process is handled by the packageinstaller.apk application. Prior to ANdroid 5.0, the Android system would monitor the few paths mentioned above for storing apk. Once a new apk is found, it will be installed. After 5.0, this strategy is not taken. The apk in this write path is only scanned when the system is started. 1.4. Apk data storage location After apk is installed, the generated data is stored in the /data file. 1.4.1. /data/app The third-party apk installed by the user, as well as the native library on which the app depends, are placed here. In Android 6.0, this directory has a folder \"oat\" for storing this app, the oat file of this app generated by dex2oat when running for the first time. In previous versions of Android, the oat file of the app installed by the user was stored in /data/dalvik-cache in. At 6.0, this directory only stores the oat file of the apk that comes with the system. 1.4.2. /data/data/ Is the sandbox directory of all apps installed by the current user of the system. The directory is actually /data/user/user ID A reference to this directory. As the user switches, \"/data/data/\" is also mapped to different users. 1.5. PMS configuration file The PMS will generate some configuration files to record the apps currently installed on the system. These files are stored in: /data/system/ Packages.xml Record all installed application information in the system, including basic information, signatures and permissions. As shown below: When the file is manipulated, the backup file packages-backup.xml is always created. When the normal operation is completed, the backup is deleted. Otherwise, when the PMS is started next time, once the backup file is found, the backup file will be resolved first. When an app is upgraded to overwrite the installation, it will use updated-packages to indicate that when the package name of the old and new versions of the app changes, the renamed-package record will be used. Packages-stoped.xml Records information about apps in the system that are forcibly stopped. It is also possible to have a backup file of packages-stoped-backup.xml. When the backup file exists, the backup file is preferred. Because the original file may have been corrupted. Packages.list Save the application's data directory and uid information. Such as: Com.qihoo.appstore 10067 0 /data/data/com.qihoo.appstore default 3002,3003,3001 The first column is the package name of the app. 10067 User ID for this app. The 0 in the third column indicates the system user ID to which this app belongs. The fourth column is the sandbox directory for this app. Default is seinfo, which is used by SEAndroid related mechanisms. The last column records the permission group in which the app is located, which means that it has permissions. 1.6. System hardware features and permissions When the PMS starts, it will /system/etc/permissions/ Read the hardware features and settings related permissions of the current Android device. The so-called hardware features can be understood in a narrow sense as which peripherals are supported by the current device, such as camera, NFC, wifi, usb, and so on. Because the files in the directory are parsed, you can view information such as features and permissions through the pm command. 1.7. Multi-user management PMS also manages multiple users. Because when installing apk, the PMS can be assigned to a specific user or to all users. 1.8. Dynamic management of permissions Dynamic authorization and cancellation of applications in the app are allowed in Android M. "},"Android PMS - Android 6 PMS Analysis.html":{"url":"Android PMS - Android 6 PMS Analysis.html","title":"Android PMS - Android 6 PMS Analysis","keywords":"","body":"1. Android 6.0 PMS analysis1.1. PMS entry point1.2. PMS constructor analysis of Settings1.3. mSettings.addSharedUserLPw1.4. Create a dexopt optimizer object1.5. Create and initialize SystemConfig1. Android 6.0 PMS analysis April 22, 2017 16:35:22 Blast - Bevis Reads: 993 Tags: PMS Personal classification: Android-PMS This article is reproduced in: http://www.iloveandroid.net/2016/06/20/Android_PackageManagerService-2/ Android 6.0 PMS analysis PMS entry point PMS constructor analysis of Settings mSettings.addSharedUserLPw Create a dexopt optimizer object Create and initialize SystemConfig I have previously introduced how the pm command is used and some of the rules and behaviors of the PMS runtime. Now you can enjoy the PMS code. 1.1. PMS entry point The PMS is started by SystemServer. Android6.0/frameworks/base/services/java/com/android/server/SystemServer.java private void startBootstrapServices(){ // Wait for installd to finish starting up so that it has a chance to // create critical directories such as /data/user with the appropriate // permissions. We need this to complete before we initialize other services. Installer installer = mSystemServiceManager.startService(Installer.class); ...................................... // Start the package manager. Slog.i(TAG, \"Package Manager\"); mPackageManagerService = PackageManagerService.main(mSystemContext, installer, mFactoryTestMode != FactoryTest.FACTORY_TEST_OFF, mOnlyCore); mFirstBoot = mPackageManagerService.isFirstBoot(); mPackageManager = mSystemContext.getPackageManager(); ...................................... } This finds the entry point for analyzing the PMS: Android6.0/frameworks/base/services/core/java/com/android/server/pm/PackageManagerService.java - main method The second parameter installer in the main function is responsible for socket communication with the installd daemon in the native layer. Here, when the Installer is started, installd will create some key directories, and the installd daemon will be described in detail later. The fourth parameter mOnlyCore is used to determine whether to scan only the system directory. It is set to true only when it is encrypted and decrypted with the data partition. In other cases, it is generally false. The main function is also very simple as follows: public static PackageManagerService main(Context context, Installer installer, boolean factoryTest, boolean onlyCore) { PackageManagerService m = new PackageManagerService(context, installer, factoryTest, onlyCore); ServiceManager.addService(\"package\", m); return m; } There are two main things to do here: Create a PackageManagerService object, which is the entity of the PMS Register the PMS with the SMS, that is, join the SMS to facilitate subsequent processes or apps to obtain PMS services through SMS. In the constructor of PMS, a lot of work has been done. To sum up, it is to scan the apk in the Android system, and establish the corresponding data structure to manage the package information, the information of the four components, the rights information and so on. 1.2. PMS constructor analysis of Settings Source code: mLazyDexOpt = \"eng\".equals(SystemProperties.get(\"ro.build.type\")); mMetrics = new DisplayMetrics(); mSettings = new Settings(mPackages); mSettings.addSharedUserLPw(\"android.uid.system\", Process.SYSTEM_UID, ApplicationInfo.FLAG_SYSTEM, ApplicationInfo.PRIVATE_FLAG_PRIVILEGED); mSettings.addSharedUserLPw(\"android.uid.phone\", RADIO_UID, ApplicationInfo.FLAG_SYSTEM, ApplicationInfo.PRIVATE_FLAG_PRIVILEGED); mSettings.addSharedUserLPw(\"android.uid.log\", LOG_UID, ApplicationInfo.FLAG_SYSTEM, ApplicationInfo.PRIVATE_FLAG_PRIVILEGED); mSettings.addSharedUserLPw(\"android.uid.nfc\", NFC_UID, ApplicationInfo.FLAG_SYSTEM, ApplicationInfo.PRIVATE_FLAG_PRIVILEGED); mSettings.addSharedUserLPw(\"android.uid.bluetooth\", BLUETOOTH_UID, ApplicationInfo.FLAG_SYSTEM, ApplicationInfo.PRIVATE_FLAG_PRIVILEGED); mSettings.addSharedUserLPw(\"android.uid.shell\", SHELL_UID, ApplicationInfo.FLAG_SYSTEM, ApplicationInfo.PRIVATE_FLAG_PRIVILEGED); First determine the build type, there are three builds: user, userdebug, eng. When it is eng, it means that no odex optimization is needed. Then create a DisplayMetrics object to hold the screen pixel parameters. Then there is the focus of this analysis. Create a Settings object. Source path: Android6.0/frameworks/base/services/core/java/com/android/server/pm/Settings.java Its construction method: Settings(Object lock) { this(Environment.getDataDirectory(), lock); } Settings(File dataDir, Object lock) { mLock = lock; mRuntimePermissionsPersistence = new RuntimePermissionPersistence(mLock); mSystemDir = new File(dataDir, \"system\"); mSystemDir.mkdirs(); FileUtils.setPermissions(mSystemDir.toString(), FileUtils.S_IRWXU|FileUtils.S_IRWXG |FileUtils.S_IROTH|FileUtils.S_IXOTH, -1, -1); mSettingsFilename = new File(mSystemDir, \"packages.xml\"); mBackupSettingsFilename = new File(mSystemDir, \"packages-backup.xml\"); mPackageListFilename = new File(mSystemDir, \"packages.list\"); FileUtils.setPermissions (mPackageListFilename, 0640 , SYSTEM_UID, PACKAGE_INFO_GID); // Deprecated: Needed for migration mStoppedPackagesFilename = new File(mSystemDir, \"packages-stopped.xml\"); mBackupStoppedPackagesFilename = new File(mSystemDir, \"packages-stopped-backup.xml\"); } dataDir is /data So mSystemDir is /data/system This constructor mainly creates the File object about several configuration files of the PMS introduced in the previous article, and sets permissions and the like. 1.3. mSettings.addSharedUserLPw addSharedUserLPw method: SharedUserSetting addSharedUserLPw(String name, int uid, int pkgFlags, int pkgPrivateFlags) { SharedUserSetting s = mSharedUsers.get(name); if (s != null) { if (s.userId == uid) { return s; } PackageManagerService.reportSettingsProblem(Log.ERROR, \"Adding duplicate shared user, keeping first: \" + name); return null; } s = new SharedUserSetting(name, pkgFlags, pkgPrivateFlags); s.userId = uid; if (addUserIdLPw(uid, s, name)) { mSharedUsers.put(name, s); return s; } return null; } This method is mainly to create related information about the shared UID. Here, first look at the name as the key in mSharedUsers to see if there is already a shared UID named name. If there is any, determine whether the UID and the incoming uid are equal, and report an error if they are not equal. This means that you cannot bind a new uid to an existing shared UID message. If not, create a new SharedUserSetting and add it to mSharedUsers. pkgFlags for ApplicationInfo.FLAG_SYSTEM indicates that the app is a system app. pkgPrivateFlags indicates that SystemInfo.PRIVATE_FLAG_PRIVILEGED has system privileges. private boolean addUserIdLPw(int uid, Object obj, Object name) { if (uid > Process.LAST_APPLICATION_UID) { return false; } if (uid >= Process.FIRST_APPLICATION_UID) { int N = mUserIds.size(); final int index = uid - Process.FIRST_APPLICATION_UID; while (index >= N) { mUserIds.add(null); N++; } if (mUserIds.get(index) != null) { PackageManagerService.reportSettingsProblem(Log.ERROR, \"Adding duplicate user id: \" + uid + \" name=\" + name); return false; } mUserIds.set(index, obj); } else { if (mOtherUserIds.get(uid) != null) { PackageManagerService.reportSettingsProblem(Log.ERROR, \"Adding duplicate shared id: \" + uid + \" name=\" + name); return false; } mOtherUserIds.put(uid, obj); } return true; } Mainly for the common uid and system uid for different processing. Every ordinary app is installed, it will be assigned a uid, which is not in the range of some system services of the Android system and the uid of the app with high authority. The uid of the normal app is added to mUsrIds, and the others are added to mOtherUserIds. The shared uid of android.uid.system, android.uid.phone, android.uid.log, android.uid.nfc, android.uid.bluetooth, android.uid.shell are created in the PMS constructor. Mainly to facilitate the use of the following scenarios: In the AndroidManifest.xml of some system apps, there will be the following information: android:sharedUserId=\"android.uis.system\" Or android.uid.phone, etc., if you do not create it in advance, there is no way to have the permissions of these shared uids. 1.4. Create a dexopt optimizer object Source code: mInstaller = installer; mPackageDexOptimizer = new PackageDexOptimizer(this); mMoveCallbacks = new MoveCallbacks(FgThread.get().getLooper()); mOnPermissionChangeListeners = new OnPermissionChangeListeners( FgThread.get().getLooper()); mInstaller is the incoming installer that communicates with the installd daemon. Create a PackageDexOptimizer object, which is mainly used to execute the patchaud command in ART to randomize the offset value of the oat file. This class is only available in Android M. Create a listener with more obvious listening permissions. Because Android M allows dynamic modification of App permissions. 1.5. Create and initialize SystemConfig Source code: SystemConfig systemConfig = SystemConfig.getInstance(); mGlobalGids = systemConfig.getGlobalGids(); mSystemPermissions = systemConfig.getSystemPermissions(); mAvailableFeatures = systemConfig.getAvailableFeatures(); SystemConfig will read /system/etc/permissions The relevant files in the folder. Take a look at its construction method: SystemConfig() { // Read configuration from system readPermissions(Environment.buildPath( Environment.getRootDirectory(), \"etc\", \"sysconfig\"), false); // Read configuration from the old permissions dir readPermissions(Environment.buildPath( Environment.getRootDirectory(), \"etc\", \"permissions\"), false); // Only read features from OEM config readPermissions(Environment.buildPath( Environment.getOemDirectory(), \"etc\", \"sysconfig\"), true); readPermissions(Environment.buildPath( Environment.getOemDirectory(), \"etc\", \"permissions\"), true); } Where rootDirectory is \"/system\". oemDirectory is \"/oem\". That is, it will try to read sequentially. /system/etc/sysconfig /system/etc/permissions /oem/etc/sysconfig /oem/etc/permissions The permissions file in these four directories. The permission file is read by the readPermissions function: void readPermissions(File libraryDir, boolean onlyFeatures) { // Read permissions from given directory. if (!libraryDir.exists() || !libraryDir.isDirectory()) { if (!onlyFeatures) { Slog.w(TAG, \"No directory \" + libraryDir + \", skipping\"); } return;//If the folder does not exist, or if it is not a folder, exit } if (!libraryDir.canRead()) { Slog.w(TAG, \"Directory \" + libraryDir + \" cannot be read\"); return;//Exit if not readable } // Iterate over the files in the directory and scan .xml files File platformFile = null; for (File f : libraryDir.listFiles()) { // We'll read platform.xml last if (f.getPath().endsWith(\"etc/permissions/platform.xml\")) { platformFile = f; continue;//Do not process platform.xml first, and will process it separately } if (!f.getPath().endsWith(\".xml\")) { Slog.i(TAG, \"Non-xml file \" + f + \" in \" + libraryDir + \" directory, ignoring\"); continue;//Only process xml files } if (!f.canRead()) { Slog.w(TAG, \"Permissions library file \" + f + \" cannot be read\"); continue;//If the xml file is not readable, skip it } readPermissionsFromXml(f, onlyFeatures);//Parsing xml file } // Read platform permissions last so it will take precedence if (platformFile != null) { //Finally, the platform.xml file is processed separately. readPermissionsFromXml(platformFile, onlyFeatures); } The function of the readPermissions method is to read the xml file in the specified directory, and then call the readPermissionsFromXml method to parse the xml file. The hardware features of the current device are indicated in these xml files: After parsing, it is stored in the variable mAvailableFeatures of the ArrayMap type. It may also indicate some java libraries that are loaded in addition to loading the libraries in the framework when running the line: The value of the name attribute in these library fields will be stored in the member variable mSharedLibrsries of the PMS. The platform specifies the relevant permissions defined in the current device: .................. .................. .................. The permission indicates that the permission represented by the string in the name is assigned to the user group in the attribute gid in the group tag. When parsing, create a PermissionEntry, which is an inner class of SystemConfig public static final class PermissionEntry { public final String name; public int[] gids; public boolean perUser; PermissionEntry(String name, boolean perUser) { this.name = name; this.perUser = perUser; } } There is an ArrayMap mPermissions variable in SystemConfig, and the created PermissionEntry will be stored in this variable. The uid in the group will be saved in the mGlobalGids integer array in SystemConfig. Assign-permission indicates that the permission represented by the string in the attribute name is assigned to the user in the attribute uid. The uid and name are stored in the mSystemPermissions variable of type SparseArray\\ in SystemConfig. "},"Android PMS - Android 6 PMS analysis article 1.html":{"url":"Android PMS - Android 6 PMS analysis article 1.html","title":"Android PMS - Android 6 PMS analysis article 1","keywords":"","body":"1. Android 6 PMS analysis article 11. Android 6 PMS analysis article 1 Android core service Android underlying development This article focuses on PMS scanning and parsing APK files. Continue to analyze the construction method of the PMS. mHandlerThread = new ServiceThread(TAG, Process.THREAD_PRIORITY_BACKGROUND, true /*allowIo*/); mHandlerThread.start(); mHandler = new PackageHandler(mHandlerThread.getLooper()); Watchdog.getInstance().addThread(mHandler, WATCHDOG_TIMEOUT); File dataDir = Environment.getDataDirectory(); mAppDataDir = new File(dataDir, \"data\"); mAppInstallDir = new File(dataDir, \"app\"); mAppLib32InstallDir = new File(dataDir, \"app-lib\"); mAsecInternalPath = new File(dataDir, \"app-asec\").getPath(); mUserAppDataDir = new File(dataDir, \"user\"); mDrmAppPrivateInstallDir = new File(dataDir, \"app-private\"); sUserManager = new UserManagerService(context, this, mInstallLock, mPackages); Create a PackageHandler object and create a message loop for the PackageHandler to handle the installation request for the apk. Generate file objects for subdirectories under the \"/data\" directory: /data/data /data/app /data/app-lib /data/user /data/app-private Create a user management service UserManagerService: Continue the PMS construction method: // Propagate permission configuration in to package manager. ArrayMap permConfig = systemConfig.getPermissions(); for (int i=0; i libConfig = systemConfig.getSharedLibraries(); for (int i=0; i The role is to put the name of the permission read from /system/etc/permission and the corresponding gid into bp, and then save it in the mPermissions of mSettings. Also put the shared library read from /system/etc/permission into the PMS variable mSharedLibraries. carry on mRestoredSettings = mSettings.readLPw(this, sUserManager.getUsers(false), mSdkVersion, mOnlyCore); String customResolverActivity = Resources.getSystem().getString( R.string.config_customResolverActivity); if (TextUtils.isEmpty(customResolverActivity)) { customResolverActivity = null; } else { mCustomResolverComponentName = ComponentName.unflattenFromString( customResolverActivity); } Here we first call the ReadLPw function of Settings to parse the installation list information saved in packages.xml and packages-backup.xml, and add the parsed pakcages information to the corresponding data structure. Here we assume that this is the first time the Android device is powered on. All the packages.xml and packages-backup.xml files do not exist yet. So the Settings readLPw function will return directly. carry on: long startTime = SystemClock.uptimeMillis(); // Get current time EventLog.writeEvent(EventLogTags.BOOT_PROGRESS_PMS_SYSTEM_SCAN_START, startTime); // Set flag to monitor and not change apk file paths when // scanning install directories. final int scanFlags = SCAN_NO_PATHS | SCAN_DEFER_DEX | SCAN_BOOTING | SCAN_INITIAL;//设置扫描模式 final ArraySet alreadyDexOpted = new ArraySet();// Store optimized files /** * Add everything in the in the boot class path to the * list of process files because dexopt will have been run * if necessary during zygote startup. */ final String bootClassPath = System.getenv(\"BOOTCLASSPATH\");// Get the value of the BOOTCLASSPATH environment variable final String systemServerClassPath = System.getenv(\"SYSTEMSERVERCLASSPATH\");//Get the value of the SYSTEMSERVERCLASSPATH environment variable if (bootClassPath != null) { String[] bootClassPathElements = splitString(bootClassPath, ':'); for (String element : bootClassPathElements) { alreadyDexOpted.add(element); //Add the specified file in the BOOTCLASSPATH to the list of optimized files. } } else { Slog.w(TAG, \"No BOOTCLASSPATH found!\"); } if (systemServerClassPath != null) { String[] systemServerClassPathElements = splitString(systemServerClassPath, ':'); for (String element : systemServerClassPathElements) { alreadyDexOpted.add(element);//Add files from SYSTEMSERVERCLASSPATH to the list of optimized files } } else { Slog.w(TAG, \"No SYSTEMSERVERCLASSPATH found!\"); } This code mainly adds the files in BOOTCLASSPATH and SYSTEMSERVERCLASSPATH to the readyDexOpted HashSet, because they have been optimized for Dex when zygote is started. carry on final List allInstructionSets = InstructionSets.getAllInstructionSets(); final String[] dexCodeInstructionSets = getDexCodeInstructionSets( allInstructionSets.toArray(new String[allInstructionSets.size()])); /** * Ensure all external libraries have had dexopt run on them. */ if (mSharedLibraries.size() > 0) { // NOTE: For now, we're compiling these system \"shared libraries\" // (and framework jars) into all available architectures. It's possible // to compile them only when we come across an app that uses them (there's // already logic for that in scanPackageLI) but that adds some complexity. for (String dexCodeInstructionSet : dexCodeInstructionSets) { for (SharedLibraryEntry libEntry : mSharedLibraries.values()) { final String lib = libEntry.path; if (lib == null) { continue; } try { int dexoptNeeded = DexFile.getDexOptNeeded(lib, null, dexCodeInstructionSet, false); if (dexoptNeeded != DexFile.NO_DEXOPT_NEEDED) { alreadyDexOpted.add(lib); mInstaller.dexopt(lib, Process.SYSTEM_UID, true, dexCodeInstructionSet, dexoptNeeded); } } catch (FileNotFoundException e) { Slog.w(TAG, \"Library not found: \" + lib); } catch (IOException e) { Slog.w(TAG, \"Cannot dexopt \" + lib + \"; is it an APK or JAR? \" + e.getMessage()); } } } } Here first get the abi list of the current Android device, that is, armeabi, armeabi-v7a, arm64-v8a and so on. Then in each abi case, use DexFile.getDexOptNeeded to check if the library has executed dexopt. NO_DEXOPT_NEEDED ：if the apk/jar is already up to date. DEX2OAT_NEEDED： if dex2oat should be called on the apk/jar file. PATCHOAT_NEEDED：if patchoat should be called on the apk/jar file to patch the odex file along side the apk/jar. SELF_PATCHOAT_NEEDED if selfpatchoat should be called on the apk/jar file to patch the oat file in the dalvik cache. When the result is not NO_DEXOPT_NEEDED, the library needs dexopt. The dexopt operation is performed by the dexopt of mInstaller. carry on: File frameworkDir = new File(Environment.getRootDirectory(), \"framework\");//\"/system/framework\" // Gross hack for now: we know this file doesn't contain any // code, so don't dexopt it to avoid the resulting log spew. alreadyDexOpted.add(frameworkDir.getPath() + \"/framework-res.apk\"); // Gross hack for now: we know this file is only part of // the boot class path for art, so don't dexopt it to // avoid the resulting log spew. alreadyDexOpted.add(frameworkDir.getPath() + \"/core-libart.jar\"); /** * There are a number of commands implemented in Java, which * we currently need to do the dexopt on so that they can be * run from a non-root shell. */ String[] frameworkFiles = frameworkDir.list(); if (frameworkFiles != null) { // TODO: We could compile these only for the most preferred ABI. We should // first double check that the dex files for these commands are not referenced // by other system apps. for (String dexCodeInstructionSet : dexCodeInstructionSets) { for (int i=0; i will /system/framework/framework-res.apk /system/framework/core-libart.jar These two files are added to the optimized list alreadyDexOpted. Then search for the jar/apk file in /system/framework that does not yet have dexopt, and perform the dexopt operation. carry on: final VersionInfo ver = mSettings.getInternalVersion(); mIsUpgrade = !Build.FINGERPRINT.equals(ver.fingerprint); // when upgrading from pre-M, promote system app permissions from install to runtime mPromoteSystemApps = mIsUpgrade && ver.sdkVersion pkgSettingIter = mSettings.mPackages.values().iterator(); while (pkgSettingIter.hasNext()) { PackageSetting ps = pkgSettingIter.next(); if (isSystemApp(ps)) { mExistingSystemPackages.add(ps.name); } } } If you are upgrading the system, if you do not perform a system upgrade, ignore this code. In the next process, you will encounter a very important function of the PMS: scanDirLI // Collect vendor overlay packages. // (Do this before scanning any apps.) // For security and version matching reason, only consider // overlay packages if they reside in VENDOR_OVERLAY_DIR. File vendorOverlayDir = new File(VENDOR_OVERLAY_DIR); scanDirLI(vendorOverlayDir, PackageParser.PARSE_IS_SYSTEM | PackageParser.PARSE_IS_SYSTEM_DIR, scanFlags | SCAN_TRUSTED_OVERLAY, 0); // Find base frameworks (resource packages without code). scanDirLI(frameworkDir, PackageParser.PARSE_IS_SYSTEM | PackageParser.PARSE_IS_SYSTEM_DIR | PackageParser.PARSE_IS_PRIVILEGED, scanFlags | SCAN_NO_DEX, 0); // Collected privileged system packages. final File privilegedAppDir = new File(Environment.getRootDirectory(), \"priv-app\"); scanDirLI(privilegedAppDir, PackageParser.PARSE_IS_SYSTEM | PackageParser.PARSE_IS_SYSTEM_DIR | PackageParser.PARSE_IS_PRIVILEGED, scanFlags, 0); // Collect ordinary system packages. final File systemAppDir = new File(Environment.getRootDirectory(), \"app\"); scanDirLI(systemAppDir, PackageParser.PARSE_IS_SYSTEM | PackageParser.PARSE_IS_SYSTEM_DIR, scanFlags, 0); // Collect all vendor packages. File vendorAppDir = new File(\"/vendor/app\"); try { vendorAppDir = vendorAppDir.getCanonicalFile(); } catch (IOException e) { // failed to look up canonical path, continue with original one } scanDirLI(vendorAppDir, PackageParser.PARSE_IS_SYSTEM | PackageParser.PARSE_IS_SYSTEM_DIR, scanFlags, 0); // Collect all OEM packages. final File oemAppDir = new File(Environment.getOemDirectory(), \"app\"); scanDirLI(oemAppDir, PackageParser.PARSE_IS_SYSTEM | PackageParser.PARSE_IS_SYSTEM_DIR, scanFlags, 0); The scanDirLI method is called in turn to scan the apk files in the following directories. /vendor/overlay /system/framework /system/priv-app /system/app /vendor/app /oem/app scanDirLI method code: private void scanDirLI(File dir, int parseFlags, int scanFlags, long currentTime) { final File[] files = dir.listFiles(); if (ArrayUtils.isEmpty(files)) { Log.d(TAG, \"No files in app dir \" + dir); return;// Will traverse all the files from the incoming dir, if there is no file, return directly } if (DEBUG_PACKAGE_SCANNING) { Log.d(TAG, \"Scanning app dir \" + dir + \" scanFlags=\" + scanFlags + \" flags=0x\" + Integer.toHexString(parseFlags)); } for (File file : files) {// If there is a file, it will be traversed // Determine whether a file is an apk file (ending with apk), or a folder and the folder satisfies the condition of isStageName final boolean isPackage = (isApkFile(file) || file.isDirectory()) && !PackageInstallerService.isStageName(file.getName()); if (!isPackage) { // Ignore entries which are not packages continue; } try { // Will call scanPackageLI for the next analysis scanPackageLI(file, parseFlags | PackageParser.PARSE_MUST_BE_APK, scanFlags, currentTime, null); } catch (PackageManagerException e) { Slog.w(TAG, \"Failed to parse \" + file + \": \" + e.getMessage()); // Delete invalid userdata apps if ((parseFlags & PackageParser.PARSE_IS_SYSTEM) == 0 && e.error == PackageManager.INSTALL_FAILED_INVALID_APK) { // The apk will only be deleted if the non-systematic apk scan fails. logCriticalInfo(Log.WARN, \"Deleting invalid package at \" + file); if (file.isDirectory()) { mInstaller.rmPackageDir(file.getAbsolutePath()); } else { file.delete(); } } } } } public static boolean isStageName(String name) { final boolean isFile = name.startsWith(\"vmdl\") && name.endsWith(\".tmp\"); final boolean isContainer = name.startsWith(\"smdl\") && name.endsWith(\".tmp\"); final boolean isLegacyContainer = name.startsWith(\"smdl2tmp\"); return isFile || isContainer || isLegacyContainer; } After finding the apk file, scanPackageLI is called to parse the file and convert the apk to a PackageParser.Package object. Source location: Android-6.0/framworks/base/core/java/android/content/pm/PackageParser.java public final static class Package { public String packageName; /** Names of any split APKs, ordered by parsed splitName */ public String[] splitNames; // TODO: work towards making these paths invariant public String volumeUuid; /** * Path where this package was found on disk. For monolithic packages * this is path to single base APK file; for cluster packages this is * path to the cluster directory. */ public String codePath; /** Path of base APK */ public String baseCodePath; /** Paths of any split APKs, ordered by parsed splitName */ public String[] splitCodePaths; /** Revision code of base APK */ public int baseRevisionCode; /** Revision codes of any split APKs, ordered by parsed splitName */ public int[] splitRevisionCodes; /** Flags of any split APKs; ordered by parsed splitName */ public int[] splitFlags; ............................... PackageParser.Package is a representative of an apk file in the PMS. The information about the apk is obtained by the pm command, which is represented by this class. It records information such as the package name of the apk. The amount of code in scanPackageLI is also very large, so it is also parsed in sections. private PackageParser.Package scanPackageLI(File scanFile, int parseFlags, int scanFlags, long currentTime, UserHandle user) throws PackageManagerException { if (DEBUG_INSTALL) Slog.d(TAG, \"Parsing: \" + scanFile); parseFlags |= mDefParseFlags; PackageParser pp = new PackageParser(); pp.setSeparateProcesses(mSeparateProcesses); pp.setOnlyCoreApps(mOnlyCore); pp.setDisplayMetrics(mMetrics); if ((scanFlags & SCAN_TRUSTED_OVERLAY) != 0) { parseFlags |= PackageParser.PARSE_TRUSTED_OVERLAY; } final PackageParser.Package pkg; try { pkg = pp.parsePackage(scanFile, parseFlags); } catch (PackageParserException e) { throw PackageManagerException.from(e); } ................. scanPackageLI creates a file parser, PackageParser, which is then parsed by the parsePackage method of the parser. Continue with scanPackageLI: PackageSetting ps = null; PackageSetting updatedPkg; // reader synchronized (mPackages) { // Look to see if we already know about this package. String oldName = mSettings.mRenamedPackages.get(pkg.packageName); if (pkg.mOriginalPackages != null && pkg.mOriginalPackages.contains(oldName)) { // This package has been renamed to its original name. Let's // use that. ps = mSettings.peekPackageLPr(oldName); } // If there was no original package, see one for the real package name. if (ps == null) { //When the device is not booting for the first time, it will parse the packages.xml and store the pacakge recorded in the mPackages of mSettings. It is an ArrayMap variable. // package names to detect whether there is a scanned the ps, PackageSetting:Settings data for a particular package we know about. ps = mSettings.peekPackageLPr (pkg.packageName); } This is mainly to deal with the inconsistency of the package name after the application is upgraded. When the device is powered on for the first time, there is no such situation. In other cases, open the opportunity to parse the packages.xml. When the package name of the apk changes, the app will be in the packages.xml.Tag tag. It also counts the information changed by the package name into the ArrayMap of the mSettings variable of the PMS. In the type variable mRenamedPackages, the key is newname. Continue with scanPackageLI: // Check to see if this package could be hiding/updating a system // package. Must look for it either under the original or real // package name depending on our state. updatedPkg = mSettings.getDisabledSystemPkgLPr(ps != null ? ps.name : pkg.packageName); if (DEBUG_INSTALL && updatedPkg != null) Slog.d(TAG, \"updatedPkg = \" + updatedPkg); } boolean updatedPkgBetter = false; // First check if this is a system package that may involve an update if (updatedPkg != null && (parseFlags&PackageParser.PARSE_IS_SYSTEM) != 0) { // If new package is not located in \"/system/priv-app\" (e.g. due to an OTA), // it needs to drop FLAG_PRIVILEGED. if (locationIsPrivileged(scanFile)) { updatedPkg.pkgPrivateFlags |= ApplicationInfo.PRIVATE_FLAG_PRIVILEGED; } else { updatedPkg.pkgPrivateFlags &= ~ApplicationInfo.PRIVATE_FLAG_PRIVILEGED; } if (ps != null && !ps.codePath.equals(scanFile)) { // The path has changed from what was last scanned... check the // version of the new path against what we have stored to determine // what to do. if (DEBUG_INSTALL) Slog.d(TAG, \"Path changing from \" + ps.codePath); if (pkg.mVersionCode Here is to deal with the installation of the system update, check whether it has an impact on the system app. That is, whether to update the system app to a newer version. If so, we have to deal with it. Next is the signature of the scan apk. // Verify certificates against what was last scanned collectCertificatesLI(pp, ps, pkg, scanFile, parseFlags); Continue with scanPackageLI: /* * A new system app appeared, but we already had a non-system one of the * same name installed earlier. */ boolean shouldHideSystemApp = false; if (updatedPkg == null && ps != null && (parseFlags & PackageParser.PARSE_IS_SYSTEM_DIR) != 0 && !isSystemApp(ps)) { /* * Check to make sure the signatures match first. If they don't, * wipe the installed application and its data. */ if (compareSignatures(ps.signatures.mSignatures, pkg.mSignatures) != PackageManager.SIGNATURE_MATCH) { logCriticalInfo(Log.WARN, \"Package \" + ps.name + \" appeared on system, but\" + \" signatures don't match existing userdata copy; removing\"); deletePackageLI(pkg.packageName, null, true, null, null, 0, null, false); ps = null; } else { /* * If the newly-added system app is an older version than the * already installed version, hide it. It will be scanned later * and re-added like an update. */ if (pkg.mVersionCode The code here is to deal with the situation: when the system is updated, the update package may have some system app out, then if the user happens to install an app with the same package name. The signatures of the two are still inconsistent, then delete Information about the scanned system application. When the two signatures are the same, if the scanned version of the app is higher, the installed application is deleted; if the scanned version of the application is low, the scanned system application is hidden. Continue with scanPackageLI: // The apk is forward locked (not public) if its code and resources // are kept in different files. (except for app in either system or // vendor path). // TODO grab this value from PackageSettings if ((parseFlags & PackageParser.PARSE_IS_SYSTEM_DIR) == 0) { if (ps != null && !ps.codePath.equals(ps.resourcePath)) { parseFlags |= PackageParser.PARSE_FORWARD_LOCK; } } // TODO: extend to support forward-locked splits String resourcePath = null; String baseResourcePath = null; if ((parseFlags & PackageParser.PARSE_FORWARD_LOCK) != 0 && !updatedPkgBetter) { if (ps != null && ps.resourcePathString != null) { resourcePath = ps.resourcePathString; baseResourcePath = ps.resourcePathString; } else { // Should not happen at all. Just log an error. Slog.e(TAG, \"Resource path not set for pkg : \" + pkg.packageName); } } else { resourcePath = pkg.codePath; baseResourcePath = pkg.baseCodePath; } // Set application objects path explicitly. pkg.applicationInfo.volumeUuid = pkg.volumeUuid; pkg.applicationInfo.setCodePath(pkg.codePath); pkg.applicationInfo.setBaseCodePath(pkg.baseCodePath); pkg.applicationInfo.setSplitCodePaths(pkg.splitCodePaths); pkg.applicationInfo.setResourcePath(resourcePath); pkg.applicationInfo.setBaseResourcePath(baseResourcePath); pkg.applicationInfo.setSplitResourcePaths(pkg.splitCodePaths); Handle the application's code path and resource path. Continue with scanPackageLI: // Note that we invoke the following method only if we are about to unpack an application PackageParser.Package scannedPkg = scanPackageLI(pkg, parseFlags, scanFlags | SCAN_UPDATE_SIGNATURE, currentTime, user); Call another packagePackageLI of PackageParser to continue processing, and then analyze it. Continue with scanPackageLI: /* * If the system app should be overridden by a previously installed * data, hide the system app now and let the /data/app scan pick it up * again. */ if (shouldHideSystemApp) { synchronized (mPackages) { mSettings.disableSystemPackageLPw(pkg.packageName); } } return scannedPkg; } If the scanned system app needs to be hidden, its information is recorded in the mDisabledSysPackages of mSettings via the mSettings.disableSystemPackageLPw method. "},"Android PMS - Android 6 PMS analysis article 2.html":{"url":"Android PMS - Android 6 PMS analysis article 2.html","title":"Android PMS - Android 6 PMS analysis article 2","keywords":"","body":"1. Android 6 PMS analysis of article 21.1. Analysis of APK files1.2. Parse a single apk1.3. Parsing an app with multiple apks1.4. scanPackageDirtyLI method1. Android 6 PMS analysis of article 2 Android core service Android underlying development Android 6 PMS analysis of article 2 Analysis of APK files Parse a single apk Parsing an app with multiple apks scanPackageDirtyLI method This article focuses on two unanalyzed methods in the previous article. 1.1. Analysis of APK files The beginning of the scanPackageLI analysis in the previous article private PackageParser.Package scanPackageLI(File scanFile, int parseFlags, int scanFlags, long currentTime, UserHandle user) throws PackageManagerException { .......................... final PackageParser.Package pkg; try { pkg = pp.parsePackage(scanFile, parseFlags); } catch (PackageParserException e) { throw PackageManagerException.from(e); } ........... We did not analyze the PackageParser.parsePackage method and now we are going to analyze what it does. public Package parsePackage(File packageFile, int flags) throws PackageParserException { if (packageFile.isDirectory()) { return parseClusterPackage(packageFile, flags); } else { return parseMonolithicPackage(packageFile, flags); } } In the parsePackage method, you need to judge the incoming File. After Android 5.0, it supports the default of one app to associate multiple APKs. When an app is like this, these APKs will be placed in a folder, then parseClusterPackage will be called. When the incoming file is an apk file, call parseMonolithicPackage to handle it. 1.2. Parse a single apk First analyze the case of file as an apk file, namely parseMonolithicPackage: public Package parseMonolithicPackage(File apkFile, int flags) throws PackageParserException { if (mOnlyCoreApps) {//When the PMS is initialized, the variable is generally false, and is true only in special cases such as encryption and decryption of the data area. final PackageLite lite = parseMonolithicPackageLite(apkFile, flags); if (!lite.coreApp) { throw new PackageParserException(INSTALL_PARSE_FAILED_MANIFEST_MALFORMED, \"Not a coreApp: \" + apkFile); } } final AssetManager assets = new AssetManager();//AssetManager is the resource management framework try { final Package pkg = parseBaseApk(apkFile, assets, flags);// When parseBaseApk, will transfer the assets pkg.codePath = apkFile.getAbsolutePath(); return pkg; } finally { IoUtils.closeQuietly(assets); } } First create a resource management framework object AssetManager, and pass it to the parseBaseApk method together with apkfile: private Package parseBaseApk(File apkFile, AssetManager assets, int flags) throws PackageParserException { final String apkPath = apkFile.getAbsolutePath();// Return apkFile absolute path name string String volumeUuid = null; if (apkPath.startsWith(MNT_EXPAND)) { final int end = apkPath.indexOf('/', MNT_EXPAND.length()); volumeUuid = apkPath.substring(MNT_EXPAND.length(), end); } mParseError = PackageManager.INSTALL_SUCCEEDED; mArchiveSourcePath = apkFile.getAbsolutePath(); if (DEBUG_JAR) Slog.d(TAG, \"Scanning base APK: \" + apkPath); final int cookie = loadApkIntoAssetManager(assets, apkPath, flags); Resources res = null; XmlResourceParser parser = null; try { res = new Resources(assets, mMetrics, null); /* The member function updateConfiguration is called in the Resources class constructor. The first is to update the current configuration information of the device according to the parameters config and metrics. For example, screen size and password, country and language, keyboard configuration, etc. Then call the member function setConfiguration of the JavaManager's AssetManager object pointed to by the member variable mAssets to set the configuration information to the associated AssetManager object of the C++ layer. */ assets.setConfiguration(0, 0, null, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, Build.VERSION.RESOURCES_SDK_INT); //Create an xml parser for AndroidMainfest.xml parser = assets.openXmlResourceParser(cookie, ANDROID_MANIFEST_FILENAME); final String[] outError = new String[1]; // Start to really parse AndroidMainfest.xml final Package pkg = parseBaseApk(res, parser, flags, outError); if (pkg == null) { throw new PackageParserException(mParseError, apkPath + \" (at \" + parser.getPositionDescription() + \"): \" + outError[0]); } pkg.volumeUuid = volumeUuid; pkg.baseCodePath = apkPath; pkg.mSignatures = null; return pkg; } catch (PackageParserException e) { throw e; } catch (Exception e) { throw new PackageParserException(INSTALL_PARSE_FAILED_UNEXPECTED_EXCEPTION, \"Failed to read manifest from \" + apkPath, e); } finally { IoUtils.closeQuietly(parser); } } The method is blunt, which is to parse the AndroidMainfest.xml file. The real parsing of this xml is the parseBaseApk method that is called internally. This method first calls a constructor with pkgName as its argument to create a PackageParser.Package object. public Package(String packageName) { this.packageName = packageName; applicationInfo.packageName = packageName; applicationInfo.uid = -1; } The next step is to assign the parsed AndroidMainfest.xml information to the related attribute fields of the Package. Such as the four major components declared in the xml, the version number of the app and so on. public final static class Package { public String packageName; ......................... public String codePath; /** Path of base APK */ public String baseCodePath; /** Paths of any split APKs, ordered by parsed splitName */ public String[] splitCodePaths; ................................ // For now we only support one application per package. public final ApplicationInfo applicationInfo = new ApplicationInfo(); public final ArrayList permissions = new ArrayList(0); public final ArrayList permissionGroups = new ArrayList(0); public final ArrayList activities = new ArrayList(0); public final ArrayList receivers = new ArrayList(0); public final ArrayList providers = new ArrayList(0); public final ArrayList services = new ArrayList(0); public final ArrayList instrumentation = new ArrayList(0); ..................................... // The version code declared for this package. public int mVersionCode; // The version name declared for this package. public String mVersionName; // The shared user id that this package wants to use. public String mSharedUserId; ................................. In fact, the process of parsing apk is the process of parsing xml and then populating the PackageParser.Package object. Timing diagram: 1.3. Parsing an app with multiple apks Split APK is Google's mechanism for solving the 65536 cap, and the APK installation package is getting bigger and bigger, introduced in Android L. Split APK can split a huge APK into multiple independent APKs according to screen density, ABI, etc. When the application is updated, you don't have to download the whole APK, just download a module to install the update. Split APK separates the original APK from multiple modules sharing the same resource into multiple APKs using their own resources, and can inherit the resources in the Base APK. Multiple APKs have the same data, cache directory, multiple dex files. , the same process, only one APK is displayed in Settings.apk, and the same package name is used. See the article to learn how to use this mechanism. When this is the case, parseClusterPackage is called private Package parseClusterPackage(File packageDir, int flags) throws PackageParserException { // Get the PackageLite object of the application directory, which separately saves the names of the core and non-core applications under the directory. final PackageLite lite = parseClusterPackageLite(packageDir, 0); if (mOnlyCoreApps && !lite.coreApp) { throw new PackageParserException(INSTALL_PARSE_FAILED_MANIFEST_MALFORMED, \"Not a coreApp: \" + packageDir); } final AssetManager assets = new AssetManager(); try { // Load the base and all splits into the AssetManager // so that resources can be overriden when parsing the manifests. // Load the resources of the core application first loadApkIntoAssetManager(assets, lite.baseCodePath, flags); // Loading resources from other non-core applications if (!ArrayUtils.isEmpty(lite.splitCodePaths)) { for (String path : lite.splitCodePaths) { loadApkIntoAssetManager(assets, path, flags); } } final File baseApk = new File(lite.baseCodePath); // Parse the base application to parseBaseApk final Package pkg = parseBaseApk(baseApk, assets, flags); if (pkg == null) { throw new PackageParserException(INSTALL_PARSE_FAILED_NOT_APK, \"Failed to parse base APK: \" + baseApk); } if (!ArrayUtils.isEmpty(lite.splitNames)) { final int num = lite.splitNames.length; pkg.splitNames = lite.splitNames; pkg.splitCodePaths = lite.splitCodePaths; pkg.splitRevisionCodes = lite.splitRevisionCodes; pkg.splitFlags = new int[num]; pkg.splitPrivateFlags = new int[num]; //Call parseSplitApk on a non-core application for (int i = 0; i The parseClusterPackage first calls parseClusterPackageLite to perform a preliminary analysis of the apk files in the directory, mainly to distinguish between core applications and non-core applications. There is only one core application, and non-core applications may or may not have multiple. ParseBaseApk is called for the core application, parseSplitApk is called for the non-core application, and the parsed result is stored in the same PackageParser.Package object. Timing diagram: 1.4. scanPackageDirtyLI method The scanPackageLI method of the previous analysis also calls the same scanPackageLI method with different parameters. private PackageParser.Package scanPackageLI(PackageParser.Package pkg, int parseFlags, int scanFlags, long currentTime, UserHandle user) throws PackageManagerException { boolean success = false; try { final PackageParser.Package res = scanPackageDirtyLI(pkg, parseFlags, scanFlags, currentTime, user); success = true; return res; } finally { if (!success && (scanFlags & SCAN_DELETE_DATA_ON_FAILURES) != 0) { removeDataDirsLI(pkg.volumeUuid, pkg.packageName); } } } The method internally calls scanPackageDirtyLI to do the corresponding work. The scanPackageLI method can also be called separately. We only care about the logic when it is called by the previous scanPackageLI method. There is such a scene in the Android system. When an intent is issued, if there are multiple responding activities in the dialog box, Android will pop up a dialog box for the user to select. A typical example is when you install multiple software files that can be opened in the device. When you open the word, if you have not set the default software, then a dialog box will pop up, let the user choose which app to use. Open the word file. This dialog is called ResolverActivity. So the dialog is an object that exists inside the system and it is stored in the mResolveActivity variable of the PMS. The code for ResolverActivity is located in framework-res.apk, so when scanPackageLi scans that the package name of the file is \"Android\", it will extract the ResolverActivity information from the file and create the mResolveActivity object. If the system specifies an alternate ResolverActivity by defining the string \"config_customResolverActivity\", then after the alternative package name is found, the mResolveActivity object is created, not using the ResolverActivity in framework-res.apk. private PackageParser.Package scanPackageDirtyLI(PackageParser.Package pkg, int parseFlags, int scanFlags, long currentTime, UserHandle user) throws PackageManagerException { ................... if (mCustomResolverComponentName != null && mCustomResolverComponentName.getPackageName().equals(pkg.packageName)) { // mResolverReplaced is set to true in this method setUpCustomResolverActivity(pkg); } ................... if (pkg.packageName.equals(\"android\")) { synchronized (mPackages) { if (mAndroidApplication != null) { Slog.w(TAG, \"*************************************************\"); Slog.w(TAG, \"Core android package being redefined. Skipping.\"); Slog.w(TAG, \" file=\" + scanFile); Slog.w(TAG, \"*************************************************\"); throw new PackageManagerException(INSTALL_FAILED_DUPLICATE_PACKAGE, \"Core android package being redefined. Skipping.\"); } // Set up information for our fall-back user intent resolution activity. mPlatformPackage = pkg; pkg.mVersionCode = mSdkVersion; mAndroidApplication = pkg.applicationInfo; if (!mResolverReplaced) { mResolveActivity.applicationInfo = mAndroidApplication; mResolveActivity.name = ResolverActivity.class.getName(); mResolveActivity.packageName = mAndroidApplication.packageName; mResolveActivity.processName = \"system:ui\"; mResolveActivity.launchMode = ActivityInfo.LAUNCH_MULTIPLE; mResolveActivity.documentLaunchMode = ActivityInfo.DOCUMENT_LAUNCH_NEVER; mResolveActivity.flags = ActivityInfo.FLAG_EXCLUDE_FROM_RECENTS; mResolveActivity.theme = R.style.Theme_Holo_Dialog_Alert; mResolveActivity.exported = true; mResolveActivity.enabled = true; mResolveInfo.activityInfo = mResolveActivity; mResolveInfo.priority = 0; mResolveInfo.preferredOrder = 0; mResolveInfo.match = 0; mResolveComponentName = new ComponentName( mAndroidApplication.packageName, mResolveActivity.name); } } } ..................... } An app with the same name may have been scanned and installed in another directory, so an exception is thrown. if (mPackages.containsKey(pkg.packageName) || mSharedLibraries.containsKey(pkg.packageName)) { throw new PackageManagerException(INSTALL_FAILED_DUPLICATE_PACKAGE, \"Application package \" + pkg.packageName + \" already installed. Skipping duplicate.\"); } The next code doesn't stick too much, and I have to say what the rest of the code does. If there is a scanning applicationLabels, and upgrade packages add the package's Sydney West to mSeetings' mRenamedPackages variable, which is also stored in packages.xmlUnder the label. Verify the signature again and check if the app signature of the shared UID is consistent. Inconsistent reports an error. Use fixProcessName() to modify the process name of the app in the future. It can be read by /proc/self/cmdline in the future. If the application's sandbox directory already exists, check for errors, such as whether the uids are consistent, etc. If an error is found, delete the data directory and re-establish it. To install the dynamics in the app, here are the differences between the system app and the third-party app. The so library of the system app is usually placed under /system/lib. In addition, there will be a connection file in the directory of the system app pointing to the so library under /system/lib, which causes the system app to determine the abi used by the so library by analyzing the directory file. The third-party app can be used by armeabi, armeabi. The directory name such as -v7a determines its abi. For third-party apps, their so libraries will be placed /data/app//lib/(arm/arm64/x86)/ Then create a lib connection file in the sandbox directory, pointing to the above directory. If it detects that the dynamic library file that the application depends on has changed, call performDexOpt to re-execute. Finally, the Activity, Service, Provider, receiver, permission, Permission Group and other information in the app are extracted and put into the PMS related member variables. "},"Android PMS - Android 6 PMS analysis of the next article.html":{"url":"Android PMS - Android 6 PMS analysis of the next article.html","title":"Android PMS - Android 6 PMS analysis of the next article","keywords":"","body":"1. Android 6 PMS analysis of the next article1. Android 6 PMS analysis of the next article Android core service Android underlying development I introduced the code when scanning the system app directory when the PMS was started. Now I analyze how to scan the user-installed app when the PMS starts. Continue PMS construction method //Call installd to execute the command script under /system/etc/updatecmds if (DEBUG_UPGRADE) Log.v(TAG, \"Running installd update commands\"); mInstaller.moveFiles(); The next piece of code is to process the system application with the upgrade package, that is, the logic that needs to be concerned when starting the OTA upgrade for the first time: // Prune any system packages that no longer exist. final List possiblyDeletedUpdatedSystemApps = new ArrayList(); if (!mOnlyCore) { Iterator psit = mSettings.mPackages.values().iterator(); while (psit.hasNext()) { PackageSetting ps = psit.next(); /* * If this is not a system app, it can't be a * disable system app. */ if ((ps.pkgFlags & ApplicationInfo.FLAG_SYSTEM) == 0) { continue;//Ignore normal applications } /* * If the package is scanned, it's not erased. */ final PackageParser.Package scannedPkg = mPackages.get(ps.name); if (scannedPkg != null) { /* * If the system app is both scanned and in the * disabled packages list, then it must have been * added via OTA. Remove it from the currently * scanned package so the previously user-installed * application can be scanned. */ // The package modified by in packages.xml will be recorded in the disable list in mSettings. // This means that the scanned system app is with the upgrade package. if (mSettings.isDisabledSystemPackageLPr(ps.name)) { logCriticalInfo(Log.WARN, \"Expecting better updated system app for \" + ps.name + \"; removing system app. Last known codePath=\" + ps.codePathString + \", installStatus=\" + ps.installStatus + \", versionCode=\" + ps.versionCode + \"; scanned versionCode=\" + scannedPkg.mVersionCode); removePackageLI(ps, true);//Remove it from mPackages mExpectingBetter.put(ps.name, ps.codePath);// Add it to mExpectingBetter, follow-up } continue; } // Run here to illustrate the app recorded in packages.xml, this time not scanned. if (!mSettings.isDisabledSystemPackageLPr(ps.name)) { // If the app is in packages.xml it does not belong to // This means that the application is left in the packages.xml, and there may be sandbox data left, so delete it too. psit.remove(); logCriticalInfo(Log.WARN, \"System package \" + ps.name + \" no longer exists; wiping its data\"); removeDataDirsLI(null, ps.name); } else { // If this app belongs to in packages.xml // Add it to the potentiallyDeletedUpdatedSystemApps final PackageSetting disabledPs = mSettings.getDisabledSystemPkgLPr(ps.name); if (disabledPs.codePath == null || !disabledPs.codePath.exists()) { possiblyDeletedUpdatedSystemApps.add(ps.name); } } } } Do some cleaning work: //Scan and delete unsuccessfully installed apk packages (for third-party apps) //look for any incomplete package installations ArrayList deletePkgsList = mSettings.getListOfIncompleteInstallPackagesLPr(); //clean up list for(int i = 0; i Now scan the user-installed app. EventLog.writeEvent(EventLogTags.BOOT_PROGRESS_PMS_DATA_SCAN_START, SystemClock.uptimeMillis()); scanDirLI(mAppInstallDir, 0, scanFlags | SCAN_REQUIRE_KNOWN, 0); scanDirLI(mDrmAppPrivateInstallDir, PackageParser.PARSE_FORWARD_LOCK, scanFlags | SCAN_REQUIRE_KNOWN, 0); The same is to call the scanDirLI method to scan the apk directory. The two files to be scanned here are: /data/app /data/app-priv The logic is the same as the previous one, except that the incoming scan parameters have changed: SCAN_REQUIRE_KNOWN. Next is the handling of possibleDeletedUpdatedSystemApps. It is stored in the packages.xml is marked as, but there is no app that scans its apk file in front. /** * Remove disable package settings for any updated system * apps that were removed via an OTA. If they're not a * previously-updated app, remove them completely. * Otherwise, just revoke their system-level permissions. */ for (String deletedAppName : possiblyDeletedUpdatedSystemApps) { // After scanning the user's app directory, try again to find out if there are these apps. PackageParser.Package deletedPkg = mPackages.get(deletedAppName); mSettings.removeDisabledSystemPackageLPw(deletedAppName); String msg; // Still not, then delete their data directory if (deletedPkg == null) { msg = \"Updated system package \" + deletedAppName + \" no longer exists; wiping its data\"; removeDataDirsLI(null, deletedAppName); } else { // Found, the description is found in the user app directory, then remove the system permissions msg = \"Updated system app + \" + deletedAppName + \" no longer present; removing system privileges for \" + deletedAppName; deletedPkg.applicationInfo.flags &= ~ApplicationInfo.FLAG_SYSTEM; PackageSetting deletedPs = mSettings.mPackages.get(deletedAppName); deletedPs.pkgFlags &= ~ApplicationInfo.FLAG_SYSTEM; } logCriticalInfo(Log.WARN, msg); } Storing to mExpectingBetter is a system application with an upgrade package. They have been removed from the PMS mPackages and placed in the mExpectingBetter. /** * Make sure all system apps that we expected to appear on * the userdata partition actually showed up. If they never * appeared, crawl back and revive the system version. */ for (int i = 0; i The next code is to update the dynamic library path of all applications. If the OTA upgrade causes the SDK versions to be inconsistent, check the permissions again and delete the app oat cache directory. Update the database version and call mSettings.writeLPr() to write the information to packages.xml. Finally create the mInstallerService object: mInstallerService = new PackageInstallerService(context, this); The implementation process of the PMS construction method is to first read all the installed app information before the system shutdown recorded in the packages.xml, and save it in the mPackages in the mSettings. Then scan the app in several specified directories and record the information in the mPackages of the PMS. Finally, compare the two to see if you can find an upgraded app, then perform related processing, and finally write to packages.xml. "},"Android PMS - Android 6 PMS install APK prelude.html":{"url":"Android PMS - Android 6 PMS install APK prelude.html","title":"Android PMS - Android 6 PMS install APK prelude","keywords":"","body":"1. Android 6 PMS install APK prelude1.1. How to get a PMS proxy object1.2. Install apk1. Android 6 PMS install APK prelude Android core service Android underlying development Android 6 PMS install APK prelude How to get a PMS proxy object Install apk I introduced how the PMS is started. Now I will show you how to install an APK on the Android system. When the PMS was introduced earlier, it has been determined that the PMS will be registered as a service. When the Android system needs to use a service, it usually finds its client agent and then uses the functions provided by the PMS through its proxy. As shown in FIG: IPackageManager uses the Android AIDL language to define the business functions to be provided by the server, then the AIDL compiler will automatically generate the IPackageManager interface code, its subclass Stub inherits the Binder and implements the IPackageManager interface. PMS inherits Stub, so it can be used as a server. An internal class Proxy in the Stub has an IBinder member variable mRemote, which can communicate with the server using mRemote. The client side is processed by using the ApplicationPackageManager object returned by the Context.getPackageManager function. The internal component variable mPM of the ApplicationPackageManager points to the object of the Proxy type. This means that you can communicate with the PMS. This is a typical Binder service model. Many key services of the Android system use the binder service model. Finally, the proxy of the PMS obtained by the upper layer is the implementation class ApplicationPackageManager object of the abstract class of PackageManager. 1.1. How to get a PMS proxy object Use the following code to get a proxy object to the PMS: Context ct = getApplicationContext(); PackageManager pm = ct.getPackageManager(); Where getPackageManager source location: Android-6/frameworks/base/core/java/android/app/ContextImpl.java The implementation code is as follows: public PackageManager getPackageManager() { if (mPackageManager != null) { return mPackageManager; } IPackageManager pm = ActivityThread.getPackageManager(); if (pm != null) { // Doesn't matter if we make more than one instance. return (mPackageManager = new ApplicationPackageManager(this, pm)); } return null; } ActivityThread.getPackageManager source location: Android-6/frameworks/base/core/java/android/app/ActivityThread.java public static IPackageManager getPackageManager() { if (sPackageManager != null) { //Slog.v(\"PackageManager\", \"returning cur default = \" + sPackageManager); return sPackageManager; } IBinder b = ServiceManager.getService(\"package\"); //Slog.v(\"PackageManager\", \"default service binder = \" + b); sPackageManager = IPackageManager.Stub.asInterface(b); //Slog.v(\"PackageManager\", \"default service = \" + sPackageManager); return sPackageManager; } As long as you understand the Android binder framework, you will immediately find out that this is nothing more than querying the SM for a service named \"package\". If the SM query is successful, return a reference object named \"package\" service, and then use asInterface to convert it. Proxy object. When the PMS registers with the SM, the name is indeed \"package\". Android-6/frameworks/base/services/core/java/com/android/server/pm/PackageManagerService.java public static PackageManagerService main(Context context, Installer installer, boolean factoryTest, boolean onlyCore) { PackageManagerService m = new PackageManagerService(context, installer, factoryTest, onlyCore); ServiceManager.addService(\"package\", m); return m; } The call to the PackageManager is eventually converted to a call to the PMS. 1.2. Install apk You can use the following code to call to install an apk file that is already in the device's apk. File apkfile = new File(\"/data/local/tmp/demo.apk\"); Uri uri = Uri.fromFile(apkfile); Intent intent = new Intent(Intent.ACTION_VIEW); intent.setDataAndType(uri,\"application/vnd.android.package-archive\"); startActivity(intent); Source path: Android-6/packages/apps/PackageInstaller The system application PackageInstaller will respond to this intent. It's in AndroidMainifest.xml: ....... In other words, PackageInstallerActivity will actually respond to this intent. There are two important members in PackageInstallerActivity PackageManager mPm; PackageInstaller mInstaller; Where mPm is the proxy object of the PMS, and mInstaller is the proxy object of the PackageInstallerService. After the PMS class, the PackageInstallerService is cohesive, and when the PMS is started, the amount of change is initialized. When the PackageInstallerActivity activity is started protected void onCreate(Bundle icicle) { super.onCreate(icicle); mPm = getPackageManager(); mInstaller = mPm.getPackageInstaller(); .............. These two objects were obtained from the beginning. Continue the onCreate of PackageInstallerActivity: if (PackageInstaller.ACTION_CONFIRM_PERMISSIONS.equals(intent.getAction())) { ............... } else { //This branch of walking mSessionId = -1; mPackageURI = intent.getData(); mOriginatingURI = intent.getParcelableExtra(Intent.EXTRA_ORIGINATING_URI); mReferrerURI = intent.getParcelableExtra(Intent.EXTRA_REFERRER); } ....................... if (\"package\".equals(mPackageURI.getScheme())) { ................. } else { // This branch of walking mInstallFlowAnalytics.setFileUri(true); final File sourceFile = new File(mPackageURI.getPath()); PackageParser.Package parsed = PackageUtil.getPackageInfo(sourceFile); // Check for parse errors if (parsed == null) { Log.w(TAG, \"Parse error when parsing manifest. Discontinuing installation\"); showDialogInner(DLG_PACKAGE_ERROR); setPmResult(PackageManager.INSTALL_FAILED_INVALID_APK); mInstallFlowAnalytics.setPackageInfoObtained(); mInstallFlowAnalytics.setFlowFinished( InstallFlowAnalytics.RESULT_FAILED_TO_GET_PACKAGE_INFO); return; } mPkgInfo = PackageParser.generatePackageInfo(parsed, null, PackageManager.GET_PERMISSIONS, 0, 0, null, new PackageUserState()); mPkgDigest = parsed.manifestDigest; as = PackageUtil.getAppSnippet(this, mPkgInfo.applicationInfo, sourceFile); } The code logic is still relatively easy to understand, from the intent to get the path to the apk to be installed. Call PackageUtil.getPackageInfo to resolve. Where PackageUtil.getPackageInfo: public static PackageParser.Package getPackageInfo(File sourceFile) { final PackageParser parser = new PackageParser(); try { PackageParser.Package pkg = parser.parseMonolithicPackage(sourceFile, 0); parser.collectManifestDigest(pkg); return pkg; } catch (PackageParserException e) { return null; } } Is there a familiar feeling, when the PMS is started, the scan parsing APK does not use the PackageParser. Android-6/frameworks/base/core/java/android/content/pm/PackageParser.java public Package parseMonolithicPackage(File apkFile, int flags) throws PackageParserException { if (mOnlyCoreApps) { .................... } final AssetManager assets = new AssetManager(); try { final Package pkg = parseBaseApk(apkFile, assets, flags); pkg.codePath = apkFile.getAbsolutePath(); return pkg; } finally { IoUtils.closeQuietly(assets); } } Is to call parseBaseApk to parse the incoming apk file, this process is actually parsing the AndroidMainfest.xml file in the apk, the information in the village is thick, and the analysis results are stored in the PackageParser.Package object. The parsed Package object is then converted to a PackageInfo object by the generatePackageInfo() method. Continue the onCreate of PackageInstallerActivity: // Block the install attempt on the Unknown Sources setting if necessary. if (!requestFromUnknownSource) { initiateInstall(); return; } // If the admin prohibits it, or we're running in a managed profile, just show error // and exit. Otherwise show an option to take the user to Settings to change the setting. final boolean isManagedProfile = mUserManager.isManagedProfile(); if (!unknownSourcesAllowedByAdmin || (!unknownSourcesAllowedByUser && isManagedProfile)) { showDialogInner(DLG_ADMIN_RESTRICTS_UNKNOWN_SOURCES); mInstallFlowAnalytics.setFlowFinished( InstallFlowAnalytics.RESULT_BLOCKED_BY_UNKNOWN_SOURCES_SETTING); } else if (!unknownSourcesAllowedByUser) { // Ask user to enable setting first showDialogInner(DLG_UNKNOWN_SOURCES); mInstallFlowAnalytics.setFlowFinished( InstallFlowAnalytics.RESULT_BLOCKED_BY_UNKNOWN_SOURCES_SETTING); } else { initiateInstall(); } requestFromUnknownSource is true because we did install it from an unknown source and did not install it through the built-in app store. Do some checks here, for example, if you do not open the allowable installation location source in the settings, this will pop up a prompt box, and then the user goes to the settings to open the allow location source installation. In the end, the method of initialInstall is called. private void initiateInstall() { String pkgName = mPkgInfo.packageName; // Check if there is already a package on the device with this name // but it has been renamed to something else. String[] oldName = mPm.canonicalToCurrentPackageNames(new String[] { pkgName }); if (oldName != null && oldName.length > 0 && oldName[0] != null) { pkgName = oldName[0]; mPkgInfo.packageName = pkgName; mPkgInfo.applicationInfo.packageName = pkgName; } // Check if package is already installed. display confirmation dialog if replacing pkg try { // This is a little convoluted because we want to get all uninstalled // apps, but this may include apps with just data, and if it is just // data we still want to count it as \"installed\". mAppInfo = mPm.getApplicationInfo(pkgName, PackageManager.GET_UNINSTALLED_PACKAGES); if ((mAppInfo.flags&ApplicationInfo.FLAG_INSTALLED) == 0) { mAppInfo = null; } } catch (NameNotFoundException e) { mAppInfo = null; } mInstallFlowAnalytics.setReplace(mAppInfo != null); mInstallFlowAnalytics.setSystemApp( (mAppInfo != null) && ((mAppInfo.flags & ApplicationInfo.FLAG_SYSTEM) != 0)); startInstallConfirm(); } The code logic is also very simple, mainly to determine whether the app is already installed in the current system. If it is installed, set the replacement flag and other information, then call startInstallConfirm, a dialog box will pop up asking if you need to install this application, and the app will What permissions are obtained, etc. Because the apk has been parsed before, it is very simple to show which permissions it has. When clicking the OK button, execute the following code: public void onClick(View v) { if (v == mOk) { if (mOkCanInstall || mScrollView == null) { mInstallFlowAnalytics.setInstallButtonClicked(); if (mSessionId != -1) { ................. } else { // Take this branch startInstall(); } } else { mScrollView.pageScroll(View.FOCUS_DOWN); } } else if(v == mCancel) { ........................ } } The main work is done by startInstall(): private void startInstall() { // Start subactivity to actually install the application Intent newIntent = new Intent(); newIntent.putExtra(PackageUtil.INTENT_ATTR_APPLICATION_INFO, mPkgInfo.applicationInfo); newIntent.setData(mPackageURI); newIntent.setClass(this, InstallAppProgress.class); newIntent.putExtra(InstallAppProgress.EXTRA_MANIFEST_DIGEST, mPkgDigest); newIntent.putExtra( InstallAppProgress.EXTRA_INSTALL_FLOW_ANALYTICS, mInstallFlowAnalytics); String installerPackageName = getIntent().getStringExtra( Intent.EXTRA_INSTALLER_PACKAGE_NAME); if (mOriginatingURI != null) { newIntent.putExtra(Intent.EXTRA_ORIGINATING_URI, mOriginatingURI); } if (mReferrerURI != null) { newIntent.putExtra(Intent.EXTRA_REFERRER, mReferrerURI); } if (mOriginatingUid != VerificationParams.NO_UID) { newIntent.putExtra(Intent.EXTRA_ORIGINATING_UID, mOriginatingUid); } if (installerPackageName != null) { newIntent.putExtra(Intent.EXTRA_INSTALLER_PACKAGE_NAME, installerPackageName); } if (getIntent().getBooleanExtra(Intent.EXTRA_RETURN_RESULT, false)) { newIntent.putExtra(Intent.EXTRA_RETURN_RESULT, true); newIntent.addFlags(Intent.FLAG_ACTIVITY_FORWARD_RESULT); } if(localLOGV) Log.i(TAG, \"downloaded app uri=\"+mPackageURI); startActivity(newIntent); finish(); } } Create an Intent here, set the data and which class to send to, call startActivity (newIntent), start InstallAppProgress. "},"Android PMS - Android 6 PMS installation APK.html":{"url":"Android PMS - Android 6 PMS installation APK.html","title":"Android PMS - Android 6 PMS installation APK","keywords":"","body":"1. Android 6 PMS installation APK1.1. Permission check1.2. Copy file1. Android 6 PMS installation APK Android core service Android underlying development Android 6 PMS installation APK Permission check Copy file Now let's formally analyze how Android installs an APK. When using an Intent to install an apk file in an Android store, it is actually called by an internal application packageinstaller of the Android system. This built-in system application will display the installation process, and naturally there is an interface. Everyone should be very familiar with it. It is nothing more than displaying some progress bars, what permissions this app has, and whether it is open after installation. The packageinstaller is also a call to the PMS. When installing, the PMS related interface will be called first, and the APK file, that is, its AndroidMainifest.xml file, will be parsed, so that the app components, permissions, package names and other information are obtained. Then check the app is installed by the package name key. If it is installed, set the flag of replace:INSTALL_REPLACE_EXISTING. If it has not been installed before, then an activity will pop up, showing what permissions the app has. There are two Buttons at the bottom: \"Cancel\" and \"Install\". Click \"Install\" and it will start to install. If the app has been installed before, the pop-up Activity will prompt: \"Do you want to install a new version of this app?...\", and finally list the new app compared to the app already installed on the device. What changes have been made to the permissions, such as which permissions have been added. Two buttons are also provided at the bottom: \"Cancel\" and \"Install\". Click \"Install\" and it will start to install. After clicking the \"Install\" button, it actually jumps to the InstallAppProgress activity of the PackageInstaller. Android-6/frameworks/base/core/java/android/content/pm/InstallAppProgress.java In fact, it is the onCreate method of the activity. The method calls the initView method. The initView method performs a series of judgments again and creates an observer class PackageInstallObserver object for observing whether the installation is successful. Then, the following method is called to start the real installation. process. pm.installPackageWithVerificationAndEncryption(mPackageURI, observer, installFlags, installerPackageName, verificationParams, null); Its code is implemented: Android6.0/frameworks/base/core/java/android/app/ApplicationPackageManager.java public void installPackageWithVerificationAndEncryption(Uri packageURI, PackageInstallObserver observer, int flags, String installerPackageName, VerificationParams verificationParams, ContainerEncryptionParams encryptionParams) { installCommon(packageURI, observer, flags, installerPackageName, verificationParams, encryptionParams); } The installCommon method is called directly inside: private void installCommon(Uri packageURI, PackageInstallObserver observer, int flags, String installerPackageName, VerificationParams verificationParams, ContainerEncryptionParams encryptionParams) { if (!\"file\".equals(packageURI.getScheme())) { throw new UnsupportedOperationException(\"Only file:// URIs are supported\"); } if (encryptionParams != null) { throw new UnsupportedOperationException(\"ContainerEncryptionParams not supported\"); } final String originPath = packageURI.getPath(); try { mPM.installPackage(originPath, observer.getBinder(), flags, installerPackageName, verificationParams, null); } catch (RemoteException ignored) { } } After making a series of judgments, then call mPM's installPackage method. mPM is a proxy for PMS. This means that the installPackage method of the PMS will actually be called here: public void installPackage(String originPath, IPackageInstallObserver2 observer, int installFlags, String installerPackageName, VerificationParams verificationParams, String packageAbiOverride) { installPackageAsUser(originPath, observer, installFlags, installerPackageName, verificationParams, packageAbiOverride, UserHandle.getCallingUserId()); } The key point here is to remind that the last parameter packageAbiOverride is passed in, meaning follow-up The entire installation process is complex and can be roughly divided into two processes: Permission check Copy file Loading application 1.1. Permission check public void installPackageAsUser(String originPath, IPackageInstallObserver2 observer, int installFlags, String installerPackageName, VerificationParams verificationParams, String packageAbiOverride, int userId) { mContext.enforceCallingOrSelfPermission(android.Manifest.permission.INSTALL_PACKAGES, null); // Use the binder mechanism to get the uid final int of the installation process. callingUid = Binder.getCallingUid(); // enforceCrossUserPermission(callingUid, userId, true , true , \"installPackageAsUser\" ); .............................................. Check permissions first: void enforceCrossUserPermission(int callingUid, int userId, boolean requireFullPermission, boolean checkShell, String message) { if (userId The permission check here is mainly to check if the process has permission to install. Continue with the installPackageAsUser code: //Check if the current system user has permission to install the app. if (isUserRestricted(userId, UserManager.DISALLOW_INSTALL_APPS)) { try { if (observer != null) { observer.onPackageInstalled(\"\", INSTALL_FAILED_USER_RESTRICTED, null, null); } } catch (RemoteException re) { } return; } //If the originating process is shell or root, add flags:PackageManager.INSTALL_FROM_ADB if ((callingUid == Process.SHELL_UID) || (callingUid == Process.ROOT_UID)) { installFlags |= PackageManager.INSTALL_FROM_ADB; } else { // Caller holds INSTALL_PACKAGES permission, so we're less strict // about installerPackageName. // Remove INSTALL_FROM_ADB and INSTALL_ALL_USERS from flags installFlags &= ~PackageManager.INSTALL_FROM_ADB; installFlags &= ~PackageManager.INSTALL_ALL_USERS; } //Create a current user's handle UserHandle user; if ((installFlags & PackageManager.INSTALL_ALL_USERS) != 0) { user = UserHandle.ALL; } else { user = new UserHandle(userId); } // Only system components can circumvent runtime permissions when installing. // Android 6.0 When the permissions belong to the runtime permissions, a pop-up box is required to allow the user to authorize. For the system app, the runtime permission permission should be canceled, but the authorization is directly authorized. // Then add INSTALL_GRANT_RUNTIME_PERMISSIONS to the system app // We install a third-party app, of course there is no INSTALL_GRANT_RUNTIME_PERMISSIONS if ((installFlags & PackageManager.INSTALL_GRANT_RUNTIME_PERMISSIONS) != 0 && mContext.checkCallingOrSelfPermission(Manifest.permission .INSTALL_GRANT_RUNTIME_PERMISSIONS) == PackageManager.PERMISSION_DENIED) { throw new SecurityException(\"You need the \" + \"android.permission.INSTALL_GRANT_RUNTIME_PERMISSIONS permission \" + \"to use the PackageManager.INSTALL_GRANT_RUNTIME_PERMISSIONS flag\"); } verificationParams.setInstallerUid(callingUid); This is mainly to check whether the current user has permission to install the app, and whether the installed app is installed only for the current user or for all users. From the above code, it can be concluded that when the installation process is shell or root, the flag contains INSTALL_ALL_USERS, it will be installed for all users, otherwise in most cases, only the current user is installed. When we use the pm command to install, we can choose which user to install to, or all users, for this reason. Continue with the installPackageAsUser code: final File originFile = new File(originPath); //Subsequent judgments when the APK is installed, will be used final OriginInfo origin = OriginInfo.fromUntrustedFile(originFile); final Message msg = mHandler.obtainMessage(INIT_COPY); msg.obj = new InstallParams(origin, null, observer, installFlags, installerPackageName, null, verificationParams, user, packageAbiOverride, null); mHandler.sendMessage(msg); } Construct InstallParams, note that packageAbiOverride is null, and then use the Handler mechanism in Android to send to the relevant thread to install. The entire execution logic of installPackageAsUser is shown below. 1.2. Copy file I sent the INIT_COPY message in front, now I see how to handle: void doHandleMessage(Message msg) { switch (msg.what) { case INIT_COPY: { HandlerParams params = (HandlerParams) msg.obj; int idx = mPendingInstalls.size(); if (DEBUG_INSTALL) Slog.i(TAG, \"init_copy idx=\" + idx + \": \" + params); // If a bind was already initiated we dont really // need to do anything. The pending install // will be processed later on. if (!mBound) { // If this is the only one pending we might // have to bind to the service again. // Will bind the DefaultContainerService service if (!connectToService()) { Slog.e(TAG, \"Failed to bind to media container service\"); params.serviceError();//Connection service failed return; } else { // Once we bind to the service, the first // pending request will be processed. // The connection is successful, save the installation information to mPendingInstalls // Wait for the return message of the connection to be received before proceeding with the installation mPendingInstalls.add(idx, params); } } else { // Insert installation information mPendingInstalls.add(idx, params); // Already bound to the service. Just make // sure we trigger off processing the first request. if (idx == 0) { //If there is only one entry in mPendingInstalls, then the MCS_BOUND message is sent immediately. mHandler.sendEmptyMessage(MCS_BOUND); } } break; } ........ The INCon_COPY message will be bound to the DefaultContainerService, because this is an asynchronous procedure. The result of the binding to be waited is returned by onServiceConnected(), so the installed parameter information is placed in the mPendingInstalls list. Bind it up, don't bind it again now, the installation information should also be placed in mPendingInstalls. If multiple installation requests arrive at the same time, they can be queued through the mPendingInstalls list. If there is only one item in the list, there is no more installation request, so in this case, you need to immediately issue the MCS_BOUND message and proceed to the next step. private boolean connectToService() { if (DEBUG_SD_INSTALL) Log.i(TAG, \"Trying to bind to\" + \" DefaultContainerService\"); Intent service = new Intent().setComponent(DEFAULT_CONTAINER_COMPONENT); Process.setThreadPriority(Process.THREAD_PRIORITY_DEFAULT); if (mContext.bindServiceAsUser(service, mDefContainerConn, Context.BIND_AUTO_CREATE, UserHandle.OWNER)) { Process.setThreadPriority(Process.THREAD_PRIORITY_BACKGROUND); mBound = true; return true; } Process.setThreadPriority(Process.THREAD_PRIORITY_BACKGROUND); return false; } class DefaultContainerConnection implements ServiceConnection { public void onServiceConnected(ComponentName name, IBinder service) { if (DEBUG_SD_INSTALL) Log.i(TAG, \"onServiceConnected\"); IMediaContainerService imcs = IMediaContainerService.Stub.asInterface(service); mHandler.sendMessage(mHandler.obtainMessage(MCS_BOUND, imcs)); } public void onServiceDisconnected(ComponentName name) { if (DEBUG_SD_INSTALL) Log.i(TAG, \"onServiceDisconnected\"); } } You can see that an IBinder is converted to an IMediaContainerService in onServiceConnected when the binding is successful. This is a remote proxy object created by the object reference of IMediaContainerService.Stub passed in by the parameter in the onServiceConnected callback function. Later, the PMS service accesses the DefaultContainerService service through the proxy object. It is an application service. The entire INIT_COPY logic is as shown. Next, analyze the MCS_BOUND message. case MCS_BOUND: { if (DEBUG_INSTALL) Slog.i(TAG, \"mcs_bound\"); if (msg.obj != null) { mContainerService = (IMediaContainerService) msg.obj; } if (mContainerService == null) { if (!mBound) { // Something seriously wrong since we are not bound and we are not // waiting for connection. Bail out. Slog.e(TAG, \"Cannot bind to media container service\"); for (HandlerParams params : mPendingInstalls) { // Indicate service bind error // The connection failed, and the caller was notified of the error through the ruined interface in the parameter. params.serviceError(); } mPendingInstalls.clear(); } else { Slog.w(TAG, \"Waiting to connect to media container service\"); } } else if (mPendingInstalls.size() > 0) { HandlerParams params = mPendingInstalls.get(0); if (params != null) { if (params.startCopy()) {//==============Perform a copy operation // We are done... look for more work or to // go idle. if (DEBUG_SD_INSTALL) Log.i(TAG, \"Checking for more work or unbind...\"); // Delete pending install if (mPendingInstalls.size() > 0) { mPendingInstalls.remove(0);//Delete the first item after the work is completed } if (mPendingInstalls.size() == 0) { if (mBound) { if (DEBUG_SD_INSTALL) Log.i(TAG, \"Posting delayed MCS_UNBIND\"); removeMessages(MCS_UNBIND); Message ubmsg = obtainMessage(MCS_UNBIND); // Unbind after a little delay, to avoid // continual thrashing. // If there is no installation information, send a MCS_UNBIND message with a delay of 10 seconds. sendMessageDelayed(ubmsg, 10000); } } else { // There are more pending requests in queue. // Just post MCS_BOUND message to trigger processing // of next pending install. // If there is still installation information, continue to send MCS_BOUND message if (DEBUG_SD_INSTALL) Log.i(TAG, \"Posting MCS_BOUND for next work\"); mHandler.sendEmptyMessage(MCS_BOUND); } } } } else { // Should never happen ideally. Slog.w(TAG, \"Empty queue\"); } break; } The processing of the MCS_BOUND message is to call the startCopy() method of the InstallParams class to perform the copy operation. As long as there is installation information in mPendingInstalls, the MCS_BOUND message will be sent repeatedly until all applications are installed, and then a MCS_UNBIND message with a delay of 10 seconds is sent. case MCS_UNBIND: { // If there is no actual work left, then time to unbind. if (DEBUG_INSTALL) Slog.i(TAG, \"mcs_unbind\"); if (mPendingInstalls.size() == 0 && mPendingVerification.size() == 0) { if (mBound) { if (DEBUG_INSTALL) Slog.i(TAG, \"calling disconnectService()\"); disconnectService(); } } else if (mPendingInstalls.size() > 0) { // There are more pending requests in queue. // Just post MCS_BOUND message to trigger processing // of next pending install. mHandler.sendEmptyMessage(MCS_BOUND); } break; } The processing of the MCS_UNBIND message is simple. When there is no installation information in mPendingInstalls, the disconnectService is called to disconnect from the DefaultContainerService. If there is still installation information, continue to send the MCS_BOUND message. Next, analyze the real copy method: startCopy final boolean startCopy() { boolean res; try { if (DEBUG_INSTALL) Slog.i(TAG, \"startCopy \" + mUser + \": \" + this); // MAX_RETRIES为4 if (++mRetries > MAX_RETRIES) { Slog.w(TAG, \"Failed to invoke remote methods on default container service. Giving up\"); mHandler.sendEmptyMessage(MCS_GIVE_UP); handleServiceError(); return false; } else { handleStartCopy(); res = true; } } catch (RemoteException e) { if (DEBUG_INSTALL) Slog.i(TAG, \"Posting install MCS_RECONNECT\"); mHandler.sendEmptyMessage(MCS_RECONNECT); res = false; } handleReturnCode();//Will try to rebind return res; } The startCopy() method does the copy operation by calling handleStartCopy() of its subclass InstallParams. Considering the uncertainty of the installation process, the main job of startCopy is to handle the error. When the exception that runs out of the handleStartCopy is captured, startCopy will send MCS_RECONNECT. In the processing of the MCS_RECONNECT message, the DefaultContainerService will be re-bound, if the binding is successful. , then the installation process will start over. startCopy will also be called again, the number of retries is recorded in mRetries, and when the cumulative retry exceeds 4 times, the installation will be lost. If the installation fails, startCopy will call handleReturnCode() to continue processing. public void handleStartCopy() throws RemoteException{ int ret = PackageManager.INSTALL_SUCCEEDED; // If we're already staged, we've firmly committed to an install location // Here staged is false, the front is false when the origin is created. if (origin.staged) { if (origin.file != null) { installFlags |= PackageManager.INSTALL_INTERNAL; installFlags &= ~PackageManager.INSTALL_EXTERNAL; } else if (origin.cid != null) { installFlags |= PackageManager.INSTALL_EXTERNAL; installFlags &= ~PackageManager.INSTALL_INTERNAL; } else { throw new IllegalStateException(\"Invalid stage location\"); } } // Check if there is a setting in installFlags where it is installed. In this case, we have not set it, but when installing through the pm command, it is possible to specify where to install it. final boolean onSd = (installFlags & PackageManager.INSTALL_EXTERNAL) != 0; final boolean onInt = (installFlags & PackageManager.INSTALL_INTERNAL) != 0; //Lite PackageInfo PackageInfoLite pkgLite = null; // If the installation is set in the internal storage and the installation is installed in the external SD, an error is reported. if (onInt && onSd) { // Check if both bits are set. Slog.w(TAG, \"Conflicting flags specified for installing on both internal and external\"); ret = PackageManager.INSTALL_FAILED_INVALID_INSTALL_LOCATION; } else { pkgLite = mContainerService.getMinimalPackageInfo(origin.resolvedPath, installFlags, packageAbiOverride); /* * If we have too little free space, try to free cache * before giving up. */ //Check if the storage space is enough to install the app. If not enough, execute the following branch. if (!origin.staged && pkgLite.recommendedInstallLocation == PackageHelper.RECOMMEND_FAILED_INSUFFICIENT_STORAGE) { // TODO: focus freeing disk space on the target device final StorageManager storage = StorageManager.from(mContext); final long lowThreshold = storage.getStorageLowBytes( Environment.getDataDirectory()); final long sizeBytes = mContainerService.calculateInstalledSize( origin.resolvedPath, isForwardLocked(), packageAbiOverride); //Try to free some cache space if (mInstaller.freeCache(null, sizeBytes + lowThreshold) >= 0) { //Then re-acquire PackageInfoLite pkgLite = mContainerService.getMinimalPackageInfo(origin.resolvedPath, installFlags, packageAbiOverride); } /* * The cache free must have deleted the file we * downloaded to install. * * TODO: fix the \"freeCache\" call to not delete * the file we care about. */ if (pkgLite.recommendedInstallLocation == PackageHelper.RECOMMEND_FAILED_INVALID_URI) { pkgLite.recommendedInstallLocation = PackageHelper.RECOMMEND_FAILED_INSUFFICIENT_STORAGE; } } } if (ret == PackageManager.INSTALL_SUCCEEDED) { int loc = pkgLite.recommendedInstallLocation; if (loc == PackageHelper.RECOMMEND_FAILED_INVALID_LOCATION) { ret = PackageManager.INSTALL_FAILED_INVALID_INSTALL_LOCATION; } else if (loc == PackageHelper.RECOMMEND_FAILED_ALREADY_EXISTS) { ret = PackageManager.INSTALL_FAILED_ALREADY_EXISTS; } else if (loc == PackageHehandleStartCopylper.RECOMMEND_FAILED_INSUFFICIENT_STORAGE) { ret = PackageManager.INSTALL_FAILED_INSUFFICIENT_STORAGE; } else if (loc == PackageHelper.RECOMMEND_FAILED_INVALID_APK) { ret = PackageManager.INSTALL_FAILED_INVALID_APK; } else if (loc == PackageHelper.RECOMMEND_FAILED_INVALID_URI) { ret = PackageManager.INSTALL_FAILED_INVALID_URI; } else if (loc == PackageHelper.RECOMMEND_MEDIA_UNAVAILABLE) { ret = PackageManager.INSTALL_FAILED_MEDIA_UNAVAILABLE; } else { // Override with defaults if needed. loc = installLocationPolicy(pkgLite); if (loc == PackageHelper.RECOMMEND_FAILED_VERSION_DOWNGRADE) { ret = PackageManager.INSTALL_FAILED_VERSION_DOWNGRADE; } else if (!onSd && !onInt) { // Override install location with flags if (loc == PackageHelper.RECOMMEND_INSTALL_EXTERNAL) { // Set the flag to install on external media. installFlags |= PackageManager.INSTALL_EXTERNAL; installFlags &= ~PackageManager.INSTALL_INTERNAL; } else { // Make sure the flag for installing on external // media is unset installFlags |= PackageManager.INSTALL_INTERNAL; installFlags &= ~PackageManager.INSTALL_EXTERNAL; } } } } // Where abiOverride is null final InstallArgs args = createInstallArgs(this); mArgs = args; if (ret == PackageManager.INSTALL_SUCCEEDED) { /* * ADB installs appear as UserHandle.USER_ALL, and can only be performed by * UserHandle.USER_OWNER, so use the package verifier for UserHandle.USER_OWNER. */ int userIdentifier = getUser().getIdentifier(); if (userIdentifier == UserHandle.USER_ALL && ((installFlags & PackageManager.INSTALL_FROM_ADB) != 0)) { userIdentifier = UserHandle.USER_OWNER; } /* * Determine if we have any installed package verifiers. If we * do, then we'll defer to them to verify the packages. */ final int requiredUid = mRequiredVerifierPackage == null ? -1 : getPackageUid(mRequiredVerifierPackage, userIdentifier); if (!origin.existing && requiredUid != -1 && isVerificationEnabled(userIdentifier, installFlags)) { //Here is the check, the specific check does not go deep, because it sent this //android.intent.action.PACKAGE_NEEDS_VERIFICATION // I didn't find anyone to handle it. .................................. } else { /* * No package verification is enabled, so immediately start * the remote call to initiate copy using temporary file. */ ret = args.copyApk(mContainerService, true); } } mRet = ret; } The handleStartCopy() method will determine where the app should be installed. If there is not enough space in the installation, try to clean up some cache space and try the installation again. A lot of the code in this method is to process some information by sending Intent android.intent.action.PACKAGE_NEEDS_VERIFICATION to all in the system to receive the Intent, but unfortunately, I did not find the Dongdong to handle this Intent. If you don't need to verify, you can call InstallArgs' copyApk() method directly. The overall logic of the method is as shown. Before analyzing copyApk, look at the relationship between InstallParams and InstallArgs: The params passed in by createInstallArgs, in this case InstallParams, have determined where the installation is in its handleStartCopy(). private InstallArgs createInstallArgs(InstallParams params) { if (params.move != null) { // Mobile app return new MoveInstallArgs(params); } else if (installOnExternalAsec(params.installFlags) || params.isForwardLocked()) { // Installed on SD return new AsecInstallArgs(params); } else { // Installed in internal storage return new FileInstallArgs(params); } } In this case, it is installed in the internal storage, so the FileInstallArgs is created, then the copyApk is called, which is naturally FileInstallArgs. int copyApk(IMediaContainerService imcs, boolean temp) throws RemoteException { if (origin.staged) { if (DEBUG_INSTALL) Slog.d(TAG, origin.file + \" already staged; skipping copy\"); codeFile = origin.file; resourceFile = origin.file; return PackageManager.INSTALL_SUCCEEDED; } try { final File tempDir = mInstallerService.allocateStageDirLegacy(volumeUuid); codeFile = tempDir; resourceFile = tempDir; } catch (IOException e) { Slog.w(TAG, \"Failed to create copy file: \" + e); return PackageManager.INSTALL_FAILED_INSUFFICIENT_STORAGE; } ............ allocateStageDirLegacy: public File allocateStageDirLegacy(String volumeUuid) throws IOException { synchronized (mSessions) { try { // Assign the ID of this installation session final int sessionId = allocateSessionIdLocked(); mLegacySessions.put(sessionId, true); // Get a staged folder for this installation, which will be renamed later final File stageDir = buildStageDir(volumeUuid, sessionId); prepareStageDir(stageDir); return stageDir; } catch (IllegalStateException e) { throw new IOException(e); } } } private File buildStageDir(String volumeUuid, int sessionId) { final File stagingDir = buildStagingDir(volumeUuid); return new File(stagingDir, \"vmdl\" + sessionId + \".tmp\"); } private File buildStagingDir(String volumeUuid) { return Environment.getDataAppDirectory(volumeUuid); } // volumeUuid is generally null public static File getDataDirectory(String volumeUuid) { if (TextUtils.isEmpty(volumeUuid)) { return new File(\"/data\"); } else { return new File(\"/mnt/expand/\" + volumeUuid); } } public static File getDataAppDirectory(String volumeUuid) { return new File(getDataDirectory(volumeUuid), \"app\"); } The path string is obtained after the buildStageDir method is executed: /data/app/vmdl.tmp prepareStageDir will create this folder and set the 755 permission. Continue to analyze copyApk: final IParcelFileDescriptorFactory target = new IParcelFileDescriptorFactory.Stub() { @Override public ParcelFileDescriptor open(String name, int mode) throws RemoteException { if (!FileUtils.isValidExtFilename(name)) { throw new IllegalArgumentException(\"Invalid filename: \" + name); } try { final File file = new File(codeFile, name); final FileDescriptor fd = Os.open(file.getAbsolutePath(), O_RDWR | O_CREAT, 0644); Os.chmod(file.getAbsolutePath(), 0644); return new ParcelFileDescriptor(fd); } catch (ErrnoException e) { throw new RemoteException(\"Failed to open: \" + e.getMessage()); } } }; int ret = PackageManager.INSTALL_SUCCEEDED; ret = imcs.copyPackage(origin.file.getAbsolutePath(), target); if (ret != PackageManager.INSTALL_SUCCEEDED) { Slog.e(TAG, \"Failed to copy package\"); return ret; } Call the copyPackage method of DefaultContainerService to copy the apk to be installed to the directory created earlier, and set the permission to 644. After executing here, copy base.apk to /data/app/vmdl.tmp In, and set the permissions to 644. Continue to analyze copyApk: final File libraryRoot = new File(codeFile, LIB_DIR_NAME); NativeLibraryHelper.Handle handle = null; try { handle = NativeLibraryHelper.Handle.create(codeFile); ret = NativeLibraryHelper.copyNativeBinariesWithOverride(handle, libraryRoot, abiOverride); } catch (IOException e) { Slog.e(TAG, \"Copying native libraries failed\", e); ret = PackageManager.INSTALL_FAILED_INTERNAL_ERROR; } finally { IoUtils.closeQuietly(handle); } After the execution is successful, the app's so will be copied to: /data/app/vmdl.tmp/lib/arm/ If it is x86, the arm is replaced with x86 and so on. The emphasis here is that abiOverride is null. You can use the following method to view the abi situation in the device: root@hammerhead:/data/system # getprop | grep abi [ro.product.cpu.abi]: [armeabi-v7a] [ro.product.cpu.abi2]: [armeabi] [ro.product.cpu.abilist]: [armeabi-v7a,armeabi] [ro.product.cpu.abilist32]: [armeabi-v7a,armeabi] [ro.product.cpu.abilist64]: [] As you can see from the results, the logic of our device does not support 64-bit abi.copyNativeBinariesWithOverride is as follows: public static int copyNativeBinariesWithOverride(Handle handle, File libraryRoot, String abiOverride) { try { // If there are folders such as armeabi, areabi-v7a, x86, etc. in the lib in apk, // Take this branch, ignore abiOverride at this time if (handle.multiArch) { // Warn if we've set an abiOverride for multi-lib packages.. // By definition, we need to copy both 32 and 64 bit libraries for // such packages. if (abiOverride != null && !CLEAR_ABI_OVERRIDE.equals(abiOverride)) { Slog.w(TAG, \"Ignoring abiOverride for multi arch application.\"); } int copyRet = PackageManager.NO_NATIVE_LIBRARIES; if (Build.SUPPORTED_32_BIT_ABIS.length > 0) { // Because there are multiple so library folders, so choose to use the so library in the appropriate folder. // The method is to obtain the abi in the list of ro.product.cpu.abilist32, and then compare the names of the so library folders, and find the matching folder. // Copy the so library in the folder /data/app/vmdl..tmp/lib/arm/, and match the folder name at //Index return in ro.product.cpu.abilist32 list copyRet = copyNativeBinariesForSupportedAbi(handle, libraryRoot, Build.SUPPORTED_32_BIT_ABIS, true /* use isa specific subdirs */); if (copyRet 0) { // If the device supports 64-bit abi, then also get the abi in the list of ro.product.cpu.abilist64, and then compare the names of the so-li folder with the names of the so-li folder, and find the matching folder. // Copy the so library in the folder /data/app/vmdl..tmp/lib/arm64/, and match the folder name at // Index return in ro.product.cpu.abilist64 list copyRet = copyNativeBinariesForSupportedAbi(handle, libraryRoot, Build.SUPPORTED_64_BIT_ABIS, true /* use isa specific subdirs */); if (copyRet 0 && cpuAbiOverride == null && hasRenderscriptBitcode(handle)) { abiList = Build.SUPPORTED_32_BIT_ABIS; } // Similarly, the abi value in the abiList is matched with the folder name of the so library in turn, and if it matches, the index of the matching abi in the abiList is returned. // And copy the so library to /data/app/vmdl..tmp/lib/XXisaXX/ // Xxisaxx can be arm arm64 x86, etc., depending on the value of abi int copyRet = copyNativeBinariesForSupportedAbi(handle, libraryRoot, abiList, true /* use isa specific subdirs */); if (copyRet "},"Android PMS - Android 6 PMS installation APK next article.html":{"url":"Android PMS - Android 6 PMS installation APK next article.html","title":"Android PMS - Android 6 PMS installation APK next article","keywords":"","body":"1. Android 6 PMS installation APK next article1. Android 6 PMS installation APK next article Android core service Android underlying development Install an apk into: check permissions, copy files, and install them in the app. The first two steps were analyzed before, and now the analysis of the app's load is started. In this step, the execution file of the oat format of converting the dex into the ART virtual machine is completed, and the data sandbox directory is created for the application, and finally the application information is loaded into the data structure of the PMS. In the startCopy method of HandlerParams called when MCS_BOUND is processed earlier final boolean startCopy() { boolean res; try { ........................... if (++mRetries > MAX_RETRIES) { .................................................... return false; } else { handleStartCopy(); res = true; } } catch (RemoteException e) { .............................. } handleReturnCode(); return res; } You can know that when the file is copied, the handleReturnCode method of InstallParams is called: void handleReturnCode() { // If mArgs is null, then MCS couldn't be reached. When it // reconnects, it will try again to install. At that point, this // will succeed. if (mArgs != null) { processPendingInstall(mArgs, mRet); } } code show as below: private void processPendingInstall(final InstallArgs args, final int currentStatus) { // Queue up an async operation since the package installation may take a little while. mHandler.post(new Runnable() { public void run() { mHandler.removeCallbacks(this); // Result object to be returned PackageInstalledInfo res = new PackageInstalledInfo(); res.returnCode = currentStatus; res.uid = -1; res.pkg = null; res.removedInfo = new PackageRemovedInfo(); if (res.returnCode == PackageManager.INSTALL_SUCCEEDED) { //Under normal circumstances, nothing will be done. args.doPreInstall(res.returnCode); synchronized (mInstallLock) { installPackageLI(args, res); } args.doPostInstall(res.returnCode, res.uid); } ..................................... /* Omit code about cloud backup */ ..................................... if (!doRestore) { // No restore possible, or the Backup Manager was mysteriously not // available -- just fire the post-install work request directly. if (DEBUG_INSTALL) Log.v(TAG, \"No restore - queue post-install for \" + token); Message msg = mHandler.obtainMessage(POST_INSTALL, token, 0); mHandler.sendMessage(msg); } } }); } A message is posted in the processPendingInstall() method so that the installation process continues in an asynchronous manner. In the post message, the first is to call installPackageLI () to load the application, the next large piece of code is in the device backup operation, the backup is done through the BackupManagerService, here is not analyzed. After the backup is complete, continue processing by sending a POST_INSTALL message. doPreInstall() generally does not do anything. Then look at the installPackageLI() method, the code is very long, so it is still parsed by segmentation. Private void installPackageLI(InstallArgs args, PackageInstalledInfo res) { / / Get installFlags, which records where the app needs to be installed final int installFlags = args.installFlags; // package name of the installer final String installerPackageName = args.installerPackageName; // related to sd card installation, generally null final String volumeUuid = args.volumeUuid; // I have previously copied the apk to the temporary stage folder /data/app/vmdl.tmp/ this directory final File tmpPackageFile = new File(args.getCodePath()); // No setting INSTALL_FORWARD_LOCK final boolean forwardLocked = ((installFlags & PackageManager.INSTALL_FORWARD_LOCK) != 0); // Whether to install to external storage final boolean onExternal = (((installFlags & PackageManager.INSTALL_EXTERNAL) != 0) || (args.volumeUuid != null)); // Initialize the replacement flag to false Boolean replace = false; / / Set the browsing parameters int scanFlags = SCAN_NEW_INSTALL | SCAN_UPDATE_SIGNATURE; // We are not a mobile app, so it is null, don't take this code if (args.move != null) { // moving a complete application; perfom an initial scan on the new install location scanFlags |= SCAN_INITIAL; } / / Initialize the return code // Result object to be returned res.returnCode = PackageManager.INSTALL_SUCCEEDED; Here is the work of doing some initialization values. See the above note for details. if (DEBUG_INSTALL) Slog.d(TAG, \"installPackageLI: path=\" + tmpPackageFile); // Retrieve PackageSettings and parse package // Set parsing apk flags final int parseFlags = mDefParseFlags | PackageParser.PARSE_CHATTY | (forwardLocked ? PackageParser.PARSE_FORWARD_LOCK : 0) | (onExternal ? PackageParser.PARSE_EXTERNAL_STORAGE : 0); // Create a parser PackageParser pp = new PackageParser(); pp.setSeparateProcesses(mSeparateProcesses); // Get screen parameters pp.setDisplayMetrics(mMetrics); final PackageParser.Package pkg; try { // Start parsing apk, pay attention to passing tmpPackageFile as a folder at this time pkg = pp.parsePackage(tmpPackageFile, parseFlags); } catch (PackageParserException e) { res.setError(\"Failed parse during installPackageLI\", e); return; } // Mark that we have an install time CPU ABI override. pkg.cpuAbiOverride = args.abiOverride; String pkgName = res.name = pkg.packageName; if ((pkg.applicationInfo.flags&ApplicationInfo.FLAG_TEST_ONLY) != 0) { if ((installFlags & PackageManager.INSTALL_ALLOW_TEST) == 0) { res.setError(INSTALL_FAILED_TEST_ONLY, \"installPackageLI\"); return; } } The main thing here is to parse the APK, which is to parse the AndroidMainifest.xml file and record the result in the PackageParser.Package. I have already explained in detail how to parse an APK, so I won't go into details here. Next is to collect the signature information of apk, the code is as follows: try { pp.collectCertificates(pkg, parseFlags); pp.collectManifestDigest(pkg); } catch (PackageParserException e) { res.setError(\"Failed collect during installPackageLI\", e); return; } If the installer has previously passed in a manifest file, then the parsed manifest file is compared to the incoming one. The installer did pass in a list, and the packageInstallerActivity also parsed the apk. At that time, the list was recorded and passed in here. Here is another step to judge that the two are the same apk. /* If the installer passed in a manifest digest, compare it now. */ if (args.manifestDigest != null) { if (DEBUG_INSTALL) { final String parsedManifest = pkg.manifestDigest == null ? \"null\" : pkg.manifestDigest.toString(); Slog.d(TAG, \"Comparing manifests: \" + args.manifestDigest.toString() + \" vs. \" + parsedManifest); } if (!args.manifestDigest.equals(pkg.manifestDigest)) { res.setError(INSTALL_FAILED_PACKAGE_CHANGED, \"Manifest digest changed\"); return; } } else if (DEBUG_INSTALL) { final String parsedManifest = pkg.manifestDigest == null ? \"null\" : pkg.manifestDigest.toString(); Slog.d(TAG, \"manifestDigest was not present, but parser got: \" + parsedManifest); } Continue to analyze installPackageLI: // Check if installing already existing package // If installing an existing application, the PackageInstaller app installer will set INSTALL_REPLACE_EXISTING in installFlags if ((installFlags & PackageManager.INSTALL_REPLACE_EXISTING) != 0) { / / Look at the package name of the apk to be replaced whether the original package name exists // When the app upgrade causes the package names to be inconsistent, the record needs to be the original package name. // So here we have to check if the app to be overwritten is like this. If so, set the package name to the old package name. String oldName = mSettings.mRenamedPackages.get(pkgName); if (pkg.mOriginalPackages != null && pkg.mOriginalPackages.contains(oldName) && mPackages.containsKey(oldName)) { // This package is derived from an original package, // and this device has been updating from that original // name. We must continue using the original name, so // rename the new package here. pkg.setPackageName(oldName); pkgName = pkg.packageName; Replace = true; if (DEBUG_INSTALL) Slog.d(TAG, \"Replacing existing renamed package: oldName=\" + oldName + \" pkgName=\" + pkgName); } else if (mPackages.containsKey(pkgName)) { // This package, under its official name, already exists // on the device; we should replace it. Replace = true; if (DEBUG_INSTALL) Slog.d(TAG, \"Replace existing pacakge: \" + pkgName); } // Prevent apps opting out from runtime permissions / / Check the new app compiled when the target target version is lower than 6.0, and the original app compiled when the target is selected 6.0, / / When an app is compiled according to 6.0, you need to parse the permissions of the app according to the rules of 6.0. if (replace) { PackageParser.Package oldPackage = mPackages.get(pkgName); final int oldTargetSdk = oldPackage.applicationInfo.targetSdkVersion; final int newTargetSdk = pkg.applicationInfo.targetSdkVersion; if (oldTargetSdk > Build.VERSION_CODES.LOLLIPOP_MR1 && newTargetSdk Here is mainly to set some variables when overwriting the installation. Continue to analyze, the next step is to conduct a preliminary check on the permissions defined by apk: // Check whether the newly-scanned package wants to define an already-defined perm int N = pkg.permissions.size(); for (int i = N-1; i >= 0; i--) { PackageParser.Permission perm = pkg.permissions.get(i); BasePermission bp = mSettings.mPermissions.get(perm.info.name); if (bp != null) { // If the defining package is signed with our cert, it's okay. This // also includes the \"updating the same package\" case, of course. // \"updating same package\" could also involve key-rotation. final boolean sigsOk; if (bp.sourcePackage.equals(pkg.packageName) && (bp.packageSetting instanceof PackageSetting) && (shouldCheckUpgradeKeySetLP((PackageSetting) bp.packageSetting, scanFlags))) { sigsOk = checkUpgradeKeySetLP((PackageSetting) bp.packageSetting, pkg); } else { sigsOk = compareSignatures(bp.packageSetting.signatures.mSignatures, pkg.mSignatures) == PackageManager.SIGNATURE_MATCH; } if (!sigsOk) { // If the owning package is the system itself, we log but allow // install to proceed; we fail the install on all other permission // redefinitions. if (!bp.sourcePackage.equals(\"android\")) { res.setError(INSTALL_FAILED_DUPLICATE_PERMISSION, \"Package \" + pkg.packageName + \" attempting to redeclare permission \" + perm.info.name + \" already owned by \" + bp.sourcePackage); res.origPermission = perm.info.name; res.origPackage = bp.sourcePackage; return; } else { Slog.w(TAG, \"Package \" + pkg.packageName + \" attempting to redeclare system permission \" + perm.info.name + \"; ignoring new declaration\"); pkg.permissions.remove(i); } } } } The function of this code is to check whether all the permissions defined in the apk have been defined by other applications. If the permissions defined by the system application are redefined, then the permission defined by the app is ignored. If you redefine the permissions of a non-system application, then this installation will return with a failure. Continue to analyze, when an app is a system application, but wants to install in external storage, then an error is reported. if (systemApp && onExternal) { // Disable updates to system apps on sdcard res.setError(INSTALL_FAILED_INVALID_INSTALL_LOCATION, \"Cannot install updates to system apps on sdcard\"); return; } This means that the system app cannot be installed to external storage. Continue to analyze: // We are not on the mobile app, so don't go this branch if (args.move != null) { // We did an in-place move, so dex is ready to roll scanFlags |= SCAN_NO_DEX; scanFlags |= SCAN_MOVE; synchronized (mPackages) { final PackageSetting ps = mSettings.mPackages.get(pkgName); if (ps == null) { res.setError(INSTALL_FAILED_INTERNAL_ERROR, \"Missing settings for moved package \" + pkgName); } // We moved the entire application as-is, so bring over the // previously derived ABI information. pkg.applicationInfo.primaryCpuAbi = ps.primaryCpuAbiString; pkg.applicationInfo.secondaryCpuAbi = ps.secondaryCpuAbiString; } } else if (!forwardLocked && !pkg.applicationInfo.isExternalAsec()) { //Go this branch // Enable SCAN_NO_DEX flag to skip dexopt at a later stage // Set SCAN_NO_DEX so that dexopt will not be executed at this stage scanFlags |= SCAN_NO_DEX; Try { derivePackageAbi(pkg, new File(pkg.codePath), args.abiOverride, True /* extract libs */); } catch (PackageManagerException pme) { Slog.e (TAG, \"Error deriving application ABI\", pme); res.setError(INSTALL_FAILED_INTERNAL_ERROR, \"Error deriving application ABI\"); Return; } // Run dexopt before old package gets removed, to minimize time when app is unavailable int result = mPackageDexOptimizer .performDexOpt(pkg, null /* instruction sets */, false /* forceDex */, False /* defer */, false /* inclDependencies */); if (result == PackageDexOptimizer.DEX_OPT_FAILED) { res.setError(INSTALL_FAILED_DEXOPT, \"Dexopt failed for \" + pkg.codePath); Return; } } The derivePackageAbi() method is also very important. It mainly completes the so library path setting of apk and the value of the primary and secondary abi. /** * Derive the ABI of a non-system package located at {@code scanFile}. This information * is derived purely on the basis of the contents of {@code scanFile} and * {@code cpuAbiOverride}. * * If {@code extractLibs} is true, native libraries are extracted from the app if required. */ public void derivePackageAbi(PackageParser.Package pkg, File scanFile, String cpuAbiOverride, boolean extractLibs) Throws PackageManagerException { / / Here is the first call, mainly to determine the following three fields in the applicationInfo in pkg // nativeLibraryRootDir /data/app/vmdl.tmp/lib // nativeLibraryRootRequiresIsa is true, the third-party app installed by the user, this field is true, indicating that you need to prefix in lib/, such as arm, arm64, etc. // nativeLibraryDir :/data/app/vmdl.tmp/lib/ setNativeLibraryPaths(pkg); // We would never need to extract libs for forward-locked and external packages, // since the container service will do it for us. We shouldn't attempt to // extract libs from system app when it was not updated. if (pkg.isForwardLocked() || isExternal(pkg) || (isSystemApp(pkg) && !pkg.isUpdatedSystemApp()) ) { extractLibs = false; } final String nativeLibraryRootStr = pkg.applicationInfo.nativeLibraryRootDir; // For a third-party app installed by the user, this flag is true, indicating that you want to add \"arm\" or \"arm64\" or \"x86\" after the nativeLibraryRootStr path. // This type of prefix, please refer to setNativeLibraryPaths() for specific reasons. final boolean useIsaSpecificSubdirs = pkg.applicationInfo.nativeLibraryRootRequiresIsa; NativeLibraryHelper.Handle handle = null; Try { Handle = NativeLibraryHelper.Handle.create(scanFile); // TODO(multiArch): This can be null for apps that didn't go through the // usual installation process. We can calculate it again, like we // do during install time. // // TODO(multiArch): Why do we need to rescan ASEC apps again ? It seems totally // unnecessary. final File nativeLibraryRoot = new File(nativeLibraryRootStr); // Null out the abis so that they can be recalculated. pkg.applicationInfo.primaryCpuAbi = null; pkg.applicationInfo.secondaryCpuAbi = null; if (isMultiArch(pkg.applicationInfo)) { // Warn if we've set an abiOverride for multi-lib packages.. // By definition, we need to copy both 32 and 64 bit libraries for // such packages. // cpuAbiOverride is not valid for apk with multiple so library folders if (pkg.cpuAbiOverride != null && !NativeLibraryHelper.CLEAR_ABI_OVERRIDE.equals(pkg.cpuAbiOverride)) { Slog.w(TAG, \"Ignoring abiOverride for multi arch application.\"); } int abi32 = PackageManager.NO_NATIVE_LIBRARIES; int abi64 = PackageManager.NO_NATIVE_LIBRARIES; if (Build.SUPPORTED_32_BIT_ABIS.length > 0) { if (extractLibs) { // Here again, if the so library timestamp in lib in apk does not change, it will not be copied, because it has been copied before. // Only copy again when the so library changes Abi32 = NativeLibraryHelper.copyNativeBinariesForSupportedAbi(handle, nativeLibraryRoot, Build.SUPPORTED_32_BIT_ABIS, useIsaSpecificSubdirs); } else { Abi32 = NativeLibraryHelper.findSupportedAbi(handle, Build.SUPPORTED_32_BIT_ABIS); } } maybeThrowExceptionForMultiArchCopy( \"Error unpackaging 32 bit native libs for multiarch app.\", abi32); if (Build.SUPPORTED_64_BIT_ABIS.length > 0) { if (extractLibs) { // Here again, if the so library timestamp in lib in apk does not change, it will not be copied, because it has been copied before. // Only copy again when the so library changes Abi64 = NativeLibraryHelper.copyNativeBinariesForSupportedAbi(handle, nativeLibraryRoot, Build.SUPPORTED_64_BIT_ABIS, useIsaSpecificSubdirs); } else { Abi64 = NativeLibraryHelper.findSupportedAbi(handle, Build.SUPPORTED_64_BIT_ABIS); } } maybeThrowExceptionForMultiArchCopy( \"Error unpackaging 64 bit native libs for multiarch app.\", abi64); if (abi64 >= 0) { // If the so library supports 64-bit abi, and the system is also 64-bit, Message1 // Set the main abi to the value of the abi64 index in the list of ro.product.cpu.abilist64 pkg.applicationInfo.primaryCpuAbi = Build.SUPPORTED_64_BIT_ABIS[abi64]; } if (abi32 >= 0) { final String abi = Build.SUPPORTED_32_BIT_ABIS[abi32]; if (abi64 >= 0) { // When the system is 64 bit. And apk contains a 64-bit library, and also contains a 32-bit library. // Then set the secondary abi to the value of the abi32 index in the list of ro.product.cpu.abilist32 pkg.applicationInfo.secondaryCpuAbi = abi; } else { // If the app has only 32-bit libraries, then put // The main abi is set to the value of the abi32 index in the list of ro.product.cpu.abilist32 pkg.applicationInfo.primaryCpuAbi = abi; } } Next, call the following code to perform the dexopt operation: // Run dexopt before old package gets removed, to minimize time when app is unavailable int result = mPackageDexOptimizer .performDexOpt(pkg, null /* instruction sets */, false /* forceDex */, false /* defer */, false /* inclDependencies */); if (result == PackageDexOptimizer.DEX_OPT_FAILED) { res.setError(INSTALL_FAILED_DEXOPT, \"Dexopt failed for \" + pkg.codePath); return; } code show as below: int performDexOpt(PackageParser.Package pkg, String[] instructionSets, boolean forceDex, boolean defer, boolean inclDependencies) { ArraySet done; if (inclDependencies && (pkg.usesLibraries != null || pkg.usesOptionalLibraries != null)) { done = new ArraySet(); done.add(pkg.packageName); } else { // Take this branch done = null; } synchronized (mPackageManagerService.mInstallLock) { final boolean useLock = mSystemReady; if (useLock) { mDexoptWakeLock.setWorkSource(new WorkSource(pkg.applicationInfo.uid)); mDexoptWakeLock.acquire(); } try { // -----------------Call the following method return performDexOptLI(pkg, instructionSets, forceDex, defer, done); } finally { if (useLock) { mDexoptWakeLock.release(); } } } } Private int performDexOptLI(PackageParser.Package pkg, String[] targetInstructionSets, Boolean forceDex, boolean defer, ArraySet done) { // The incoming targetInstructionSets is null / / So instructionSets is the primary and secondary abi values ​​of pkg.applicationInfo / / If there is no so library, there is no primary and secondary abi, then the first value of the ro.product.cpu.abilist list, get isa final String[] instructionSets = targetInstructionSets != null ? targetInstructionSets : getAppDexInstructionSets(pkg.applicationInfo); // done is null. So skip if (done != null) { Done.add(pkg.packageName); if (pkg.usesLibraries != null) { performDexOptLibsLI(pkg.usesLibraries, instructionSets, forceDex, defer, done); } if (pkg.usesOptionalLibraries != null) { performDexOptLibsLI(pkg.usesOptionalLibraries, instructionSets, forceDex, defer, Done); } } if ((pkg.applicationInfo.flags & ApplicationInfo.FLAG_HAS_CODE) == 0) { Return DEX_OPT_SKIPPED; } final boolean vmSafeMode = (pkg.applicationInfo.flags & ApplicationInfo.FLAG_VM_SAFE_MODE) != 0; final boolean debuggable = (pkg.applicationInfo.flags & ApplicationInfo.FLAG_DEBUGGABLE) != 0; final List paths = pkg.getAllCodePathsExcludingResourceOnly(); Boolean performedDexOpt = false; // There are three basic cases here: // 1.) we need to dexopt, either because we are forced or it is needed // 2.) we are deferring a needed dexopt // 3.) we are skipping an unneeded dexopt final String[] dexCodeInstructionSets = getDexCodeInstructionSets(instructionSets); For (String dexCodeInstructionSet : dexCodeInstructionSets) { if (!forceDex && pkg.mDexOptPerformed.contains(dexCodeInstructionSet)) { Continue; } For (String path : paths) { final int dexoptNeeded; if (forceDex) { // is false, so don't go here dexoptNeeded = DexFile.DEX2OAT_NEEDED; } else { Try { // Because it is installing apk, getDexOptNeeded returns DEX2OAT_NEEDED dexoptNeeded = DexFile.getDexOptNeeded(path, pkg.packageName, dexCodeInstructionSet, defer); } catch (IOException ioe) { Slog.w(TAG, \"IOException reading apk: \" + path, ioe); Return DEX_OPT_FAILED; } } if (!forceDex && defer && dexoptNeeded != DexFile.NO_DEXOPT_NEEDED) { // We're deciding to defer a needed dexopt. Don't bother dexopting for other // paths and instruction sets. We'll deal with them all together when we process // our list of deferred dexopts. addPackageForDeferredDexopt(pkg); Return DEX_OPT_DEFERRED; } if (dexoptNeeded != DexFile.NO_DEXOPT_NEEDED) { final String dexoptType; String oatDir = null; if (dexoptNeeded == DexFile.DEX2OAT_NEEDED) { dexoptType = \"dex2oat\"; Try { / / Get the oat directory: /data/app/vmdl .tmp/oat oatDir = createOatDirIfSupported(pkg, dexCodeInstructionSet); } catch (IOException ioe) { Slog.w(TAG, \"Unable to create oatDir for package: \" + pkg.packageName); Return DEX_OPT_FAILED; } } else if (dexoptNeeded == DexFile.PATCHOAT_NEEDED) { dexoptType = \"patchoat\"; } else if (dexoptNeeded == DexFile.SELF_PATCHOAT_NEEDED) { dexoptType = \"self patchoat\"; } else { Throw new IllegalStateException(\"Invalid dexopt needed: \" + dexoptNeeded); } // Start executing dex2oat Log.i(TAG, \"Running dexopt (\" + dexoptType + \") on: \" + path + \" pkg=\" + pkg.applicationInfo.packageName + \" isa=\" + dexCodeInstructionSet + \" vmSafeMode=\" + vmSafeMode + \" debuggable=\" + debuggable + \" oatDir = \" + oatDir); final int sharedGid = UserHandle.getSharedAppGid(pkg.applicationInfo.uid); final int ret = mPackageManagerService.mInstaller.dexopt(path, sharedGid, !pkg.isForwardLocked(), pkg.packageName, dexCodeInstructionSet, dexoptNeeded, vmSafeMode, debuggable, oatDir); // Dex2oat might fail to compiler / verifier errors. We soldier on // regardless, and attempt to interpret the app as a safety net. if (ret == 0) { performedDexOpt = true; } } Executing dexopt here is actually executing dex2oat, which is used to convert the dex file in apk into an oat file. It's worth noting that the oat files generated before Android 6.0 are all in /data/dalvik_cache/ In the folder, starting from Android 6.0, this folder only stores the oat file of the built-in application of the system. The oat file of the app installed by the user is in the end. /data/app/Package names/oat/ Continue to analyze installPackageLI: if (!args.doRename(res.returnCode, pkg, oldCodePath)) { res.setError(INSTALL_FAILED_INSUFFICIENT_STORAGE, \"Failed rename\"); return; } This code is very clear from the name: rename. Is going to /data/app/vmdl.tmp Rename /data/app/Package names-suffix Suffix is ​​1,2....... Also update the affected fields in pkg. Continue to analyze installPackageLI: startIntentFilterVerifications(args.user.getIdentifier(), replace, pkg); if (replace) { // If it is an overlay installation, go here replacePackageLI(pkg, parseFlags, scanFlags | SCAN_REPLACING, args.user, installerPackageName, volumeUuid, res); } else { // First time installation, go here installNewPackageLI(pkg, parseFlags, scanFlags | SCAN_DELETE_DATA_ON_FAILURES, Args.user, installerPackageName, volumeUuid, res); } synchronized (mPackages) { final PackageSetting ps = mSettings.mPackages.get(pkgName); if (ps != null) { res.newUsers = ps.queryInstalledUsers(sUserManager.getUserIds(), true); } } private void installNewPackageLI(PackageParser.Package pkg, int parseFlags, int scanFlags, UserHandle user, String installerPackageName, String volumeUuid, PackageInstalledInfo res) { // Remember this for later, in case we need to rollback this install String pkgName = pkg.packageName; if (DEBUG_INSTALL) Slog.d(TAG, \"installNewPackageLI: \" + pkg); final boolean dataDirExists = Environment .getDataUserPackageDirectory(volumeUuid, UserHandle.USER_OWNER, pkgName).exists(); synchronized(mPackages) { / / Determine whether it constitutes an upgrade relationship if (mSettings.mRenamedPackages.containsKey(pkgName)) { res.setError(INSTALL_FAILED_ALREADY_EXISTS, \"Attempt to re-install \" + pkgName + \"with first uninstalling package running as \" + mSettings.mRenamedPackages.get(pkgName)); Return; } // See if it is already installed if (mPackages.containsKey(pkgName)) { // Don't allow installation over an existing package with the same name. res.setError(INSTALL_FAILED_ALREADY_EXISTS, \"Attempt to re-install \" + pkgName + \" without first uninstalling.\"); Return; } } try { // Very familiar, here is the scanPackageLI PackageParser.Package newPackage = scanPackageLI(pkg, parseFlags, scanFlags, System.currentTimeMillis(), user); updateSettingsLI(newPackage, installerPackageName, volumeUuid, null, null, res, user); if (res.returnCode != PackageManager.INSTALL_SUCCEEDED) { deletePackageLI(pkgName, UserHandle.ALL, false, null, null, dataDirExists ? PackageManager.DELETE_KEEP_DATA : 0, res.removedInfo, true); } } catch (PackageManagerException e) { res.setError(\"Package couldn't be installed in \" + pkg.codePath, e); } } The focus has returned to the scanPackageLI parameter for the Package method. The method internally calls the scanPackageDirtyLI method, which was explained in detail in the previous article. The value here is the code associated with the user's installed app. private PackageParser.Package scanPackageDirtyLI(PackageParser.Package pkg, int parseFlags, int scanFlags, long currentTime, UserHandle user) throws PackageManagerException { final File scanFile = new File(pkg.codePath); ........................ if ((parseFlags&PackageParser.PARSE_IS_SYSTEM) != 0) { pkg.applicationInfo.flags |= ApplicationInfo.FLAG_SYSTEM; } else { // Only allow system apps to be flagged as core apps. pkg.coreApp = false; } ......................................... // Initialize package source and resource directories File destCodeFile = new File(pkg.applicationInfo.getCodePath()); File destResourceFile = new File(pkg.applicationInfo.getResourcePath()); SharedUserSetting suid = null; PackageSetting pkgSetting = null; ............................................. //writer synchronized (mPackages) { if (pkg.mSharedUserId != null) { ................................. } // Check if we are renaming from an original package name. PackageSetting origPackage = null; String realName = null; if (pkg.mOriginalPackages != null) { ............................... } .................................. // Very important, in this method, the UID is assigned to the apk // and record some information about the current user's package status file: // /data/system/users/userid/package-restrictions.xml // Not as good as the current app is hidden, or disabled, and which components of the current app are disabled. pkgSetting = mSettings.getPackageLPw(pkg, origPackage, realName, suid, destCodeFile, destResourceFile, pkg.applicationInfo.nativeLibraryRootDir, pkg.applicationInfo.primaryCpuAbi, pkg.applicationInfo.secondaryCpuAbi, pkg.applicationInfo.flags, pkg.applicationInfo.privateFlags, User, false); if (pkgSetting == null) { Throw new PackageManagerException(INSTALL_FAILED_INSUFFICIENT_STORAGE, \"Creating application package \" + pkg.packageName + \" failed\"); } ................................. pkg.applicationInfo.uid = pkgSetting.appId; pkg.mExtras = pkgSetting; ..................................... / / Check whether the installed app conflicts with the components defined by the installed app if ((scanFlags & SCAN_NEW_INSTALL) != 0) { final int N = pkg.providers.size(); int i; For (i=0; i The important execution process from installPackageLI is shown below: After executing installPackageLI, return to the processPendingInstall method as follows: private void processPendingInstall(final InstallArgs args, final int currentStatus) { // Queue up an async operation since the package installation may take a little while. mHandler.post(new Runnable() { public void run() { ........................... if (res.returnCode == PackageManager.INSTALL_SUCCEEDED) { //Under normal circumstances, nothing will be done. args.doPreInstall(res.returnCode); synchronized (mInstallLock) { installPackageLI(args, res); } // Delete the contents of /data/app/package name when the installation fails args.doPostInstall(res.returnCode, res.uid); } ..................................... /* Omit the code about cloud backup*/ ..................................... if (!doRestore) { // No restore possible, or the Backup Manager was mysteriously not // available -- just fire the post-install work request directly. If (DEBUG_INSTALL) Log.v(TAG, \"No restore - queue post-install for \" + token); Message msg = mHandler.obtainMessage(POST_INSTALL, token, 0); mHandler.sendMessage(msg); } } }); } The next step is to send a POST_INSTALL message. The processing of the message is mainly to send the broadcast. After the application is installed, the other applications in the system are notified to start processing. For example, the icon of the app needs to be added in the launcher. After the broadcast is finished, the installation is over, and finally the initial caller is returned to the original caller through the initial installation. The broadcast sent has android.intent.action.PACKAGE_ADDED When overwriting the installation, you also need to send: android.intent.extra.REPLACING code show as below: sendPackageBroadcast(Intent.ACTION_PACKAGE_ADDED, packageName, extras, null, null, firstUsers); final boolean update = res.removedInfo.removedPackage != null; if (update) { extras.putBoolean(Intent.EXTRA_REPLACING, true); } sendPackageBroadcast(Intent.ACTION_PACKAGE_ADDED, packageName, extras, null, null, updateUsers); if (update) { sendPackageBroadcast(Intent.ACTION_PACKAGE_REPLACED, packageName, extras, null, null, updateUsers); sendPackageBroadcast(Intent.ACTION_MY_PACKAGE_REPLACED, null, null, packageName, null, updateUsers); ................ "},"Android PMS - Android 6 PMS Uninstall APK.html":{"url":"Android PMS - Android 6 PMS Uninstall APK.html","title":"Android PMS - Android 6 PMS Uninstall APK","keywords":"","body":"1. Android 6 PMS Uninstall APK1. Android 6 PMS Uninstall APK Android core service Android underlying development The previous section describes how to install an apk, and now analyze the process of PMS uninstalling APK. Uninstall an app to indicate which user to uninstall the app. The uninstall process is nothing more than deleting the sandbox directory, deleting the /data/app/package name, and deleting its related information in the PMS, such as removing the component information related to the app from the PMS. Also clear the records in the relevant configuration file, such as packages.xml. The PMS uninstalls an app's api, which is called deletePackageAsUser, which corresponds to the installPackageAsUser() method of installing apk. public void deletePackageAsUser(String packageName, IPackageDeleteObserver observer, int userId, int flags) { deletePackage(packageName, new LegacyPackageDeleteObserver(observer).getBinder(), userId, Flags); } public void deletePackage(final String packageName, final IPackageDeleteObserver2 observer, final int userId, final int flags) { // Also check the permissions to see if there is permission to uninstall / / Mainly check whether the uninstall initiator process is authorized to uninstall // Does the current user have permission to uninstall // and uninstall all users or current users mContext.enforceCallingOrSelfPermission( android.Manifest.permission.DELETE_PACKAGES, null); Preconditions.checkNotNull(packageName); Preconditions.checkNotNull(observer); final int uid = Binder.getCallingUid(); if (UserHandle.getUserId(uid) != userId) { mContext.enforceCallingPermission( android.Manifest.permission.INTERACT_ACROSS_USERS_FULL, \"deletePackage for user \" + userId); } if (isUserRestricted(userId, UserManager.DISALLOW_UNINSTALL_APPS)) { try { observer.onPackageDeleted(packageName, PackageManager.DELETE_FAILED_USER_RESTRICTED, null); } catch (RemoteException re) { } return; } ................................................ / / Perform the operation of uninstalling the application in the message processing method mHandler.post(new Runnable() { public void run() { mHandler.removeCallbacks(this); / / Call this method to perform the actual uninstall operation final int returnCode = deletePackageX(packageName, userId, flags); if (observer != null) { try { // Send the results of uninstalling the app observer.onPackageDeleted(packageName, returnCode, null); } catch (RemoteException e) { Log.i(TAG, \"Observer no longer exists.\"); } //end catch } //end if } //end run }); } After the deletePackageAsUser() method checks the caller permissions, a message is posted. The uninstall operation is continued in the message processing method, thus avoiding the Binder call time being too long. The actual uninstall process is done again by the deletePackageX() method. Private int deletePackageX(String packageName, int userId, int flags) { final PackageRemovedInfo info = new PackageRemovedInfo(); final boolean res; // Uninstall which app under the user final UserHandle removeForUser = (flags & PackageManager.DELETE_ALL_USERS) != 0 UserHandle.ALL : new UserHandle(userId); / / Check if the user represented by userid is uninstalled by the application if (isPackageDeviceAdmin(packageName, removeForUser.getIdentifier())) { Slog.w(TAG, \"Not removing package \" + packageName + \": has active device admin\"); return PackageManager.DELETE_FAILED_DEVICE_POLICY_MANAGER; } // Whether to uninstall this app for all users Boolean removedForAllUsers = false; Boolean systemUpdate = false; // for the uninstall-updates case and restricted profiles, remember the per- // userhandle installed state int[] allUsers; Boolean[] perUserInstalled; synchronized (mPackages) { // Get the information recorded by the app in mSettings PackageSetting ps = mSettings.mPackages.get(packageName); // Get which users currently have the app installed allUsers = sUserManager.getUserIds(); perUserInstalled = new boolean[allUsers.length]; For (int i = 0; i = 0 ? info.removedAppId : info.uid); extras.putBoolean(Intent.EXTRA_REPLACING, true); sendPackageBroadcast(Intent.ACTION_PACKAGE_ADDED, packageName, Extras, null, null, null); sendPackageBroadcast(Intent.ACTION_PACKAGE_REPLACED, packageName, Extras, null, null, null); sendPackageBroadcast(Intent.ACTION_MY_PACKAGE_REPLACED, null, Null, packageName, null, null); } } // Force a gc here. Runtime.getRuntime().gc(); // Delete the resources here after sending the broadcast to let // other processes clean up before deleting resources. if (info.args != null) { synchronized (mInstallLock) { / / Call this method in FileInstallArgs to clean up // Ensure that the files in the /data/app/package name are deleted. info.args.doPostDeleteLI(true); } } return res ? PackageManager.DELETE_SUCCEEDED : PackageManager.DELETE_FAILED_INTERNAL_ERROR; } The deletePackageX() method calls the deletePackageLI() method to continue the uninstallation and delete operation after the application is installed under different users. If you uninstall an upgrade package for a system application, you should also broadcast a notification that the previous low-level system application can be used again. deletePackageLI method parameters: The package name of the apk to be uninstalled Uninstall which user in the apk Whether to delete code and Resources Current user The installation status of the app in all current users flags PackageRemovedInfo Whether to modify packages.xml /* * This method handles package deletion in general */ Private boolean deletePackageLI(String packageName, UserHandle user, Boolean deleteCodeAndResources, int[] allUserHandles, boolean[] perUserInstalled, int flags, PackageRemovedInfo outInfo, Boolean writeSettings) { if (packageName == null) { Slog.w(TAG, \"Attempt to delete null packageName.\"); return false; } if (DEBUG_REMOVE) Slog.d(TAG, \"deletePackageLI: \" + packageName + \" user \" + user); PackageSetting ps; Boolean dataOnly = false; int removeUser = -1; int appId = -1; synchronized (mPackages) { Ps = mSettings.mPackages.get(packageName); if (ps == null) { Slog.w(TAG, \"Package named '\" + packageName + \"' doesn't exist.\"); return false; } if ((!isSystemApp(ps) || (flags&PackageManager.DELETE_SYSTEM_APP) != 0) && user != null && user.getIdentifier() != UserHandle.USER_ALL) { // Set the user state of the app to be uninstalled, modify the app's relevant information in the user, mark it as uninstall, and delete the data in the sandbox in the user. if (DEBUG_REMOVE) Slog.d(TAG, \"Only deleting for single user\"); final int userId = user.getIdentifier(); ps.setUserState(userId, COMPONENT_ENABLED_STATE_DEFAULT, False, //installed True, //stopped True, //notLaunched False, //hidden Null, null, null, False, // blockUninstall ps.readUserState(userId).domainVerificationStatus, 0); if (!isSystemApp(ps)) { // The app is also installed by other users, so you can't delete the app under /data/app/ // can only delete the sandbox directory for the app user's own if (ps.isAnyInstalled(sUserManager.getUserIds())) { if (DEBUG_REMOVE) Slog.d(TAG, \"Still installed by other users\"); removeUser = user.getIdentifier(); appId = ps.appId; // Modify /data/users//package-restrictions.xml // Record the above information scheduleWritePackageRestrictionsLocked(removeUser); } else { / / Only one user installed, you must set the installed state in its userState to true // set it to false in front if (DEBUG_REMOVE) Slog.d(TAG, \"Not installed by other users, full delete\"); ps.setInstalled(true, user.getIdentifier()); } } else { if (DEBUG_REMOVE) Slog.d(TAG, \"Deleting system app\"); removeUser = user.getIdentifier(); appId = ps.appId; scheduleWritePackageRestrictionsLocked(removeUser); } } } // It’s a user who handles it tightly // because USER_ALL = -1 if (removeUser >= 0) { // From above, we determined that we are deleting this only // for a single user. Continue the work here. if (DEBUG_REMOVE) Slog.d(TAG, \"Updating install state for user: \" + removeUser); if (outInfo != null) { outInfo.removedPackage = packageName; outInfo.removedAppId = appId; outInfo.removedUsers = new int[] {removeUser}; } // Delete the sandbox directory of the app in the user mInstaller.clearUserData(ps.volumeUuid, packageName, removeUser); removeKeystoreDataIfNeeded(removeUser, appId); // Send a START_CLEANING_PACKAGE message // call startCleaningPackages() when processing the message // This method will send an intent of \"android.content.pm.CLEAN_EXTERNAL_STORAGE\" // com.android.defcontainer.DefaultContainerService will handle it schedulePackageCleaning(packageName, removeUser, false); synchronized (mPackages) { if (clearPackagePreferredActivitiesLPw(packageName, removeUser)) { / / Handle UserHandle.USER_ALL scheduleWritePackageRestrictionsLocked(removeUser); } resetUserChangesToRuntimePermissionsAndFlagsLPw(ps, removeUser); } return true; } .............................. / / Handle USER_ALL // that is, uninstall the app from all users Boolean ret = false; if (isSystemApp(ps)) { if (DEBUG_REMOVE) Slog.d(TAG, \"Removing system package:\" + ps.name); Ret = deleteSystemPackageLI(ps, allUserHandles, perUserInstalled, Flags, outInfo, writeSettings); } else { if (DEBUG_REMOVE) Slog.d(TAG, \"Removing non-system package:\" + ps.name); / / In addition to deleting the sandbox directory, /data/app/package name and other files, but also delete its data structure in the PMS, such as registered components, etc. // This is done by its internal removePackageLI() method. killApplication(packageName, ps.appId, \"uninstall pkg\"); Ret = deleteInstalledPackageLI(ps, deleteCodeAndResources, flags, allUserHandles, perUserInstalled, outInfo, writeSettings); } return ret; ....... The so-called uninstall apk is the content, delete the file and its related data structure in the PMS. "},"Android PMS - Android 6 PMS daemon installd.html":{"url":"Android PMS - Android 6 PMS daemon installd.html","title":"Android PMS - Android 6 PMS daemon installd","keywords":"","body":"1. Android 6 PMS daemon installd1. Android 6 PMS daemon installd Android core service Android underlying development There is a native daemon called installd that silently serves the PMS. Now let's see what it is doing. Installd is defined in init.rc: Service installd /system/bin/installd Class main Socket installd stream 600 system system The installd architecture is relatively simple and will listen for a local socket created by specifying the service attribute in the init.rc file. The local socket created is located at: /dev/socket/installd Source location: Android-6/frameworks/native/cmds/installd/Installd.cpp Entry point Naturally the main function is: int main(const int argc unused, char ×argv[]) { ................... / / Initialize global variables if (initialize_globals() = BUFFER_MAX)) { ALOGE(\"invalid size %d\\n\", count); break; } // read command if (readx(s, buf, count)) { ALOGE(\"failed to read command\\n\"); break; } Buf[count] = 0; if (selinux_enabled && selinux_status_updated() > 0) { selinux_android_seapp_context_reload(); } // Excuting an order if (execute(s, buf)) break; } ALOGI(\"closing connection\\n\"); close(s); } return 0; } Through the comments in the code, you can already get a general idea of ​​his workflow. Initialize_globals() is used to initialize global variables. When the method is executed, the following global variables can be determined: dir_rec_t android_data_dir; // /data dir_rec_t android_asec_dir; // /mnt/asec dir_rec_t android_app_dir; // /data/app dir_rec_t android_app_private_dir; // /data/priv-app dir_rec_t android_app_lib_dir; // /data/app-lib dir_rec_t android_media_dir;// /data/media dir_rec_t android_mnt_expand_dir; // /mnt/expand // android_system_dirs.count = 4; // /system/app // /system/priv-app // /vendor/app // /oem/app dir_rec_array_t android_system_dirs;// / The initialize_directories() is responsible for ensuring that the above folders are created and that the correct permissions are set. Installd supported commands Support the following commands: struct cmdinfo cmds[] = { { \"ping\", 0, do_ping }, // empty operation for testing { \"install\", 5, do_install }, // Install the app { \"dexopt\", 9, do_dexopt }, // convert dex to oat or patchat oat file { \"markbootcomplete\", 1, do_mark_boot_complete }, { \"movedex\", 3, do_move_dex }, // move the apk file from one directory to another { \"rmdex\", 2, do_rm_dex }, // delete the apk file { \"remove\", 3, do_remove }, // Uninstall the app { \"rename\", 2, do_rename }, // change the name of the application data directory { \"fixuid\", 4, do_fixuid }, // change the uid of the application data directory { \"freecache\", 2, do_free_cache }, // Clear files in the /cache directory { \"rmcache\", 3, do_rm_cache }, // delete the directory of an application under /cache { \"rmcodecache\", 3, do_rm_code_cache }, // delete the code_cache folder in the data directory { \"getsize\", 8, do_get_size }, // Calculate the amount of space occupied by an application, including apk size, data directory, cache directory, etc. { \"rmuserdata\", 3, do_rm_user_data }, // Delete application data of an app in a user { \"cpcompleteapp\", 6, do_cp_complete_app }, { \"movefiles\", 0, do_movefiles }, // ​​execute the script in /system/etc/updatecmds/ { \"linklib\", 4, do_linklib }, // create a jib connection { \"mkuserdata\", 5, do_mk_user_data }, // Create an application data directory for a user { \"mkuserconfig\", 1, do_mk_user_config }, // Create /data/misc/user/userid/ { \"rmuser\", 2, do_rm_user }, // ​​delete all files of a user { \"idmap\", 3, do_idmap }, { \"restorecondata\", 4, do_restorecon_data }, // Restore the SEAndroid security context of the directory { \"createoatdir\", 2, do_create_oat_dir }, // Create /data/app/package name /oat/ folder { \"rmpackagedir\", 1, do_rm_package_dir }, / / ​​delete /data/app/package name { \"linkfile\", 3, do_link_file } // Create a soft connection }; The installation work done by do_install is actually to create an application data directory, which is divided into two cases: user id is 0 and not (Application installed in internal storage) When the user ID is 0: /data/data/package name/ User ID is not 0: /data/user/userid/package name A situation when a user installs on external storage: /mnt/expand/volume_uuid/user/userid/package name After creating the folder, modify the permissions to 0751, then the SEAndroid context, and uid and gid. In addition, in do_dexopt, you can execute the dex2oat command to convert dex to oat file, or execute patchat to randomize the memory load address for the oat file. Also to understand is the format of the installd command: Send the command length first, then send the command. "},"Android AOSP - Debugging AOSP Platform code with Android Studio - Java Debugger.html":{"url":"Android AOSP - Debugging AOSP Platform code with Android Studio - Java Debugger.html","title":"Android AOSP - Debugging AOSP Platform code with Android Studio - Java Debugger","keywords":"","body":"1. Android AOSP - Debugging AOSP Platform code with Android Studio - Java Debugger1.1. Live Debugging Session (with screenshots)1. Android AOSP - Debugging AOSP Platform code with Android Studio - Java Debugger Original link In my previous post about using JDWP I have listed the theory and practice of connecting and debugging a remote Java based application in Android, using adb, ddms, monitor, and jdwp. What all IDE's do for your application debugging is essentially the same; They work, and require no introduction. But what happens when you want to debug Android Framework code (Android Platform, AOSP, I don't know why some people refer to it as Framework, it's just a small component in the platform!)? The answer for it is that you need to work hard, figure out all kind of JDWP connectivity issues, and then find your IDE specific way to both connect, instrument (debug), and show the right source code. In this post I will detail the steps to make it work with Android Studio. Without too many stories about what I like and mostly dislike about Studio, once you have: Built your AOSP platform *( . build/envsetup.sh && lunch \\-\\ && make ...)* Created the Android Studio project for importing to *( mmm development/tools/idegen && development/tools/idegen/idegen.sh )* Imported the project ( open android.ipr from Android Studio) You can view sources, and efficiently navigate the Java code, which is nice, but you can't do much with it, despite Android Studio's announcement that it \"identified Android Framework code\", because Studio still expects an Application to be debugged. However, Android Studio does allow to connect to a remote Java debugger, which is exactly what we need in our case! The Application selection and port forwarding processes (e.g. who gets port 8700, when you need another port) are the same as in my previous post, so I will not repeat them, but rather concentrate on the steps to configure Android Studio to connect to the target over port 8700 (you can do it on any other port forwarded app as well). Now what you need to do the get the job done is: Create a Remote debugging configuration Set the port in it Select the Debuggable process. I recommend to start monitor and then click on the relevant process. This will only attach You can also from within the platform itself set a debuggable process (won't work for the system_process if you want to do live debugging, but you can actually also take care of that, if you run it manually (adb stop firs) Hit debug / Run-Debug / ctrl+alt+F9 - This will attach to the process Set your breakpoints (you can of course do it before Debug). Some screenshots and explanations are listed below (and so bloat the post. Sorry about that, but it seems to help more than just text.) 1.1. Live Debugging Session (with screenshots) Objective: Enter a breakpoint in the Phone Dialier application when the user dials \"1\" on the DialPad. Means: Show the configuration, show a typical connection error, how to workaround it, and get the job done! Steps: First, import the Android.ipr to Studio. You will see something like this: Create a new Debug Configuration: On Android Studio's menu: go to Run, Edit Configurations and then click the Remote configuration, and click the + sign at the top left part of the window. This will duplicate the configuration. Give it a meaningful name, and edit the port (to 8700, or any port. You can create multiple configurations, and debug multiple apps simultaneously). I called the new configuration AOSP_Java_Debug , and set the port to 8700 . After editing the settings click OK. You are now ready to debug. Or are you? Well, you are not, because there is a connection error. In the next step will explain it. The previous error message told us Android Studio could not connect to port 8700 on the localhost, which is the DDMS port on our host. Let's see if it is bluffing, by checking what is the status of port 8700 in netstat . We can see that no one is listening on this port. In order to listen on the port, we need DDMS. So the next thing to do is to open monitor from the Android SDK. You could also open DDMS directly from your AOSP build. If you want to take care of port forwarding yourself, or not deal with port 8700 - you are more than welcome to do so. After opening monitor you will be in the following state as in the following diagram. Click the process you would like to debug, and you will see that there is a / 8700 next to its debugging port (that's the other number in the last column, The rest of the column describe the package or \"nice name\" (set when starting app_process/zygotte, I won't get to that here), and the PID (Process id) of the app. Important for Native debugging: If you want to use GDB on the native part - --attach to this PID! Let's set a breakpoint at the relevant line (Just click next to it in the pane) Now let's connect our debugger. Hit the debug button. Now when you try to debug - you will see you are connected (\" Connected to the target VM, address: 'localhost:8700' , transport: 'socket' \"). Sweet! Let's open the debugged app, and reach our breakpoint. Note the green bug in the monitor/DDMS, it means that we are connected. You will also see a corresponding message in the Logcat. When we press \"1\" , we will reach our breakpoint. Disregard the 'Connection Refused' error message - it was 7 minutes ago - before we opened the monitor! Now you can proceed debugging. If you single step, you will hear an annoying beep that will not go away until you have resumed / finished the business logic of the button. That's a good sign - you have felt progress in several senses! After resuming, you will see \"1\" pressed. Hooray! Documenting is harder than actually doing, so just get doing it, and if you found the explanation helpful - please let me know. I really wrote this post because I didn't find any normal answer to that over the internet, am being asked about it in my Android Internals/Security/Advanced Native Programming classes (\\@see http://www.thepscg.com ) and outside of them, so I am pretty sure it will interest a reader or two. Next in line - Native debugging (come on, just use gdb and gdbserver. I am willing to give you the pleasure of using ndk-debug et. al...) "},"Android AOSP - Modify applications and rebuild emulator image effectively.html":{"url":"Android AOSP - Modify applications and rebuild emulator image effectively.html","title":"Android AOSP - Modify applications and rebuild emulator image effectively","keywords":"","body":"1. Android AOSP - Modify applications and rebuild emulator image effectively1. Android AOSP - Modify applications and rebuild emulator image effectively The system image file used by the emulator is system-qemu.img. For some reason, the file is not make snodgenerated, it only makes system.img. I think the need is an extra goal, so you can say make qsnodor by what, but it does not seem. I don't know who can do this. I can not understand the structure of the file system to learn how to add a qsnodgoal, but there is a way. Please note that make -nN the final step in the report is: [100% 255/255] Create system-qemu.img To find out what commands it runs, you can say make showcommands -jN. I did this and found the following is my Macbook Pro: [100% 255/255]/bin/bash -c\"(export SGDISK=out/host/darwin-x86/bin/sgdisk; device/generic/goldfish/tools/mk_qemu_image.sh out/target/product/generic_x86_64/system.img)\" This is from the input system.img (which is make snod generated does) system-qemu.img command. Thus, after changing /java file under the base frame, re-created on my computer system.img trick is: mmm frameworks/base -jN make snod -jN SGDISK=out/host/linux-x86/bin/sgdisk device/generic/goldfish/tools/mk_qemu_image.sh out/target/product/generic_x86_64/system.img Then when I restarted the emulator, I saw that my changes have taken effect. "},"Android General - Reliable connection to AIDL IPC Service in Android.html":{"url":"Android General - Reliable connection to AIDL IPC Service in Android.html","title":"Android General - Reliable connection to AIDL IPC Service in Android","keywords":"","body":"1. Reliable connection to AIDL IPC Service in Android1.1. Android Service life-cycle:1.2. What is the exact life-cycle of a connection to bound IPC Service:1.3. Conclusion:1. Reliable connection to AIDL IPC Service in Android By Vasiliy| June 9th, 2016|Android development|5 Comments Reliable connection to AIDL IPC Service in Android Android Service life-cycle: What is the exact life-cycle of a connection to bound IPC Service: Conclusion: The following statement opens the official Services documentation page: A Service is an application component that can perform long-running operations in the background, and it does not provide a user interface There are two mechanisms by which application’s logic can interact with Service: start it, or bind it. In this post we are only concerned with bound Services. The official documentation on Bound Services starts with the following statement: A bound service is the server in a client-server interface. It allows components (such as activities) to bind to the service, send requests, receive responses, and perform interprocess communication (IPC) We are going to deep dive into bound IPC Services (i.e. Services that run in different process), and discuss how exactly we can establish a reliable connection to Services in another processes. 1.1. Android Service life-cycle: Android Service’s life-cycle is tricky – it can be started, bound, or both. Furthermore, Service’s life-cycle changes depending on the value it returns from its onStartCommand() method, and depending on the flags used in bindService() call. Official documentation on bound services provides very basic information which isn’t sufficient for developers to implement reliable services, and even contains plainly wrong statements (as will be discussed later in this post). While many blogs, tutorials and StackOverflow questions attempt to provide additional information on Services, almost no source discusses how exactly the clients, which bind to Services, perceive Services’ life-cycle, and how to account for that life-cycle on client’s side of connection. This post attempts to provide that crucial piece of information by looking at the connection to bound IPC Services from client’s point of view. How bound IPC Service connection’s life-cycle is different from life-cycle of the Service itself: From client’s point of view, the “effective” life-cycle of IPC Service is shorter than the actual one – it starts when the client executes bindService() call, and ends when the client calls unbindService(). Client shouldn’t be aware whether the Service existed before the client attempted to bind to it, or whether the Service is going to die once the client unbinds from it [side note: clients shouldn’t be aware, but sometimes developers force their clients to be aware (which is a bad idea); nothing else could explain the popularity of this StackOverflow answer]. Although the “effective” life-cycle (as seen from client’s point of view) is shorter, it does not imply that it is simpler. For instance, there is widely accepted knowledge that bound IPC Services can crash or be killed by OS (in which case it might, or might not, be restarted by OS – will be discussed later), but almost no source addresses the question of what implications does Service crash have on clients that are bound to it. It turns out (and will be discussed shortly), that clients can and should handle this situation gracefully, and that service crash, as seen from client’s point of view, might be both recoverable and irrecoverable error, depending on circumstances. 1.2. What is the exact life-cycle of a connection to bound IPC Service: The life-cycle of a connection to bound IPC Service (the “effective” life-cycle of the Service from client’s point of view) is summarized in the following diagram: In order to make the following discussions clear, let’s define three types of errors which can occur while the client is being connected to an IPC Service: Recoverable error: an error from which the client can recover while the Service is bound (without making a rebind attempt). Irrecoverable error: an error from which the client can’t recover while the Service is bound – in order to handle irrecoverable error the client will need to attempt to rebind the Service (unbind and bind again). Fatal error: an error after which the client should assume that the Service won’t be available. Looking at the above diagram, we can see “paths” having three different colors. The color codes mean: Green: this “path” corresponds to normal flow – the client binds to Serivce, uses it and unbinds while either not encountering any errors along the way, or handling the encountered errors correctly. Orange: this “path” corresponds to sub-flow of recoverable errors – the connection to Service had been lost at some point, but was restored later. Red: this “path” corresponds to sub-flow of fatal error – either the service couldn’t be bound, or the connection was lost and never restored, and the client couldn’t handle this irrecoverable error correctly. It is also important to note, that connection’s life-cycle can be “terminated” in either of three states: STATE_UNBOUND: this would be a terminating state in case the client calls unbindService() by itself. STATE_BINDING_FAILED: this would be a terminating state in case the client couldn’t bind to IPC Service at all. This is a fatal error, and IMHO there is no reason to attempt to rebind the Service again. STATE_BOUND_DISCONNECTED: this would be a terminating state in case an irrecoverable error took place, but client wasn’t designed to handle it correctly – it remains stuck in this state indefinitely long, or until client’s life-cycle callback (e.g. onStop()) invoked. How can we account for connection’s life-cycle when writing clients of bound IPC Services: So far we saw that in addition to a non-trivial life-cycle of bound IPC Service, there is also non-trivial life-cycle of client’s connection to it, which makes a task of writing a reliable client a real challenge. Since the states shown in the above diagram are abstract (in a sense that framework does not expose them as constants or enums), I began by implementing IpcServiceConnector class which wraps the connection, derives its state, and exposes this information to the outside world as state constants. Actually it does a bit more than that, but let me not repeat myself – it is all summed up in javadoc in details. One important note is that IpcServiceConnector was designed to be used by background worker threads rather than main UI thread – some of its methods would block a calling thread, which is not acceptable in case of UI thread. The rationale was simple – you can always offload work from UI thread to background threads. The method that will allow us to implement reliable clients is waitForState() (by invoking this method we can make backgrounds thread wait until connection transitions to a specific state): /** * Call to this method will block the calling thread until this connector transitions to the * specified state, or until the specified amount of time passes If the connector is already in * the requested state then this method returns immediately. * * NOTE: {@link ServiceConnection#onServiceConnected(ComponentName, IBinder)} and * {@link ServiceConnection#onServiceDisconnected(ComponentName)} will be invoked BEFORE * threads which are waiting due to calls to this method are unblocked. This allows you to * use ServiceConnection's callbacks in order perform the required setup before the execution * of the blocked threads continues. * * This method MUST NOT be called from UI thread. * @param targetState IpcServiceConnector's state in which the calling thread should be * unblocked. Should be either of: * {@link #STATE_NONE} * {@link #STATE_BOUND_WAITING_FOR_CONNECTION} * {@link #STATE_BOUND_CONNECTED} * {@link #STATE_BOUND_DISCONNECTED} * {@link #STATE_UNBOUND} * {@link #STATE_BINDING_FAILED} * * @param blockingTimeout the period of time (in milliseconds) after which the calling thread will * be unblocked (regardless of the state of this IpcServiceConnector) * @return true if target state was reached; false otherwise */ @WorkerThread public boolean waitForState(int targetState, int blockingTimeout) { ... } In the tutorial application (source here) the client is Activity that should display accurate date and time on the screen (I chose Activity instead of Service in order to simplify the code; not sure that it worked that way though). The date is provided by a Service which is exposed through AIDL and running in a separate child process (this is the closest we can get to simulating a real IPC Service in a single application). Except for fetching from the Service an accurate date and time, the client can also make the Service crash by calling a special pre-defined method. This functionality is available to app users on special button click: Since client’s code is also heavily commented, I will post it here instead of repeating myself: public class MainActivity extends AppCompatActivity { private static final String TAG = \"MainActivity\"; private static final int CONNECTION_TIMEOUT = 5000; // ms private static final long DATE_REFRESH_INTERVAL = 100; // ms private final ServiceConnection mServiceConnection = new ServiceConnection() { @Override public void onServiceConnected(ComponentName name, IBinder service) { Log.d(TAG, \"onServiceConnected()\"); mDateProvider = IDateProvider.Stub.asInterface(service); mBtnCrashService.setEnabled(true); } @Override public void onServiceDisconnected(ComponentName name) { Log.d(TAG, \"onServiceDisconnected()\"); mBtnCrashService.setEnabled(false); mDateProvider = null; } }; private IpcServiceConnector mIpcServiceConnector; private IDateProvider mDateProvider; private final DateMonitor mDateMonitor = new DateMonitor(); private TextView mTxtDate; private Button mBtnCrashService; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); mIpcServiceConnector = new IpcServiceConnector(this, \"DateProviderConnector\"); mTxtDate = (TextView) findViewById(R.id.txt_date); mBtnCrashService = (Button) findViewById(R.id.btn_crash_service); mBtnCrashService.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View v) { try { mDateProvider.crashService(); } catch (RemoteException e) { e.printStackTrace(); } } }); } @Override protected void onStart() { super.onStart(); Log.d(TAG, \"onStart(); binding and connecting to IPC service\"); if (!bindDateProviderService()) { // service couldn't be bound - handle this error by disabling the logic which depends // on this service (in this case we will do it in onResume()) } } @Override protected void onStop() { super.onStop(); Log.d(TAG, \"onStop(); unbinding IPC service\"); mIpcServiceConnector.unbindIpcService(); } @Override protected void onResume() { super.onResume(); if (mIpcServiceConnector.isServiceBound()) { Log.d(TAG, \"onResume(); starting date monitor\"); mDateMonitor.start(); } else { Log.e(TAG, \"onResume(); IPC service is not bound - aborting date monitoring\"); } } @Override protected void onPause() { super.onPause(); Log.d(TAG, \"onPause(); stopping date monitor\"); mDateMonitor.stop(); } private boolean bindDateProviderService() { return mIpcServiceConnector.bindAndConnectToIpcService( new Intent(this, DateProviderService.class), mServiceConnection, Context.BIND_AUTO_CREATE); } private class DateMonitor { private final Runnable mConnectionInProgressNotification = new Runnable() { @Override public void run() { mTxtDate.setText(\"connecting to IPC service...\"); } }; private final Runnable mDateNotification = new Runnable() { @Override public void run() { mTxtDate.setText(mCurrentDate); } }; private String mCurrentDate = \"-\"; private boolean mConnectionFailure = false; private final Handler mMainHandler = new Handler(Looper.getMainLooper()); private Thread mWorkerThread; private Thread mOldWorkerThread; public void start() { // make sure we stop the worker thread, but keep reference to it if (mWorkerThread != null) { mOldWorkerThread = mWorkerThread; stop(); } mWorkerThread = new Thread(new Runnable() { @Override public void run() { // make this thread wait until the old thread dies if (mOldWorkerThread != null) { try { mOldWorkerThread.join(); } catch (InterruptedException e) { // set the interrupted status back (it was cleared in join()) Thread.currentThread().interrupt(); } mOldWorkerThread = null; } mConnectionFailure = false; mCurrentDate = \"-\"; // loop until interrupted while (!Thread.currentThread().isInterrupted()) { updateDate(); try { Thread.sleep(DATE_REFRESH_INTERVAL); } catch (InterruptedException e) { // set the interrupted status back (it was cleared in sleep()) Thread.currentThread().interrupt(); } } } }); mWorkerThread.start(); } public void stop() { if (mWorkerThread != null) { mWorkerThread.interrupt(); mWorkerThread = null; } } @WorkerThread private void updateDate() { /* We don't want the date displayed being stuck if we ever need to wait for connection, therefore we show informative notification. The notification should be cancelled if the service is connected */ if (!mConnectionFailure) { mMainHandler.postDelayed(mConnectionInProgressNotification, 100); } // this call can block the worker thread for up to CONNECTION_TIMEOUT milliseconds if (mIpcServiceConnector.waitForState(IpcServiceConnector.STATE_BOUND_CONNECTED, CONNECTION_TIMEOUT)) { // IPC service connected mConnectionFailure = false; mMainHandler.removeCallbacks(mConnectionInProgressNotification); try { mCurrentDate = mDateProvider.getDate(); } catch (RemoteException e) { // this exception can still be thrown (e.g. service crashed, but the system hasn't // notified us yet) mCurrentDate = \"-\"; e.printStackTrace(); } catch (NullPointerException e) { /* Since mDateProvider is assigned/cleared on UI thread, but is being used on worker thread, there is a chance of race condition that will result in NPE. We could either add synchronization, or catch NPE - I chose the latter in order to simplify the (already complex) example */ mCurrentDate = \"-\"; e.printStackTrace(); } } else { // could not connect to IPC service Log.e(TAG, \"connection attempt timed out - attempting to rebind to the service\"); notifyUserConnectionAttemptFailed(); /* Connection error handling here. I just attempt to rebind to the service, but a real error handling could also employ some extrapolation of cached data, etc. If this is a fatal error from your application's point ov view, then unbind from the service and stop the worker thread. */ mConnectionFailure = true; mIpcServiceConnector.unbindIpcService(); if (!bindDateProviderService()) { Log.e(TAG, \"rebind attempt failed - stopping DateMonitor completely\"); DateMonitor.this.stop(); } return; } mMainHandler.post(mDateNotification); } private void notifyUserConnectionAttemptFailed() { MainActivity.this.runOnUiThread(new Runnable() { @Override public void run() { Toast.makeText( MainActivity.this, \"connection attempt timed out - rebinding\", Toast.LENGTH_LONG) .show(); } }); } } } the main part of the code is an inner class DateMonitor – this class spawns a new thread, makes sure that IPC Service is connected, queries the Service for a data and handles all the errors (except for a single fatal error which would occur if initial binding wouldn’t succeed). I encourage you to download the source of a tutorial application, install it and play around. You will discover a very interesting system’s policy concerning bound, but crashing IPC Services. You can also use DDMS in order to kill the child process in which the Service runs, thus simulating the Service being killed by OS. You might be surprised to find out that the system treats killed and crashed Services very differently. Happy shell users could kill the child process with a command similar to this one: adb shell ps | grep childProcess | perl -ane 'END {print @F[1]}' | xargs adb shell kill and even automate this process in order to see what happens when the Service is being killed perpetually (and if you do that – please let me know about your results in comments). 1.3. Conclusion: In this post we saw that, though far from trivial, it is possible to implement clients that establish reliable, crash and kill tolerant connections to IPC Services. This becomes possible once we “distill” the states of connections to bound IPC services, and understand how various transitions between these states should be handled. We also discovered that the system treats crashed and killed bound IPC Services differently. Please leave your comments and questions below, and consider subscribing to our newsletter if you liked the post. "},"Live555 - Live555 source code analysis_introduction.html":{"url":"Live555 - Live555 source code analysis_introduction.html","title":"Live555 - Live555 source code analysis_introduction","keywords":"","body":"1. Live555 source code analysis: introduction1.1. Source code download and compilation1.2. Provide streaming services using live555MediaServer1.3. Live555 source structure1.4. UsageEnvironment and BasicUsageEnvironment1.5. Groupsock1.6. liveMedia1.7. mediaServer and proxyServer1.8. WindowsAudioInputDevice1.9. testProgs1.10. Live555 source code analysis series1. Live555 source code analysis: introduction Posted on 2017-08-28 | In live555 | Live555 source code analysis: introduction Source code download and compilation Provide streaming services using live555MediaServer Live555 source structure UsageEnvironment and BasicUsageEnvironment Groupsock liveMedia mediaServer and proxyServer WindowsAudioInputDevice testProgs Live555 source code analysis series Live555 is a streaming media project developed by C++. It is mainly composed of several libraries for multimedia streaming. Its official website address is http://www.live555.com/. Live555 uses an open standard protocol (RTP/RTCP, RTSP, SIP) to facilitate interoperability with other standard streaming components. These libraries can be compiled for systems such as Unix-like (including Linux and Mac OS X), Windows, and QNX (and other POSIX compatible systems), which can be used to build streaming applications. In addition to the library, live555 also includes two streaming applications \" LIVE555 Media Server \" and \" LIVE555 Proxy Server \", both of which are RTSP server applications. Live555's library can be used to process MPEG, H.265, H.264, H.263+, DV or JPEG video, and multiple audio formats. They can also be extended very simply to support other audio or video codec formats and can be used to build basic RTSP or SIP clients and servers. 1.1. Source code download and compilation The source code of live555 is open, and can be easily studied by all audio and video development research enthusiasts, or extended for their actual projects. The source code download address is http://www.live555.com/liveMedia/public/ : Among them live555-latest.tar.gz is the latest version of the source code, live.2017.07.18.tar.gz is the target version of this series. In addition to the source code, live555 also provides a number of audio and video files for development and testing, such as the 264 directory for the original H.264 test streams files, 265 directory for the original H.265 test streams files. Here we use the latest version of live555 source code, live555-latest.tar.gz , and the operating system is 64-bit Ubuntu 16.04. Download the source code and extract it with the following command: Hanpfei0306 \\@ThundeRobot :/media/data/osprojects \\$ tar xf live555-latest.tar.gz Hanpfei0306 \\@ThundeRobot :/media/data/osprojects \\$ cd live You can compile live555 with the following command: Hanpfei0306 \\@ThundeRobot :/media/data/osprojects/live \\$ ./genMakefiles linux-64bit Hanpfei0306 \\@ThundeRobot :/media/data/osprojects/live \\$ make cd liveMedia ; make In which the genMakefilesscript is used to generate the Makefile, it needs an operating system identifier as a parameter, the contents of the script file is as follows: #!/bin/sh usage() { echo \"Usage: $0 \" exit 1 } if [ $# -ne 1 ] then usage $* fi platform=$1 subdirs=\"liveMedia groupsock UsageEnvironment BasicUsageEnvironment testProgs mediaServer proxyServer\" for subdir in $subdirs do /bin/rm -f $subdir/Makefile cat $subdir/Makefile.head config.$platform $subdir/Makefile.tail > $subdir/Makefile chmod a-w $subdir/Makefile done /bin/rm -f Makefile cat Makefile.head config.$1 Makefile.tail > Makefile chmod a-w Makefile This script combines the predefined Makefile content of multiple files in each directory to produce the final Makefile. Platform-specific configuration files are predefined under each folder, for example, in the project root directory: hanpfei0306@ThundeRobot:/media/data/osprojects/live$ ls | grep config config.aix config.alpha config.armeb-uclibc config.armlinux config.avr32-linux config.bfin-linux-uclibc config.bfin-uclinux config.bsplinux config.cris-axis-linux-gnu config.cygwin config.cygwin-for-vlc config.freebsd config.iphoneos config.iphone-simulator config.irix config.linux config.linux-64bit config.linux-gdb config.linux-with-shared-libraries config.macosx config.macosx-32bit config.macosx-before-version-10.4 config.mingw config.openbsd config.qnx4 config.solaris-32bit config.solaris-64bit config.sunos config.uClinux Provided to the genMakefiles script parameters of the operating system identifier, and each OS identifier requires a configuration file, the configuration file extension to compile matches the corresponding target operating system. After compilation, it produces the various library .a files, libraries, and each individual application object files are located in their own directory. The executable for the media service application is located under live/mediaServer/live555MediaServer. 1.2. Provide streaming services using live555MediaServer streaming media server application in live555 live555MediaServer can easily be used to provide streaming media services. Execute in the directory where the streaming media server live555MediaServer is stored: $ ./live555MediaServer Then you can play the streaming file with a URL in the following format: rtsp://10.240.248.20:8554/ Which is the streaming media file in the directory of live555MediaServer command, after IP address for the host. Once the program live555MediaServer is up and running, you can play streaming content using player software such as VLC Media Player and ffplay. Such as: $ ffplay rtsp:// 10.240.248.20:8000/raw_h264_stream.264 If you just want to play live555MediaServer itself, then it can also directly download the compiled binary files, address . 1.3. Live555 source structure We look at the source code structure of live555. First create an Eclipse C++ Project for live555 by selecting File -> New -> C++ Project from the menu bar. The following dialog pops up: Project Name: Column, enter the project name, here live555; invert the selection Use default location, then Location: enter the path live555 source column; inProject type: the next selection Makefile project -> Empty Project; in Toolchains: selecting the next Linux GCC. Then click on the bottom right corner of the Finishbutton to create the project. The live555 source structure is as follows: The live555 source code is mainly composed of eight parts: UsageEnvironment, BasicUsageEnvironment, groupsock, liveMedia, mediaServer, proxyServer, testProgs, WindowsAudioInputDevice. The amount of code for each part is shown in the following table: Submodule Number of files Code amount (row) UsageEnvironment 3 162 BasicUsageEnvironment 6 1187 Groupsock 8 2672 liveMedia 168 49552 mediaServer 2 332 proxyServer 1 251 WindowsAudioInputDevice 4 1037 testProgs 32 6510 Total 224 61703 A brief description of each part is as follows. 1.4. UsageEnvironment and BasicUsageEnvironment The UsageEnvironment and TaskScheduler classes in UsageEnvironment module are used to schedule delayed events, to allocate handlers for asynchronous read events, and to output error/warning messages. The \"HashTable\" class in UsageEnvironment also defines an interface for the generic hash table, which is used by the rest of the code. The UsageEnvironment contains only abstract classes; they must be inherited by other implementations. These subclasses can take advantage of specific properties of the environment in which they run, such as its GUI and/or scripting environment. The BasicUsageEnvironment library defines a set of concrete implementation of the classes in UsageEnvironment for simple terminal applications. Read events and delay operation using a select() loop processing. 1.5. Groupsock The classes in this library encapsulate network interfaces and sockets. In particular, the \"Groupsock\" class encapsulates a socket for sending (and/or receiving) multicast datagrams. 1.6. liveMedia This library is at the heart of live555. It defines a class hierarchy with \"Medium\" as the top-level base class for a variety of streaming types and codecs. 1.7. mediaServer and proxyServer Under the mediaServer directory is \"LIVE555 Media Server\", which is a complete RTSP server application. It can convert several media files into streams. As you saw earlier, these media files must be in the current working directory. These include: MPEG TS file (file suffix \".ts\") Matroska or WebM files (file suffix \".mkv\" or \".webm\") Ogg file (file suffix \".ogg\", \"ogv\" or \".opus\") MPEG-1 or 2 program stream file (file suffix \".mpg\") MPEG-4 Video Elementary Stream file (file suffix \".m4e\") H.264 Video Elementary Stream file (file suffix named \".264\") H.265 Video Elementary Stream file (file suffix named \".265\") VOB video + audio file (file suffix named \".vob\") DV video file (file suffix is ​​named \".dv\") MPEG-1 or 2 (including layer III - such as 'MP3') audio file (file suffix named \".mp3\") WAV (PCM) audio file (file suffix named \".wav\") AMR audio file (file suffix is ​​named \".amr\") AC-3 audio file (file suffix is ​​named \".ac3\") AAC (ADTS format) audio file (file suffix named \".aac\") Under the proxyServer directory is \"LIVE555 Proxy Server\", a unicast RTSP server that acts as a \"proxy\" for one or more \"backend\" unicast or multicast RTSP/RTP streams. 1.8. WindowsAudioInputDevice This is an implementation of the \"AudioInputDevice\" abstract class of the \"liveMedia\" library. It can be used by Windows applications to read PCM audio samples from an input device. 1.9. testProgs This directory implements some simple programs that use \"BasicUsageEnvironment\" to demonstrate how to use these libraries to develop applications. In addition to the test application for the test library, it also includes \" openRTSP \" - the RTSP client for the command line, \" playSIP \" - the SIP session logger for the command line, \" vobStreamer \" - tools such as the network DVD player. Reward Done. 1.10. Live555 source code analysis series Live555 Source code analysis: Introduction live555 Source code analysis: Infrastructure live555 Source code analysis: MediaSever Wireshark capture packet analysis RTSP/RTP/RTCP Basic working process live555 Source code analysis: RTSPServer live555 Source code analysis: DESCRIBE processing live555 Source code analysis: SETUP processing live555 Source code analysis :PLAY processing live555 Source code analysis: RTSPServer component structure live555 Source code analysis: ServerMediaSession live555 Source code analysis: sub-session SDP line generation live555 Source code analysis: sub-session SETUP live555 Source code analysis: play start "},"Live555 - Live555 source code analysis_infrastructure.html":{"url":"Live555 - Live555 source code analysis_infrastructure.html","title":"Live555 - Live555 source code analysis_infrastructure","keywords":"","body":"1. Live555 Source code analysis: Infrastructure1.1. HashTable1.2. UsageEnvironment : HashTable1.3. BasicUsageEnvironment 的 BasicHashTable1.4. Insert an element into the BasicHashTable1.5. Find elements in the BasicHashTable1.6. Remove elements from BasicHashTable1.7. Traversing the BasicHashTable through Iterator1.8. UsageEnvironment1.9. TaskScheduler1.10. Representation of time1.11. Deferred task representation and organization1.12. Delayed task scheduling1.13. User event task scheduling1.14. Event loop execution framework1.15. Socket I/O event description and its organization1.16. Socket I/O event processing task scheduling1.17. Live555 source code analysis series1. Live555 Source code analysis: Infrastructure Posted on 2017-08-30 | In live555 Live555 Source code analysis: Infrastructure HashTable UsageEnvironment : HashTable BasicUsageEnvironment 的 BasicHashTable Insert an element into the BasicHashTable Find elements in the BasicHashTable Remove elements from BasicHashTable Traversing the BasicHashTable through Iterator UsageEnvironment TaskScheduler Representation of time Deferred task representation and organization Delayed task scheduling User event task scheduling Event loop execution framework Socket I/O event description and its organization Socket I/O event processing task scheduling Live555 source code analysis series Live555 consists of multiple modules, such as UsageEnvironment, BasicUsageEnvironment, and groupsock. They provide event loops, input and output, basic data structures, and network IO functions respectively, which can be seen as the live555 infrastructure. In our analysis of the live555 source code, we'll start with these infrastructures. The basic data structure. 1.1. HashTable First of all HashTable, this is a generic association container defined by live555. 1.2. UsageEnvironment : HashTable In UsageEnvironment, The HashTable class defines an interface, the interface is defined as follows: class HashTable { public: virtual ~HashTable(); // The following must be implemented by a particular // implementation (subclass): static HashTable* create(int keyType); virtual void* Add(char const* key, void* value) = 0; // Returns the old value if different, otherwise 0 virtual Boolean Remove(char const* key) = 0; virtual void* Lookup(char const* key) const = 0; // Returns 0 if not found virtual unsigned numEntries() const = 0; Boolean IsEmpty() const { return numEntries() == 0; } // Used to iterate through the members of the table: class Iterator { public: // The following must be implemented by a particular // implementation (subclass): static Iterator* create(HashTable const& hashTable); virtual ~Iterator(); virtual void* next(char const*& key) = 0; // returns 0 if none protected: Iterator(); // abstract base class }; // A shortcut that can be used to successively remove each of // the entries in the table (e.g., so that their values can be // deleted, if they happen to be pointers to allocated memory). void* RemoveNext(); // Returns the first entry in the table. // (This is useful for deleting each entry in the table, if the entry's destructor also removes itself from the table.) void* getFirst(); protected: HashTable(); // abstract base class }; // Warning: The following are deliberately the same as in // Tcl's hash table implementation int const STRING_HASH_KEYS = 0; int const ONE_WORD_HASH_KEYS = 1; Although HashTable to be defined as a paradigm associative containers, but it did not use C ++ templates. In HashTable, the request key is a C-style string, that is char const*, the value is void*, which can represent various types of values. Just like the many container types in the C++ standard library, HashTable has iterator class which is defined internally to traverse the container. Other operations such as adding, removing, and finding elements are not much different from other common container designs. HashTable Public class implements two template functions not related to specific memory structure RemoveNext() and getFirst(), for the removal of these two functions are the next element in the container and returns the value of the element, and to obtain a first container elements, their The implementation is as follows: #include \"HashTable.hh\" HashTable::HashTable() { } HashTable::~HashTable() { } HashTable::Iterator::Iterator() { } HashTable::Iterator::~Iterator() {} void* HashTable::RemoveNext() { Iterator* iter = Iterator::create(*this); char const* key; void* removedValue = iter->next(key); if (removedValue != 0) Remove(key); delete iter; return removedValue; } void* HashTable::getFirst() { Iterator* iter = Iterator::create(*this); char const* key; void* firstValue = iter->next(key); delete iter; return firstValue; } Both of these functions are implemented by means of an iterator of the container. Iterator Class next(char const*& key) receives an outgoing parameter for the key to return to the caller. Defined by live555 from the perspective of interface definition HashTable. Its Iterator class object is Iterator a static method of the class create(HashTable const& hashTable) is created, but the responsibility to destroy the object is created in the caller here, which greatly undermined the HashTable flexibility to achieve the interface, such as the creation of the object and therefore can not do caching. HashTable Class and its iterator class Iterator each defining a static method create(). Here the use of bridging the way HashTable of this method as a bridge, like the HashTable interface and the implementation of the interface link up. This class of static functions is defined in the class that implements the interface. HashTable There are two types were identified using two integer values, STRING_HASH_KEYS and ONE_WORD_HASH_KEYS. Of course, it relies on create() a method according to HashTable still create objects of different classes of objects created in the same class type may be create() design method is understood to bridging, or factory methods. 1.3. BasicUsageEnvironment 的 BasicHashTable The BasicUsageEnvironment BasicHashTable provides a HashTable realization. BasicHashTable The definition is as follows: // A simple hash table implementation, inspired by the hash table // implementation used in Tcl 7.6: #define SMALL_HASH_TABLE_SIZE 4 class BasicHashTable: public HashTable { private: class TableEntry; // forward public: BasicHashTable(int keyType); virtual ~BasicHashTable(); // Used to iterate through the members of the table: class Iterator; friend class Iterator; // to make Sun's C++ compiler happy class Iterator: public HashTable::Iterator { public: Iterator(BasicHashTable const& table); private: // implementation of inherited pure virtual functions void* next(char const*& key); // returns 0 if none private: BasicHashTable const& fTable; unsigned fNextIndex; // index of next bucket to be enumerated after this TableEntry* fNextEntry; // next entry in the current bucket }; private: // implementation of inherited pure virtual functions virtual void* Add(char const* key, void* value); // Returns the old value if different, otherwise 0 virtual Boolean Remove(char const* key); virtual void* Lookup(char const* key) const; // Returns 0 if not found virtual unsigned numEntries() const; private: class TableEntry { public: TableEntry* fNext; char const* key; void* value; }; TableEntry* lookupKey(char const* key, unsigned& index) const; // returns entry matching \"key\", or NULL if none Boolean keyMatches(char const* key1, char const* key2) const; // used to implement \"lookupKey()\" TableEntry* insertNewEntry(unsigned index, char const* key); // creates a new entry, and inserts it in the table void assignKey(TableEntry* entry, char const* key); // used to implement \"insertNewEntry()\" void deleteEntry(unsigned index, TableEntry* entry); void deleteKey(TableEntry* entry); // used to implement \"deleteEntry()\" void rebuild(); // rebuilds the table as its size increases unsigned hashIndexFromKey(char const* key) const; // used to implement many of the routines above unsigned randomIndex(uintptr_t i) const { return (unsigned)(((i*1103515245) >> fDownShift) & fMask); } private: TableEntry** fBuckets; // pointer to bucket array TableEntry* fStaticBuckets[SMALL_HASH_TABLE_SIZE];// used for small tables unsigned fNumBuckets, fNumEntries, fRebuildSize, fDownShift, fMask; int fKeyType; }; BasicHashTable A class is defined TableEntry to represent key-value pairs. fNext The field is used to point to the next of the different key-value pairs for the hash value conflict of the computed key. View BasicHashTable of creation: BasicHashTable::BasicHashTable(int keyType) : fBuckets(fStaticBuckets), fNumBuckets(SMALL_HASH_TABLE_SIZE), fNumEntries(0), fRebuildSize(SMALL_HASH_TABLE_SIZE*REBUILD_MULTIPLIER), fDownShift(28), fMask(0x3), fKeyType(keyType) { for (unsigned i = 0; i BasicHashTable With TableEntry preservation of all the key array pointer - value pairs. When the class object is created, a small TableEntry array of pointers fStaticBuckets will be created with the creation of objects in BasicHashTable, save the key elements in this array directly to the relatively little time in order to optimize performance when the element is relatively small, reducing memory The overhead of allocation. fBuckets Save key point - the value of the TableEntry array of pointers, created early in the object, which points to fStaticBuckets the time, while the expansion in the hash bucket, it points to a newly allocated TableEntry array of pointers. Access to the elements in the container is fBuckets done through. fNumBuckets For storing TableEntry the length of an array of pointers. fNumEntries Used to hold the number of key-value pairs in the container.fRebuildSize Hash bucket for the expansion threshold, that is, when BasicHashTable stored in key-value pairs exceeds this value, the hash bucket capacity is needed. fDownShift And fMask for calculating the hash value, the hash value and the hash bucket maps to the capacity range. 1.4. Insert an element into the BasicHashTable By Add(char const* key, void* value) the BasicHashTable insertion element, the function is as follows: void* BasicHashTable::Add(char const* key, void* value) { void* oldValue; unsigned index; TableEntry* entry = lookupKey(key, index); if (entry != NULL) { // There's already an item with this key oldValue = entry->value; } else { // There's no existing entry; create a new one: entry = insertNewEntry(index, key); oldValue = NULL; } entry->value = value; // If the table has become too large, rebuild it with more buckets: if (fNumEntries >= fRebuildSize) rebuild(); return oldValue; } The car that is inserted into the BasicHashTable is roughly as follows: Find the element in the BasicHashTable that matches the key of the key-value pair you want to insert TableEntry. If found, the old value of the element is stored in oldValuethe. If none is found, by insertNewEntry(index, key) creating a TableEntryand added to the hash bucket oldValueis assigned the value NULL. To insert the key - value pair saved into a newly created or found TableEntry in. If the number of elements BasicHashTable exceeds the fRebuildSize size of the hash bucket expansion. Returns the old value of the element. BasicHashTable with lookup key to be inserted - the element matching key value pairs TableEntry are as follows: BasicHashTable::TableEntry* BasicHashTable ::lookupKey(char const* key, unsigned& index) const { TableEntry* entry; index = hashIndexFromKey(key); for (entry = fBuckets[index]; entry != NULL; entry = entry->fNext) { if (keyMatches(key, entry->key)) break; } return entry; } Boolean BasicHashTable ::keyMatches(char const* key1, char const* key2) const { // The way we check the keys for a match depends upon their type: if (fKeyType == STRING_HASH_KEYS) { return (strcmp(key1, key2) == 0); } else if (fKeyType == ONE_WORD_HASH_KEYS) { return (key1 == key2); } else { unsigned* k1 = (unsigned*)key1; unsigned* k2 = (unsigned*)key2; for (int i = 0; i lookupKey() First, by hashIndexFromKey(key) calculating the key based on a key on the hash value, and this value is mapped to the hash bucket capacity range, to give an index. Then based on the resulting index, find the element that matches the passed key. Here we can more clearly see the different types of HashTable differences between the different treatment lies in key ways. For STRING_HASH_KEYS type HashTable, the key is the content of the string pointed to by the incoming string pointer, while the ONE_WORD_HASH_KEYS type HashTable is the incoming string pointer itself. Calculate the final hash value and map the value to the hash bucket size range. The process of getting the index is as follows: unsigned randomIndex(uintptr_t i) const { return (unsigned)(((i*1103515245) >> fDownShift) & fMask); } insertNewEntry(index, key) Creating a TableEntry and added to the hash bucket is as follows: BasicHashTable::TableEntry* BasicHashTable ::insertNewEntry(unsigned index, char const* key) { TableEntry* entry = new TableEntry(); entry->fNext = fBuckets[index]; fBuckets[index] = entry; ++fNumEntries; assignKey(entry, key); return entry; } void BasicHashTable::assignKey(TableEntry* entry, char const* key) { // The way we assign the key depends upon its type: if (fKeyType == STRING_HASH_KEYS) { entry->key = strDup(key); } else if (fKeyType == ONE_WORD_HASH_KEYS) { entry->key = key; } else if (fKeyType > 0) { unsigned* keyFrom = (unsigned*)key; unsigned* keyTo = new unsigned[fKeyType]; for (int i = 0; i key = (char const*)keyTo; } } It can be seen that the process of insertion is mainly Create a TableEntry object and insert it into the head of the TableEntry element chain in the array of TableEntry pointers corresponding to the key. Increase the count of the number of elements in the container. Assign the passed key to the TableEntry. According to the HashTable different types of distribution keys in different ways. For the STRING_HASH_KEYS type HashTable, you need to copy the contents of the string pointed to by the incoming string pointer and assign it to TableEntry key. For the ONE_WORD_HASH_KEYS type HashTable, you need to assign the passed string pointer itself to the TableEntry key. For fKeyType the case of greater than 0, it is necessary before the contents of the string pointer to the incoming string (the sizeof (unsigned) fKeyType) copy byte, assigned to the TableEntry key. This kind of code is really scary, in case the incoming key string length is less than (sizeof(unsigned) fKeyType) bytes? . . . Contrast keyMatches() and assignKey() implementation of a function, not difficult to find, when the HashTable type fKeyType is greater than 0, and not ONE_WORD_HASH_KEYS when the required length of the string as a key-value pair in the hash table key is fixed to (sizeof (unsigned) * fKeyType) bytes. Then, look at the process of expanding the hash bucket in the BasicHashTable: void BasicHashTable::rebuild() { // Remember the existing table size: unsigned oldSize = fNumBuckets; TableEntry** oldBuckets = fBuckets; // Create the new sized table: fNumBuckets *= 4; fBuckets = new TableEntry*[fNumBuckets]; for (unsigned i = 0; i 0; --oldSize, ++oldChainPtr) { for (TableEntry* hPtr = *oldChainPtr; hPtr != NULL; hPtr = *oldChainPtr) { *oldChainPtr = hPtr->fNext; unsigned index = hashIndexFromKey(hPtr->key); hPtr->fNext = fBuckets[index]; fBuckets[index] = hPtr; } } // Free the old bucket array, if it was dynamically allocated: if (oldBuckets != fStaticBuckets) delete[] oldBuckets; } Here is, To fBuckets allocate a new memory, the capacity of the original 4-fold. Appropriately updated fNumBuckets, fRebuildSize, fDownShift and fMask so on. The older of fBuckets the elements, according to the elements keyand a new hash bucket capacity, moved to a new fBuckets medium. Old release according to the needs fBuckets of memory. 1.5. Find elements in the BasicHashTable Then look at the process of finding elements in the BasicHashTable: void* BasicHashTable::Lookup(char const* key) const { unsigned index; TableEntry* entry = lookupKey(key, index); if (entry == NULL) return NULL; // no such entry return entry->value; } This process is mainly based on key, by lookupKey() finds the corresponding elements TableEntry, and then returns its value. 1.6. Remove elements from BasicHashTable To see the process of removing elements from a BasicHashTable: Boolean BasicHashTable::Remove(char const* key) { unsigned index; TableEntry* entry = lookupKey(key, index); if (entry == NULL) return False; // no such entry deleteEntry(index, entry); return True; } . . . . . . void BasicHashTable::deleteEntry(unsigned index, TableEntry* entry) { TableEntry** ep = &fBuckets[index]; Boolean foundIt = False; while (*ep != NULL) { if (*ep == entry) { foundIt = True; *ep = entry->fNext; break; } ep = &((*ep)->fNext); } if (!foundIt) { // shouldn't happen #ifdef DEBUG fprintf(stderr, \"BasicHashTable[%p]::deleteEntry(%d,%p): internal error - not found (first entry %p\", this, index, entry, fBuckets[index]); if (fBuckets[index] != NULL) fprintf(stderr, \", next entry %p\", fBuckets[index]->fNext); fprintf(stderr, \")\\n\"); #endif } --fNumEntries; deleteKey(entry); delete entry; } void BasicHashTable::deleteKey(TableEntry* entry) { // The way we delete the key depends upon its type: if (fKeyType == ONE_WORD_HASH_KEYS) { entry->key = NULL; } else { delete[] (char*)entry->key; entry->key = NULL; } } The process of removing the element BasicHashTable, but also inevitably find the first element BasicHashTable after TableEntry in, found by deleteEntry() removing elements. In the deleteEntry() middle, from the first element BasicHashTable is removed out, and then by deleteKey() releasing the memory occupied key, then release the memory occupied TableEntry itself. Here TableEntry from the BasicHashTable removal of the out of use following this approach: TableEntry** ep = &fBuckets[index]; Boolean foundIt = False; while (*ep != NULL) { if (*ep == entry) { foundIt = True; *ep = entry->fNext; break; } ep = &((*ep)->fNext); } By traversing the linked list through the secondary pointer, the element is removed. I remember this is a way of writing inspired by Linus God in this scene. Deleting an element from a linked list, using several temporary variables, or adding a lot of judgments, is weak. 1.7. Traversing the BasicHashTable through Iterator You can use BasicHashTable defined Iterator to traverse it. The process is as follows: BasicHashTable::Iterator::Iterator(BasicHashTable const& table) : fTable(table), fNextIndex(0), fNextEntry(NULL) { } void* BasicHashTable::Iterator::next(char const*& key) { while (fNextEntry == NULL) { if (fNextIndex >= fTable.fNumBuckets) return NULL; fNextEntry = fTable.fBuckets[fNextIndex++]; } BasicHashTable::TableEntry* entry = fNextEntry; fNextEntry = entry->fNext; key = entry->key; return entry->value; } . . . . . . HashTable::Iterator* HashTable::Iterator::create(HashTable const& hashTable) { // \"hashTable\" is assumed to be a BasicHashTable return new BasicHashTable::Iterator((BasicHashTable const&)hashTable); } BasicHashTable Of fBuckets each element are stored a TableEntry linked list. Here we will traverse one by one. live555 definition HashTable content there is to it. 1.8. UsageEnvironment In live555, the UsageEnvironment class plays the role of a simple controller. In the UsageEnvironment module, the UsageEnvironment class is defined as follows: class TaskScheduler; // forward // An abstract base class, subclassed for each use of the library class UsageEnvironment { public: Boolean reclaim(); // returns True iff we were actually able to delete our object // task scheduler: TaskScheduler& taskScheduler() const {return fScheduler;} // result message handling: typedef char const* MsgString; virtual MsgString getResultMsg() const = 0; virtual void setResultMsg(MsgString msg) = 0; virtual void setResultMsg(MsgString msg1, MsgString msg2) = 0; virtual void setResultMsg(MsgString msg1, MsgString msg2, MsgString msg3) = 0; virtual void setResultErrMsg(MsgString msg, int err = 0) = 0; // like setResultMsg(), except that an 'errno' message is appended. (If \"err == 0\", the \"getErrno()\" code is used instead.) virtual void appendToResultMsg(MsgString msg) = 0; virtual void reportBackgroundError() = 0; // used to report a (previously set) error message within // a background event virtual void internalError(); // used to 'handle' a 'should not occur'-type error condition within the library. // 'errno' virtual int getErrno() const = 0; // 'console' output: virtual UsageEnvironment& operator UsageEnvironment Class holds TaskScheduler a reference, and providing a text output operation for outputting information, also provides other operation acquisition errno, the processing routine when the internal error occurs internalError(), and the destruction of their own operation. UsageEnvironment The class itself implements the following functions: Boolean UsageEnvironment::reclaim() { // We delete ourselves only if we have no remainining state: if (liveMediaPriv == NULL && groupsockPriv == NULL) { delete this; return True; } return False; } UsageEnvironment::UsageEnvironment(TaskScheduler& scheduler) : liveMediaPriv(NULL), groupsockPriv(NULL), fScheduler(scheduler) { } UsageEnvironment::~UsageEnvironment() { } // By default, we handle 'should not occur'-type library errors by calling abort(). Subclasses can redefine this, if desired. // (If your runtime library doesn't define the \"abort()\" function, then define your own (e.g., that does nothing).) void UsageEnvironment::internalError() { abort(); } These functions are relatively simple and will not be described here. UsageEnvironment Is an interface class, BasicUsageEnvironment module by two classes BasicUsageEnvironment and BasicUsageEnvironment0 provides one of its implementation. BasicUsageEnvironment0 The class provides an implementation of the set of functions that directly manipulate the string, which is defined as follows: class BasicUsageEnvironment0: public UsageEnvironment { public: // redefined virtual functions: virtual MsgString getResultMsg() const; virtual void setResultMsg(MsgString msg); virtual void setResultMsg(MsgString msg1, MsgString msg2); virtual void setResultMsg(MsgString msg1, MsgString msg2, MsgString msg3); virtual void setResultErrMsg(MsgString msg, int err = 0); virtual void appendToResultMsg(MsgString msg); virtual void reportBackgroundError(); protected: BasicUsageEnvironment0(TaskScheduler& taskScheduler); virtual ~BasicUsageEnvironment0(); private: void reset(); char fResultMsgBuffer[RESULT_MSG_BUFFER_MAX]; unsigned fCurBufferSize; unsigned fBufferMaxSize; }; This class defines a buffer with a size of RESULT_MSG_BUFFER_MAX. The implementation of the class is as follows: BasicUsageEnvironment0::BasicUsageEnvironment0(TaskScheduler& taskScheduler) : UsageEnvironment(taskScheduler), fBufferMaxSize(RESULT_MSG_BUFFER_MAX) { reset(); } BasicUsageEnvironment0::~BasicUsageEnvironment0() { } void BasicUsageEnvironment0::reset() { fCurBufferSize = 0; fResultMsgBuffer[fCurBufferSize] = '\\0'; } // Implementation of virtual functions: char const* BasicUsageEnvironment0::getResultMsg() const { return fResultMsgBuffer; } void BasicUsageEnvironment0::setResultMsg(MsgString msg) { reset(); appendToResultMsg(msg); } void BasicUsageEnvironment0::setResultMsg(MsgString msg1, MsgString msg2) { setResultMsg(msg1); appendToResultMsg(msg2); } void BasicUsageEnvironment0::setResultMsg(MsgString msg1, MsgString msg2, MsgString msg3) { setResultMsg(msg1, msg2); appendToResultMsg(msg3); } void BasicUsageEnvironment0::setResultErrMsg(MsgString msg, int err) { setResultMsg(msg); if (err == 0) err = getErrno(); . . . . . . appendToResultMsg(strerror(err)); #endif } void BasicUsageEnvironment0::appendToResultMsg(MsgString msg) { char* curPtr = &fResultMsgBuffer[fCurBufferSize]; unsigned spaceAvailable = fBufferMaxSize - fCurBufferSize; unsigned msgLength = strlen(msg); // Copy only enough of \"msg\" as will fit: if (msgLength > spaceAvailable-1) { msgLength = spaceAvailable-1; } memmove(curPtr, (char*)msg, msgLength); fCurBufferSize += msgLength; fResultMsgBuffer[fCurBufferSize] = '\\0'; } void BasicUsageEnvironment0::reportBackgroundError() { fputs(getResultMsg(), stderr); } This set of functions provides the ability to add incoming strings to the buffer and output the contents of the buffer to standard output. BasicUsageEnvironment The class provides the set of operators for outputting basic data types. The definition of this class is as follows: class BasicUsageEnvironment: public BasicUsageEnvironment0 { public: static BasicUsageEnvironment* createNew(TaskScheduler& taskScheduler); // redefined virtual functions: virtual int getErrno() const; virtual UsageEnvironment& operator The definition is relatively simple. Then look at its implementation: BasicUsageEnvironment::BasicUsageEnvironment(TaskScheduler& taskScheduler) : BasicUsageEnvironment0(taskScheduler) { . . . . . . } BasicUsageEnvironment::~BasicUsageEnvironment() { } BasicUsageEnvironment* BasicUsageEnvironment::createNew(TaskScheduler& taskScheduler) { return new BasicUsageEnvironment(taskScheduler); } int BasicUsageEnvironment::getErrno() const { #if defined(__WIN32__) || defined(_WIN32) || defined(_WIN32_WCE) return WSAGetLastError(); #else return errno; #endif } UsageEnvironment& BasicUsageEnvironment::operator BasicUsageEnvironment Class also provides a function to create a static object createNew() used to create BasicUsageEnvironment objects. For those implementations of the output operator, it is relatively straightforward. I feel that the live555 implementation of this set of I / O functions is not very good, the C + + standard library has a good implementation of these interfaces, but live555 does not seem to have the intention of introducing the C++ standard library. 1.9. TaskScheduler TaskScheduler is the task scheduler in live555, which implements the event loop for live555. In the UsageEnvironment module, the TaskScheduler class is defined as follows: typedef void TaskFunc(void* clientData); typedef void* TaskToken; typedef u_int32_t EventTriggerId; class TaskScheduler { public: virtual ~TaskScheduler(); virtual TaskToken scheduleDelayedTask(int64_t microseconds, TaskFunc* proc, void* clientData) = 0; // Schedules a task to occur (after a delay) when we next // reach a scheduling point. // (Does not delay if \"microseconds\" TaskScheduler The interfaces can be divided into the following groups: Schedule timer tasks. This includes scheduleDelayedTask(), unscheduleDelayedTask() and rescheduleDelayedTask() these functions, which are used to schedule a task delay, cancel a delayed task, and reschedule a delay task. Schedule Socket I/O processing operations in the background. This includes setBackgroundHandling(), disableBackgroundHandling(), moveSocketHandling(), turnOnBackgroundReadHandling() and turnOffBackgroundReadHandling() so that several functions are used to set, modify or cancel processing program on a particular socket I / O event. User event scheduling. This includes createEventTrigger(), deleteEventTrigger() and triggerEvent() so a few functions that are used to create, delete, and trigger a user-defined events. Execute the event loop. This a doEventLoop() complete function, which is usually the main loop of the program application. Internal error handler. This refers to the internalError() function for TaskScheduler an internal fault occurs, performs some processing. TaskScheduler The class itself provides an implementation of several simple functions: TaskScheduler::TaskScheduler() { } TaskScheduler::~TaskScheduler() { } void TaskScheduler::rescheduleDelayedTask(TaskToken& task, int64_t microseconds, TaskFunc* proc, void* clientData) { unscheduleDelayedTask(task); task = scheduleDelayedTask(microseconds, proc, clientData); } // By default, we handle 'should not occur'-type library errors by calling abort(). Subclasses can redefine this, if desired. void TaskScheduler::internalError() { abort(); } They are simple and easy to understand, so I won't go into details here. TaskScheduler The implementation of the interface is also provided in the BasicUsageEnvironment module . And UsageEnvironment the case is similar to the interface, TaskScheduler an interface, implemented by the same two classes, respectively BasicTaskScheduler, and BasicTaskScheduler0 wherein BasicTaskScheduler0 classes implement Group 1, Group 3 interface, and we mentioned earlier doEventLoop() frame, and BasicTaskScheduler is used to implement the second group interface and implement doEventLoop() the event loop the loop. BasicTaskScheduler0 The class is defined as follows: class HandlerSet; // forward #define MAX_NUM_EVENT_TRIGGERS 32 // An abstract base class, useful for subclassing // (e.g., to redefine the implementation of socket event handling) class BasicTaskScheduler0: public TaskScheduler { public: virtual ~BasicTaskScheduler0(); virtual void SingleStep(unsigned maxDelayTime = 0) = 0; // \"maxDelayTime\" is in microseconds. It allows a subclass to impose a limit // on how long \"select()\" can delay, in case it wants to also do polling. // 0 (the default value) means: There's no maximum; just look at the delay queue public: // Redefined virtual functions: virtual TaskToken scheduleDelayedTask(int64_t microseconds, TaskFunc* proc, void* clientData); virtual void unscheduleDelayedTask(TaskToken& prevTask); virtual void doEventLoop(char volatile* watchVariable); virtual EventTriggerId createEventTrigger(TaskFunc* eventHandlerProc); virtual void deleteEventTrigger(EventTriggerId eventTriggerId); virtual void triggerEvent(EventTriggerId eventTriggerId, void* clientData = NULL); protected: BasicTaskScheduler0(); protected: // To implement delayed operations: DelayQueue fDelayQueue; // To implement background reads: HandlerSet* fHandlers; int fLastHandledSocketNum; // To implement event triggers: EventTriggerId volatile fTriggersAwaitingHandling; // implemented as a 32-bit bitmap EventTriggerId fLastUsedTriggerMask; // implemented as a 32-bit bitmap TaskFunc* fTriggeredEventHandlers[MAX_NUM_EVENT_TRIGGERS]; void* fTriggeredEventClientDatas[MAX_NUM_EVENT_TRIGGERS]; unsigned fLastUsedTriggerNum; // in the range [0,MAX_NUM_EVENT_TRIGGERS) }; BasicTaskScheduler0 Class member function, basically inherited from TaskScheduler class, it is to realize that part of the interface functions, but it adds a new virtual function SingleStep(), for let subclasses override, to achieve a single event loop iteration. BasicTaskScheduler0 Class member variables is clearly divided into three groups: fDelayQueue to implement a timer operation; fHandlers and fLastHandledSocketNum for implementing the Socket I / O event processing operation; fTriggersAwaitingHandling, fLastUsedTriggerMask, fTriggeredEventHandlers, fTriggeredEventClientDatas, and fLastUsedTriggerNum for implementing a user event. For fHandlers and fLastHandledSocketNum, in fact, feel no need to BasicTaskScheduler0 define the class. Throughout the BasicTaskScheduler0 class of the entire implementation, in addition to the initialization these two member variables, there is no other access operations. From the functions of the two variables, it is not in BasicTaskScheduler0 the range of duty class. These two variables actually feel in BasicTaskScheduler class a little more appropriate. BasicTaskScheduler0 The class object creation and destruction process is as follows: BasicTaskScheduler0::BasicTaskScheduler0() : fLastHandledSocketNum(-1), fTriggersAwaitingHandling(0), fLastUsedTriggerMask(1), fLastUsedTriggerNum(MAX_NUM_EVENT_TRIGGERS-1) { fHandlers = new HandlerSet; for (unsigned i = 0; i During the creation of a class object, member objects are created and/or initialized, and when the object is destroyed, the member objects are destroyed. 1.10. Representation of time In the BasicUsageEnvironment live555 module, with Timeval the class to describe time, and use DelayInterval described delay time. The definitions of these two classes are as follows: class Timeval { public: time_base_seconds seconds() const { return fTv.tv_sec; } time_base_seconds seconds() { return fTv.tv_sec; } time_base_seconds useconds() const { return fTv.tv_usec; } time_base_seconds useconds() { return fTv.tv_usec; } int operator>=(Timeval const& arg2) const; int operator= *this; } int operator= arg2); } int operator>(Timeval const& arg2) const { return arg2 = arg2 && arg2 >= *this; } int operator!=(Timeval const& arg2) const { return !(*this == arg2); } void operator+=(class DelayInterval const& arg2); void operator-=(class DelayInterval const& arg2); // returns ZERO iff arg2 >= arg1 protected: Timeval(time_base_seconds seconds, time_base_seconds useconds) { fTv.tv_sec = seconds; fTv.tv_usec = useconds; } private: time_base_seconds& secs() { return (time_base_seconds&)fTv.tv_sec; } time_base_seconds& usecs() { return (time_base_seconds&)fTv.tv_usec; } struct timeval fTv; }; . . . . . . class DelayInterval: public Timeval { public: DelayInterval(time_base_seconds seconds, time_base_seconds useconds) : Timeval(seconds, useconds) {} }; DelayInterval Class is basically Timeval like an alias, but the reason why such a redefinition of class, probably mainly for readability maintain it. Timeval Standard class library storage time of struct timeval storage time value of the structure, but by the operator overloading, a number of operator functions convenient operation time value. The implementation of the operator function defined as a member function is as follows: int Timeval::operator>=(const Timeval& arg2) const { return seconds() > arg2.seconds() || (seconds() == arg2.seconds() && useconds() >= arg2.useconds()); } void Timeval::operator+=(const DelayInterval& arg2) { secs() += arg2.seconds(); usecs() += arg2.useconds(); if (useconds() >= MILLION) { usecs() -= MILLION; ++secs(); } } void Timeval::operator-=(const DelayInterval& arg2) { secs() -= arg2.seconds(); usecs() -= arg2.useconds(); if ((int)useconds() The implementation of these operator functions is relatively straightforward. In addition to these operators defined by member operator functions, the operators of these non-member functions are also included: #ifndef max inline Timeval max(Timeval const& arg1, Timeval const& arg2) { return arg1 >= arg2 ? arg1 : arg2; } #endif #ifndef min inline Timeval min(Timeval const& arg1, Timeval const& arg2) { return arg1 Their implementation is also relatively straightforward. 1.11. Deferred task representation and organization In the BasicUsageEnvironment live555 module, with DelayQueueEntry class represents a delay task. The class is defined as follows: class DelayQueueEntry { public: virtual ~DelayQueueEntry(); intptr_t token() { return fToken; } protected: // abstract base class DelayQueueEntry(DelayInterval delay); virtual void handleTimeout(); private: friend class DelayQueue; DelayQueueEntry* fNext; DelayQueueEntry* fPrev; DelayInterval fDeltaTimeRemaining; intptr_t fToken; static intptr_t tokenCounter; }; Delay tasks identified by token, token when the object is created, by means of global tokenCounter production. fDeltaTimeRemaining Used to indicate the interval between the time that the delayed task needs to be executed and the current time. Made fNext and fPrev not difficult to guess, it is doubly linked list in BasicUsageEnvironment module to organize delayed tasks. handleTimeout() A function is the body of a deferred task and needs to be implemented by a concrete subclass. DelayQueueEntry The specific implementation of the class is as follows: intptr_t DelayQueueEntry::tokenCounter = 0; DelayQueueEntry::DelayQueueEntry(DelayInterval delay) : fDeltaTimeRemaining(delay) { fNext = fPrev = this; fToken = ++tokenCounter; } DelayQueueEntry::~DelayQueueEntry() { } void DelayQueueEntry::handleTimeout() { delete this; } BasicUsageEnvironment modules actually used AlarmHandler to describe the delayed tasks, which are defined as follows: class AlarmHandler: public DelayQueueEntry { public: AlarmHandler(TaskFunc* proc, void* clientData, DelayInterval timeToDelay) : DelayQueueEntry(timeToDelay), fProc(proc), fClientData(clientData) { } private: // redefined virtual functions virtual void handleTimeout() { (*fProc)(fClientData); DelayQueueEntry::handleTimeout(); } private: TaskFunc* fProc; void* fClientData; }; BasicUsageEnvironment need modules DelayQueueEntry represent classes and delay the task organization, whereas in the interface layer, i.e. TaskScheduler in the through TaskFunc represented delay data pointer and user tasks. AlarmHandler Assist in the conversion of the structure of the interface to the implementation of the structure. BasicUsageEnvironment module uses DelayQueue the DelayQueueEntry organized as a doubly linked list, the class is defined as follows: class DelayQueue: public DelayQueueEntry { public: DelayQueue(); virtual ~DelayQueue(); void addEntry(DelayQueueEntry* newEntry); // returns a token for the entry void updateEntry(DelayQueueEntry* entry, DelayInterval newDelay); void updateEntry(intptr_t tokenToFind, DelayInterval newDelay); void removeEntry(DelayQueueEntry* entry); // but doesn't delete it DelayQueueEntry* removeEntry(intptr_t tokenToFind); // but doesn't delete it DelayInterval const& timeToNextAlarm(); void handleAlarm(); private: DelayQueueEntry* head() { return fNext; } DelayQueueEntry* findEntryByToken(intptr_t token); void synchronize(); // bring the 'time remaining' fields up-to-date _EventTime fLastSyncTime; };s First look at the `DelayQueue` class object construction and destruction process: DelayQueue::DelayQueue() : DelayQueueEntry(ETERNITY) { fLastSyncTime = TimeNow(); } DelayQueue::~DelayQueue() { while (fNext != this) { DelayQueueEntry* entryToRemove = fNext; removeEntry(entryToRemove); delete entryToRemove; } } Then take a look at the process of adding elements to the list: void DelayQueue::addEntry(DelayQueueEntry* newEntry) { synchronize(); DelayQueueEntry* cur = head(); while (newEntry->fDeltaTimeRemaining >= cur->fDeltaTimeRemaining) { newEntry->fDeltaTimeRemaining -= cur->fDeltaTimeRemaining; cur = cur->fNext; } cur->fDeltaTimeRemaining -= newEntry->fDeltaTimeRemaining; // Add \"newEntry\" to the queue, just before \"cur\": newEntry->fNext = cur; newEntry->fPrev = cur->fPrev; cur->fPrev = newEntry->fPrev->fNext = newEntry; } . . . . . . void DelayQueue::synchronize() { // First, figure out how much time has elapsed since the last sync: _EventTime timeNow = TimeNow(); if (timeNow = curEntry->fDeltaTimeRemaining) { timeSinceLastSync -= curEntry->fDeltaTimeRemaining; curEntry->fDeltaTimeRemaining = DELAY_ZERO; curEntry = curEntry->fNext; } curEntry->fDeltaTimeRemaining -= timeSinceLastSync; } With these two functions, can be more clearly seen in DelayQueue the organization is how delayed tasks. DelayQueue Because it is one in itself DelayQueueEntry, it is actually a circular doubly linked list. It fNext points to the head of the logical linked list element, but it is itself trailing elements of this list. Each element of the doubly linked list fDeltaTimeRemaining stored is a time point that the task should be scheduled for execution, the task that precedes it should be a difference between the scheduled time point of execution when the value is 0, it indicates that The task needs to be executed. This means that it DelayQueue is a bidirectional circular ordered list, arranged in order of the required execution time. removeEntry() Used to remove a task from a doubly linked list: void DelayQueue::removeEntry(DelayQueueEntry* entry) { if (entry == NULL || entry->fNext == NULL) return; entry->fNext->fDeltaTimeRemaining += entry->fDeltaTimeRemaining; entry->fPrev->fNext = entry->fNext; entry->fNext->fPrev = entry->fPrev; entry->fNext = entry->fPrev = NULL; // in case we should try to remove it again } DelayQueueEntry* DelayQueue::removeEntry(intptr_t tokenToFind) { DelayQueueEntry* entry = findEntryByToken(tokenToFind); removeEntry(entry); return entry; } . . . . . . DelayQueueEntry* DelayQueue::findEntryByToken(intptr_t tokenToFind) { DelayQueueEntry* cur = head(); while (cur != this) { if (cur->token() == tokenToFind) return cur; cur = cur->fNext; } return NULL; } removeEntry(DelayQueueEntry* entry) In, in entry->fNext == NULL a direct return to the establishment, but also because DelayQueue actually a two-way circular linked list sake. DelayQueue An interface for updating the execution time of delayed tasks is also provided: void DelayQueue::updateEntry(DelayQueueEntry* entry, DelayInterval newDelay) { if (entry == NULL) return; removeEntry(entry); entry->fDeltaTimeRemaining = newDelay; addEntry(entry); } void DelayQueue::updateEntry(intptr_t tokenToFind, DelayInterval newDelay) { DelayQueueEntry* entry = findEntryByToken(tokenToFind); updateEntry(entry, newDelay); } Further, timeToNextAlarm() for calculating the time of the most recent execution of a task, and handleAlarm() is used to perform this task. DelayInterval const& DelayQueue::timeToNextAlarm() { if (head()->fDeltaTimeRemaining == DELAY_ZERO) return DELAY_ZERO; // a common case synchronize(); return head()->fDeltaTimeRemaining; } void DelayQueue::handleAlarm() { if (head()->fDeltaTimeRemaining != DELAY_ZERO) synchronize(); if (head()->fDeltaTimeRemaining == DELAY_ZERO) { // This event is due to be handled: DelayQueueEntry* toRemove = head(); removeEntry(toRemove); // do this first, in case handler accesses queue toRemove->handleTimeout(); } } 1.12. Delayed task scheduling After seeing the representation of time in the live555's BasicUsageEnvironment module, and the representation and organization of the delayed task, look at the scheduling of the delayed task. BasicTaskScheduler0 Classes scheduleDelayedTask() and unscheduleDelayedTask() implemented timer task scheduling function, respectively, and for scheduling a task to cancel a delay of the delay task, they are implemented as follows: TaskToken BasicTaskScheduler0::scheduleDelayedTask(int64_t microseconds, TaskFunc* proc, void* clientData) { if (microseconds token()); } void BasicTaskScheduler0::unscheduleDelayedTask(TaskToken& prevTask) { DelayQueueEntry* alarmHandler = fDelayQueue.removeEntry((intptr_t)prevTask); prevTask = NULL; delete alarmHandler; } Task scheduling delay is the delay into the task DelayQueue, the task is delayed and canceled, the task from DelayQueue the removal of. Let's look at the process of delaying the execution of the task. 1.13. User event task scheduling The user event task dispatch interface allows the caller to create a task and trigger the task to execute in the event loop. This set of interfaces mainly includes such a few: createEventTrigger(), deleteEventTrigger() and triggerEvent(), they are used to create tasks, delete tasks, and trigger task execution. The implementation of these interfaces is as follows: EventTriggerId BasicTaskScheduler0::createEventTrigger(TaskFunc* eventHandlerProc) { unsigned i = fLastUsedTriggerNum; EventTriggerId mask = fLastUsedTriggerMask; do { i = (i+1)%MAX_NUM_EVENT_TRIGGERS; mask >>= 1; if (mask == 0) mask = 0x80000000; if (fTriggeredEventHandlers[i] == NULL) { // This trigger number is free; use it: fTriggeredEventHandlers[i] = eventHandlerProc; fTriggeredEventClientDatas[i] = NULL; // sanity fLastUsedTriggerMask = mask; fLastUsedTriggerNum = i; return mask; } } while (i != fLastUsedTriggerNum); // All available event triggers are allocated; return 0 instead: return 0; } void BasicTaskScheduler0::deleteEventTrigger(EventTriggerId eventTriggerId) { fTriggersAwaitingHandling &=~ eventTriggerId; if (eventTriggerId == fLastUsedTriggerMask) { // common-case optimization: fTriggeredEventHandlers[fLastUsedTriggerNum] = NULL; fTriggeredEventClientDatas[fLastUsedTriggerNum] = NULL; } else { // \"eventTriggerId\" should have just one bit set. // However, we do the reasonable thing if the user happened to 'or' together two or more \"EventTriggerId\"s: EventTriggerId mask = 0x80000000; for (unsigned i = 0; i >= 1; } } } void BasicTaskScheduler0::triggerEvent(EventTriggerId eventTriggerId, void* clientData) { // First, record the \"clientData\". (Note that we allow \"eventTriggerId\" to be a combination of bits for multiple events.) EventTriggerId mask = 0x80000000; for (unsigned i = 0; i >= 1; } // Then, note this event as being ready to be handled. // (Note that because this function (unlike others in the library) can be called from an external thread, we do this last, to // reduce the risk of a race condition.) fTriggersAwaitingHandling |= eventTriggerId; } BasicTaskScheduler0 Of fTriggeredEventHandlers and fTriggeredEventClientDatas user data for saving mission itself, which are the main task of preservation function, as well as passing when performing tasks. They are all arrays, each task occupies one element, and the elements at the same index belong to the same task. The length of the array MAX_NUM_EVENT_TRIGGERS is 32, which means that the maximum number of tasks that can be created is 32. fTriggersAwaitingHandling Used to record which tasks are currently triggered. The trigger state of each task corresponds to one of the bits. When the corresponding position is 1, it indicates that the task is triggered and needs to be executed; otherwise, it does not need to be executed. For example, fTriggeredEventHandlers and fTriggeredEventClientDatas trigger status of the task 0 in the index corresponds to fTriggersAwaitingHandling the highest level, triggering state of the task at index 1, corresponding to the next high level, and so on. Create a task, that is, in fTriggeredEventHandlers and fTriggeredEventClientDatas for the task to find a free position, the preserved body of the function pointer of the task, the task of the index returned in fTriggersAwaitingHandling the mask corresponding bit in, as a task of identification. fLastUsedTriggerNum To prevent traverse fTriggeredEventHandlers an infinite loop when looking. Delete a task that is to remove all data-related tasks, including resetting fTriggersAwaitingHandlingtrigger state, as well as fTriggeredEventHandlers and fTriggeredEventClientDatas the main function pointer and user data in the task. Task trigger event is set for the task in fTriggersAwaitingHandling the corresponding position, and set the task data. The actual execution of the task also needs to be performed in the event loop. 1.14. Event loop execution framework BasicTaskScheduler0 Performed by the event loop doEventLoop() complete function, specifically implemented as follows: void BasicTaskScheduler0::doEventLoop(char volatile* watchVariable) { // Repeatedly loop, handling readble sockets and timed events: while (1) { if (watchVariable != NULL && *watchVariable != 0) break; SingleStep(); } } The main special concern is the incoming parameters watchVariable: the caller can use this parameter to control outside the event loop and when the event loop ends. 1.15. Socket I/O event description and its organization BasicUsageEnvironment module, with a HandlerDescriptor description of the processing procedures of the event and the event occurred to listening socket, the class is defined as follows: class HandlerDescriptor { HandlerDescriptor(HandlerDescriptor* nextHandler); virtual ~HandlerDescriptor(); public: int socketNum; int conditionSet; TaskScheduler::BackgroundHandlerProc* handlerProc; void* clientData; private: // Descriptors are linked together in a doubly-linked list: friend class HandlerSet; friend class HandlerIterator; HandlerDescriptor* fNextHandler; HandlerDescriptor* fPrevHandler; }; socketNum For the socket to be listened to, conditionSet describe the event on the socket to be listened to handlerProc, the handler when the event occurs, and clientData the user data passed to the event handler. While fNextHandler and then used to HandlerDescriptor organize. Not difficult to guess, BasicUsageEnvironment module HandlerDescriptor is to be organized as a doubly linked list. HandlerDescriptor The implementation of the class is as follows: HandlerDescriptor::HandlerDescriptor(HandlerDescriptor* nextHandler) : conditionSet(0), handlerProc(NULL) { // Link this descriptor into a doubly-linked list: if (nextHandler == this) { // initialization fNextHandler = fPrevHandler = this; } else { fNextHandler = nextHandler; fPrevHandler = nextHandler->fPrevHandler; nextHandler->fPrevHandler = this; fPrevHandler->fNextHandler = this; } } HandlerDescriptor::~HandlerDescriptor() { // Unlink this descriptor from a doubly-linked list: fNextHandler->fPrevHandler = fPrevHandler; fPrevHandler->fNextHandler = fNextHandler; } BasicUsageEnvironment module, used HandlerSet to maintain all HandlerDescriptor, class definition as follows: class HandlerSet { public: HandlerSet(); virtual ~HandlerSet(); void assignHandler(int socketNum, int conditionSet, TaskScheduler::BackgroundHandlerProc* handlerProc, void* clientData); void clearHandler(int socketNum); void moveHandler(int oldSocketNum, int newSocketNum); private: HandlerDescriptor* lookupHandler(int socketNum); private: friend class HandlerIterator; HandlerDescriptor fHandlers; }; HandlerSet/HandlerDescriptor Design with DelayQueue/DelayQueueEntry design is very similar.HandlerSet The implementation is as follows: HandlerSet::HandlerSet() : fHandlers(&fHandlers) { fHandlers.socketNum = -1; // shouldn't ever get looked at, but in case... } HandlerSet::~HandlerSet() { // Delete each handler descriptor: while (fHandlers.fNextHandler != &fHandlers) { delete fHandlers.fNextHandler; // changes fHandlers->fNextHandler } } void HandlerSet ::assignHandler(int socketNum, int conditionSet, TaskScheduler::BackgroundHandlerProc* handlerProc, void* clientData) { // First, see if there's already a handler for this socket: HandlerDescriptor* handler = lookupHandler(socketNum); if (handler == NULL) { // No existing handler, so create a new descr: handler = new HandlerDescriptor(fHandlers.fNextHandler); handler->socketNum = socketNum; } handler->conditionSet = conditionSet; handler->handlerProc = handlerProc; handler->clientData = clientData; } void HandlerSet::clearHandler(int socketNum) { HandlerDescriptor* handler = lookupHandler(socketNum); delete handler; } void HandlerSet::moveHandler(int oldSocketNum, int newSocketNum) { HandlerDescriptor* handler = lookupHandler(oldSocketNum); if (handler != NULL) { handler->socketNum = newSocketNum; } } HandlerDescriptor* HandlerSet::lookupHandler(int socketNum) { HandlerDescriptor* handler; HandlerIterator iter(*this); while ((handler = iter.next()) != NULL) { if (handler->socketNum == socketNum) break; } return handler; } HandlerSet Similarly, it is designed as a HandlerDescriptor two-way circulation list, but there is no significance to the order in which the elements. The BasicUsageEnvironment module also provides an iteratorHandlerIterator for traversal HandlerSet, which is defined and implemented as follows: class HandlerIterator { public: HandlerIterator(HandlerSet& handlerSet); virtual ~HandlerIterator(); HandlerDescriptor* next(); // returns NULL if none void reset(); private: HandlerSet& fOurSet; HandlerDescriptor* fNextPtr; }; ///////////////////////////////////// Implementation HandlerIterator::HandlerIterator(HandlerSet& handlerSet) : fOurSet(handlerSet) { reset(); } HandlerIterator::~HandlerIterator() { } void HandlerIterator::reset() { fNextPtr = fOurSet.fHandlers.fNextHandler; } HandlerDescriptor* HandlerIterator::next() { HandlerDescriptor* result = fNextPtr; if (result == &fOurSet.fHandlers) { // no more result = NULL; } else { fNextPtr = fNextPtr->fNextHandler; } return result; } In summary, you can listen to events on each socket, and executes the handler when an event occurs, the event listener on the socket and the event handler from the HandlerDescriptor description; all HandlerDescriptor by the HandlerSet organization as a two-way circular list, actually between elements The order has no meaning, and the newly added elements are placed in the logical head of the linked list. 1.16. Socket I/O event processing task scheduling Socket I / O event processing task scheduling are BasicTaskScheduler completed class, this class definition is as follows: class BasicTaskScheduler: public BasicTaskScheduler0 { public: static BasicTaskScheduler* createNew(unsigned maxSchedulerGranularity = 10000/*microseconds*/); virtual ~BasicTaskScheduler(); protected: BasicTaskScheduler(unsigned maxSchedulerGranularity); // called only by \"createNew()\" static void schedulerTickTask(void* clientData); void schedulerTickTask(); protected: // Redefined virtual functions: virtual void SingleStep(unsigned maxDelayTime); virtual void setBackgroundHandling(int socketNum, int conditionSet, BackgroundHandlerProc* handlerProc, void* clientData); virtual void moveSocketHandling(int oldSocketNum, int newSocketNum); protected: // To implement background reads: HandlerSet* fHandlers; int fLastHandledSocketNum; unsigned fMaxSchedulerGranularity; // To implement background operations: int fMaxNumSockets; fd_set fReadSet; fd_set fWriteSet; fd_set fExceptionSet; . . . . . . }; fHandlers For the organization HandlerDescriptor, fReadSet, fWriteSet, fExceptionSet and fMaxNumSockets mainly in order to adapt select() the interface, it is used to describe the event to listen for its readable, writable event, socket set of unusual events, as well as to listen socket in socket number of the largest. Socket I / O event processing task scheduling by setBackgroundHandling() and moveSocketHandling() two complete functions, they are implemented as follows: void BasicTaskScheduler ::setBackgroundHandling(int socketNum, int conditionSet, BackgroundHandlerProc* handlerProc, void* clientData) { if (socketNum = (int)(FD_SETSIZE)) return; #endif FD_CLR((unsigned)socketNum, &fReadSet); FD_CLR((unsigned)socketNum, &fWriteSet); FD_CLR((unsigned)socketNum, &fExceptionSet); if (conditionSet == 0) { fHandlers->clearHandler(socketNum); if (socketNum+1 == fMaxNumSockets) { --fMaxNumSockets; } } else { fHandlers->assignHandler(socketNum, conditionSet, handlerProc, clientData); if (socketNum+1 > fMaxNumSockets) { fMaxNumSockets = socketNum+1; } if (conditionSet&SOCKET_READABLE) FD_SET((unsigned)socketNum, &fReadSet); if (conditionSet&SOCKET_WRITABLE) FD_SET((unsigned)socketNum, &fWriteSet); if (conditionSet&SOCKET_EXCEPTION) FD_SET((unsigned)socketNum, &fExceptionSet); } } void BasicTaskScheduler::moveSocketHandling(int oldSocketNum, int newSocketNum) { if (oldSocketNum = (int)(FD_SETSIZE) || newSocketNum >= (int)(FD_SETSIZE)) return; // sanity check #endif if (FD_ISSET(oldSocketNum, &fReadSet)) {FD_CLR((unsigned)oldSocketNum, &fReadSet); FD_SET((unsigned)newSocketNum, &fReadSet);} if (FD_ISSET(oldSocketNum, &fWriteSet)) {FD_CLR((unsigned)oldSocketNum, &fWriteSet); FD_SET((unsigned)newSocketNum, &fWriteSet);} if (FD_ISSET(oldSocketNum, &fExceptionSet)) {FD_CLR((unsigned)oldSocketNum, &fExceptionSet); FD_SET((unsigned)newSocketNum, &fExceptionSet);} fHandlers->moveHandler(oldSocketNum, newSocketNum); if (oldSocketNum+1 == fMaxNumSockets) { --fMaxNumSockets; } if (newSocketNum+1 > fMaxNumSockets) { fMaxNumSockets = newSocketNum+1; } } For setBackgroundHandling(), when conditionSet is a non-zero value, updated or new listen for a specific socket; is 0, the listening socket will clear. moveSocketHandling() Update the listener for socket events. BasicTaskScheduler The SingleStep() realization of a single event loop iteration: void BasicTaskScheduler::SingleStep(unsigned maxDelayTime) { fd_set readSet = fReadSet; // make a copy for this select() call fd_set writeSet = fWriteSet; // ditto fd_set exceptionSet = fExceptionSet; // ditto DelayInterval const& timeToDelay = fDelayQueue.timeToNextAlarm(); struct timeval tv_timeToDelay; tv_timeToDelay.tv_sec = timeToDelay.seconds(); tv_timeToDelay.tv_usec = timeToDelay.useconds(); // Very large \"tv_sec\" values cause select() to fail. // Don't make it any larger than 1 million seconds (11.5 days) const long MAX_TV_SEC = MILLION; if (tv_timeToDelay.tv_sec > MAX_TV_SEC) { tv_timeToDelay.tv_sec = MAX_TV_SEC; } // Also check our \"maxDelayTime\" parameter (if it's > 0): if (maxDelayTime > 0 && (tv_timeToDelay.tv_sec > (long)maxDelayTime/MILLION || (tv_timeToDelay.tv_sec == (long)maxDelayTime/MILLION && tv_timeToDelay.tv_usec > (long)maxDelayTime%MILLION))) { tv_timeToDelay.tv_sec = maxDelayTime/MILLION; tv_timeToDelay.tv_usec = maxDelayTime%MILLION; } int selectResult = select(fMaxNumSockets, &readSet, &writeSet, &exceptionSet, &tv_timeToDelay); if (selectResult = 0) closeSocket(fDummySocketNum); fDummySocketNum = socket(AF_INET, SOCK_DGRAM, 0); FD_SET((unsigned)fDummySocketNum, &fReadSet); } if (err != EINTR) { #else if (errno != EINTR && errno != EAGAIN) { #endif // Unexpected error - treat this as fatal: #if !defined(_WIN32_WCE) perror(\"BasicTaskScheduler::SingleStep(): select() fails\"); // Because this failure is often \"Bad file descriptor\" - which is caused by an invalid socket number (i.e., a socket number // that had already been closed) being used in \"select()\" - we print out the sockets that were being used in \"select()\", // to assist in debugging: fprintf(stderr, \"socket numbers used in the select() call:\"); for (int i = 0; i = 0) { while ((handler = iter.next()) != NULL) { if (handler->socketNum == fLastHandledSocketNum) break; } if (handler == NULL) { fLastHandledSocketNum = -1; iter.reset(); // start from the beginning instead } } while ((handler = iter.next()) != NULL) { int sock = handler->socketNum; // alias int resultConditionSet = 0; if (FD_ISSET(sock, &readSet) && FD_ISSET(sock, &fReadSet)/*sanity check*/) resultConditionSet |= SOCKET_READABLE; if (FD_ISSET(sock, &writeSet) && FD_ISSET(sock, &fWriteSet)/*sanity check*/) resultConditionSet |= SOCKET_WRITABLE; if (FD_ISSET(sock, &exceptionSet) && FD_ISSET(sock, &fExceptionSet)/*sanity check*/) resultConditionSet |= SOCKET_EXCEPTION; if ((resultConditionSet&handler->conditionSet) != 0 && handler->handlerProc != NULL) { fLastHandledSocketNum = sock; // Note: we set \"fLastHandledSocketNum\" before calling the handler, // in case the handler calls \"doEventLoop()\" reentrantly. (*handler->handlerProc)(handler->clientData, resultConditionSet); break; } } if (handler == NULL && fLastHandledSocketNum >= 0) { // We didn't call a handler, but we didn't get to check all of them, // so try again from the beginning: iter.reset(); while ((handler = iter.next()) != NULL) { int sock = handler->socketNum; // alias int resultConditionSet = 0; if (FD_ISSET(sock, &readSet) && FD_ISSET(sock, &fReadSet)/*sanity check*/) resultConditionSet |= SOCKET_READABLE; if (FD_ISSET(sock, &writeSet) && FD_ISSET(sock, &fWriteSet)/*sanity check*/) resultConditionSet |= SOCKET_WRITABLE; if (FD_ISSET(sock, &exceptionSet) && FD_ISSET(sock, &fExceptionSet)/*sanity check*/) resultConditionSet |= SOCKET_EXCEPTION; if ((resultConditionSet&handler->conditionSet) != 0 && handler->handlerProc != NULL) { fLastHandledSocketNum = sock; // Note: we set \"fLastHandledSocketNum\" before calling the handler, // in case the handler calls \"doEventLoop()\" reentrantly. (*handler->handlerProc)(handler->clientData, resultConditionSet); break; } } if (handler == NULL) fLastHandledSocketNum = -1;//because we didn't call a handler } // Also handle any newly-triggered event (Note that we do this *after* calling a socket handler, // in case the triggered event handler modifies The set of readable sockets.) if (fTriggersAwaitingHandling != 0) { if (fTriggersAwaitingHandling == fLastUsedTriggerMask) { // Common-case optimization for a single event trigger: fTriggersAwaitingHandling &=~ fLastUsedTriggerMask; if (fTriggeredEventHandlers[fLastUsedTriggerNum] != NULL) { (*fTriggeredEventHandlers[fLastUsedTriggerNum])(fTriggeredEventClientDatas[fLastUsedTriggerNum]); } } else { // Look for an event trigger that needs handling (making sure that we make forward progress through all possible triggers): unsigned i = fLastUsedTriggerNum; EventTriggerId mask = fLastUsedTriggerMask; do { i = (i+1)%MAX_NUM_EVENT_TRIGGERS; mask >>= 1; if (mask == 0) mask = 0x80000000; if ((fTriggersAwaitingHandling&mask) != 0) { fTriggersAwaitingHandling &=~ mask; if (fTriggeredEventHandlers[i] != NULL) { (*fTriggeredEventHandlers[i])(fTriggeredEventClientDatas[i]); } fLastUsedTriggerMask = mask; fLastUsedTriggerNum = i; break; } } while (i != fLastUsedTriggerNum); } } // Also handle any delayed event that may have come due. fDelayQueue.handleAlarm(); } This function is a bit long, but is clearly divided into the following sections: According to the timer task list, the point in time from the current time needed to perform the task as well as the recent passing of the maximum delay time, calculate select() the maximum amount of time to be able to wait. Execution select() latency on the socket. select() When a timeout or an I/O event on a socket arrives, the I/O event handler for the socket where the I/O event occurred is first executed. This function executes at most one I/O handler on the socket at a time. Execute a user event handler. Also perform at most one at a time. The timer task is executed, and the same one is executed at a time. The basics of live555 are basically that. Reward Done. 1.17. Live555 source code analysis series Live555 Source code analysis: Introduction live555 Source code analysis: Infrastructure live555 Source code analysis: MediaSever Wireshark capture packet analysis RTSP/RTP/RTCP Basic working process live555 Source code analysis: RTSPServer live555 Source code analysis: DESCRIBE processing live555 Source code analysis: SETUP processing live555 Source code analysis :PLAY processing live555 Source code analysis: RTSPServer component structure live555 Source code analysis: ServerMediaSession live555 Source code analysis: sub-session SDP line generation live555 Source code analysis: sub-session SETUP live555 Source code analysis: play start "},"Live555 - Live555 source code analysis_mediaserver.html":{"url":"Live555 - Live555 source code analysis_mediaserver.html","title":"Live555 - Live555 source code analysis_mediaserver","keywords":"","body":"1. Live555 Source code analysis: MediaSever1.1. Server socket creation and connection establishment1.2. Live555 source code analysis series1. Live555 Source code analysis: MediaSever Posted on 2017-08-31 | In live555 Live555 Source code analysis: MediaSever Server socket creation and connection establishment Live555 source code analysis series Located in the mediaServer directory of the live555 project is \"LIVE555 Media Server\", which is a complete RTSP server application. It can turn a variety of media files into a stream and provide them to the requester. Let's take a look at the implementation of \"LIVE555 Media Server\". Aside from the code in which the application information is output to the terminal, the code of the \"LIVE555 Media Server\" main program looks like this: #include #include \"DynamicRTSPServer.hh\" #include \"version.hh\" int main(int argc, char** argv) { // Begin by setting up our usage environment: TaskScheduler* scheduler = BasicTaskScheduler::createNew(); UsageEnvironment* env = BasicUsageEnvironment::createNew(*scheduler); UserAuthenticationDatabase* authDB = NULL; #ifdef ACCESS_CONTROL // To implement client access control to the RTSP server, do the following: authDB = new UserAuthenticationDatabase; authDB->addUserRecord(\"username1\", \"password1\"); // replace these with real strings // Repeat the above with each , that you wish to allow // access to the server. #endif // Create the RTSP server. Try first with the default port number (554), // and then with the alternative port number (8554): RTSPServer* rtspServer; portNumBits rtspServerPortNum = 554; rtspServer = DynamicRTSPServer::createNew(*env, rtspServerPortNum, authDB); if (rtspServer == NULL) { rtspServerPortNum = 8554; rtspServer = DynamicRTSPServer::createNew(*env, rtspServerPortNum, authDB); } if (rtspServer == NULL) { *env getResultMsg() setUpTunnelingOverHTTP(80) || rtspServer->setUpTunnelingOverHTTP(8000) || rtspServer->setUpTunnelingOverHTTP(8080)) { *env httpServerPortNum() taskScheduler().doEventLoop(); // does not return return 0; // only to prevent compiler warning } The main program of \"LIVE555 Media Server\" is very simple, and the only thing to do is as follows: Created TaskScheduler for performing a task scheduling. About TaskScheduler more detailed information refer to live555 source code analysis: infrastructure . Creating UsageEnvironment a log output, I / O operations. About UsageEnvironmentmore detailed information refer to live555 source code analysis:infrastructure . Create RTSPServer for accepting connections, processing request and the like. Here we will try to use port 554 first. If it fails, try to use port If both ports are unusable, it will fail to exit the program. To RTSPServer set up HTTP tunneling port. Here we will try to use the 80, 8000 and 8080 ports in turn. Execute the event loop. TaskScheduler For performing a task scheduling, but listening socket, and the handler I/O event on the socket, it is necessary RTSPServer, is DynamicRTSPServer provided. DynamicRTSPServer It is the core of the \"LIVE555 Media Server\" application and is defined as follows: #ifndef _RTSP_SERVER_SUPPORTING_HTTP_STREAMING_HH #include \"RTSPServerSupportingHTTPStreaming.hh\" #endif class DynamicRTSPServer: public RTSPServerSupportingHTTPStreaming { public: static DynamicRTSPServer* createNew(UsageEnvironment& env, Port ourPort, UserAuthenticationDatabase* authDatabase, unsigned reclamationTestSeconds = 65); protected: DynamicRTSPServer(UsageEnvironment& env, int ourSocket, Port ourPort, UserAuthenticationDatabase* authDatabase, unsigned reclamationTestSeconds); // called only by createNew(); virtual ~DynamicRTSPServer(); protected: // redefined virtual functions virtual ServerMediaSession* lookupServerMediaSession(char const* streamName, Boolean isFirstLookupInSession); }; DynamicRTSPServer The class hierarchy is as follows: To listen socket and handler on the socket I/O events is in DynamicRTSPServer the process of creating the registration to the TaskScheduler. DynamicRTSPServer Through its static function needs to createNew() create the function is defined as follows: DynamicRTSPServer* DynamicRTSPServer::createNew(UsageEnvironment& env, Port ourPort, UserAuthenticationDatabase* authDatabase, unsigned reclamationTestSeconds) { int ourSocket = setUpOurSocket(env, ourPort); if (ourSocket == -1) return NULL; return new DynamicRTSPServer(env, ourSocket, ourPort, authDatabase, reclamationTestSeconds); } DynamicRTSPServer::DynamicRTSPServer(UsageEnvironment& env, int ourSocket, Port ourPort, UserAuthenticationDatabase* authDatabase, unsigned reclamationTestSeconds) : RTSPServerSupportingHTTPStreaming(env, ourSocket, ourPort, authDatabase, reclamationTestSeconds) { } In DynamicRTSPServer the createNew(), first create a socket, and then use this to create a socket DynamicRTSPServer object. The constructor goes along the first level of the class inheritance hierarchy. RTSPServerSupportingHTTPStreaming The constructor is defined as follows: RTSPServerSupportingHTTPStreaming ::RTSPServerSupportingHTTPStreaming(UsageEnvironment& env, int ourSocket, Port rtspPort, UserAuthenticationDatabase* authDatabase, unsigned reclamationTestSeconds) : RTSPServer(env, ourSocket, rtspPort, authDatabase, reclamationTestSeconds) { } RTSPServer The constructor is defined as follows: RTSPServer::RTSPServer(UsageEnvironment& env, int ourSocket, Port ourPort, UserAuthenticationDatabase* authDatabase, unsigned reclamationSeconds) : GenericMediaServer(env, ourSocket, ourPort, reclamationSeconds), fHTTPServerSocket(-1), fHTTPServerPort(0), fClientConnectionsForHTTPTunneling(NULL), // will get created if needed fTCPStreamingDatabase(HashTable::create(ONE_WORD_HASH_KEYS)), fPendingRegisterOrDeregisterRequests(HashTable::create(ONE_WORD_HASH_KEYS)), fRegisterOrDeregisterRequestCounter(0), fAuthDB(authDatabase), fAllowStreamingRTPOverTCP(True) { } GenericMediaServer The constructor is defined as follows: GenericMediaServer ::GenericMediaServer(UsageEnvironment& env, int ourSocket, Port ourPort, unsigned reclamationSeconds) : Medium(env), fServerSocket(ourSocket), fServerPort(ourPort), fReclamationSeconds(reclamationSeconds), fServerMediaSessions(HashTable::create(STRING_HASH_KEYS)), fClientConnections(HashTable::create(ONE_WORD_HASH_KEYS)), fClientSessions(HashTable::create(STRING_HASH_KEYS)) { ignoreSigPipeOnSocket(fServerSocket); // so that clients on the same host that are killed don't also kill us // Arrange to handle connections from others: env.taskScheduler().turnOnBackgroundReadHandling(fServerSocket, incomingConnectionHandler, this); } In the GenericMediaServer constructor, to listen Server socket and I/O event on the socket handler is registered to the task scheduler. The handler is called when an I/O event occurs on the socket detected in the event loop. The registered event handler is GenericMediaServer::incomingConnectionHandler(). Medium The constructor is defined as follows: Medium::Medium(UsageEnvironment& env) : fEnviron(env), fNextTask(NULL) { // First generate a name for the new medium: MediaLookupTable::ourMedia(env)->generateNewName(fMediumName, mediumNameMaxLen); env.setResultMsg(fMediumName); // Then add it to our table: MediaLookupTable::ourMedia(env)->addNew(this, fMediumName); } In Medium mainly byMediaLookupTable maintaining a medium name to Medium map objects. MediaLookupTable can be regarded as BasicHashTable a value of type Medium Patent object pointer, the class is defined as follows: class MediaLookupTable { public: static MediaLookupTable* ourMedia(UsageEnvironment& env); HashTable const& getTable() { return *fTable; } protected: MediaLookupTable(UsageEnvironment& env); virtual ~MediaLookupTable(); private: friend class Medium; Medium* lookup(char const* name) const; // Returns NULL if none already exists void addNew(Medium* medium, char* mediumName); void remove(char const* name); void generateNewName(char* mediumName, unsigned maxLen); private: UsageEnvironment& fEnv; HashTable* fTable; unsigned fNameGenerator; }; MediaLookupTable The actual quote from the UsageEnvironment holding: _Tables* _Tables::getOurTables(UsageEnvironment& env, Boolean createIfNotPresent) { if (env.liveMediaPriv == NULL && createIfNotPresent) { env.liveMediaPriv = new _Tables(env); } return (_Tables*)(env.liveMediaPriv); } . . . . . . MediaLookupTable* MediaLookupTable::ourMedia(UsageEnvironment& env) { _Tables* ourTables = _Tables::getOurTables(env); if (ourTables->mediaTable == NULL) { // Create a new table to record the media that are to be created in // this environment: ourTables->mediaTable = new MediaLookupTable(env); } return ourTables->mediaTable; } . . . . . . void MediaLookupTable::generateNewName(char* mediumName, unsigned /*maxLen*/) { // We should really use snprintf() here, but not all systems have it sprintf(mediumName, \"liveMedia%d\", fNameGenerator++); } MediaLookupTable::MediaLookupTable(UsageEnvironment& env) : fEnv(env), fTable(HashTable::create(STRING_HASH_KEYS)), fNameGenerator(0) { } medium name in the Medium distribution construction process, created Medium at this time are added MediaLookupTable in: void MediaLookupTable::addNew(Medium* medium, char* mediumName) { fTable->Add(mediumName, (void*)medium); } . . . . . . void MediaLookupTable::generateNewName(char* mediumName, unsigned /*maxLen*/) { // We should really use snprintf() here, but not all systems have it sprintf(mediumName, \"liveMedia%d\", fNameGenerator++); } 1.1. Server socket creation and connection establishment In DynamicRTSPServer the createNew() created DynamicRTSPServer before the object will first by setUpOurSocket() creating a socket, setUpOurSocket() is GenericMediaServer a static function, which is defined as: int GenericMediaServer::setUpOurSocket(UsageEnvironment& env, Port& ourPort) { int ourSocket = -1; do { // The following statement is enabled by default. // Don't disable it (by defining ALLOW_SERVER_PORT_REUSE) unless you know what you're doing. #if !defined(ALLOW_SERVER_PORT_REUSE) && !defined(ALLOW_RTSP_SERVER_PORT_REUSE) // ALLOW_RTSP_SERVER_PORT_REUSE is for backwards-compatibility ##### NoReuse dummy(env); // Don't use this socket if there's already a local server using it #endif ourSocket = setupStreamSocket(env, ourPort); if (ourSocket GenericMediaServer::setUpOurSocket() That is, mainly, by setupStreamSocket() creating a function a TCP socket, the socket's send buffer increases, and listen to the socket. setupStreamSocket() The function is defined in the groupsock module: _groupsockPriv* groupsockPriv(UsageEnvironment& env) { if (env.groupsockPriv == NULL) { // We need to create it _groupsockPriv* result = new _groupsockPriv; result->socketTable = NULL; result->reuseFlag = 1; // default value => allow reuse of socket numbers env.groupsockPriv = result; } return (_groupsockPriv*)(env.groupsockPriv); } void reclaimGroupsockPriv(UsageEnvironment& env) { _groupsockPriv* priv = (_groupsockPriv*)(env.groupsockPriv); if (priv->socketTable == NULL && priv->reuseFlag == 1/*default value*/) { // We can delete the structure (to save space); it will get created again, if needed: delete priv; env.groupsockPriv = NULL; } } static int createSocket(int type) { // Call \"socket()\" to create a (IPv4) socket of the specified type. // But also set it to have the 'close on exec' property (if we can) int sock; #ifdef SOCK_CLOEXEC sock = socket(AF_INET, type|SOCK_CLOEXEC, 0); if (sock != -1 || errno != EINVAL) return sock; // An \"errno\" of EINVAL likely means that the system wasn't happy with the SOCK_CLOEXEC; fall through and try again without it: #endif sock = socket(AF_INET, type, 0); #ifdef FD_CLOEXEC if (sock != -1) fcntl(sock, F_SETFD, FD_CLOEXEC); #endif return sock; } . . . . . . int setupStreamSocket(UsageEnvironment& env, Port port, Boolean makeNonBlocking) { if (!initializeWinsockIfNecessary()) { socketErr(env, \"Failed to initialize 'winsock': \"); return -1; } int newSocket = createSocket(SOCK_STREAM); if (newSocket reuseFlag; reclaimGroupsockPriv(env); if (setsockopt(newSocket, SOL_SOCKET, SO_REUSEADDR, (const char*)&reuseFlag, sizeof reuseFlag) Here is basically to create a TCP socket, set the RESUE option for the socket, bind the socket to the target port, and set the socket to be non-blocking as needed. Then, in live555, how to start listening for I/O events on the server socket and handling these events. We see that in GenericMediaServer the constructor for receiving client-initiated server socket connection, and I/O event handler on the socket, is registered to the task scheduler. This handler is called when a client initiates a connection to the \"LIVE555 Media Server\". The event handler is GenericMediaServer::incomingConnectionHandler(), the related functions are declared as: class GenericMediaServer: public Medium { . . . . . . protected: . . . . . . static void incomingConnectionHandler(void*, int /*mask*/); void incomingConnectionHandler(); void incomingConnectionHandlerOnSocket(int serverSocket); . . . . . . protected: virtual ClientConnection* createNewClientConnection(int clientSocket, struct sockaddr_in clientAddr) = 0; GenericMediaServer::incomingConnectionHandler() is a static function, incomingConnectionHandler() and incomingConnectionHandlerOnSocket(int serverSocket) For non-virtual functions, they are defined as: void GenericMediaServer::incomingConnectionHandler(void* instance, int /*mask*/) { GenericMediaServer* server = (GenericMediaServer*)instance; server->incomingConnectionHandler(); } void GenericMediaServer::incomingConnectionHandler() { incomingConnectionHandlerOnSocket(fServerSocket); } void GenericMediaServer::incomingConnectionHandlerOnSocket(int serverSocket) { struct sockaddr_in clientAddr; SOCKLEN_T clientAddrLen = sizeof clientAddr; int clientSocket = accept(serverSocket, (struct sockaddr*)&clientAddr, &clientAddrLen); if (clientSocket It can be seen that when a client-initiated connection request is found on the monitored server socket, the processing is generally: By accept() obtaining a new socket connection established. Set the option for the new socket to make it a non-blocking socket and increase the send buffer for that socket. Take a look at these functions that set the socket option in live555, which are defined in the groupsock module: Boolean makeSocketNonBlocking(int sock) { . . . . . . int curFlags = fcntl(sock, F_GETFL, 0); return fcntl(sock, F_SETFL, curFlags|O_NONBLOCK) >= 0; #endif } . . . . . . void ignoreSigPipeOnSocket(int socketNum) { . . . . . . signal(SIGPIPE, SIG_IGN); #endif #endif } static unsigned getBufferSize(UsageEnvironment& env, int bufOptName, int socket) { unsigned curSize; SOCKLEN_T sizeSize = sizeof curSize; if (getsockopt(socket, SOL_SOCKET, bufOptName, (char*)&curSize, &sizeSize) curSize) { SOCKLEN_T sizeSize = sizeof requestedSize; if (setsockopt(socket, SOL_SOCKET, bufOptName, (char*)&requestedSize, sizeSize) >= 0) { // success return requestedSize; } requestedSize = (requestedSize+curSize)/2; } return getBufferSize(env, bufOptName, socket); } unsigned increaseSendBufferTo(UsageEnvironment& env, int socket, unsigned requestedSize) { return increaseBufferTo(env, SO_SNDBUF, socket, requestedSize); } By createNewClientConnection(), create a new client connection ClientConnection. createNewClientConnection() is a pure virtual function, its implementation will be realized in the class hierarchy of the function of the lowest class in the class inheritance hierarchy, for DynamicRTSPServer -> RTSPServerSupportingHTTPStreaming -> RTSPServer -> GenericMediaServer this inheritance hierarchy, from the DynamicRTSPServer class began, looking up step by step, you can We found that createNewClientConnection() implementation of the function in the RTSPServerSupportingHTTPStreaming class. RTSPServerSupportingHTTPStreaming The createNewClientConnection() function of the class is defined as follows: GenericMediaServer::ClientConnection* RTSPServerSupportingHTTPStreaming::createNewClientConnection(int clientSocket, struct sockaddr_in clientAddr) { return new RTSPClientConnectionSupportingHTTPStreaming(*this, clientSocket, clientAddr); } RTSPServerSupportingHTTPStreaming::RTSPClientConnectionSupportingHTTPStreaming ::RTSPClientConnectionSupportingHTTPStreaming(RTSPServer& ourServer, int clientSocket, struct sockaddr_in clientAddr) : RTSPClientConnection(ourServer, clientSocket, clientAddr), fClientSessionId(0), fStreamSource(NULL), fPlaylistSource(NULL), fTCPSink(NULL) { } Here simply create a RTSPClientConnectionSupportingHTTPStreaming class object. In live555, washed with GenericMediaServer interior class GenericMediaServer::ClientConnection represents a client connection. For the \"LIVE555 Media Server\", the inheritance hierarchy of this class is shown in the following figure: RTSPClientConnectionSupportingHTTPStreaming Class object constructor call parent class RTSPServer::RTSPClientConnection constructor, which is implemented as: GenericMediaServer::ClientConnection ::ClientConnection(GenericMediaServer& ourServer, int clientSocket, struct sockaddr_in clientAddr) : fOurServer(ourServer), fOurSocket(clientSocket), fClientAddr(clientAddr) { // Add ourself to our 'client connections' table: fOurServer.fClientConnections->Add((char const*)this, this); // Arrange to handle incoming requests: resetRequestBuffer(); envir().taskScheduler() .setBackgroundHandling(fOurSocket, SOCKET_READABLE|SOCKET_EXCEPTION, incomingRequestHandler, this); } RTSPServer::RTSPClientConnection Constructor continues to call its parent class GenericMediaServer::ClientConnection constructor: void GenericMediaServer::ClientConnection::incomingRequestHandler(void* instance, int /*mask*/) { ClientConnection* connection = (ClientConnection*)instance; connection->incomingRequestHandler(); } void GenericMediaServer::ClientConnection::incomingRequestHandler() { struct sockaddr_in dummy; // 'from' address, meaningless in this case int bytesRead = readSocket(envir(), fOurSocket, &fRequestBuffer[fRequestBytesAlreadySeen], fRequestBufferBytesLeft, dummy); handleRequestBytes(bytesRead); } In live555, it is GenericMediaServer used to perform common media server-related management, including managing all client connections. GenericMediaServer::ClientConnection Constructor added adds its own GenericMediaServer hash table fClientConnections in. More importantly, the client-attached socket and the I/O event handler on the socket are registered to the task scheduler, where the I/O event handler is GenericMediaServer::ClientConnection::incomingRequestHandler() function. In other words, the interaction with the client in \"LIVE555 Media Server\" will be GenericMediaServer::ClientConnection::incomingRequestHandler() The function is completed, this function is defined as follows: void GenericMediaServer::ClientConnection::incomingRequestHandler(void* instance, int /*mask*/) { ClientConnection* connection = (ClientConnection*)instance; connection->incomingRequestHandler(); } void GenericMediaServer::ClientConnection::incomingRequestHandler() { struct sockaddr_in dummy; // 'from' address, meaningless in this case int bytesRead = readSocket(envir(), fOurSocket, &fRequestBuffer[fRequestBytesAlreadySeen], fRequestBufferBytesLeft, dummy); handleRequestBytes(bytesRead); } In GenericMediaServer::ClientConnection the incomingRequestHandler() middle, to read data from the client socket connection, and then calls handleRequestBytes() the function for further processing. Reading data from the operation module groupsock readSocket() completed: int readSocket(UsageEnvironment& env, int socket, unsigned char* buffer, unsigned bufferSize, struct sockaddr_in& fromAddress) { SOCKLEN_T addressSize = sizeof fromAddress; int bytesRead = recvfrom(socket, (char*)buffer, bufferSize, 0, (struct sockaddr*)&fromAddress, &addressSize); if (bytesRead Here by recvfrom() reading data from the socket functions. GenericMediaServer::ClientConnection In the process, the functions that handle client requests are declared as follows: static void incomingRequestHandler(void*, int /*mask*/); void incomingRequestHandler(); virtual void handleRequestBytes(int newBytesRead) = 0; handleRequestBytes() For pure virtual functions, it needs to be implemented by subclasses. for RTSPServerSupportingHTTPStreaming::RTSPClientConnectionSupportingHTTPStreaming -> RTSPServer::RTSPClientConnection -> GenericMediaServer::ClientConnection. The inheritance hierarchy, implementation of the function is actually located in RTSPServer::RTSPClientConnection. The request received from the client will be RTSPServer::RTSPClientConnection::handleRequestBytes() deal with. Reward Done. 1.2. Live555 source code analysis series Live555 Source code analysis: Introduction live555 Source code analysis: Infrastructure live555 Source code analysis: MediaSever Wireshark capture packet analysis RTSP/RTP/RTCP Basic working process live555 Source code analysis: RTSPServer live555 Source code analysis: DESCRIBE processing live555 Source code analysis: SETUP processing live555 Source code analysis :PLAY processing live555 Source code analysis: RTSPServer component structure live555 Source code analysis: ServerMediaSession live555 Source code analysis: sub-session SDP line generation live555 Source code analysis: sub-session SETUP live555 Source code analysis: play start "},"Live555 - Wireshark capture packet analysis RTSP_RTP_RTCP basic working process.html":{"url":"Live555 - Wireshark capture packet analysis RTSP_RTP_RTCP basic working process.html","title":"Live555 - Wireshark capture packet analysis RTSP_RTP_RTCP basic working process","keywords":"","body":"1. Wireshark capture packet analysis RTSP/RTP/RTCP basic working process1.1. Live555 source code analysis series1. Wireshark capture packet analysis RTSP/RTP/RTCP basic working process Posted on 2017-09-01 | In live555 Wireshark capture packet analysis RTSP/RTP/RTCP basic working process Live555 source code analysis series In general, RTSP usually works on the reliable transport protocol TCP, like HTTP, to initiate/end streaming media and exchange streaming meta-information. RTP usually works on top of UDP and is used to transmit actual streaming media data. The payload format varies according to the specific streaming media type. It is usually defined by a special RFC specification, such as H.264 encoded video data. The payload format is defined in RFC 6184, RTP Payload Format for H.264 Video , and other streaming data types are defined by other specifications. RTCP also works on UDP and is used to control RTP. The transceivers of streaming media data send RTCP packets to each other during transmission, and pass the QoS information detected by the other end to the other party, using RTP/RTCP. The protocol application uses this information to control the transceiving process. RTP and RTCP work on different ports during transmission. Let's take a look at the basic working process of RTSP/RTP/RTCP through Wireshark. We started live555MediaServer, and there are some streaming media files in its working directory, including files in H.264 source stream format raw_h264_stream.264. Start Wireshark to capture the packet. Then by ffplaythe request live555MediaServer and play raw_h264_stream.264: $ ffplay rtsp://10.240.248.20:8554/raw_h264_stream.264 Where the IP address in the URI for the live555MediaServer IP address of the host running the port number for the port number used. In Wireshark by Display Filter filtration display only RTSP/RTP/RTCP packets, packet sequence will see something like this: As you can see, the first is the interaction of RTSP data, establishing a media transfer session, and then starting to transfer data over RTP/RTCP. The RTSP protocol is more referenced to the HTTP/1.1 protocol at the time of development, and even much of the content is identical to HTTP/1.1. Similar to HTTP/1.1, the RTSP client first sends a request to the server, and then the server sends back a response to interact with the data. RTSP also defines a set of methods that represent the operations performed on the resources identified by the URI. The specific methods defined by RTSP are as follows: method direction object requirement DESCRIBE C->S P,S recommended ANNOUNCE C->S, S->C P,S optional GET_PARAMETER C->S, S->C P,S optional OPTIONS C->S, S->C P,S required (S->C: optional) PAUSE C->S P,S recommended PLAY C->S P,S required RECORD C->S P,S optional REDIRECT S->C P,S optional SETUP C->S S required SET_PARAMETER C->S, S->C P,S optional TEARDOWN C->S P,S required Go back to the package that Wireshark grabbed to see the basic working process of RTSP/RTP/RTCP. First, the client sends the server a way to OPTIONS request packet as No. 112, the requested content as shown above, carries information URL, RTSP version, User-Agent and the like. The RTSP OPTIONS and HTTP / 1.1 of the corresponding method have the same semantics, in particular specifications of RFC 2616 HTTP/1.1 9.2 Sectiondefined. This method is used by the client to understand what methods the server provides for the URL. No. 112 RTSP packet is a client of the server OPTIONSresponse to the request, the details are as follows: The server returns a list of methods supported by the URL to the client. For the situation here, that is OPTIONS, DESCRIBE, SETUP, TEARDOWN, PLAY, PAUSE, GET_PARAMETER, SET_PARAMETER。 The client sends the server a DESCRIBE request, i.e., packet No. 116, the requested content is as follows: DESCRIBE The method is for the client to extract the description of the representation or media object identified by the requested URL. It can use the Accept header to specify client understood description format. The server responds with a description of the requested resource. DESCRIBE The response response pair constitutes the media initialization phase of the RTSP. In the case here, DESCRIBE the request Accept header value application/sdp, indicates that the client wishes to receive the media SDP format representation. The server responds with an RTSP/SDP packet, as shown in the 118th package: The text format of the actual content of this SDP package is as follows: v=0 o=- 1504179985128927 1 IN IP4 10.240.248.20 s=H.264 Video, streamed by the LIVE555 Media Server i=raw_h264_stream.264 t=0 0 a=tool:LIVE555 Streaming Media v2017.07.18 a=type:broadcast a=control:* a=range:npt=0- a=x-qt-text-nam:H.264 Video, streamed by the LIVE555 Media Server a=x-qt-text-inf:raw_h264_stream.264 m=video 0 RTP/AVP 96 c=IN IP4 0.0.0.0 b=AS:500 a=rtpmap:96 H264/90000 a=fmtp:96 packetization-mode=1;profile-level-id=42802A;sprop-parameter-sets=Z0KAKtoBEA8eXlIKDAoNoUJq,aM4G4g== a=control:track1 The server uses the SDP package to inform the protocol used for streaming data transmission and some information about the streaming media itself. The protocol used here is RTP/RTCP. In the usual SDP file, the \"Media Description\" option, which is specified in the line beginning with \"m\", specifies the port that the client needs to listen to when receiving the RTP packet, but here the port is 0. The port selected by the client and server for RTP/RTCP packet transceiving during the transfer will be exchanged in subsequent RTSP requests. After the client receives the SDP packet sent from the server, you select two ports, respectively for transmitting and receiving RTP and RTCP packets, and sends a SETUPrequest for establishing a media session, such as a packet No. 119: Customers SETUP request Transport header, RTP and RTCP for transmitting the selected port, and the communication protocol (UDP unicast or multicast) to the client. It can be seen here that the client selects two ports 19008 and 19009 for RTP and RTCP packets. Subsequent server SETUP request responded, as packet No. 121: Through this response, the server notifies the client of the information for the port for sending and receiving RTP, RTCP packets, the identifier of the session, and the timeout period, which are enabled for the media session. The client then sends two packets to the server's RTP and RTCP ports on the RTP and RTCP ports, such as the 122nd and 123rd packets: Both of these packages carry meaningless data. The purpose of sending them is probably mainly for NAT through the wall. The client then transmits to the server a PLAYrequest to start playback, such as packet No. 124: PLAY Request carries from the previous SETUP session identifier obtained in response to the request. The server then sends an RTCP packet to the client, such as package 125: In this package, the server sends information such as the RTP timestamp, the server's SSRC, and the server's CNAME to the client. Thereafter, the server sends a PLAYresponse to the request: In this package, important information such as the initial sequence number of the RTP packet sent, RTP time, etc. are sent to the client. At this point, the media session is finally established, and the video data can be transmitted through RTP. The first two NALUs of the requested H.264 video file, SPS and PPS, are as follows: 00000000 00 00 00 01 67 42 80 2A DA 01 10 0F 1E 5E 52 0A ....gB.*.....^R. 00000010 0C 0A 0D A1 42 6A 00 00 00 01 68 CE 06 E2 The first two RTP packages, the 127th package and the 128th package, are as follows: Their content exactly matches the content of the first two NALUs of the H.264 video file, ie live555 sends the first two NALU SPS and PPS through two RTP packets. RTSP from the OPTIONS start request, the first video data NALU start sending, after a total of about 102 ms of time, the media session is fully established. The video data is stably transmitted at one end and ends with an RTCP BYE packet sent by the server to the client, such as the 6451 packet: Summarize this process: First, the client sends to the server a method for the OPTIONS request, the server provides support to understand what method of a URL. The server returns a list of methods supported by the URL to the client. The client sends to the server a DESCRIBE request, or to extract description information indicates the URL of the media object identified by the request. The server informs the protocol used for streaming data transmission through the SDP package, as well as some information about the streaming media itself. After the client receives the SDP packet sent from the server, you select two ports, respectively for transmitting and receiving RTP and RTCP packets, and sends a SETUP request for establishing a media session. The server sends back SETUP in response, turn it on for a media session for transmitting and receiving RTP, RTCP packet port, an identifier of the session timeout information to the other client. The client sends two packets to the RTP and RTCP ports of the server on the RTP and RTCP ports. The client sends to the server a PLAY request to start playback. The server sends an RTCP packet to the client, and sends information such as the RTP timestamp, the server's SSRC, and the server's CNAME to the client. The server sends PLAY a response to the request, which contains important information about the initial sequence number of RTP packets, RTP time. At this point, the media session is finally completed. Send streaming media data via RTP/RTCP. The server sends an RTCP BYE packet to the client to end the session. Reward Done. 1.1. Live555 source code analysis series Live555 Source code analysis: Introduction live555 Source code analysis: Infrastructure live555 Source code analysis: MediaSever Wireshark capture packet analysis RTSP/RTP/RTCP Basic working process live555 Source code analysis: RTSPServer live555 Source code analysis: DESCRIBE processing live555 Source code analysis: SETUP processing live555 Source code analysis :PLAY processing live555 Source code analysis: RTSPServer component structure live555 Source code analysis: ServerMediaSession live555 Source code analysis: sub-session SDP line generation live555 Source code analysis: sub-session SETUP live555 Source code analysis: play start "},"Live555 - Live555 source code analysis_rtspserver.html":{"url":"Live555 - Live555 source code analysis_rtspserver.html","title":"Live555 - Live555 source code analysis_rtspserver","keywords":"","body":"1. Live555 Source code analysis: RTSPServer1.1. RTSP message format1.2. RTSP request processing1.3. Processing of OPTIONS requests1.4. Processing of requests applied to the entire server1.5. Processing of DESCRIBE requests1.6. Processing of SETUP requests1.7. Processing of TEARDOWN, PLAY, PAUSE, GET_PARAMETER, SET_PARAMETER requests1.8. Processing of REGISTER, DEREGISTER requests1.9. Handling of error methods1.10. Live555 source code analysis series1. Live555 Source code analysis: RTSPServer Posted on 2017-09-03 | In live555 Live555 Source code analysis: RTSPServer RTSP message format RTSP request processing Processing of OPTIONS requests Processing of requests applied to the entire server Processing of DESCRIBE requests Processing of SETUP requests Processing of TEARDOWN, PLAY, PAUSE, GET_PARAMETER, SET_PARAMETER requests Processing of REGISTER, DEREGISTER requests Handling of error methods Live555 source code analysis series Live555 uses the RTSP/RTP/RTCP protocol for streaming media, where RTSP is used to establish streaming sessions and control streaming sessions. In live555 by class RTSPServerSupportingHTTPStreaming::RTSPClientConnectionSupportingHTTPStreaming to handle the RTSP request. Request sent by the client in the parent class GenericMediaServer::ClientConnectionof incomingRequestHandler(void*, int /*mask*/) receiver functions, and its parent class RTSPServer::RTSPClientConnection function handleRequestBytes() processing. 1.1. RTSP message format In particular look at GenericMediaServer::ClientConnection the incomingRequestHandler(void*, int /*mask*/) before implementation of a function, we first look at the format RTSP message. The RTSP message is divided into a request message and a response message. The format of the request message sent from the client to the server is as follows: Request = Request-Line *( general-header | request-header | entity-header ) CRLF [ message-body ] The first line of the request message is the request line, which contains the method to be applied to the resource, the identifier of the resource, which is the URL, and the protocol used. The specific format of the request line is as follows: Request-Line = Method SP Request-URI SP RTSP-Version CRLF The SP in the above format represents a space, that is, the different elements in the request line are separated by spaces and \\n\\rend with CRLF. The methods supported by RTSP mainly include the following: Method = \"DESCRIBE\" | \"ANNOUNCE\" | \"GET_PARAMETER\" | \"OPTIONS\" | \"PAUSE\" | \"PLAY\" | \"RECORD\" | \"REDIRECT\" | \"SETUP\" | \"SET_PARAMETER\" | \"TEARDOWN\" | extension-method extension-method = token The format of the URI is: Request-URI = \"*\" | absolute_URI That is, it can be \"*\" or a complete URI, where the former indicates that the operation applies to all resources. The format of the RTSP version number is: RTSP-Version = \"RTSP\" \"/\" 1*DIGIT \".\" 1*DIGIT That is, the string \"RTSP/\" is followed by two integers separated by a period (\".\"). After the request line is the header. The headers are divided into three categories, namely the generic header, the request header, and the entity header. The generic header mainly contains the following: general-header = Cache-Control | Connection | Date | Via The request header has the following: request-header = Accept | Accept-Encoding | Accept-Language | Authorization | From | If-Modified-Since | Range | Referer | User-Agent The entity headers include these: entity-header = Allow | Content-Base | Content-Encoding | Content-Language | Content-Length | Content-Location | Content-Type | Expires | Last-Modified | extension-header extension-header = message-header Each head also ends with a CRLF. After all the headers, you need to add another CRLF to separate the header from the message body. At the end of the message body, CRLF is also added as the end. The request message structure of RTSP is very similar to that of HTTP. OPTIONS Request message example: OPTIONS rtsp://10.240.248.20:8554/raw_h264_stream.264 RTSP/1.0 CSeq: 1 User-Agent: Lavf56.40.101 DESCRIBE Request message example: DESCRIBE rtsp://10.240.248.20:8554/raw_h264_stream.264 RTSP/1.0 Accept: application/sdp CSeq: 2 User-Agent: Lavf56.40.101 SETUP Request message example: SETUP rtsp://10.240.248.20:8554/raw_h264_stream.264/track1 RTSP/1.0 Transport: RTP/AVP/UDP;unicast;client_port=27056-27057 CSeq: 3 User-Agent: Lavf56.40.101 PLAY Request message example: PLAY rtsp://10.240.248.20:8554/raw_h264_stream.264/ RTSP/1.0 Range: npt=0.000- CSeq: 4 User-Agent: Lavf56.40.101 Session: 92C91EC2 The response message format is as follows: Response = Status-Line *( general-header | response-header | entity-header ) CRLF [ message-body ] The first line of the response message is the status line, which is described by the protocol version number, the numeric status code, and the text format associated with the status code. The specific format is defined as follows: Status-Line = RTSP-Version SP Status-Code SP Reason-Phrase CRLF Following the status line is the header, which is similar to the header of the request message, except that the request header is replaced with the response header. The response header mainly includes the following: response-header = Location | Proxy-Authenticate | Public | Retry-After | Server | Vary | WWW-Authenticate Each head also ends with a CRLF. After all the headers, you need to add another CRLF to separate the header from the message body. At the end of the message body, CRLF is also added as the end. OPTIONS Example response message: RTSP/1.0 200 OK CSeq: 1 Date: Fri, Sep 01 2017 07:18:16 GMT Public: OPTIONS, DESCRIBE, SETUP, TEARDOWN, PLAY, PAUSE, GET_PARAMETER, SET_PARAMETER DESCRIBE Example response message: RTSP/1.0 200 OK CSeq: 2 Date: Fri, Sep 01 2017 07:18:16 GMT Content-Base: rtsp://10.240.248.20:8554/raw_h264_stream.264/ Content-Type: application/sdp Content-Length: 531 v=0 o=- 1504250296129739 1 IN IP4 10.240.248.20 s=H.264 Video, streamed by the LIVE555 Media Server i=raw_h264_stream.264 t=0 0 a=tool:LIVE555 Streaming Media v2017.07.18 a=type:broadcast a=control:* a=range:npt=0- a=x-qt-text-nam:H.264 Video, streamed by the LIVE555 Media Server a=x-qt-text-inf:raw_h264_stream.264 m=video 0 RTP/AVP 96 c=IN IP4 0.0.0.0 b=AS:500 a=rtpmap:96 H264/90000 a=fmtp:96 packetization-mode=1;profile-level-id=42802A;sprop-parameter-sets=Z0KAKtoBEA8eXlIKDAoNoUJq,aM4G4g== a=control:track1 RTSPClientConnection[0x8018c0]::handleRequestBytes() read 163 new bytes:SETUP rtsp://10.240.248.20:8554/raw_h264_stream.264/track1 RTSP/1.0 Transport: RTP/AVP/UDP;unicast;client_port=27056-27057 CSeq: 3 User-Agent: Lavf56.40.101 In this response, the message body is an SDP message. SETUP Example response message: RTSP/1.0 200 OK CSeq: 3 Date: Fri, Sep 01 2017 07:18:16 GMT Transport: RTP/AVP;unicast;destination=10.240.248.20;source=10.240.248.20;client_port=27056-27057;server_port=6970-6971 Session: 92C91EC2;timeout=65 PLAY Example response message: RTSP/1.0 200 OK CSeq: 4 Date: Fri, Sep 01 2017 07:18:16 GMT Range: npt=0.000- Session: 92C91EC2 RTP-Info: url=rtsp://10.240.248.20:8554/raw_h264_stream.264/track1;seq=32567;rtptime=2735105232 This is basically the case with the RTSP message format. 1.2. RTSP request processing With the knowledge of the RTSP message format, look at RTSPServer the processing functions for RTSP messages in live555 RTSPServer::RTSPClientConnection::handleRequestBytes(). The definition of this function is a bit long, throwing away the processing of HTTP. The processing logic of RTSP is as follows: void RTSPServer::RTSPClientConnection::handleRequestBytes(int newBytesRead) { int numBytesRemaining = 0; ++fRecursionCount; do { RTSPServer::RTSPClientSession* clientSession = NULL; if (newBytesRead = fRequestBufferBytesLeft) { // Either the client socket has died, or the request was too big for us. // Terminate this connection: #ifdef DEBUG fprintf(stderr, \"RTSPClientConnection[%p]::handleRequestBytes() read %d new bytes (of %d); terminating connection!\\n\", this, newBytesRead, fRequestBufferBytesLeft); #endif fIsActive = False; break; } Boolean endOfMsg = False; unsigned char* ptr = &fRequestBuffer[fRequestBytesAlreadySeen]; #ifdef DEBUG ptr[newBytesRead] = '\\0'; fprintf(stderr, \"RTSPClientConnection[%p]::handleRequestBytes() %s %d new bytes:%s\\n\", this, numBytesRemaining > 0 ? \"processing\" : \"read\", newBytesRead, ptr); #endif . . . . . . unsigned char* tmpPtr = fLastCRLF + 2; if (fBase64RemainderCount == 0) { // no more Base-64 bytes remain to be read/decoded // Look for the end of the message: if (tmpPtr noteLiveness(); } // We now have a complete RTSP request. // Handle the specified command (beginning with commands that are session-independent): fCurrentCSeq = cseq; if (strcmp(cmdName, \"OPTIONS\") == 0) { // If the \"OPTIONS\" command included a \"Session:\" id for a session that doesn't exist, // then treat this as an error: if (requestIncludedSessionId && clientSession == NULL) { handleCmd_sessionNotFound(); } else { // Normal case: handleCmd_OPTIONS(); } } else if (urlPreSuffix[0] == '\\0' && urlSuffix[0] == '*' && urlSuffix[1] == '\\0') { // The special \"*\" URL means: an operation on the entire server. This works only for GET_PARAMETER and SET_PARAMETER: if (strcmp(cmdName, \"GET_PARAMETER\") == 0) { handleCmd_GET_PARAMETER((char const*) fRequestBuffer); } else if (strcmp(cmdName, \"SET_PARAMETER\") == 0) { handleCmd_SET_PARAMETER((char const*) fRequestBuffer); } else { handleCmd_notSupported(); } } else if (strcmp(cmdName, \"DESCRIBE\") == 0) { handleCmd_DESCRIBE(urlPreSuffix, urlSuffix, (char const*) fRequestBuffer); } else if (strcmp(cmdName, \"SETUP\") == 0) { Boolean areAuthenticated = True; if (!requestIncludedSessionId) { // No session id was present in the request. // So create a new \"RTSPClientSession\" object for this request. // But first, make sure that we're authenticated to perform this command: char urlTotalSuffix[2 * RTSP_PARAM_STRING_MAX]; // enough space for urlPreSuffix/urlSuffix'\\0' urlTotalSuffix[0] = '\\0'; if (urlPreSuffix[0] != '\\0') { strcat(urlTotalSuffix, urlPreSuffix); strcat(urlTotalSuffix, \"/\"); } strcat(urlTotalSuffix, urlSuffix); if (authenticationOK(\"SETUP\", urlTotalSuffix, (char const*) fRequestBuffer)) { clientSession = (RTSPServer::RTSPClientSession*) fOurRTSPServer.createNewClientSessionWithId(); } else { areAuthenticated = False; } } if (clientSession != NULL) { clientSession->handleCmd_SETUP(this, urlPreSuffix, urlSuffix, (char const*) fRequestBuffer); playAfterSetup = clientSession->fStreamAfterSETUP; } else if (areAuthenticated) { handleCmd_sessionNotFound(); } } else if (strcmp(cmdName, \"TEARDOWN\") == 0 || strcmp(cmdName, \"PLAY\") == 0 || strcmp(cmdName, \"PAUSE\") == 0 || strcmp(cmdName, \"GET_PARAMETER\") == 0 || strcmp(cmdName, \"SET_PARAMETER\") == 0) { if (clientSession != NULL) { clientSession->handleCmd_withinSession(this, cmdName, urlPreSuffix, urlSuffix, (char const*) fRequestBuffer); } else { handleCmd_sessionNotFound(); } } else if (strcmp(cmdName, \"REGISTER\") == 0 || strcmp(cmdName, \"DEREGISTER\") == 0) { // Because - unlike other commands - an implementation of this command needs // the entire URL, we re-parse the command to get it: char* url = strDupSize((char*) fRequestBuffer); if (sscanf((char*) fRequestBuffer, \"%*s %s\", url) == 1) { // Check for special command-specific parameters in a \"Transport:\" header: Boolean reuseConnection, deliverViaTCP; char* proxyURLSuffix; parseTransportHeaderForREGISTER((const char*) fRequestBuffer, reuseConnection, deliverViaTCP, proxyURLSuffix); handleCmd_REGISTER(cmdName, url, urlSuffix, (char const*) fRequestBuffer, reuseConnection, deliverViaTCP, proxyURLSuffix); delete[] proxyURLSuffix; } else { handleCmd_bad(); } delete[] url; } else { // The command is one that we don't handle: handleCmd_notSupported(); } } . . . . . . #ifdef DEBUG fprintf(stderr, \"sending response: %s\", fResponseBuffer); #endif send(fClientOutputSocket, (char const*)fResponseBuffer, strlen((char*)fResponseBuffer), 0); if (playAfterSetup) { // The client has asked for streaming to commence now, rather than after a // subsequent \"PLAY\" command. So, simulate the effect of a \"PLAY\" command: clientSession->handleCmd_withinSession(this, \"PLAY\", urlPreSuffix, urlSuffix, (char const*)fRequestBuffer); } // Check whether there are extra bytes remaining in the buffer, after the end of the request (a rare case). // If so, move them to the front of our buffer, and keep processing it, because it might be a following, pipelined request. unsigned requestSize = (fLastCRLF+4-fRequestBuffer) + contentLength; numBytesRemaining = fRequestBytesAlreadySeen - requestSize; resetRequestBuffer(); // to prepare for any subsequent request if (numBytesRemaining > 0) { memmove(fRequestBuffer, &fRequestBuffer[requestSize], numBytesRemaining); newBytesRead = numBytesRemaining; } } while (numBytesRemaining > 0); --fRecursionCount; if (!fIsActive) { if (fRecursionCount > 0) closeSockets(); else delete this; // Note: The \"fRecursionCount\" test is for a pathological situation where we reenter the event loop and get called recursively // while handling a command (e.g., while handling a \"DESCRIBE\", to get a SDP description). // In such a case we don't want to actually delete ourself until we leave the outermost call. } } This function will process the complete RTSP message stored in the buffer from the socket one by one through a do-while loop. At the beginning of the loop body, RTSPServer::RTSPClientConnection::handleRequestBytes() first find the end position of the request message header, which is achieved by the following code: unsigned char* tmpPtr = fLastCRLF + 2; if (fBase64RemainderCount == 0) { // no more Base-64 bytes remain to be read/decoded // Look for the end of the message: if (tmpPtr A portion of the front RTSP message format, we know, RTSP request message header are two continuous \"\\n \\r\", i.e. the end of the message to find the end position, i.e. the position of this sequence is found, fLastCRLF points to the beginning of this sequence position. If the end position of the request message header is not found, that is, the data read from the socket does not contain the complete message header, and some of the message has not been read yet, and the loop end processing will be skipped. After finding the end position of the request message header, it is to parse out different elements from the message header. This is mainly through the parseRTSPRequestString() function completes: // Parse the request string into command name and 'CSeq', then handle the command: fRequestBuffer[fRequestBytesAlreadySeen] = '\\0'; char cmdName[RTSP_PARAM_STRING_MAX]; char urlPreSuffix[RTSP_PARAM_STRING_MAX]; char urlSuffix[RTSP_PARAM_STRING_MAX]; char cseq[RTSP_PARAM_STRING_MAX]; char sessionIdStr[RTSP_PARAM_STRING_MAX]; unsigned contentLength = 0; fLastCRLF[2] = '\\0'; // temporarily, for parsing Boolean parseSucceeded = parseRTSPRequestString( (char*) fRequestBuffer, fLastCRLF + 2 - fRequestBuffer, cmdName, sizeof cmdName, urlPreSuffix, sizeof urlPreSuffix, urlSuffix, sizeof urlSuffix, cseq, sizeof cseq, sessionIdStr, sizeof sessionIdStr, contentLength); fLastCRLF[2] = '\\r'; // restore its value This is not to parse out all the elements in the RTSP message header, but to parse out several elements in the RTSP message header that determine what to do next, including the requested Method, URL, CSeq and SessionId, message body length ContentLength, and so on. The parsing success indicates that the message is a valid RTSP message, otherwise it is an HTTP message. Here we only look at the processing in the case of successful resolution. After the parsing succeeds, it will first determine whether the message body is complete: at this time (ptr + newBytesRead) points to the end position of the data read in the buffer, tmpPtr pointing to the two \"\\n\\r\" sequences in the end of the message header. that, i.e., the last message header , this comparison (ptr + newBytesRead) and (tmpPtr + 2 + contentLength) to determine whether the message buffer full. When the same message is incomplete, it jumps out of the loop and ends processing. Then, when the processing of the message needs to establish a streaming media session, the established streaming media session is first searched, and a keep-alive operation is performed for the session. Subsequent processing is performed according to the type of RTSP request message. 1.3. Processing of OPTIONS requests OPTIONS The request is processed as follows: if (strcmp(cmdName, \"OPTIONS\") == 0) { // If the \"OPTIONS\" command included a \"Session:\" id for a session that doesn't exist, // then treat this as an error: if (requestIncludedSessionId && clientSession == NULL) { handleCmd_sessionNotFound(); } else { // Normal case: handleCmd_OPTIONS(); } } According to the specification, OPTIONS the request may be initiated at any stage of the streaming media session, when the request header contains SessionId time but can not find the corresponding client session configuration, handleCmd_sessionNotFound() processed: void RTSPServer::RTSPClientConnection::handleCmd_sessionNotFound() { setRTSPResponse(\"454 Session Not Found\"); } . . . . . . void RTSPServer::RTSPClientConnection::setRTSPResponse( char const* responseStr) { snprintf((char*) fResponseBuffer, sizeof fResponseBuffer, \"RTSP/1.0 %s\\r\\n\" \"CSeq: %s\\r\\n\" \"%s\\r\\n\", responseStr, fCurrentCSeq, dateHeader()); } Wherein the dateHeader() return RTSP Datehead, wherein the current time is the time string RTSP header time format: char const* dateHeader() { static char buf[200]; #if !defined(_WIN32_WCE) time_t tt = time(NULL); strftime(buf, sizeof buf, \"Date: %a, %b %d %Y %H:%M:%S GMT\\r\\n\", gmtime(&tt)); #else . . . . . . #endif return buf; } handleCmd_sessionNotFound() The process that is the fResponseBuffer response to an error message 454 is filled RTSP. Normally, the handleCmd_OPTIONS() processing request: char const* RTSPServer::allowedCommandNames() { return \"OPTIONS, DESCRIBE, SETUP, TEARDOWN, PLAY, PAUSE, GET_PARAMETER, SET_PARAMETER\"; } . . . . . . void RTSPServer::RTSPClientConnection::handleCmd_OPTIONS() { snprintf((char*) fResponseBuffer, sizeof fResponseBuffer, \"RTSP/1.0 200 OK\\r\\nCSeq: %s\\r\\n%sPublic: %s\\r\\n\\r\\n\", fCurrentCSeq, dateHeader(), fOurRTSPServer.allowedCommandNames()); } This is the fResponseBuffer response message filling a successful RTSP, wherein the Public header contains all RTSP Methods RTSP server supports. 1.4. Processing of requests applied to the entire server The special URL \"*\" indicates that the requested operation is applied to the entire server. According to RTSP specification, only two operations can be applied to the entire server, i.e., GET_PARAMETER, and SET_PARAMETER. It applies to the entire server GET_PARAMETER and SET_PARAMETER process requests as follows: } else if (urlPreSuffix[0] == '\\0' && urlSuffix[0] == '*' && urlSuffix[1] == '\\0') { // The special \"*\" URL means: an operation on the entire server. This works only for GET_PARAMETER and SET_PARAMETER: if (strcmp(cmdName, \"GET_PARAMETER\") == 0) { handleCmd_GET_PARAMETER((char const*) fRequestBuffer); } else if (strcmp(cmdName, \"SET_PARAMETER\") == 0) { handleCmd_SET_PARAMETER((char const*) fRequestBuffer); } else { handleCmd_notSupported(); } } Here by invoking handleCmd_GET_PARAMETER() and handleCmd_SET_PARAMETER() to process GET_PARAMETER and SET_PARAMETER requests: void RTSPServer::RTSPClientConnection ::handleCmd_GET_PARAMETER(char const* /*fullRequestStr*/) { // By default, we implement \"GET_PARAMETER\" (on the entire server) just as a 'no op', and send back a dummy response. // (If you want to handle this type of \"GET_PARAMETER\" differently, you can do so by defining a subclass of \"RTSPServer\" // and \"RTSPServer::RTSPClientConnection\", and then reimplement this virtual function in your subclass.) setRTSPResponse(\"200 OK\", LIVEMEDIA_LIBRARY_VERSION_STRING); } void RTSPServer::RTSPClientConnection ::handleCmd_SET_PARAMETER(char const* /*fullRequestStr*/) { // By default, we implement \"SET_PARAMETER\" (on the entire server) just as a 'no op', and send back an empty response. // (If you want to handle this type of \"SET_PARAMETER\" differently, you can do so by defining a subclass of \"RTSPServer\" // and \"RTSPServer::RTSPClientConnection\", and then reimplement this virtual function in your subclass.) setRTSPResponse(\"200 OK\"); } . . . . . . void RTSPServer::RTSPClientConnection ::setRTSPResponse(char const* responseStr, char const* contentStr) { if (contentStr == NULL) contentStr = \"\"; unsigned const contentLen = strlen(contentStr); snprintf((char*) fResponseBuffer, sizeof fResponseBuffer, \"RTSP/1.0 %s\\r\\n\" \"CSeq: %s\\r\\n\" \"%s\" \"Content-Length: %d\\r\\n\\r\\n\" \"%s\", responseStr, fCurrentCSeq, dateHeader(), contentLen, contentStr); } live555 liveMedia library RTSPServer::RTSPClientConnection itself does not realize GET_PARAMETER and SET_PARAMETER requests. If the application needs to provide two methods to achieve this, we need to inherit RTSPServer and RTSPServer::RTSPClientConnection, and to implement the corresponding virtual functions. By default, the processing GET_PARAMETER time, RTSPServer::RTSPClientConnection the repository is returned to the client, to SET_PARAMETER request, always return success. 1.5. Processing of DESCRIBE requests DESCRIBE The request is processed as follows: } else if (strcmp(cmdName, \"DESCRIBE\") == 0) { handleCmd_DESCRIBE(urlPreSuffix, urlSuffix, (char const*) fRequestBuffer); } Here by the handleCmd_DESCRIBE() handler DESCRIBE message. 1.6. Processing of SETUP requests The SETUP request is processed as follows: } else if (strcmp(cmdName, \"SETUP\") == 0) { Boolean areAuthenticated = True; if (!requestIncludedSessionId) { // No session id was present in the request. // So create a new \"RTSPClientSession\" object for this request. // But first, make sure that we're authenticated to perform this command: char urlTotalSuffix[2 * RTSP_PARAM_STRING_MAX]; // enough space for urlPreSuffix/urlSuffix'\\0' urlTotalSuffix[0] = '\\0'; if (urlPreSuffix[0] != '\\0') { strcat(urlTotalSuffix, urlPreSuffix); strcat(urlTotalSuffix, \"/\"); } strcat(urlTotalSuffix, urlSuffix); if (authenticationOK(\"SETUP\", urlTotalSuffix, (char const*) fRequestBuffer)) { clientSession = (RTSPServer::RTSPClientSession*) fOurRTSPServer.createNewClientSessionWithId(); } else { areAuthenticated = False; } } if (clientSession != NULL) { clientSession->handleCmd_SETUP(this, urlPreSuffix, urlSuffix, (char const*) fRequestBuffer); playAfterSetup = clientSession->fStreamAfterSETUP; } else if (areAuthenticated) { handleCmd_sessionNotFound(); } } If SETUP the request without SessionID, it means that streaming media session has not been created, then there will first attempt to create a streaming media session request. The process of creation is as follows: The request is first authenticated. After authentication requires the full path portion of the URL, parses the request header, urlPreSuffix a save request path portion of the URL, all portions of the path in front of the last component, while urlSuffixthe last part of the path component of the URL is saved. Such as a URL rtsp://10.240.248.20:8554/raw_h264_stream.264, urlPreSuffix an empty string \"\", urlSuffix as \"raw_h264_stream.264\", for the URL rtsp://10.240.248.20:8000/video/raw_h264_stream.264, urlPreSuffix an empty string \"video\", urlSuffix is \"raw_h264_stream.264\". Thus before certification, will again spell out the first full path portion of the URL, and then through authenticationOK() the implementation of certification. “LIVE555 Media Server” does not provide authentication and authentication will always succeed. The certification process is not analyzed in detail here. When requesting authentication is successful, through the GenericMediaServer::createNewClientSessionWithId() creation RTSPServer::RTSPClientSession object. GenericMediaServer In ClientSession several related function the following statement: virtual ClientSession* createNewClientSession(u_int32_t sessionId) = 0; ClientSession* createNewClientSessionWithId(); // Generates a new (unused) random session id, and calls the \"createNewClientSession()\" // virtual function with this session id as parameter. // Lookup a \"ClientSession\" object by sessionId (integer, and string): ClientSession* lookupClientSession(u_int32_t sessionId); ClientSession* lookupClientSession(char const* sessionIdStr); createNewClientSession() It is a pure virtual function, createNewClientSessionWithId() and two lookupClientSession() non-virtual functions. GenericMediaServer::createNewClientSessionWithId() The function is defined as follows: GenericMediaServer::ClientSession* GenericMediaServer::createNewClientSessionWithId() { u_int32_t sessionId; char sessionIdStr[8+1]; // Choose a random (unused) 32-bit integer for the session id // (it will be encoded as a 8-digit hex number). (We avoid choosing session id 0, // because that has a special use by some servers.) do { sessionId = (u_int32_t)our_random32(); snprintf(sessionIdStr, sizeof sessionIdStr, \"%08X\", sessionId); } while (sessionId == 0 || lookupClientSession(sessionIdStr) != NULL); ClientSession* clientSession = createNewClientSession(sessionId); if (clientSession != NULL) fClientSessions->Add(sessionIdStr, clientSession); return clientSession; } GenericMediaServer::ClientSession* GenericMediaServer::lookupClientSession(u_int32_t sessionId) { char sessionIdStr[8+1]; snprintf(sessionIdStr, sizeof sessionIdStr, \"%08X\", sessionId); return lookupClientSession(sessionIdStr); } GenericMediaServer::ClientSession* GenericMediaServer::lookupClientSession(char const* sessionIdStr) { return (GenericMediaServer::ClientSession*)fClientSessions->Lookup(sessionIdStr); } Created GenericMediaServer::ClientSession, the GenericMediaServer::createNewClientSessionWithId() first to find a non-zero, and has not been occupied by a random value as SessionID; then by createNewClientSession() creating objects function; finally cached objects created and returned to the caller. createNewClientSession() Is a pure virtual function, for DynamicRTSPServer -> RTSPServerSupportingHTTPStreaming -> RTSPServer -> GenericMediaServer this inheritance hierarchy, it is RTSPServer defined: GenericMediaServer::ClientSession* RTSPServer::createNewClientSession(u_int32_t sessionId) { return new RTSPClientSession(*this, sessionId); } live555 the GenericMediaServer::ClientSession inheritance hierarchy is as follows: With RTSPServer::RTSPClientSession Thereafter, through its handleCmd_SETUP() process SETUP request. At the same time, according to the settings of the session, set playAfterSetup. When not be created RTSPServer::RTSPClientSession, but the authentication is successful, the handleCmd_sessionNotFound() return 454 error response to the client. But if the authentication fails, it does not seem to give the client any response. 1.7. Processing of TEARDOWN, PLAY, PAUSE, GET_PARAMETER, SET_PARAMETER requests The processing of the TEARDOWN, PLAY, PAUSE, GET_PARAMETER and SET_PARAMETER requests are as follows: } else if (strcmp(cmdName, \"TEARDOWN\") == 0 || strcmp(cmdName, \"PLAY\") == 0 || strcmp(cmdName, \"PAUSE\") == 0 || strcmp(cmdName, \"GET_PARAMETER\") == 0 || strcmp(cmdName, \"SET_PARAMETER\") == 0) { if (clientSession != NULL) { clientSession->handleCmd_withinSession(this, cmdName, urlPreSuffix, urlSuffix, (char const*) fRequestBuffer); } else { handleCmd_sessionNotFound(); } } These requests are required to initiate a streaming media session after creation, thus directly call client session structure RTSPServer::RTSPClientSession of handleCmd_withinSession() to deal with. When the session configuration does not exist, the handleCmd_sessionNotFound() error message back to the client. Here GET_PARAMETER and SET_PARAMETER operation is only applied to a particular resource identified by the incoming URL, the RTSPServer::RTSPClientSession processing of these two methods, the same as seen previously applied to the entire operation of the server: void RTSPServer::RTSPClientSession ::handleCmd_withinSession( RTSPServer::RTSPClientConnection* ourClientConnection, char const* cmdName, char const* urlPreSuffix, char const* urlSuffix, char const* fullRequestStr) { . . . . . . } else if (strcmp(cmdName, \"GET_PARAMETER\") == 0) { handleCmd_GET_PARAMETER(ourClientConnection, subsession, fullRequestStr); } else if (strcmp(cmdName, \"SET_PARAMETER\") == 0) { handleCmd_SET_PARAMETER(ourClientConnection, subsession, fullRequestStr); } } . . . . . . void RTSPServer::RTSPClientSession ::handleCmd_GET_PARAMETER(RTSPServer::RTSPClientConnection* ourClientConnection, ServerMediaSubsession* /*subsession*/, char const* /*fullRequestStr*/) { // By default, we implement \"GET_PARAMETER\" just as a 'keep alive', and send back a dummy response. // (If you want to handle \"GET_PARAMETER\" properly, you can do so by defining a subclass of \"RTSPServer\" // and \"RTSPServer::RTSPClientSession\", and then reimplement this virtual function in your subclass.) setRTSPResponse(ourClientConnection, \"200 OK\", fOurSessionId, LIVEMEDIA_LIBRARY_VERSION_STRING); } void RTSPServer::RTSPClientSession ::handleCmd_SET_PARAMETER(RTSPServer::RTSPClientConnection* ourClientConnection, ServerMediaSubsession* /*subsession*/, char const* /*fullRequestStr*/) { // By default, we implement \"SET_PARAMETER\" just as a 'keep alive', and send back an empty response. // (If you want to handle \"SET_PARAMETER\" properly, you can do so by defining a subclass of \"RTSPServer\" // and \"RTSPServer::RTSPClientSession\", and then reimplement this virtual function in your subclass.) setRTSPResponse(ourClientConnection, \"200 OK\", fOurSessionId); } RTSPServer::RTSPClientSession The setRTSPResponse() operation is entrusted directly to the RTSPServer::RTSPClientConnection corresponding function is complete: class RTSPClientSession: public GenericMediaServer::ClientSession { . . . . . . // Shortcuts for setting up a RTSP response (prior to sending it): void setRTSPResponse(RTSPClientConnection* ourClientConnection, char const* responseStr) { ourClientConnection->setRTSPResponse(responseStr); } void setRTSPResponse(RTSPClientConnection* ourClientConnection, char const* responseStr, u_int32_t sessionId) { ourClientConnection->setRTSPResponse(responseStr, sessionId); } void setRTSPResponse(RTSPClientConnection* ourClientConnection, char const* responseStr, char const* contentStr) { ourClientConnection->setRTSPResponse(responseStr, contentStr); } void setRTSPResponse(RTSPClientConnection* ourClientConnection, char const* responseStr, u_int32_t sessionId, char const* contentStr) { ourClientConnection->setRTSPResponse(responseStr, sessionId, contentStr); } 1.8. Processing of REGISTER, DEREGISTER requests REGISTER and DEREGISTER standard RTSP specification method is not well-defined. Here is a quick look at the live 555 for their handling: else if (strcmp(cmdName, \"REGISTER\") == 0 || strcmp(cmdName, \"DEREGISTER\") == 0) { // Because - unlike other commands - an implementation of this command needs // the entire URL, we re-parse the command to get it: char* url = strDupSize((char*) fRequestBuffer); if (sscanf((char*) fRequestBuffer, \"%*s %s\", url) == 1) { // Check for special command-specific parameters in a \"Transport:\" header: Boolean reuseConnection, deliverViaTCP; char* proxyURLSuffix; parseTransportHeaderForREGISTER((const char*) fRequestBuffer, reuseConnection, deliverViaTCP, proxyURLSuffix); handleCmd_REGISTER(cmdName, url, urlSuffix, (char const*) fRequestBuffer, reuseConnection, deliverViaTCP, proxyURLSuffix); delete[] proxyURLSuffix; } else { handleCmd_bad(); } delete[] url; } 1.9. Handling of error methods When the method of the RTSP message is not recognized RTSPServer::RTSPClientConnection by the handleCmd_notSupported() processed: void RTSPServer::RTSPClientConnection::handleCmd_notSupported() { snprintf((char*) fResponseBuffer, sizeof fResponseBuffer, \"RTSP/1.0 405 Method Not Allowed\\r\\nCSeq: %s\\r\\n%sAllow: %s\\r\\n\\r\\n\", fCurrentCSeq, dateHeader(), fOurRTSPServer.allowedCommandNames()); } Here the fResponseBuffer response message filled with a RTSP 405 error. According to the RTSP request message type, the process of performing separate processing generates an RTSP response message for the corresponding request and puts it into the response buffer. After processing, the contents of this buffer will be sent to the client: send(fClientOutputSocket, (char const*)fResponseBuffer, strlen((char*)fResponseBuffer), 0); If the streaming session is configured to start playback immediately after SETUP, playback will start immediately: if (playAfterSetup) { // The client has asked for streaming to commence now, rather than after a // subsequent \"PLAY\" command. So, simulate the effect of a \"PLAY\" command: clientSession->handleCmd_withinSession(this, \"PLAY\", urlPreSuffix, urlSuffix, (char const*)fRequestBuffer); } At the end of the loop body, the contents of the already processed message are removed from the request buffer and the remaining unprocessed data is moved to the beginning of the buffer: unsigned requestSize = (fLastCRLF+4-fRequestBuffer) + contentLength; numBytesRemaining = fRequestBytesAlreadySeen - requestSize; resetRequestBuffer(); // to prepare for any subsequent request if (numBytesRemaining > 0) { memmove(fRequestBuffer, &fRequestBuffer[requestSize], numBytesRemaining); newBytesRead = numBytesRemaining; } Which resetRequestBuffer() is defined as follows: void RTSPServer::RTSPClientConnection::resetRequestBuffer() { ClientConnection::resetRequestBuffer(); fLastCRLF = &fRequestBuffer[-3]; // hack: Ensures that we don't think we have end-of-msg if the data starts with fBase64RemainderCount = 0; } ClientConnection::resetRequestBuffer() The definition is as follows: void GenericMediaServer::ClientConnection::resetRequestBuffer() { fRequestBytesAlreadySeen = 0; fRequestBufferBytesLeft = sizeof fRequestBuffer; } I.e. resetRequestBuffer() reset the fRequestBytesAlreadySeen, fRequestBufferBytesLeft, fLastCRLF and fBase64RemainderCount other states. Note that newBytesRead is updated, so if there are still data for unprocessed incomplete messages in the buffer, these states will be updated correctly at the beginning of the next iteration of the loop. Finally, the RTSPServer::RTSPClientConnection::handleRequestBytes() last function needed closes socket: --fRecursionCount; if (!fIsActive) { if (fRecursionCount > 0) closeSockets(); else delete this; // Note: The \"fRecursionCount\" test is for a pathological situation where we reenter the event loop and get called recursively // while handling a command (e.g., while handling a \"DESCRIBE\", to get a SDP description). // In such a case we don't want to actually delete ourself until we leave the outermost call. } Reward Done. 1.10. Live555 source code analysis series Live555 Source code analysis: Introduction [live555 Source code analysis: Infrastructure ]Live555 - Live555 source code analysis_infrastructure.html) live555 Source code analysis: MediaSever Wireshark capture packet analysis RTSP/RTP/RTCP Basic working process live555 Source code analysis: RTSPServer live555 Source code analysis: DESCRIBE processing live555 Source code analysis: SETUP processing live555 Source code analysis :PLAY processing live555 Source code analysis: RTSPServer component structure live555 Source code analysis: ServerMediaSession live555 Source code analysis: sub-session SDP line generation live555 Source code analysis: sub-session SETUP live555 Source code analysis: play start "},"Live555 - Live555 source code analysis_describe processing.html":{"url":"Live555 - Live555 source code analysis_describe processing.html","title":"Live555 - Live555 source code analysis_describe processing","keywords":"","body":"1. Live555 Source code analysis: DESCRIBE processing1.1. Create/Find ServerMediaSession1.2. Generate an SDP message1.3. Live555 source code analysis series1. Live555 Source code analysis: DESCRIBE processing Posted on 2017-09-04 | In live555 Live555 Source code analysis: DESCRIBE processing Create/Find ServerMediaSession Generate an SDP message Live555 source code analysis series In the live555 source code analysis: RTSPServer analyzes the general process of processing RTSP requests in live555, and analyzes some methods that are not so complicated to deal with, such as OPTIONS, GET_PARAMETER and so SET_PARAMETER on. Limited space, there is no analysis of the most important DESCRIBE, SETUP and PLAY deal with these methods. This article continues the analysis live555 of RTSP requests, analysis DESCRIBE, SETUP and PLAY of these the most important methods of treatment. in RTSPServer::RTSPClientConnection::handleRequestBytes(int newBytesRead) By calling handleCmd_DESCRIBE() function processing DESCRIBE request, as follows: } else if (strcmp(cmdName, \"DESCRIBE\") == 0) { handleCmd_DESCRIBE(urlPreSuffix, urlSuffix, (char const*) fRequestBuffer); } handleCmd_DESCRIBE() The definition of a function is like this: void RTSPServer::RTSPClientConnection ::handleCmd_DESCRIBE(char const* urlPreSuffix, char const* urlSuffix, char const* fullRequestStr) { ServerMediaSession* session = NULL; char* sdpDescription = NULL; char* rtspURL = NULL; do { char urlTotalSuffix[2*RTSP_PARAM_STRING_MAX]; // enough space for urlPreSuffix/urlSuffix'\\0' urlTotalSuffix[0] = '\\0'; if (urlPreSuffix[0] != '\\0') { strcat(urlTotalSuffix, urlPreSuffix); strcat(urlTotalSuffix, \"/\"); } strcat(urlTotalSuffix, urlSuffix); if (!authenticationOK(\"DESCRIBE\", urlTotalSuffix, fullRequestStr)) break; // We should really check that the request contains an \"Accept:\" ##### // for \"application/sdp\", because that's what we're sending back ##### // Begin by looking up the \"ServerMediaSession\" object for the specified \"urlTotalSuffix\": session = fOurServer.lookupServerMediaSession(urlTotalSuffix); if (session == NULL) { handleCmd_notFound(); break; } // Increment the \"ServerMediaSession\" object's reference count, in case someone removes it // while we're using it: session->incrementReferenceCount(); // Then, assemble a SDP description for this session: sdpDescription = session->generateSDPDescription(); if (sdpDescription == NULL) { // This usually means that a file name that was specified for a // \"ServerMediaSubsession\" does not exist. setRTSPResponse(\"404 File Not Found, Or In Incorrect Format\"); break; } unsigned sdpDescriptionSize = strlen(sdpDescription); // Also, generate our RTSP URL, for the \"Content-Base:\" header // (which is necessary to ensure that the correct URL gets used in subsequent \"SETUP\" requests). rtspURL = fOurRTSPServer.rtspURL(session, fClientInputSocket); snprintf((char*) fResponseBuffer, sizeof fResponseBuffer, \"RTSP/1.0 200 OK\\r\\nCSeq: %s\\r\\n\" \"%s\" \"Content-Base: %s/\\r\\n\" \"Content-Type: application/sdp\\r\\n\" \"Content-Length: %d\\r\\n\\r\\n\" \"%s\", fCurrentCSeq, dateHeader(), rtspURL, sdpDescriptionSize, sdpDescription); } while (0); if (session != NULL) { // Decrement its reference count, now that we're done using it: session->decrementReferenceCount(); if (session->referenceCount() == 0 && session->deleteWhenUnreferenced()) { fOurServer.removeServerMediaSession(session); } } delete[] sdpDescription; delete[] rtspURL; } handleCmd_DESCRIBE() Function by a do-while (0) of the structure to achieve DESCRIBE the processing method. The advantage of the do-while(0) structure is probably that, in the event of an error, there is no need to return directly, messing up the control flow, and jumping to the end of the function without the goto statement. This function is in DESCRIBE operation the whole execution process: First of execution on the URL DESCRIBE certification authority operations, \"LIVE555 Media Server\" does not provide authentication, authentication will always be successful. Find or create a ServerMediaSession structure for operating the meta information of the media stream. The search is based on the path of the resource in the URL. For \"LIVE555 Media Server\", it is also the relative path of the corresponding file relative to the directory running on the server. When the function fails to execute, it will directly return 404 to the client: void RTSPServer::RTSPClientConnection::handleCmd_notFound() { setRTSPResponse(\"404 Stream Not Found\"); } Generate an SDP description. On failure, it also returns a 404 failure to the client. Get the RTSP URL. The RTSP URL is spliced ​​by the server's IP address and URL path: char* RTSPServer ::rtspURL(ServerMediaSession const* serverMediaSession, int clientSocket) const { char* urlPrefix = rtspURLPrefix(clientSocket); char const* sessionName = serverMediaSession->streamName(); char* resultURL = new char[strlen(urlPrefix) + strlen(sessionName) + 1]; sprintf(resultURL, \"%s%s\", urlPrefix, sessionName); delete[] urlPrefix; return resultURL; } char* RTSPServer::rtspURLPrefix(int clientSocket) const { struct sockaddr_in ourAddress; if (clientSocket :/\" portNumBits portNumHostOrder = ntohs(fServerPort.num()); if (portNumHostOrder == 554 /* the default port number */) { sprintf(urlBuffer, \"rtsp://%s/\", AddressString(ourAddress).val()); } else { sprintf(urlBuffer, \"rtsp://%s:%hu/\", AddressString(ourAddress).val(), portNumHostOrder); } return strDup(urlBuffer); } Generate a response message. In the DESCRIBE request, the client can through Accept the server shows that what the media streaming session supports the following way, but in live555, it seems is to identify the client requests only SDP, and therefore the whole process all manner of produce SDP media stream get on. The SDP message is placed in the body of the response message. 1.1. Create/Find ServerMediaSession handleCmd_DESCRIBE() By function lookupServerMediaSession() to find or create a ServerMediaSession structure, the function GenericMediaServer declaration class: virtual ServerMediaSession* lookupServerMediaSession(char const* streamName, Boolean isFirstLookupInSession = True); It is a virtual function, and the actual function implementation called is located in the lowest level class that implements the function in the inheritance hierarchy. For DynamicRTSPServer -> RTSPServerSupportingHTTPStreaming -> RTSPServer -> GenericMediaServer this inheritance hierarchy, class implements this method has DynamicRTSPServer and GenericMediaServer. Here to see DynamicRTSPServer the class implementation: ServerMediaSession* DynamicRTSPServer ::lookupServerMediaSession(char const* streamName, Boolean isFirstLookupInSession) { // First, check whether the specified \"streamName\" exists as a local file: FILE* fid = fopen(streamName, \"rb\"); Boolean fileExists = fid != NULL; // Next, check whether we already have a \"ServerMediaSession\" for this file: ServerMediaSession* sms = RTSPServer::lookupServerMediaSession(streamName); Boolean smsExists = sms != NULL; // Handle the four possibilities for \"fileExists\" and \"smsExists\": if (!fileExists) { if (smsExists) { // \"sms\" was created for a file that no longer exists. Remove it: removeServerMediaSession(sms); sms = NULL; } return NULL; } else { if (smsExists && isFirstLookupInSession) { // Remove the existing \"ServerMediaSession\" and create a new one, in case the underlying // file has changed in some way: removeServerMediaSession(sms); sms = NULL; } if (sms == NULL) { sms = createNewSMS(envir(), streamName, fid); addServerMediaSession(sms); } fclose(fid); return sms; } } DynamicRTSPServer::lookupServerMediaSession() First checks whether the corresponding file exists, the file and find the corresponding parent class by ServerMediaSession whether the existing structure. The method of the parent class in GenericMediaServer the definition of the class is as follows: ServerMediaSession* GenericMediaServer ::lookupServerMediaSession(char const* streamName, Boolean /*isFirstLookupInSession*/) { // Default implementation: return (ServerMediaSession*)(fServerMediaSessions->Lookup(streamName)); } Then according to the results of the inspection and search, it is divided into several cases: File does not exist, the corresponding ServerMediaSession structure already exists -> Remove ServerMediaSession structure, returned NULL to the caller. File does not exist, the corresponding ServerMediaSession structure does not exist -> returns NULL to the caller. File exists, ServerMediaSession there is structure, and is the first streaming media session in a Find -> Remove ServerMediaSession structure, and create a new structure, saved, and returns it to the caller. The file exists, (the ServerMediaSession structure exists, but not the first lookup in the streaming session) or (the ServerMediaSession structure does not exist) -> Create a new ServerMediaSession structure, save it, and return it to the caller. For the DESCRIBE purposes of the method, this time streaming media sessions usually are not established, and therefore will always find the first execution flow. Create a new ServerMediaSession being to createNewSMS() be done: #define NEW_SMS(description) do {\\ char const* descStr = description\\ \", streamed by the LIVE555 Media Server\";\\ sms = ServerMediaSession::createNew(env, fileName, fileName, descStr);\\ } while(0) static ServerMediaSession* createNewSMS(UsageEnvironment& env, char const* fileName, FILE* /*fid*/) { // Use the file name extension to determine the type of \"ServerMediaSession\": char const* extension = strrchr(fileName, '.'); if (extension == NULL) return NULL; ServerMediaSession* sms = NULL; Boolean const reuseSource = False; . . . . . . } else if (strcmp(extension, \".264\") == 0) { // Assumed to be a H.264 Video Elementary Stream file: NEW_SMS(\"H.264 Video\"); OutPacketBuffer::maxSize = 100000; // allow for some possibly large H.264 frames sms->addSubsession(H264VideoFileServerMediaSubsession::createNew(env, fileName, reuseSource)); } else if (strcmp(extension, \".265\") == 0) { . . . . . . return sms; } createNewSMS() Created based on the file extension ServerMediaSession structure. We look H.264 video format ServerMediaSession to create a structure. createNewSMS() Create a macro ServerMediaSession structure, the macro by the (0) do-while ServerMediaSession::createNew() created; the output buffer is set to 100000 bytes; creating type H264VideoFileServerMediaSubsession of ServerMediaSubsession and provided to the ServerMediaSession structure; and then ServerMediaSession returns to the caller structure. Note that the output buffer limits the size of one frame in the video stream. For some video streams with higher resolution, this size may not meet the requirements. For example, 1080P video stream, some frame sizes may exceed 100000, reaching 150,000. ,even more. ServerMediaSession::createNew() The definition is as follows: ServerMediaSession* ServerMediaSession ::createNew(UsageEnvironment& env, char const* streamName, char const* info, char const* description, Boolean isSSM, char const* miscSDPLines) { return new ServerMediaSession(env, streamName, info, description, isSSM, miscSDPLines); } . . . . . . ServerMediaSession::ServerMediaSession(UsageEnvironment& env, char const* streamName, char const* info, char const* description, Boolean isSSM, char const* miscSDPLines) : Medium(env), fIsSSM(isSSM), fSubsessionsHead(NULL), fSubsessionsTail(NULL), fSubsessionCounter(0), fReferenceCount(0), fDeleteWhenUnreferenced(False) { fStreamName = strDup(streamName == NULL ? \"\" : streamName); char* libNamePlusVersionStr = NULL; // by default if (info == NULL || description == NULL) { libNamePlusVersionStr = new char[strlen(libNameStr) + strlen(libVersionStr) + 1]; sprintf(libNamePlusVersionStr, \"%s%s\", libNameStr, libVersionStr); } fInfoSDPString = strDup(info == NULL ? libNamePlusVersionStr : info); fDescriptionSDPString = strDup(description == NULL ? libNamePlusVersionStr : description); delete[] libNamePlusVersionStr; fMiscSDPLines = strDup(miscSDPLines == NULL ? \"\" : miscSDPLines); gettimeofday(&fCreationTime, NULL); } ServerMediaSession It is ServerMediaSubsession organized as a singly linked list. Boolean ServerMediaSession::addSubsession(ServerMediaSubsession* subsession) { if (subsession->fParentSession != NULL) return False; // it's already used if (fSubsessionsTail == NULL) { fSubsessionsHead = subsession; } else { fSubsessionsTail->fNext = subsession; } fSubsessionsTail = subsession; subsession->fParentSession = this; subsession->fTrackNumber = ++fSubsessionCounter; return True; } Newly added ServerMediaSubsession will always be placed at the end of the list. 1.2. Generate an SDP message SDP message by the ServerMediaSession generated: float ServerMediaSession::duration() const { float minSubsessionDuration = 0.0; float maxSubsessionDuration = 0.0; for (ServerMediaSubsession* subsession = fSubsessionsHead; subsession != NULL; subsession = subsession->fNext) { // Hack: If any subsession supports seeking by 'absolute' time, then return a negative value, to indicate that only subsessions // will have a \"a=range:\" attribute: char* absStartTime = NULL; char* absEndTime = NULL; subsession->getAbsoluteTimeRange(absStartTime, absEndTime); if (absStartTime != NULL) return -1.0f; float ssduration = subsession->duration(); if (subsession == fSubsessionsHead) { // this is the first subsession minSubsessionDuration = maxSubsessionDuration = ssduration; } else if (ssduration maxSubsessionDuration) { maxSubsessionDuration = ssduration; } } if (maxSubsessionDuration != minSubsessionDuration) { return -maxSubsessionDuration; // because subsession durations differ } else { return maxSubsessionDuration; // all subsession durations are the same } } . . . . . . char* ServerMediaSession::generateSDPDescription() { AddressString ipAddressStr(ourIPAddress(envir())); unsigned ipAddressStrSize = strlen(ipAddressStr.val()); // For a SSM sessions, we need a \"a=source-filter: incl ...\" line also: char* sourceFilterLine; if (fIsSSM) { char const* const sourceFilterFmt = \"a=source-filter: incl IN IP4 * %s\\r\\n\" \"a=rtcp-unicast: reflection\\r\\n\"; unsigned const sourceFilterFmtSize = strlen(sourceFilterFmt) + ipAddressStrSize + 1; sourceFilterLine = new char[sourceFilterFmtSize]; sprintf(sourceFilterLine, sourceFilterFmt, ipAddressStr.val()); } else { sourceFilterLine = strDup(\"\"); } char* rangeLine = NULL; // for now char* sdp = NULL; // for now do { // Count the lengths of each subsession's media-level SDP lines. // (We do this first, because the call to \"subsession->sdpLines()\" // causes correct subsession 'duration()'s to be calculated later.) unsigned sdpLength = 0; ServerMediaSubsession* subsession; for (subsession = fSubsessionsHead; subsession != NULL; subsession = subsession->fNext) { char const* sdpLines = subsession->sdpLines(); if (sdpLines == NULL) continue; // the media's not available sdpLength += strlen(sdpLines); } if (sdpLength == 0) break; // the session has no usable subsessions // Unless subsessions have differing durations, we also have a \"a=range:\" line: float dur = duration(); if (dur == 0.0) { rangeLine = strDup(\"a=range:npt=0-\\r\\n\"); } else if (dur > 0.0) { char buf[100]; sprintf(buf, \"a=range:npt=0-%.3f\\r\\n\", dur); rangeLine = strDup(buf); } else { // subsessions have differing durations, so \"a=range:\" lines go there rangeLine = strDup(\"\"); } char const* const sdpPrefixFmt = \"v=0\\r\\n\" \"o=- %ld%06ld %d IN IP4 %s\\r\\n\" \"s=%s\\r\\n\" \"i=%s\\r\\n\" \"t=0 0\\r\\n\" \"a=tool:%s%s\\r\\n\" \"a=type:broadcast\\r\\n\" \"a=control:*\\r\\n\" \"%s\" \"%s\" \"a=x-qt-text-nam:%s\\r\\n\" \"a=x-qt-text-inf:%s\\r\\n\" \"%s\"; sdpLength += strlen(sdpPrefixFmt) + 20 + 6 + 20 + ipAddressStrSize + strlen(fDescriptionSDPString) + strlen(fInfoSDPString) + strlen(libNameStr) + strlen(libVersionStr) + strlen(sourceFilterLine) + strlen(rangeLine) + strlen(fDescriptionSDPString) + strlen(fInfoSDPString) + strlen(fMiscSDPLines); sdpLength += 1000; // in case the length of the \"subsession->sdpLines()\" calls below change sdp = new char[sdpLength]; if (sdp == NULL) break; // Generate the SDP prefix (session-level lines): snprintf(sdp, sdpLength, sdpPrefixFmt, fCreationTime.tv_sec, fCreationTime.tv_usec, // o= 1, // o= // (needs to change if params are modified) ipAddressStr.val(), // o= fDescriptionSDPString, // s= fInfoSDPString, // i= libNameStr, libVersionStr, // a=tool: sourceFilterLine, // a=source-filter: incl (if a SSM session) rangeLine, // a=range: line fDescriptionSDPString, // a=x-qt-text-nam: line fInfoSDPString, // a=x-qt-text-inf: line fMiscSDPLines); // miscellaneous session SDP lines (if any) // Then, add the (media-level) lines for each subsession: char* mediaSDP = sdp; for (subsession = fSubsessionsHead; subsession != NULL; subsession = subsession->fNext) { unsigned mediaSDPLength = strlen(mediaSDP); mediaSDP += mediaSDPLength; sdpLength -= mediaSDPLength; if (sdpLength sdpLines(); if (sdpLines != NULL) snprintf(mediaSDP, sdpLength, \"%s\", sdpLines); } } while (0); delete[] rangeLine; delete[] sourceFilterLine; return sdp; } The SDP message mainly includes two pieces of content, one is the general SDP message content, which mainly includes the timestamp, the server IP address, the duration, etc., and the other is the sub-session-specific information in the streaming media session. For the following SDP messages: v=0 o=- 1504342443358944 1 IN IP4 10.240.248.20 s=H.264 Video, streamed by the LIVE555 Media Server i=video/raw_h264_stream.264 t=0 0 a=tool:LIVE555 Streaming Media v2017.07.18 a=type:broadcast a=control:* a=range:npt=0- a=x-qt-text-nam:H.264 Video, streamed by the LIVE555 Media Server a=x-qt-text-inf:video/raw_h264_stream.264 m=video 0 RTP/AVP 96 c=IN IP4 0.0.0.0 b=AS:500 a=rtpmap:96 H264/90000 a=fmtp:96 packetization-mode=1;profile-level-id=42802A;sprop-parameter-sets=Z0KAKtoBEA8eXlIKDAoNoUJq,aM4G4g== a=control:track1 The general SDP message content is: v=0 o=- 1504342443358944 1 IN IP4 10.240.248.20 s=H.264 Video, streamed by the LIVE555 Media Server i=video/raw_h264_stream.264 t=0 0 a=tool:LIVE555 Streaming Media v2017.07.18 a=type:broadcast a=control:* a=range:npt=0- a=x-qt-text-nam:H.264 Video, streamed by the LIVE555 Media Server a=x-qt-text-inf:video/raw_h264_stream.264 The content generated by the H.264 streaming file is: m=video 0 RTP/AVP 96 c=IN IP4 0.0.0.0 b=AS:500 a=rtpmap:96 H264/90000 a=fmtp:96 packetization-mode=1;profile-level-id=42802A;sprop-parameter-sets=Z0KAKtoBEA8eXlIKDAoNoUJq,aM4G4g== a=control:track1 The SDP message for the child session comes from ServerMediaSubsession::sdpLines(), it is declared as a pure virtual function: class ServerMediaSubsession: public Medium { public: unsigned trackNumber() const { return fTrackNumber; } char const* trackId(); virtual char const* sdpLines() = 0; For H.264 streaming sub-session we created a document, ServerMediaSubsession as H264VideoFileServerMediaSubsession it has inherited system as shown below: As you can see from the figure, the SDP content specific to H.264 streaming sub-sessions will come from OnDemandServerMediaSubsession::sdpLines(): char const* OnDemandServerMediaSubsession::sdpLines() { if (fSDPLines == NULL) { // We need to construct a set of SDP lines that describe this // subsession (as a unicast stream). To do so, we first create // dummy (unused) source and \"RTPSink\" objects, // whose parameters we use for the SDP lines: unsigned estBitrate; FramedSource* inputSource = createNewStreamSource(0, estBitrate); if (inputSource == NULL) return NULL; // file not found struct in_addr dummyAddr; dummyAddr.s_addr = 0; Groupsock* dummyGroupsock = createGroupsock(dummyAddr, 0); unsigned char rtpPayloadType = 96 + trackNumber()-1; // if dynamic RTPSink* dummyRTPSink = createNewRTPSink(dummyGroupsock, rtpPayloadType, inputSource); if (dummyRTPSink != NULL && dummyRTPSink->estimatedBitrate() > 0) estBitrate = dummyRTPSink->estimatedBitrate(); setSDPLinesFromRTPSink(dummyRTPSink, inputSource, estBitrate); Medium::close(dummyRTPSink); delete dummyGroupsock; closeStreamSource(inputSource); } return fSDPLines; } In this function, in order to construct the line SDP session descriptor, it first creates a temporary FramedSource and RTPSink then get information from these structures to construct the SDP line, and in the final destruction of temporary FramedSource and RTPSink. The process of constructing an SDP line is as follows: float ServerMediaSubsession::duration() const { // default implementation: assume an unbounded session: return 0.0; } void ServerMediaSubsession::getAbsoluteTimeRange(char*& absStartTime, char*& absEndTime) const { // default implementation: We don't support seeking by 'absolute' time, so indicate this by setting both parameters to NULL: absStartTime = absEndTime = NULL; } void ServerMediaSubsession::setServerAddressAndPortForSDP(netAddressBits addressBits, portNumBits portBits) { fServerAddressForSDP = addressBits; fPortNumForSDP = portBits; } void OnDemandServerMediaSubsession ::setSDPLinesFromRTPSink(RTPSink* rtpSink, FramedSource* inputSource, unsigned estBitrate) { if (rtpSink == NULL) return; char const* mediaType = rtpSink->sdpMediaType(); unsigned char rtpPayloadType = rtpSink->rtpPayloadType(); AddressString ipAddressStr(fServerAddressForSDP); char* rtpmapLine = rtpSink->rtpmapLine(); char const* rtcpmuxLine = fMultiplexRTCPWithRTP ? \"a=rtcp-mux\\r\\n\" : \"\"; char const* rangeLine = rangeSDPLine(); char const* auxSDPLine = getAuxSDPLine(rtpSink, inputSource); if (auxSDPLine == NULL) auxSDPLine = \"\"; char const* const sdpFmt = \"m=%s %u RTP/AVP %d\\r\\n\" \"c=IN IP4 %s\\r\\n\" \"b=AS:%u\\r\\n\" \"%s\" \"%s\" \"%s\" \"%s\" \"a=control:%s\\r\\n\"; unsigned sdpFmtSize = strlen(sdpFmt) + strlen(mediaType) + 5 /* max short len */ + 3 /* max char len */ + strlen(ipAddressStr.val()) + 20 /* max int len */ + strlen(rtpmapLine) + strlen(rtcpmuxLine) + strlen(rangeLine) + strlen(auxSDPLine) + strlen(trackId()); char* sdpLines = new char[sdpFmtSize]; sprintf(sdpLines, sdpFmt, mediaType, // m= fPortNumForSDP, // m= rtpPayloadType, // m= ipAddressStr.val(), // c= address estBitrate, // b=AS: rtpmapLine, // a=rtpmap:... (if present) rtcpmuxLine, // a=rtcp-mux:... (if present) rangeLine, // a=range:... (if present) auxSDPLine, // optional extra SDP line trackId()); // a=control: delete[] (char*) rangeLine; delete[] rtpmapLine; fSDPLines = strDup(sdpLines); delete[] sdpLines; } Create a temporary FramedSource and RTPSink functions are pure virtual function: virtual FramedSource* createNewStreamSource(unsigned clientSessionId, unsigned& estBitrate) = 0; // \"estBitrate\" is the stream's estimated bitrate, in kbps virtual RTPSink* createNewRTPSink(Groupsock* rtpGroupsock, unsigned char rtpPayloadTypeIfDynamic, FramedSource* inputSource) = 0; For the H264VideoFileServerMediaSubsession class inheritance hierarchy, to achieve these two functions are in H264VideoFileServerMediaSubsession class: FramedSource* H264VideoFileServerMediaSubsession::createNewStreamSource(unsigned /*clientSessionId*/, unsigned& estBitrate) { estBitrate = 500; // kbps, estimate // Create the video source: ByteStreamFileSource* fileSource = ByteStreamFileSource::createNew(envir(), fFileName); if (fileSource == NULL) return NULL; fFileSize = fileSource->fileSize(); // Create a framer for the Video Elementary Stream: return H264VideoStreamFramer::createNew(envir(), fileSource); } RTPSink* H264VideoFileServerMediaSubsession::createNewRTPSink( Groupsock* rtpGroupsock, unsigned char rtpPayloadTypeIfDynamic, FramedSource* /*inputSource*/) { return H264VideoRTPSink::createNew(envir(), rtpGroupsock, rtpPayloadTypeIfDynamic); } Actually created FramedSource and RTPSink type respectively H264VideoStreamFramer and H264VideoRTPSink. Reward Done. 1.3. Live555 source code analysis series Live555 Source code analysis: Introduction live555 Source code analysis: Infrastructure live555 Source code analysis: MediaSever Wireshark capture packet analysis RTSP/RTP/RTCP Basic working process live555 Source code analysis: RTSPServer live555 Source code analysis: DESCRIBE processing live555 Source code analysis: SETUP processing live555 Source code analysis :PLAY processing live555 Source code analysis: RTSPServer component structure live555 Source code analysis: ServerMediaSession live555 Source code analysis: sub-session SDP line generation live555 Source code analysis: sub-session SETUP live555 Source code analysis: play start "},"Live555 - Live555 source code analysis_setup processing.html":{"url":"Live555 - Live555 source code analysis_setup processing.html","title":"Live555 - Live555 source code analysis_setup processing","keywords":"","body":"1. Live555 Source Code Analysis: SETUP processing1.1. Live555 source code analysis series1. Live555 Source Code Analysis: SETUP processing Posted on 2017-09-05 | In live555 Live555 Source Code Analysis: SETUP processing Live555 source code analysis series SETUP The request is used to establish a streaming session throughout the RTSP workflow. This paper analyzes live555 of SETUP processing the request. in RTSPServer::RTSPClientConnection::handleRequestBytes(intnewBytesRead) By RTSPServer::RTSPClientSession the handleCmd_SETUP() function of processing SETUP the request, as follows: void RTSPServer::RTSPClientSession ::handleCmd_SETUP(RTSPServer::RTSPClientConnection* ourClientConnection, char const* urlPreSuffix, char const* urlSuffix, char const* fullRequestStr) { // Normally, \"urlPreSuffix\" should be the session (stream) name, and \"urlSuffix\" should be the subsession (track) name. // However (being \"liberal in what we accept\"), we also handle 'aggregate' SETUP requests (i.e., without a track name), // in the special case where we have only a single track. I.e., in this case, we also handle: // \"urlPreSuffix\" is empty and \"urlSuffix\" is the session (stream) name, or // \"urlPreSuffix\" concatenated with \"urlSuffix\" (with \"/\" inbetween) is the session (stream) name. char const* streamName = urlPreSuffix; // in the normal case char const* trackId = urlSuffix; // in the normal case char* concatenatedStreamName = NULL; // in the normal case do { // First, make sure the specified stream name exists: ServerMediaSession* sms = fOurServer.lookupServerMediaSession(streamName, fOurServerMediaSession == NULL); if (sms == NULL) { // Check for the special case (noted above), before we give up: if (urlPreSuffix[0] == '\\0') { streamName = urlSuffix; } else { concatenatedStreamName = new char[strlen(urlPreSuffix) + strlen(urlSuffix) + 2]; // allow for the \"/\" and the trailing '\\0' sprintf(concatenatedStreamName, \"%s/%s\", urlPreSuffix, urlSuffix); streamName = concatenatedStreamName; } trackId = NULL; // Check again: sms = fOurServer.lookupServerMediaSession(streamName, fOurServerMediaSession == NULL); } if (sms == NULL) { if (fOurServerMediaSession == NULL) { // The client asked for a stream that doesn't exist (and this session descriptor has not been used before): ourClientConnection->handleCmd_notFound(); } else { // The client asked for a stream that doesn't exist, but using a stream id for a stream that does exist. Bad request: ourClientConnection->handleCmd_bad(); } break; } else { if (fOurServerMediaSession == NULL) { // We're accessing the \"ServerMediaSession\" for the first time. fOurServerMediaSession = sms; fOurServerMediaSession->incrementReferenceCount(); } else if (sms != fOurServerMediaSession) { // The client asked for a stream that's different from the one originally requested for this stream id. Bad request: ourClientConnection->handleCmd_bad(); break; } } if (fStreamStates == NULL) { // This is the first \"SETUP\" for this session. Set up our array of states for all of this session's subsessions (tracks): fNumStreamStates = fOurServerMediaSession->numSubsessions(); fStreamStates = new struct streamState[fNumStreamStates]; ServerMediaSubsessionIterator iter(*fOurServerMediaSession); ServerMediaSubsession* subsession; for (unsigned i = 0; i trackId()) == 0) break; } if (trackNum >= fNumStreamStates) { // The specified track id doesn't exist, so this request fails: ourClientConnection->handleCmd_notFound(); break; } } else { // Weird case: there was no track id in the URL. // This works only if we have only one subsession: if (fNumStreamStates != 1 || fStreamStates[0].subsession == NULL) { ourClientConnection->handleCmd_bad(); break; } trackNum = 0; subsession = fStreamStates[trackNum].subsession; } // ASSERT: subsession != NULL void*& token = fStreamStates[trackNum].streamToken; // alias if (token != NULL) { // We already handled a \"SETUP\" for this track (to the same client), // so stop any existing streaming of it, before we set it up again: subsession->pauseStream(fOurSessionId, token); fOurRTSPServer.unnoteTCPStreamingOnSocket(fStreamStates[trackNum].tcpSocketNum, this, trackNum); subsession->deleteStream(fOurSessionId, token); } // Look for a \"Transport:\" header in the request string, to extract client parameters: StreamingMode streamingMode; char* streamingModeString = NULL; // set when RAW_UDP streaming is specified char* clientsDestinationAddressStr; u_int8_t clientsDestinationTTL; portNumBits clientRTPPortNum, clientRTCPPortNum; unsigned char rtpChannelId, rtcpChannelId; parseTransportHeader(fullRequestStr, streamingMode, streamingModeString, clientsDestinationAddressStr, clientsDestinationTTL, clientRTPPortNum, clientRTCPPortNum, rtpChannelId, rtcpChannelId); if ((streamingMode == RTP_TCP && rtpChannelId == 0xFF) || (streamingMode != RTP_TCP && ourClientConnection->fClientOutputSocket != ourClientConnection->fClientInputSocket)) { // An anomolous situation, caused by a buggy client. Either: // 1/ TCP streaming was requested, but with no \"interleaving=\" fields. (QuickTime Player sometimes does this.), or // 2/ TCP streaming was not requested, but we're doing RTSP-over-HTTP tunneling (which implies TCP streaming). // In either case, we assume TCP streaming, and set the RTP and RTCP channel ids to proper values: streamingMode = RTP_TCP; rtpChannelId = fTCPStreamIdCount; rtcpChannelId = fTCPStreamIdCount+1; } if (streamingMode == RTP_TCP) fTCPStreamIdCount += 2; Port clientRTPPort(clientRTPPortNum); Port clientRTCPPort(clientRTCPPortNum); // Next, check whether a \"Range:\" or \"x-playNow:\" header is present in the request. // This isn't legal, but some clients do this to combine \"SETUP\" and \"PLAY\": double rangeStart = 0.0, rangeEnd = 0.0; char* absStart = NULL; char* absEnd = NULL; Boolean startTimeIsNow; if (parseRangeHeader(fullRequestStr, rangeStart, rangeEnd, absStart, absEnd, startTimeIsNow)) { delete[] absStart; delete[] absEnd; fStreamAfterSETUP = True; } else if (parsePlayNowHeader(fullRequestStr)) { fStreamAfterSETUP = True; } else { fStreamAfterSETUP = False; } // Then, get server parameters from the 'subsession': if (streamingMode == RTP_TCP) { // Note that we'll be streaming over the RTSP TCP connection: fStreamStates[trackNum].tcpSocketNum = ourClientConnection->fClientOutputSocket; fOurRTSPServer.noteTCPStreamingOnSocket(fStreamStates[trackNum].tcpSocketNum, this, trackNum); } netAddressBits destinationAddress = 0; u_int8_t destinationTTL = 255; #ifdef RTSP_ALLOW_CLIENT_DESTINATION_SETTING if (clientsDestinationAddressStr != NULL) { // Use the client-provided \"destination\" address. // Note: This potentially allows the server to be used in denial-of-service // attacks, so don't enable this code unless you're sure that clients are // trusted. destinationAddress = our_inet_addr(clientsDestinationAddressStr); } // Also use the client-provided TTL. destinationTTL = clientsDestinationTTL; #endif delete[] clientsDestinationAddressStr; Port serverRTPPort(0); Port serverRTCPPort(0); // Make sure that we transmit on the same interface that's used by the client (in case we're a multi-homed server): struct sockaddr_in sourceAddr; SOCKLEN_T namelen = sizeof sourceAddr; getsockname(ourClientConnection->fClientInputSocket, (struct sockaddr*)&sourceAddr, &namelen); netAddressBits origSendingInterfaceAddr = SendingInterfaceAddr; netAddressBits origReceivingInterfaceAddr = ReceivingInterfaceAddr; // NOTE: The following might not work properly, so we ifdef it out for now: #ifdef HACK_FOR_MULTIHOMED_SERVERS ReceivingInterfaceAddr = SendingInterfaceAddr = sourceAddr.sin_addr.s_addr; #endif subsession->getStreamParameters(fOurSessionId, ourClientConnection->fClientAddr.sin_addr.s_addr, clientRTPPort, clientRTCPPort, fStreamStates[trackNum].tcpSocketNum, rtpChannelId, rtcpChannelId, destinationAddress, destinationTTL, fIsMulticast, serverRTPPort, serverRTCPPort, fStreamStates[trackNum].streamToken); SendingInterfaceAddr = origSendingInterfaceAddr; ReceivingInterfaceAddr = origReceivingInterfaceAddr; AddressString destAddrStr(destinationAddress); AddressString sourceAddrStr(sourceAddr); char timeoutParameterString[100]; if (fOurRTSPServer.fReclamationSeconds > 0) { sprintf(timeoutParameterString, \";timeout=%u\", fOurRTSPServer.fReclamationSeconds); } else { timeoutParameterString[0] = '\\0'; } if (fIsMulticast) { switch (streamingMode) { case RTP_UDP: { snprintf((char*) ourClientConnection->fResponseBuffer, sizeof ourClientConnection->fResponseBuffer, \"RTSP/1.0 200 OK\\r\\n\" \"CSeq: %s\\r\\n\" \"%s\" \"Transport: RTP/AVP;multicast;destination=%s;source=%s;port=%d-%d;ttl=%d\\r\\n\" \"Session: %08X%s\\r\\n\\r\\n\", ourClientConnection->fCurrentCSeq, dateHeader(), destAddrStr.val(), sourceAddrStr.val(), ntohs(serverRTPPort.num()), ntohs(serverRTCPPort.num()), destinationTTL, fOurSessionId, timeoutParameterString); break; } case RTP_TCP: { // multicast streams can't be sent via TCP ourClientConnection->handleCmd_unsupportedTransport(); break; } case RAW_UDP: { snprintf((char*) ourClientConnection->fResponseBuffer, sizeof ourClientConnection->fResponseBuffer, \"RTSP/1.0 200 OK\\r\\n\" \"CSeq: %s\\r\\n\" \"%s\" \"Transport: %s;multicast;destination=%s;source=%s;port=%d;ttl=%d\\r\\n\" \"Session: %08X%s\\r\\n\\r\\n\", ourClientConnection->fCurrentCSeq, dateHeader(), streamingModeString, destAddrStr.val(), sourceAddrStr.val(), ntohs(serverRTPPort.num()), destinationTTL, fOurSessionId, timeoutParameterString); break; } } } else { switch (streamingMode) { case RTP_UDP: { snprintf((char*) ourClientConnection->fResponseBuffer, sizeof ourClientConnection->fResponseBuffer, \"RTSP/1.0 200 OK\\r\\n\" \"CSeq: %s\\r\\n\" \"%s\" \"Transport: RTP/AVP;unicast;destination=%s;source=%s;client_port=%d-%d;server_port=%d-%d\\r\\n\" \"Session: %08X%s\\r\\n\\r\\n\", ourClientConnection->fCurrentCSeq, dateHeader(), destAddrStr.val(), sourceAddrStr.val(), ntohs(clientRTPPort.num()), ntohs(clientRTCPPort.num()), ntohs(serverRTPPort.num()), ntohs(serverRTCPPort.num()), fOurSessionId, timeoutParameterString); break; } case RTP_TCP: { if (!fOurRTSPServer.fAllowStreamingRTPOverTCP) { ourClientConnection->handleCmd_unsupportedTransport(); } else { snprintf((char*) ourClientConnection->fResponseBuffer, sizeof ourClientConnection->fResponseBuffer, \"RTSP/1.0 200 OK\\r\\n\" \"CSeq: %s\\r\\n\" \"%s\" \"Transport: RTP/AVP/TCP;unicast;destination=%s;source=%s;interleaved=%d-%d\\r\\n\" \"Session: %08X%s\\r\\n\\r\\n\", ourClientConnection->fCurrentCSeq, dateHeader(), destAddrStr.val(), sourceAddrStr.val(), rtpChannelId, rtcpChannelId, fOurSessionId, timeoutParameterString); } break; } case RAW_UDP: { snprintf((char*) ourClientConnection->fResponseBuffer, sizeof ourClientConnection->fResponseBuffer, \"RTSP/1.0 200 OK\\r\\n\" \"CSeq: %s\\r\\n\" \"%s\" \"Transport: %s;unicast;destination=%s;source=%s;client_port=%d;server_port=%d\\r\\n\" \"Session: %08X%s\\r\\n\\r\\n\", ourClientConnection->fCurrentCSeq, dateHeader(), streamingModeString, destAddrStr.val(), sourceAddrStr.val(), ntohs(clientRTPPort.num()), ntohs(serverRTPPort.num()), fOurSessionId, timeoutParameterString); break; } } } delete[] streamingModeString; } while (0); delete[] concatenatedStreamName; } The first step, in this function, first find the corresponding resource ServerMediaSession, first try to find the part of the resource path that does not contain the track id, if it fails, it will find the full path of the resource: ServerMediaSession* sms = fOurServer.lookupServerMediaSession(streamName, fOurServerMediaSession == NULL); if (sms == NULL) { // Check for the special case (noted above), before we give up: if (urlPreSuffix[0] == '\\0') { streamName = urlSuffix; } else { concatenatedStreamName = new char[strlen(urlPreSuffix) + strlen(urlSuffix) + 2]; // allow for the \"/\" and the trailing '\\0' sprintf(concatenatedStreamName, \"%s/%s\", urlPreSuffix, urlSuffix); streamName = concatenatedStreamName; } trackId = NULL; // Check again: sms = fOurServer.lookupServerMediaSession(streamName, fOurServerMediaSession == NULL); } it's here lookupServerMediaSession(char const* streamName, boolean isFirstLookupInSession) The isFirstLookupInSessionargument is no longer the default value, but rather based on fOurServerMediaSession the value determined. Visible in the process DESCRIBE created when the request ServerMediaSessionwill always be destroyed and rebuilt. In the second step, the fault-tolerant processing or update status is performed according to the search result of the previous step. If find or create ServerMediaSession fails, and fOurServerMediaSession is empty, an error returned to the client 404, this situation is more easily understood, i.e. DESCRIBE after the request, the resource is removed; or if create lookup ServerMediaSession fails, and fOurServerMediaSession is non-empty, then this time the 400 client returns an error, this scenario seems to be that perform a number of SETUP operations performed when the resources for the first time in, but when performed behind the resources do not exist. Find or create a ServerMediaSession failure always causes the function to return early. if (sms == NULL) { if (fOurServerMediaSession == NULL) { // The client asked for a stream that doesn't exist (and this session descriptor has not been used before): ourClientConnection->handleCmd_notFound(); } else { // The client asked for a stream that doesn't exist, but using a stream id for a stream that does exist. Bad request: ourClientConnection->handleCmd_bad(); } break; } else { To find or create ServerMediaSession a successful situation, if this time fOurServerMediaSession is empty, indicating that this is the streaming media session for the first time to perform SETUP the operation, this time to update fOurServerMediaSession and increase its reference count; if fOurServerMediaSession not empty, and find different, then the customer The end returns a 400 error response message, not quite sure what the scene is . The third part, create a flow state as needed. Create a stream state structure for each subsession of the streaming media streamState. if (fStreamStates == NULL) { // This is the first \"SETUP\" for this session. Set up our array of states for all of this session's subsessions (tracks): fNumStreamStates = fOurServerMediaSession->numSubsessions(); fStreamStates = new struct streamState[fNumStreamStates]; ServerMediaSubsessionIterator iter(*fOurServerMediaSession); ServerMediaSubsession* subsession; for (unsigned i = 0; i The fourth step is to find information about a specific sub-track. For a request with a track id in the URL, it is searched according to the track id, otherwise it is used as a track session for the case of only one child session. // Look up information for the specified subsession (track): ServerMediaSubsession* subsession = NULL; unsigned trackNum; if (trackId != NULL && trackId[0] != '\\0') { // normal case for (trackNum = 0; trackNum trackId()) == 0) break; } if (trackNum >= fNumStreamStates) { // The specified track id doesn't exist, so this request fails: ourClientConnection->handleCmd_notFound(); break; } } else { // Weird case: there was no track id in the URL. // This works only if we have only one subsession: if (fNumStreamStates != 1 || fStreamStates[0].subsession == NULL) { ourClientConnection->handleCmd_bad(); break; } trackNum = 0; subsession = fStreamStates[trackNum].subsession; } A fifth step, if a non-null token track sub-session, indicating that track has been treated SETUP prior to the request, then it is reset, to stop its existing stream. void*& token = fStreamStates[trackNum].streamToken; // alias if (token != NULL) { // We already handled a \"SETUP\" for this track (to the same client), // so stop any existing streaming of it, before we set it up again: subsession->pauseStream(fOurSessionId, token); fOurRTSPServer.unnoteTCPStreamingOnSocket(fStreamStates[trackNum].tcpSocketNum, this, trackNum); subsession->deleteStream(fOurSessionId, token); } The specific operation process of the control of streaming media in the session is not analyzed in detail for the time being. The sixth step, find the string from the request Transport:header and extracts the client parameters. SETUP Request Transport:header might look like this: Transport: RTP/AVP/UDP;unicast;client_port=19586-19587 In this header, there is a way of communication, whether UDP is unicast or multicast, and the port number used by the client to send and receive RTP/RTCP packets. typedef enum StreamingMode { RTP_UDP, RTP_TCP, RAW_UDP } StreamingMode; static void parseTransportHeader(char const* buf, StreamingMode& streamingMode, char*& streamingModeString, char*& destinationAddressStr, u_int8_t& destinationTTL, portNumBits& clientRTPPortNum, // if UDP portNumBits& clientRTCPPortNum, // if UDP unsigned char& rtpChannelId, // if TCP unsigned char& rtcpChannelId // if TCP ) { // Initialize the result parameters to default values: streamingMode = RTP_UDP; streamingModeString = NULL; destinationAddressStr = NULL; destinationTTL = 255; clientRTPPortNum = 0; clientRTCPPortNum = 1; rtpChannelId = rtcpChannelId = 0xFF; portNumBits p1, p2; unsigned ttl, rtpCid, rtcpCid; // First, find \"Transport:\" while (1) { if (*buf == '\\0') return; // not found if (*buf == '\\r' && *(buf+1) == '\\n' && *(buf+2) == '\\r') return; // end of the headers => not found if (_strncasecmp(buf, \"Transport:\", 10) == 0) break; ++buf; } // Then, run through each of the fields, looking for ones we handle: char const* fields = buf + 10; while (*fields == ' ') ++fields; char* field = strDupSize(fields); while (sscanf(fields, \"%[^;\\r\\n]\", field) == 1) { if (strcmp(field, \"RTP/AVP/TCP\") == 0) { streamingMode = RTP_TCP; } else if (strcmp(field, \"RAW/RAW/UDP\") == 0 || strcmp(field, \"MP2T/H2221/UDP\") == 0) { streamingMode = RAW_UDP; streamingModeString = strDup(field); } else if (_strncasecmp(field, \"destination=\", 12) == 0) { delete[] destinationAddressStr; destinationAddressStr = strDup(field+12); } else if (sscanf(field, \"ttl%u\", &ttl) == 1) { destinationTTL = (u_int8_t)ttl; } else if (sscanf(field, \"client_port=%hu-%hu\", &p1, &p2) == 2) { clientRTPPortNum = p1; clientRTCPPortNum = streamingMode == RAW_UDP ? 0 : p2; // ignore the second port number if the client asked for raw UDP } else if (sscanf(field, \"client_port=%hu\", &p1) == 1) { clientRTPPortNum = p1; clientRTCPPortNum = streamingMode == RAW_UDP ? 0 : p1 + 1; } else if (sscanf(field, \"interleaved=%u-%u\", &rtpCid, &rtcpCid) == 2) { rtpChannelId = (unsigned char)rtpCid; rtcpChannelId = (unsigned char)rtcpCid; } fields += strlen(field); while (*fields == ';' || *fields == ' ' || *fields == '\\t') ++fields; // skip over separating ';' chars or whitespace if (*fields == '\\0' || *fields == '\\r' || *fields == '\\n') break; } delete[] field; } . . . . . . // Look for a \"Transport:\" header in the request string, to extract client parameters: StreamingMode streamingMode; char* streamingModeString = NULL; // set when RAW_UDP streaming is specified char* clientsDestinationAddressStr; u_int8_t clientsDestinationTTL; portNumBits clientRTPPortNum, clientRTCPPortNum; unsigned char rtpChannelId, rtcpChannelId; parseTransportHeader(fullRequestStr, streamingMode, streamingModeString, clientsDestinationAddressStr, clientsDestinationTTL, clientRTPPortNum, clientRTCPPortNum, rtpChannelId, rtcpChannelId); if ((streamingMode == RTP_TCP && rtpChannelId == 0xFF) || (streamingMode != RTP_TCP && ourClientConnection->fClientOutputSocket != ourClientConnection->fClientInputSocket)) { // An anomolous situation, caused by a buggy client. Either: // 1/ TCP streaming was requested, but with no \"interleaving=\" fields. (QuickTime Player sometimes does this.), or // 2/ TCP streaming was not requested, but we're doing RTSP-over-HTTP tunneling (which implies TCP streaming). // In either case, we assume TCP streaming, and set the RTP and RTCP channel ids to proper values: streamingMode = RTP_TCP; rtpChannelId = fTCPStreamIdCount; rtcpChannelId = fTCPStreamIdCount+1; } if (streamingMode == RTP_TCP) fTCPStreamIdCount += 2; Port clientRTPPort(clientRTPPortNum); Port clientRTCPPort(clientRTCPPortNum); In our earlier example Transport: of the head, you can see \"unicast\", but in live555, rather than according Transport: to determine the flow unicast or multicast content head. Whether there is a seventh step, check request Range: or x-playNow: head. This is not the standard RTSP support the practice, but some clients may be put in this way SETUP and PLAY together. Boolean parseRangeParam(char const* paramStr, double& rangeStart, double& rangeEnd, char*& absStartTime, char*& absEndTime, Boolean& startTimeIsNow) { delete[] absStartTime; delete[] absEndTime; absStartTime = absEndTime = NULL; // by default, unless \"paramStr\" is a \"clock=...\" string startTimeIsNow = False; // by default double start, end; int numCharsMatched1 = 0, numCharsMatched2 = 0, numCharsMatched3 = 0, numCharsMatched4 = 0; Locale l(\"C\", Numeric); if (sscanf(paramStr, \"npt = %lf - %lf\", &start, &end) == 2) { rangeStart = start; rangeEnd = end; } else if (sscanf(paramStr, \"npt = %n%lf -\", &numCharsMatched1, &start) == 1) { if (paramStr[numCharsMatched1] == '-') { // special case for \"npt = -\", which matches here: rangeStart = 0.0; startTimeIsNow = True; rangeEnd = -start; } else { rangeStart = start; rangeEnd = 0.0; } } else if (sscanf(paramStr, \"npt = now - %lf\", &end) == 1) { rangeStart = 0.0; startTimeIsNow = True; rangeEnd = end; } else if (sscanf(paramStr, \"npt = now -%n\", &numCharsMatched2) == 0 && numCharsMatched2 > 0) { rangeStart = 0.0; startTimeIsNow = True; rangeEnd = 0.0; } else if (sscanf(paramStr, \"clock = %n\", &numCharsMatched3) == 0 && numCharsMatched3 > 0) { rangeStart = rangeEnd = 0.0; char const* utcTimes = &paramStr[numCharsMatched3]; size_t len = strlen(utcTimes) + 1; char* as = new char[len]; char* ae = new char[len]; int sscanfResult = sscanf(utcTimes, \"%[^-]-%[^\\r\\n]\", as, ae); if (sscanfResult == 2) { absStartTime = as; absEndTime = ae; } else if (sscanfResult == 1) { absStartTime = as; delete[] ae; } else { delete[] as; delete[] ae; return False; } } else if (sscanf(paramStr, \"smtpe = %n\", &numCharsMatched4) == 0 && numCharsMatched4 > 0) { // We accept \"smtpe=\" parameters, but currently do not interpret them. } else { return False; // The header is malformed } return True; } Boolean parseRangeHeader(char const* buf, double& rangeStart, double& rangeEnd, char*& absStartTime, char*& absEndTime, Boolean& startTimeIsNow) { // First, find \"Range:\" while (1) { if (*buf == '\\0') return False; // not found if (_strncasecmp(buf, \"Range: \", 7) == 0) break; ++buf; } char const* fields = buf + 7; while (*fields == ' ') ++fields; return parseRangeParam(fields, rangeStart, rangeEnd, absStartTime, absEndTime, startTimeIsNow); } . . . . . . static Boolean parsePlayNowHeader(char const* buf) { // Find \"x-playNow:\" header, if present while (1) { if (*buf == '\\0') return False; // not found if (_strncasecmp(buf, \"x-playNow:\", 10) == 0) break; ++buf; } return True; } . . . . . . double rangeStart = 0.0, rangeEnd = 0.0; char* absStart = NULL; char* absEnd = NULL; Boolean startTimeIsNow; if (parseRangeHeader(fullRequestStr, rangeStart, rangeEnd, absStart, absEnd, startTimeIsNow)) { delete[] absStart; delete[] absEnd; fStreamAfterSETUP = True; } else if (parsePlayNowHeader(fullRequestStr)) { fStreamAfterSETUP = True; } else { fStreamAfterSETUP = False; } Although RTP/RTCP also supports TCP mode, this approach is not very mainstream. Later we mainly look at the UDP unicast-based mode. The eighth step is to allocate network resources for the session, such as server-side RTP and RTCP ports. netAddressBits destinationAddress = 0; u_int8_t destinationTTL = 255; #ifdef RTSP_ALLOW_CLIENT_DESTINATION_SETTING if (clientsDestinationAddressStr != NULL) { // Use the client-provided \"destination\" address. // Note: This potentially allows the server to be used in denial-of-service // attacks, so don't enable this code unless you're sure that clients are // trusted. destinationAddress = our_inet_addr(clientsDestinationAddressStr); } // Also use the client-provided TTL. destinationTTL = clientsDestinationTTL; #endif delete[] clientsDestinationAddressStr; Port serverRTPPort(0); Port serverRTCPPort(0); // Make sure that we transmit on the same interface that's used by the client (in case we're a multi-homed server): struct sockaddr_in sourceAddr; SOCKLEN_T namelen = sizeof sourceAddr; getsockname(ourClientConnection->fClientInputSocket, (struct sockaddr*)&sourceAddr, &namelen); netAddressBits origSendingInterfaceAddr = SendingInterfaceAddr; netAddressBits origReceivingInterfaceAddr = ReceivingInterfaceAddr; // NOTE: The following might not work properly, so we ifdef it out for now: #ifdef HACK_FOR_MULTIHOMED_SERVERS ReceivingInterfaceAddr = SendingInterfaceAddr = sourceAddr.sin_addr.s_addr; #endif subsession->getStreamParameters(fOurSessionId, ourClientConnection->fClientAddr.sin_addr.s_addr, clientRTPPort, clientRTCPPort, fStreamStates[trackNum].tcpSocketNum, rtpChannelId, rtcpChannelId, destinationAddress, destinationTTL, fIsMulticast, serverRTPPort, serverRTCPPort, fStreamStates[trackNum].streamToken); SendingInterfaceAddr = origSendingInterfaceAddr; ReceivingInterfaceAddr = origReceivingInterfaceAddr; AddressString destAddrStr(destinationAddress); AddressString sourceAddrStr(sourceAddr); Later we come to analyze H264VideoFileServerMediaSubsession the process in more detail. In the ninth step, a timeout parameter string is generated. if (fOurRTSPServer.fReclamationSeconds > 0) { sprintf(timeoutParameterString, \";timeout=%u\", fOurRTSPServer.fReclamationSeconds); } else { timeoutParameterString[0] = '\\0'; } In the tenth step, a response message is generated. We only look at the generation of RTP UDP unicast mode response messages. } else { switch (streamingMode) { case RTP_UDP: { snprintf((char*) ourClientConnection->fResponseBuffer, sizeof ourClientConnection->fResponseBuffer, \"RTSP/1.0 200 OK\\r\\n\" \"CSeq: %s\\r\\n\" \"%s\" \"Transport: RTP/AVP;unicast;destination=%s;source=%s;client_port=%d-%d;server_port=%d-%d\\r\\n\" \"Session: %08X%s\\r\\n\\r\\n\", ourClientConnection->fCurrentCSeq, dateHeader(), destAddrStr.val(), sourceAddrStr.val(), ntohs(clientRTPPort.num()), ntohs(clientRTCPPort.num()), ntohs(serverRTPPort.num()), ntohs(serverRTCPPort.num()), fOurSessionId, timeoutParameterString); break; } The generated message looks like this: RTSP/1.0 200 OK CSeq: 3 Date: Sat, Sep 02 2017 08:54:03 GMT Transport: RTP/AVP;unicast;destination=10.240.248.20;source=10.240.248.20;client_port=19586-19587;server_port=6970-6971 Session: D10C8C71;timeout=65 By Transport: the negotiation of communication parameters, such as the server for the session allocated UDP ports for transmitting and receiving RTP/RTCP packets. Put aside the fault tolerance and summarize the general processing flow of the SETUP request: Created for the session ServerMediaSession. Resolution request header Transport: content transmission method on the client request included, such as by using TCP or UDP transport transmission, the client is opened RTP / RTCP transmission ports. Resolution request header Range:and x-playNow:to support SETUP and PLAY combined. Allocate network resources to the session, such as the RTP/RTCP port on the server side. Generate a response message. In ServerMediaSubsession, some of the process in more detail, the rear left analysis. Reward Done. 1.1. Live555 source code analysis series Live555 Source code analysis: Introduction live555 Source code analysis: Infrastructure live555 Source code analysis: MediaSever Wireshark capture packet analysis RTSP/RTP/RTCP Basic working process live555 Source code analysis: RTSPServer live555 Source code analysis: DESCRIBE processing live555 Source code analysis: SETUP processing live555 Source code analysis :PLAY processing live555 Source code analysis: RTSPServer component structure live555 Source code analysis: ServerMediaSession live555 Source code analysis: sub-session SDP line generation live555 Source code analysis: sub-session SETUP live555 Source code analysis: play start "},"Live555 - Live555 source code analysis_play processing.html":{"url":"Live555 - Live555 source code analysis_play processing.html","title":"Live555 - Live555 source code analysis_play processing","keywords":"","body":"1. Live555 Source Code Analysis: PLAY processing1.1. Live555 source code analysis series1. Live555 Source Code Analysis: PLAY processing Posted on 2017-09-05 | In live555 Live555 Source Code Analysis: PLAY processing Live555 source code analysis series In the SETUP following request, the client initiates PLAY a request to a server request to start transmission of audio and video data. In the PLAY request execution, you must have executed SETUP the request, establish a good client session, which will request a client session has been established with other requirements, through clientSession -> handleCmd_withinSession() the implementation of: } else if (strcmp(cmdName, \"TEARDOWN\") == 0 || strcmp(cmdName, \"PLAY\") == 0 || strcmp(cmdName, \"PAUSE\") == 0 || strcmp(cmdName, \"GET_PARAMETER\") == 0 || strcmp(cmdName, \"SET_PARAMETER\") == 0) { if (clientSession != NULL) { clientSession->handleCmd_withinSession(this, cmdName, urlPreSuffix, urlSuffix, (char const*) fRequestBuffer); } else { handleCmd_sessionNotFound(); } } RTSPServer::RTSPClientSession::handleCmd_withinSession() The definition is as follows: void RTSPServer::RTSPClientSession ::handleCmd_withinSession(RTSPServer::RTSPClientConnection* ourClientConnection, char const* cmdName, char const* urlPreSuffix, char const* urlSuffix, char const* fullRequestStr) { // This will either be: // - a non-aggregated operation, if \"urlPreSuffix\" is the session (stream) // name and \"urlSuffix\" is the subsession (track) name, or // - an aggregated operation, if \"urlSuffix\" is the session (stream) name, // or \"urlPreSuffix\" is the session (stream) name, and \"urlSuffix\" is empty, // or \"urlPreSuffix\" and \"urlSuffix\" are both nonempty, but when concatenated, (with \"/\") form the session (stream) name. // Begin by figuring out which of these it is: ServerMediaSubsession* subsession; if (fOurServerMediaSession == NULL) { // There wasn't a previous SETUP! ourClientConnection->handleCmd_notSupported(); return; } else if (urlSuffix[0] != '\\0' && strcmp(fOurServerMediaSession->streamName(), urlPreSuffix) == 0) { // Non-aggregated operation. // Look up the media subsession whose track id is \"urlSuffix\": ServerMediaSubsessionIterator iter(*fOurServerMediaSession); while ((subsession = iter.next()) != NULL) { if (strcmp(subsession->trackId(), urlSuffix) == 0) break; // success } if (subsession == NULL) { // no such track! ourClientConnection->handleCmd_notFound(); return; } } else if (strcmp(fOurServerMediaSession->streamName(), urlSuffix) == 0 || (urlSuffix[0] == '\\0' && strcmp(fOurServerMediaSession->streamName(), urlPreSuffix) == 0)) { // Aggregated operation subsession = NULL; } else if (urlPreSuffix[0] != '\\0' && urlSuffix[0] != '\\0') { // Aggregated operation, if / is the session (stream) name: unsigned const urlPreSuffixLen = strlen(urlPreSuffix); if (strncmp(fOurServerMediaSession->streamName(), urlPreSuffix, urlPreSuffixLen) == 0 && fOurServerMediaSession->streamName()[urlPreSuffixLen] == '/' && strcmp(&(fOurServerMediaSession->streamName())[urlPreSuffixLen + 1], urlSuffix) == 0) { subsession = NULL; } else { ourClientConnection->handleCmd_notFound(); return; } } else { // the request doesn't match a known stream and/or track at all! ourClientConnection->handleCmd_notFound(); return; } if (strcmp(cmdName, \"TEARDOWN\") == 0) { handleCmd_TEARDOWN(ourClientConnection, subsession); } else if (strcmp(cmdName, \"PLAY\") == 0) { handleCmd_PLAY(ourClientConnection, subsession, fullRequestStr); } else if (strcmp(cmdName, \"PAUSE\") == 0) { handleCmd_PAUSE(ourClientConnection, subsession); } else if (strcmp(cmdName, \"GET_PARAMETER\") == 0) { handleCmd_GET_PARAMETER(ourClientConnection, subsession, fullRequestStr); } else if (strcmp(cmdName, \"SET_PARAMETER\") == 0) { handleCmd_SET_PARAMETER(ourClientConnection, subsession, fullRequestStr); } } In this function, you will first find the corresponding URL of the request ServerMediaSubsession. If the search fails, it will return 404 directly and end the processing; then it will be processed by different methods according to the specific type of the request. Found ServerMediaSubsession stored subsession in. subsession A value of null does not mean that the lookup failed. Here by the value NULLshowing the operation applied to the fOurServerMediaSession description of the overall streaming media session. Path to the resource request can be divided into two parts, namely resource prefixes urlPreSuffix and suffixes identify a specific track urlSuffix. by live555 ServerMediaSession and ServerMediaSubsession two object management streaming media session. Depending on the correspondence between the path of the requested resource and the state of the streaming session, it is determined whether the operation can be supported and the scope of the application is operated. Find ServerMediaSubsession later, PLAY the request by the RTSPServer::RTSPClientSession::handleCmd_PLAY() function processing: void RTSPServer::RTSPClientSession ::handleCmd_PLAY(RTSPServer::RTSPClientConnection* ourClientConnection, ServerMediaSubsession* subsession, char const* fullRequestStr) { char* rtspURL = fOurRTSPServer.rtspURL(fOurServerMediaSession, ourClientConnection->fClientInputSocket); unsigned rtspURLSize = strlen(rtspURL); // Parse the client's \"Scale:\" header, if any: float scale; Boolean sawScaleHeader = parseScaleHeader(fullRequestStr, scale); // Try to set the stream's scale factor to this value: if (subsession == NULL /*aggregate op*/) { fOurServerMediaSession->testScaleFactor(scale); } else { subsession->testScaleFactor(scale); } char buf[100]; char* scaleHeader; if (!sawScaleHeader) { buf[0] = '\\0'; // Because we didn't see a Scale: header, don't send one back } else { sprintf(buf, \"Scale: %f\\r\\n\", scale); } scaleHeader = strDup(buf); // Parse the client's \"Range:\" header, if any: float duration = 0.0; double rangeStart = 0.0, rangeEnd = 0.0; char* absStart = NULL; char* absEnd = NULL; Boolean startTimeIsNow; Boolean sawRangeHeader = parseRangeHeader(fullRequestStr, rangeStart, rangeEnd, absStart, absEnd, startTimeIsNow); if (sawRangeHeader && absStart == NULL/*not seeking by 'absolute' time*/) { // Use this information, plus the stream's duration (if known), to create our own \"Range:\" header, for the response: duration = subsession == NULL /*aggregate op*/ ? fOurServerMediaSession->duration() : subsession->duration(); if (duration duration) rangeStart = duration; if (rangeEnd duration) rangeEnd = duration; if ((scale > 0.0 && rangeStart > rangeEnd && rangeEnd > 0.0) || (scale setStreamScale(fOurSessionId, fStreamStates[i].streamToken, scale); } if (absStart != NULL) { // Special case handling for seeking by 'absolute' time: fStreamStates[i].subsession->seekStream(fOurSessionId, fStreamStates[i].streamToken, absStart, absEnd); } else { // Seeking by relative (NPT) time: u_int64_t numBytes; if (!sawRangeHeader || startTimeIsNow) { // We're resuming streaming without seeking, so we just do a 'null' seek // (to get our NPT, and to specify when to end streaming): fStreamStates[i].subsession->nullSeekStream(fOurSessionId, fStreamStates[i].streamToken, rangeEnd, numBytes); } else { // We do a real 'seek': double streamDuration = 0.0; // by default; means: stream until the end of the media if (rangeEnd > 0.0 && (rangeEnd + 0.001) seekStream(fOurSessionId, fStreamStates[i].streamToken, rangeStart, streamDuration, numBytes); } } } } } // Create the \"Range:\" header that we'll send back in our response. // (Note that we do this after seeking, in case the seeking operation changed the range start time.) if (absStart != NULL) { // We're seeking by 'absolute' time: if (absEnd == NULL) { sprintf(buf, \"Range: clock=%s-\\r\\n\", absStart); } else { sprintf(buf, \"Range: clock=%s-%s\\r\\n\", absStart, absEnd); } delete[] absStart; delete[] absEnd; } else { // We're seeking by relative (NPT) time: if (!sawRangeHeader || startTimeIsNow) { // We didn't seek, so in our response, begin the range with the current NPT (normal play time): float curNPT = 0.0; for (i = 0; i getCurrentNPT(fStreamStates[i].streamToken); if (npt > curNPT) curNPT = npt; // Note: If this is an aggregate \"PLAY\" on a multi-subsession stream, // then it's conceivable that the NPTs of each subsession may differ // (if there has been a previous seek on just one subsession). // In this (unusual) case, we just return the largest NPT; I hope that turns out OK... } } rangeStart = curNPT; } if (rangeEnd == 0.0 && scale >= 0.0) { sprintf(buf, \"Range: npt=%.3f-\\r\\n\", rangeStart); } else { sprintf(buf, \"Range: npt=%.3f-%.3f\\r\\n\", rangeStart, rangeEnd); } } char* rangeHeader = strDup(buf); // Now, start streaming: for (i = 0; i startStream(fOurSessionId, fStreamStates[i].streamToken, (TaskFunc*) noteClientLiveness, this, rtpSeqNum, rtpTimestamp, RTSPServer::RTSPClientConnection::handleAlternativeRequestByte, ourClientConnection); const char *urlSuffix = fStreamStates[i].subsession->trackId(); char* prevRTPInfo = rtpInfo; unsigned rtpInfoSize = rtpInfoFmtSize + strlen(prevRTPInfo) + 1 + rtspURLSize + strlen(urlSuffix) + 5 /*max unsigned short len*/ + 10 /*max unsigned (32-bit) len*/ + 2 /*allows for trailing \\r\\n at final end of string*/; rtpInfo = new char[rtpInfoSize]; sprintf(rtpInfo, rtpInfoFmt, prevRTPInfo, numRTPInfoItems++ == 0 ? \"\" : \",\", rtspURL, urlSuffix, rtpSeqNum, rtpTimestamp); delete[] prevRTPInfo; } } if (numRTPInfoItems == 0) { rtpInfo[0] = '\\0'; } else { unsigned rtpInfoLen = strlen(rtpInfo); rtpInfo[rtpInfoLen] = '\\r'; rtpInfo[rtpInfoLen + 1] = '\\n'; rtpInfo[rtpInfoLen + 2] = '\\0'; } // Fill in the response: snprintf((char*) ourClientConnection->fResponseBuffer, sizeof ourClientConnection->fResponseBuffer, \"RTSP/1.0 200 OK\\r\\n\" \"CSeq: %s\\r\\n\" \"%s\" \"%s\" \"%s\" \"Session: %08X\\r\\n\" \"%s\\r\\n\", ourClientConnection->fCurrentCSeq, dateHeader(), scaleHeader, rangeHeader, fOurSessionId, rtpInfo); delete[] rtpInfo; delete[] rangeHeader; delete[] scaleHeader; delete[] rtspURL; } Before describing the analysis function, look at a PLAY request / response exemplary. PLAY Request example: PLAY rtsp://10.240.248.20:8554/video/raw_h264_stream.264/ RTSP/1.0 Range: npt=0.000- CSeq: 4 User-Agent: Lavf56.40.101 Session: D10C8C71 PLAY Example of response: RTSP/1.0 200 OK CSeq: 4 Date: Sat, Sep 02 2017 08:54:03 GMT Range: npt=0.000- Session: D10C8C71 RTP-Info: url=rtsp://10.240.248.20:8554/video/raw_h264_stream.264/track1;seq=12647;rtptime=2457491257 Then look at RTSPServer::RTSPClientSession::handleCmd_PLAY() the specific process. The first step, parsing Scale: head, provided for the respective sub-session Scale streaming media session, and configured to return Scale: the head. // Parse the client's \"Scale:\" header, if any: float scale; Boolean sawScaleHeader = parseScaleHeader(fullRequestStr, scale); // Try to set the stream's scale factor to this value: if (subsession == NULL /*aggregate op*/) { fOurServerMediaSession->testScaleFactor(scale); } else { subsession->testScaleFactor(scale); } char buf[100]; char* scaleHeader; if (!sawScaleHeader) { buf[0] = '\\0'; // Because we didn't see a Scale: header, don't send one back } else { sprintf(buf, \"Scale: %f\\r\\n\", scale); } scaleHeader = strDup(buf); For parsing the Scale: header parseScaleHeader() is defined as follows: Boolean parseScaleHeader(char const* buf, float& scale) { // Initialize the result parameter to a default value: scale = 1.0; // First, find \"Scale:\" while (1) { if (*buf == '\\0') return False; // not found if (_strncasecmp(buf, \"Scale:\", 6) == 0) break; ++buf; } char const* fields = buf + 6; while (*fields == ' ') ++fields; float sc; if (sscanf(fields, \"%f\", &sc) == 1) { scale = sc; } else { return False; // The header is malformed } return True; } scale It will be set to 1.0 by default. Explain the role of the scale value. According to the RTSP specification RFC 2326 12.34 Scale , the scale value is used to control the playback speed. A scale value of 1 indicates normal playback or recording at a normal forward viewing rate. If not 1, the value corresponds to a ratio relative to the normal viewing rate. For example, a ratio of 2 indicates twice the normal viewing rate (\"fast forward\"), while a ratio of 0.5 indicates a half of the viewing rate. In other words, a ratio of 2 plays a time-growth rate that is twice that of a wall clock. For every second of elapsed time, 2 seconds of content will be sent. Negative values ​​indicate the opposite direction. Unless the Speed parameters requires otherwise, the data rate can not be changed. The implementation of Scale changes depends on the server and media type. For video, the server can, for example, transmit a keyframe or selected keyframe. For audio, it can scale the audio while maintaining the tone, or less desirable to transmit the audio clip. The server should attempt to provide an approximate viewing rate, but can limit the range of scale values ​​it supports. The response is to include the actual scale of the server selection. If the request contains the Rangeparameters, the new scale will be in effect at this time. Is applied to the entire streaming media session PLAY request, by ServerMediaSession::testScaleFactor(float& scale) setting Scale, applied to the specific sub-session PLAY request, by ServerMediaSubsessionthe testScaleFactor(float& scale) setting. For us H264VideoFileServerMediaSubsession, testScaleFactor(float& scale) implementation or in the ServerMediaSubsession middle: void ServerMediaSubsession::testScaleFactor(float& scale) { // default implementation: Support scale = 1 only scale = 1; } ServerMediaSession::testScaleFactor(float& scale) The definition is as follows: void ServerMediaSession::testScaleFactor(float& scale) { // First, try setting all subsessions to the desired scale. // If the subsessions' actual scales differ from each other, choose the // value that's closest to 1, and then try re-setting all subsessions to that // value. If the subsessions' actual scales still differ, re-set them all to 1. float minSSScale = 1.0; float maxSSScale = 1.0; float bestSSScale = 1.0; float bestDistanceTo1 = 0.0; ServerMediaSubsession* subsession; for (subsession = fSubsessionsHead; subsession != NULL; subsession = subsession->fNext) { float ssscale = scale; subsession->testScaleFactor(ssscale); if (subsession == fSubsessionsHead) { // this is the first subsession minSSScale = maxSSScale = bestSSScale = ssscale; bestDistanceTo1 = (float)fabs(ssscale - 1.0f); } else { if (ssscale maxSSScale) { maxSSScale = ssscale; } float distanceTo1 = (float) fabs(ssscale - 1.0f); if (distanceTo1 fNext) { float ssscale = bestSSScale; subsession->testScaleFactor(ssscale); if (ssscale != bestSSScale) break; // no luck } if (subsession == NULL) { // All subsessions are at the same scale: bestSSScale scale = bestSSScale; return; } // Still no luck. Set each subsession's scale to 1: for (subsession = fSubsessionsHead; subsession != NULL; subsession = subsession->fNext) { float ssscale = 1; subsession->testScaleFactor(ssscale); } scale = 1; } In this function, the steps are as follows: Step 1: Try to set the scale of all sub-sessions to the value requested by the client, and record the maximum, minimum, and closest value of the scale selected by the sub-session. Step 2: During the execution of step 1, all child sessions select the same scale value, and the scale is returned to the caller. Step 3: During the execution of step 1, all sub-sessions select different scale values, then try to set the closest scale value to 1 to all. Step 4: Step 3 can successfully set the closest scale value to 1 for all child sessions, then return the scale to the caller. Step 5: Step 3 cannot set the scale value closest to 1 to all subsessions, and set the scale value of each subsession to 1. Go back RTSPServer::RTSPClientSession::handleCmd_PLAY(). The second step, to resolve the client's Range: head, and updated range value based on the value scale. // Parse the client's \"Range:\" header, if any: float duration = 0.0; double rangeStart = 0.0, rangeEnd = 0.0; char* absStart = NULL; char* absEnd = NULL; Boolean startTimeIsNow; Boolean sawRangeHeader = parseRangeHeader(fullRequestStr, rangeStart, rangeEnd, absStart, absEnd, startTimeIsNow); if (sawRangeHeader && absStart == NULL/*not seeking by 'absolute' time*/) { // Use this information, plus the stream's duration (if known), to create our own \"Range:\" header, for the response: duration = subsession == NULL /*aggregate op*/ ? fOurServerMediaSession->duration() : subsession->duration(); if (duration duration) rangeStart = duration; if (rangeEnd duration) rangeEnd = duration; if ((scale > 0.0 && rangeStart > rangeEnd && rangeEnd > 0.0) || (scale The fourth step is to create a RTP-Info: line: // Create a \"RTP-Info:\" line. It will get filled in from each subsession's state: char const* rtpInfoFmt = \"%s\" // \"RTP-Info:\", plus any preceding rtpInfo items \"%s\" // comma separator, if needed \"url=%s/%s\" \";seq=%d\" \";rtptime=%u\" ; unsigned rtpInfoFmtSize = strlen(rtpInfoFmt); char* rtpInfo = strDup(\"RTP-Info: \"); unsigned i, numRTPInfoItems = 0; In the fifth step, before starting the streaming, the required seeking/scaling is performed for each sub-session, that is, the playback progress and the playback rate are set. for (i = 0; i setStreamScale(fOurSessionId, fStreamStates[i].streamToken, scale); } if (absStart != NULL) { // Special case handling for seeking by 'absolute' time: fStreamStates[i].subsession->seekStream(fOurSessionId, fStreamStates[i].streamToken, absStart, absEnd); } else { // Seeking by relative (NPT) time: u_int64_t numBytes; if (!sawRangeHeader || startTimeIsNow) { // We're resuming streaming without seeking, so we just do a 'null' seek // (to get our NPT, and to specify when to end streaming): fStreamStates[i].subsession->nullSeekStream(fOurSessionId, fStreamStates[i].streamToken, rangeEnd, numBytes); } else { // We do a real 'seek': double streamDuration = 0.0; // by default; means: stream until the end of the media if (rangeEnd > 0.0 && (rangeEnd + 0.001) seekStream(fOurSessionId, fStreamStates[i].streamToken, rangeStart, streamDuration, numBytes); } } } } } The sixth step, create a response will be sent in Range: the head. if (absStart != NULL) { // We're seeking by 'absolute' time: if (absEnd == NULL) { sprintf(buf, \"Range: clock=%s-\\r\\n\", absStart); } else { sprintf(buf, \"Range: clock=%s-%s\\r\\n\", absStart, absEnd); } delete[] absStart; delete[] absEnd; } else { // We're seeking by relative (NPT) time: if (!sawRangeHeader || startTimeIsNow) { // We didn't seek, so in our response, begin the range with the current NPT (normal play time): float curNPT = 0.0; for (i = 0; i getCurrentNPT(fStreamStates[i].streamToken); if (npt > curNPT) curNPT = npt; // Note: If this is an aggregate \"PLAY\" on a multi-subsession stream, // then it's conceivable that the NPTs of each subsession may differ // (if there has been a previous seek on just one subsession). // In this (unusual) case, we just return the largest NPT; I hope that turns out OK... } } rangeStart = curNPT; } if (rangeEnd == 0.0 && scale >= 0.0) { sprintf(buf, \"Range: npt=%.3f-\\r\\n\", rangeStart); } else { sprintf(buf, \"Range: npt=%.3f-%.3f\\r\\n\", rangeStart, rangeEnd); } } char* rangeHeader = strDup(buf); A seventh step, start streaming media, and generate the final RTP-Info: row. // Now, start streaming: for (i = 0; i startStream(fOurSessionId, fStreamStates[i].streamToken, (TaskFunc*) noteClientLiveness, this, rtpSeqNum, rtpTimestamp, RTSPServer::RTSPClientConnection::handleAlternativeRequestByte, ourClientConnection); const char *urlSuffix = fStreamStates[i].subsession->trackId(); char* prevRTPInfo = rtpInfo; unsigned rtpInfoSize = rtpInfoFmtSize + strlen(prevRTPInfo) + 1 + rtspURLSize + strlen(urlSuffix) + 5 /*max unsigned short len*/ + 10 /*max unsigned (32-bit) len*/ + 2 /*allows for trailing \\r\\n at final end of string*/; rtpInfo = new char[rtpInfoSize]; sprintf(rtpInfo, rtpInfoFmt, prevRTPInfo, numRTPInfoItems++ == 0 ? \"\" : \",\", rtspURL, urlSuffix, rtpSeqNum, rtpTimestamp); delete[] prevRTPInfo; } } if (numRTPInfoItems == 0) { rtpInfo[0] = '\\0'; } else { unsigned rtpInfoLen = strlen(rtpInfo); rtpInfo[rtpInfoLen] = '\\r'; rtpInfo[rtpInfoLen + 1] = '\\n'; rtpInfo[rtpInfoLen + 2] = '\\0'; } In the eighth step, the final response is generated and the temporarily allocated memory is released. // Fill in the response: snprintf((char*) ourClientConnection->fResponseBuffer, sizeof ourClientConnection->fResponseBuffer, \"RTSP/1.0 200 OK\\r\\n\" \"CSeq: %s\\r\\n\" \"%s\" \"%s\" \"%s\" \"Session: %08X\\r\\n\" \"%s\\r\\n\", ourClientConnection->fCurrentCSeq, dateHeader(), scaleHeader, rangeHeader, fOurSessionId, rtpInfo); delete[] rtpInfo; delete[] rangeHeader; delete[] scaleHeader; delete[] rtspURL; Reward Done. 1.1. Live555 source code analysis series Live555 Source code analysis: Introduction live555 Source code analysis: Infrastructure live555 Source code analysis: MediaSever Wireshark capture packet analysis RTSP/RTP/RTCP Basic working process live555 Source code analysis: RTSPServer live555 Source code analysis: DESCRIBE processing live555 Source code analysis: SETUP processing live555 Source code analysis :PLAY processing live555 Source code analysis: RTSPServer component structure live555 Source code analysis: ServerMediaSession live555 Source code analysis: sub-session SDP line generation live555 Source code analysis: sub-session SETUP live555 Source code analysis: play start "},"Live555 - Live555 source code analysis_RTSPServer component structure.html":{"url":"Live555 - Live555 source code analysis_RTSPServer component structure.html","title":"Live555 - Live555 source code analysis_RTSPServer component structure","keywords":"","body":"1. Live555 source code analysis: RTSPServer component structure1.1. Live555 source code analysis series1. Live555 source code analysis: RTSPServer component structure Posted on 2017-09-06 | In live555 Live555 source code analysis: RTSPServer component structure Live555 source code analysis series The previous articles analyzed the processing logic of RTSP in live555. The processing logic of RTSP processing related components is a bit complicated. This article will review the relationship between them. The relationship between RTSP processing related components in live555 is as follows: The source of the event and execution process is at TaskScheduler. GenericMediaServer When an object is created, it will be the TaskScheduler registered handler events on a server socket and the socket processing GenericMediaServer::incomingConnectionHandler(void* instance, int /*mask*/)。 The event handler execution on the server socket is triggered when a client connects to the server. At this point the client socket is created based on ClientConnection the object, and RTSPClientConnection. RTSPClientConnection During the creation of the object, the client socket and ClientConnection the handler that handles the event on the socket are processed. GenericMediaServer::ClientConnection::incomingRequestHandler(void* instance, int /*mask*/) Register to TaskScheduler. After the RTSP request data sent by the client arrives, the GenericMediaServer::ClientConnection data will be read and handed over to RTSPServer::RTSPClientConnection::handleRequestBytes(int newBytesRead) deal with. RTSPServer::RTSPClientConnection Parse the RTSP request, and processing OPTIONS, DESCRIBE and the like without SETUP streaming session establishment request to process. RTSPServer::RTSPClientConnection In the process SETUP a request, it will create a streaming media session RTSPServer::RTSPClientSession, a specific session establishment process will be delegated to the latter process. After the session establishment request needs to be processed, it will be handed over to RTSPServer::RTSPClientSession treatment. Here we take a look at RTSPServer::RTSPClientConnection the full definition: class RTSPServer: public GenericMediaServer { . . . . . . public: // should be protected, but some old compilers complain otherwise // The state of a TCP connection used by a RTSP client: class RTSPClientSession; // forward class RTSPClientConnection: public GenericMediaServer::ClientConnection { public: // A data structure that's used to implement the \"REGISTER\" command: class ParamsForREGISTER { public: ParamsForREGISTER(char const* cmd/*\"REGISTER\" or \"DEREGISTER\"*/, RTSPClientConnection* ourConnection, char const* url, char const* urlSuffix, Boolean reuseConnection, Boolean deliverViaTCP, char const* proxyURLSuffix); virtual ~ParamsForREGISTER(); private: friend class RTSPClientConnection; char const* fCmd; RTSPClientConnection* fOurConnection; char* fURL; char* fURLSuffix; Boolean fReuseConnection, fDeliverViaTCP; char* fProxyURLSuffix; }; protected: // redefined virtual functions: virtual void handleRequestBytes(int newBytesRead); protected: RTSPClientConnection(RTSPServer& ourServer, int clientSocket, struct sockaddr_in clientAddr); virtual ~RTSPClientConnection(); friend class RTSPServer; friend class RTSPClientSession; // Make the handler functions for each command virtual, to allow subclasses to reimplement them, if necessary: virtual void handleCmd_OPTIONS(); // You probably won't need to subclass/reimplement this function; reimplement \"RTSPServer::allowedCommandNames()\" instead. virtual void handleCmd_GET_PARAMETER(char const* fullRequestStr); // when operating on the entire server virtual void handleCmd_SET_PARAMETER(char const* fullRequestStr); // when operating on the entire server virtual void handleCmd_DESCRIBE(char const* urlPreSuffix, char const* urlSuffix, char const* fullRequestStr); virtual void handleCmd_REGISTER(char const* cmd/*\"REGISTER\" or \"DEREGISTER\"*/, char const* url, char const* urlSuffix, char const* fullRequestStr, Boolean reuseConnection, Boolean deliverViaTCP, char const* proxyURLSuffix); // You probably won't need to subclass/reimplement this function; // reimplement \"RTSPServer::weImplementREGISTER()\" and \"RTSPServer::implementCmd_REGISTER()\" instead. virtual void handleCmd_bad(); virtual void handleCmd_notSupported(); virtual void handleCmd_notFound(); virtual void handleCmd_sessionNotFound(); virtual void handleCmd_unsupportedTransport(); // Support for optional RTSP-over-HTTP tunneling: virtual Boolean parseHTTPRequestString(char* resultCmdName, unsigned resultCmdNameMaxSize, char* urlSuffix, unsigned urlSuffixMaxSize, char* sessionCookie, unsigned sessionCookieMaxSize, char* acceptStr, unsigned acceptStrMaxSize); virtual void handleHTTPCmd_notSupported(); virtual void handleHTTPCmd_notFound(); virtual void handleHTTPCmd_OPTIONS(); virtual void handleHTTPCmd_TunnelingGET(char const* sessionCookie); virtual Boolean handleHTTPCmd_TunnelingPOST(char const* sessionCookie, unsigned char const* extraData, unsigned extraDataSize); virtual void handleHTTPCmd_StreamingGET(char const* urlSuffix, char const* fullRequestStr); protected: void resetRequestBuffer(); void closeSocketsRTSP(); static void handleAlternativeRequestByte(void*, u_int8_t requestByte); void handleAlternativeRequestByte1(u_int8_t requestByte); Boolean authenticationOK(char const* cmdName, char const* urlSuffix, char const* fullRequestStr); void changeClientInputSocket(int newSocketNum, unsigned char const* extraData, unsigned extraDataSize); // used to implement RTSP-over-HTTP tunneling static void continueHandlingREGISTER(ParamsForREGISTER* params); virtual void continueHandlingREGISTER1(ParamsForREGISTER* params); // Shortcuts for setting up a RTSP response (prior to sending it): void setRTSPResponse(char const* responseStr); void setRTSPResponse(char const* responseStr, u_int32_t sessionId); void setRTSPResponse(char const* responseStr, char const* contentStr); void setRTSPResponse(char const* responseStr, u_int32_t sessionId, char const* contentStr); RTSPServer& fOurRTSPServer; // same as ::fOurServer int& fClientInputSocket; // aliased to ::fOurSocket int fClientOutputSocket; Boolean fIsActive; unsigned char* fLastCRLF; unsigned fRecursionCount; char const* fCurrentCSeq; Authenticator fCurrentAuthenticator; // used if access control is needed char* fOurSessionCookie; // used for optional RTSP-over-HTTP tunneling unsigned fBase64RemainderCount; // used for optional RTSP-over-HTTP tunneling (possible values: 0,1,2,3) }; RTSPServer::RTSPClientConnection inherited from GenericMediaServer::ClientConnection: class GenericMediaServer: public Medium { . . . . . . public: // should be protected, but some old compilers complain otherwise // The state of a TCP connection used by a client: class ClientConnection { protected: ClientConnection(GenericMediaServer& ourServer, int clientSocket, struct sockaddr_in clientAddr); virtual ~ ClientConnection (); UsageEnvironment& envir() { return fOurServer.envir(); } void closeSockets(); static void incomingRequestHandler(void*, int /*mask*/); void incomingRequestHandler(); virtual void handleRequestBytes(int newBytesRead) = 0; void resetRequestBuffer(); protected: friend class GenericMediaServer; friend class ClientSession; friend class RTSPServer; // needed to make some broken Windows compilers work; remove this in the future when we end support for Windows GenericMediaServer& fOurServer; int fOurSocket; struct sockaddr_in fClientAddr; unsigned char fRequestBuffer[REQUEST_BUFFER_SIZE]; unsigned char fResponseBuffer[RESPONSE_BUFFER_SIZE]; unsigned fRequestBytesAlreadySeen, fRequestBufferBytesLeft; }; From their definitions, it's not hard to understand that their responsibilities are primarily to handle network I/O, handle RTSP requests, and establish sessions. Let's look at RTSPServer::RTSPClientSession the definition: class RTSPServer: public GenericMediaServer { . . . . . . // The state of an individual client session (using one or more sequential TCP connections) handled by a RTSP server: class RTSPClientSession: public GenericMediaServer::ClientSession { protected: RTSPClientSession(RTSPServer& ourServer, u_int32_t sessionId); virtual ~RTSPClientSession(); friend class RTSPServer; friend class RTSPClientConnection; // Make the handler functions for each command virtual, to allow subclasses to redefine them: virtual void handleCmd_SETUP(RTSPClientConnection* ourClientConnection, char const* urlPreSuffix, char const* urlSuffix, char const* fullRequestStr); virtual void handleCmd_withinSession(RTSPClientConnection* ourClientConnection, char const* cmdName, char const* urlPreSuffix, char const* urlSuffix, char const* fullRequestStr); virtual void handleCmd_TEARDOWN(RTSPClientConnection* ourClientConnection, ServerMediaSubsession* subsession); virtual void handleCmd_PLAY(RTSPClientConnection* ourClientConnection, ServerMediaSubsession* subsession, char const* fullRequestStr); virtual void handleCmd_PAUSE(RTSPClientConnection* ourClientConnection, ServerMediaSubsession* subsession); virtual void handleCmd_GET_PARAMETER(RTSPClientConnection* ourClientConnection, ServerMediaSubsession* subsession, char const* fullRequestStr); virtual void handleCmd_SET_PARAMETER(RTSPClientConnection* ourClientConnection, ServerMediaSubsession* subsession, char const* fullRequestStr); protected: void deleteStreamByTrack(unsigned trackNum); void reclaimStreamStates(); Boolean isMulticast() const { return fIsMulticast; } // Shortcuts for setting up a RTSP response (prior to sending it): void setRTSPResponse(RTSPClientConnection* ourClientConnection, char const* responseStr) { ourClientConnection->setRTSPResponse(responseStr); } void setRTSPResponse(RTSPClientConnection* ourClientConnection, char const* responseStr, u_int32_t sessionId) { ourClientConnection->setRTSPResponse(responseStr, sessionId); } void setRTSPResponse(RTSPClientConnection* ourClientConnection, char const* responseStr, char const* contentStr) { ourClientConnection->setRTSPResponse(responseStr, contentStr); } void setRTSPResponse(RTSPClientConnection* ourClientConnection, char const* responseStr, u_int32_t sessionId, char const* contentStr) { ourClientConnection->setRTSPResponse(responseStr, sessionId, contentStr); } protected: RTSPServer& fOurRTSPServer; // same as ::fOurServer Boolean fIsMulticast, fStreamAfterSETUP; unsigned char fTCPStreamIdCount; // used for (optional) RTP/TCP Boolean usesTCPTransport() const { return fTCPStreamIdCount > 0; } unsigned fNumStreamStates; struct streamState { ServerMediaSubsession* subsession; int tcpSocketNum; void* streamToken; } * fStreamStates; }; RTSPServer::RTSPClientSession inherited from GenericMediaServer::ClientSession: // The state of an individual client session (using one or more sequential TCP connections) handled by a server: class ClientSession { protected: ClientSession(GenericMediaServer& ourServer, u_int32_t sessionId); virtual ~ ClientSession (); UsageEnvironment& envir() { return fOurServer.envir(); } void noteLiveness(); static void noteClientLiveness(ClientSession* clientSession); static void livenessTimeoutTask(ClientSession* clientSession); protected: friend class GenericMediaServer; friend class ClientConnection; GenericMediaServer& fOurServer; u_int32_t fOurSessionId; ServerMediaSession* fOurServerMediaSession; TaskToken fLivenessCheckTask; }; It will be appreciated RTSPServer::RTSPClientSession for enclosing the entire streaming session, an RTSP request that requires processing streaming media session has been established, such as PLAY the like. Specific interactive streaming media data, such as audio and video files / parsed data, RTP/RTCP data package and a transceiver or the like, dependent on ServerMediaSession and ServerMediaSubsession. Reward Done. 1.1. Live555 source code analysis series Live555 Source code analysis: Introduction live555 Source code analysis: Infrastructure live555 Source code analysis: MediaSever Wireshark capture packet analysis RTSP/RTP/RTCP Basic working process live555 Source code analysis: RTSPServer live555 Source code analysis: DESCRIBE processing live555 Source code analysis: SETUP processing live555 Source code analysis :PLAY processing live555 Source code analysis: RTSPServer component structure live555 Source code analysis: ServerMediaSession live555 Source code analysis: sub-session SDP line generation live555 Source code analysis: sub-session SETUP live555 Source code analysis: play start "},"Live555 - Live555 source code analysis_servermediasession.html":{"url":"Live555 - Live555 source code analysis_servermediasession.html","title":"Live555 - Live555 source code analysis_servermediasession","keywords":"","body":"1. Live555 Source code analysis: ServerMediaSession1.1. ServerMediaSession1.2. ServerMediaSubsession1.3. Live555 source code analysis series1. Live555 Source code analysis: ServerMediaSession Posted on 2017-09-07 | In live555 Live555 Source code analysis: ServerMediaSession ServerMediaSession ServerMediaSubsession Live555 source code analysis series In live555, treated with a ServerMediaSession represents a streaming media session, it connects RTSPServer and lower streaming logic. ServerMediaSession and ServerMediaSubsession the common bottom for performing streaming and state maintenance. And ServerMediaSession it is GenericMediaServer by HashTable to maintain. In the analysis processing live555 DESCRIBE requested code ( live555 source code analysis: DESCRIBE the process ), we have seen RTSPServer::RTSPClientConnection to SDP message generated by it. This article analyzes the definition and implementation of this class in more detail. 1.1. ServerMediaSession First, look at the ServerMediaSession definition: class ServerMediaSubsession; // forward class ServerMediaSession: public Medium { public: static ServerMediaSession* createNew(UsageEnvironment& env, char const* streamName = NULL, char const* info = NULL, char const* description = NULL, Boolean isSSM = False, char const* miscSDPLines = NULL); static Boolean lookupByName(UsageEnvironment& env, char const* mediumName, ServerMediaSession*& resultSession); char* generateSDPDescription(); // based on the entire session // Note: The caller is responsible for freeing the returned string char const* streamName() const { return fStreamName; } Boolean addSubsession(ServerMediaSubsession* subsession); unsigned numSubsessions() const { return fSubsessionCounter; } void testScaleFactor(float& scale); // sets \"scale\" to the actual supported scale float duration() const; // a result == 0 means an unbounded session (the default) // a result 0 means: this is the duration of a bounded session virtual void noteLiveness(); // called whenever a client - accessing this media - notes liveness. // The default implementation does nothing, but subclasses can redefine this - e.g., if you // want to remove long-unused \"ServerMediaSession\"s from the server. unsigned referenceCount() const { return fReferenceCount; } void incrementReferenceCount() { ++fReferenceCount; } void decrementReferenceCount() { if (fReferenceCount > 0) --fReferenceCount; } Boolean& deleteWhenUnreferenced() { return fDeleteWhenUnreferenced; } void deleteAllSubsessions(); // Removes and deletes all subsessions added by \"addSubsession()\", returning us to an 'empty' state // Note: If you have already added this \"ServerMediaSession\" to a \"RTSPServer\" then, before calling this function, // you must first close any client connections that use it, // by calling \"RTSPServer::closeAllClientSessionsForServerMediaSession()\". protected: ServerMediaSession(UsageEnvironment& env, char const* streamName, char const* info, char const* description, Boolean isSSM, char const* miscSDPLines); // called only by \"createNew()\" virtual ~ServerMediaSession(); private: // redefined virtual functions virtual Boolean isServerMediaSession() const; private: Boolean fIsSSM; // Linkage fields: friend class ServerMediaSubsessionIterator; ServerMediaSubsession* fSubsessionsHead; ServerMediaSubsession* fSubsessionsTail; unsigned fSubsessionCounter; char* fStreamName; char* fInfoSDPString; char* fDescriptionSDPString; char* fMiscSDPLines; struct timeval fCreationTime; unsigned fReferenceCount; Boolean fDeleteWhenUnreferenced; }; From this definition, difficult to understand, it is mainly ServerMediaSubsession a container, and to maintain them through a one-way linked list. And provides the entire operation requires the action of a streaming media session all sub-session, such as the SDP message is generated generateSDPDescription() and the playback speed is set testScaleFactor(). ServerMediaSession Create objects, like live555 created many classes as through a static creation functions createNew() to achieve, the function is defined as follows: ServerMediaSession* ServerMediaSession ::createNew(UsageEnvironment& env, char const* streamName, char const* info, char const* description, Boolean isSSM, char const* miscSDPLines) { return new ServerMediaSession(env, streamName, info, description, isSSM, miscSDPLines); } . . . . . . static char const* const libNameStr = \"LIVE555 Streaming Media v\"; char const* const libVersionStr = LIVEMEDIA_LIBRARY_VERSION_STRING; ServerMediaSession::ServerMediaSession(UsageEnvironment& env, char const* streamName, char const* info, char const* description, Boolean isSSM, char const* miscSDPLines) : Medium(env), fIsSSM(isSSM), fSubsessionsHead(NULL), fSubsessionsTail(NULL), fSubsessionCounter(0), fReferenceCount(0), fDeleteWhenUnreferenced(False) { fStreamName = strDup(streamName == NULL ? \"\" : streamName); char* libNamePlusVersionStr = NULL; // by default if (info == NULL || description == NULL) { libNamePlusVersionStr = new char[strlen(libNameStr) + strlen(libVersionStr) + 1]; sprintf(libNamePlusVersionStr, \"%s%s\", libNameStr, libVersionStr); } fInfoSDPString = strDup(info == NULL ? libNamePlusVersionStr : info); fDescriptionSDPString = strDup(description == NULL ? libNamePlusVersionStr : description); delete[] libNamePlusVersionStr; fMiscSDPLines = strDup(miscSDPLines == NULL ? \"\" : miscSDPLines); gettimeofday(&fCreationTime, NULL); } ServerMediaSession::~ServerMediaSession() { deleteAllSubsessions(); delete[] fStreamName; delete[] fInfoSDPString; delete[] fDescriptionSDPString; delete[] fMiscSDPLines; } Each ServerMediaSession consists of a string of the streamName identifier, the identifier is in GenericMediaServer by HashTable time to maintain, with the key. streamName Passed by the caller when it is created. For \"LIVE555 Media Server\", this value is the path to the resource. The caller can also be passed when creating info and description providing more descriptive information about the session. For \"LIVE555 Media Server\", info the same as the path of the resource, but description a string containing the streaming media type format \"$MediaType, streamed by the LIVE555 Media Server\", such as for H.264 video \"H.264 Video, streamed by the LIVE555 Media Server\"。 When you create an object, you mainly initialize the state with the value passed in by the caller. Like many other Medium sub-classes, ServerMediaSession also it provides an object lookup functions: Boolean ServerMediaSession ::lookupByName(UsageEnvironment& env, char const* mediumName, ServerMediaSession*& resultSession) { resultSession = NULL; // unless we succeed Medium* medium; if (!Medium::lookupByName(env, mediumName, medium)) return False; if (!medium->isServerMediaSession()) { env.setResultMsg(mediumName, \" is not a 'ServerMediaSession' object\"); return False; } resultSession = (ServerMediaSession*)medium; return True; } As ServerMediaSubsession containers, ServerMediaSession also provides ServerMediaSubsession the added management operations: Boolean ServerMediaSession::addSubsession(ServerMediaSubsession* subsession) { if (subsession->fParentSession != NULL) return False; // it's already used if (fSubsessionsTail == NULL) { fSubsessionsHead = subsession; } else { fSubsessionsTail->fNext = subsession; } fSubsessionsTail = subsession; subsession->fParentSession = this; subsession->fTrackNumber = ++fSubsessionCounter; return True; } . . . . . . void ServerMediaSession::noteLiveness() { // default implementation: do nothing } void ServerMediaSession::deleteAllSubsessions() { Medium::close(fSubsessionsHead); fSubsessionsHead = fSubsessionsTail = NULL; fSubsessionCounter = 0; } Boolean ServerMediaSession::isServerMediaSession() const { return True; } . . . . . . Ask ServerMediaSession when you add sub-session, the newly added sub-session will always be placed on a one-way linked list header. Time to add sub-session, the session will be based on the sub counter fSubsessionCounter assigned track number for the sub-session. SDP messages for generating generateSDPDescription() and duration() function, and to set the speed of playback testScaleFactor(float& scale) functions, in live555 source analysis: the DESCRIBE processing and live555 source code analysis: PLAY processing is already described in a more detailed manner, is not repeated here. For easy access ServerMediaSubsession, live555 also provides an iterator, which is defined as follows: class ServerMediaSubsessionIterator { public: ServerMediaSubsessionIterator(ServerMediaSession& session); virtual ~ServerMediaSubsessionIterator(); ServerMediaSubsession* next(); // NULL if none void reset(); private: ServerMediaSession& fOurSession; ServerMediaSubsession* fNextPtr; }; The iterator is implemented as follows: ServerMediaSubsessionIterator ::ServerMediaSubsessionIterator(ServerMediaSession& session) : fOurSession(session) { reset(); } ServerMediaSubsessionIterator::~ServerMediaSubsessionIterator() { } ServerMediaSubsession* ServerMediaSubsessionIterator::next() { ServerMediaSubsession* result = fNextPtr; if (fNextPtr != NULL) fNextPtr = fNextPtr->fNext; return result; } void ServerMediaSubsessionIterator::reset() { fNextPtr = fOurSession.fSubsessionsHead; } We can see ServerMediaSession and there is not much content. Most of the time, it obtained only as ServerMediaSubsession an intermediary exists. 1.2. ServerMediaSubsession In the RTSPServer::RTSPClientSession processing SETUP code requests, we see it from ServerMediaSession obtaining ServerMediaSubsession and took over their management, and bypass ServerMediaSession direct to ServerMediaSubsession operate. The entry to perform data operations for a single session of streaming media is also there ServerMediaSubsession. For the case of requesting an H.264 video file from the \"LIVE555 Media Server\" server, ServerMediaSubsession the actual type is H264VideoFileServerMediaSubsession, we use this as an example to analyze ServerMediaSubsession. H264VideoFileServerMediaSubsession In the DynamicRTSPServer class lookupServerMediaSession() in with the ServerMediaSession creation together to create and be added directly to the ServerMediaSession medium. #define NEW_SMS(description) do {\\ char const* descStr = description\\ \", streamed by the LIVE555 Media Server\";\\ sms = ServerMediaSession::createNew(env, fileName, fileName, descStr);\\ } while(0) . . . . . . } else if (strcmp(extension, \".264\") == 0) { // Assumed to be a H.264 Video Elementary Stream file: NEW_SMS(\"H.264 Video\"); OutPacketBuffer::maxSize = 100000; // allow for some possibly large H.264 frames sms->addSubsession(H264VideoFileServerMediaSubsession::createNew(env, fileName, reuseSource)); } H264VideoFileServerMediaSubsession has an inheritance system as shown below: In this inheritance system, ServerMediaSubsession operations that can be performed on a single stream are defined. The definition of the class is as follows: class ServerMediaSubsession: public Medium { public: unsigned trackNumber() const { return fTrackNumber; } char const* trackId(); virtual char const* sdpLines() = 0; virtual void getStreamParameters(unsigned clientSessionId, // in netAddressBits clientAddress, // in Port const& clientRTPPort, // in Port const& clientRTCPPort, // in int tcpSocketNum, // in (-1 means use UDP, not TCP) unsigned char rtpChannelId, // in (used if TCP) unsigned char rtcpChannelId, // in (used if TCP) netAddressBits& destinationAddress, // in out u_int8_t& destinationTTL, // in out Boolean& isMulticast, // out Port& serverRTPPort, // out Port& serverRTCPPort, // out void*& streamToken // out ) = 0; virtual void startStream(unsigned clientSessionId, void* streamToken, TaskFunc* rtcpRRHandler, void* rtcpRRHandlerClientData, unsigned short& rtpSeqNum, unsigned& rtpTimestamp, ServerRequestAlternativeByteHandler* serverRequestAlternativeByteHandler, void* serverRequestAlternativeByteHandlerClientData) = 0; virtual void pauseStream(unsigned clientSessionId, void* streamToken); virtual void seekStream(unsigned clientSessionId, void* streamToken, double& seekNPT, double streamDuration, u_int64_t& numBytes); // This routine is used to seek by relative (i.e., NPT) time. // \"streamDuration\", if >0.0, specifies how much data to stream, past \"seekNPT\". (If Z\". // \"absEnd\" should be either NULL (for no end time), or a string of the same form as \"absStart\". // These strings may be modified in-place, or can be reassigned to a newly-allocated value (after delete[]ing the original). virtual void nullSeekStream(unsigned clientSessionId, void* streamToken, double streamEndTime, u_int64_t& numBytes); // Called whenever we're handling a \"PLAY\" command without a specified start time. virtual void setStreamScale(unsigned clientSessionId, void* streamToken, float scale); virtual float getCurrentNPT(void* streamToken); virtual FramedSource* getStreamSource(void* streamToken); virtual void getRTPSinkandRTCP(void* streamToken, RTPSink const*& rtpSink, RTCPInstance const*& rtcp) = 0; // Returns pointers to the \"RTPSink\" and \"RTCPInstance\" objects for \"streamToken\". // (This can be useful if you want to get the associated 'Groupsock' objects, for example.) // You must not delete these objects, or start/stop playing them; instead, that is done // using the \"startStream()\" and \"deleteStream()\" functions. virtual void deleteStream(unsigned clientSessionId, void*& streamToken); virtual void testScaleFactor(float& scale); // sets \"scale\" to the actual supported scale virtual float duration() const; // returns 0 for an unbounded session (the default) // returns > 0 for a bounded session virtual void getAbsoluteTimeRange(char*& absStartTime, char*& absEndTime) const; // Subclasses can reimplement this iff they support seeking by 'absolute' time. // The following may be called by (e.g.) SIP servers, for which the // address and port number fields in SDP descriptions need to be non-zero: void setServerAddressAndPortForSDP(netAddressBits addressBits, portNumBits portBits); protected: // we're a virtual base class ServerMediaSubsession(UsageEnvironment& env); virtual ~ServerMediaSubsession(); char const* rangeSDPLine() const; // returns a string to be delete[]d ServerMediaSession* fParentSession; netAddressBits fServerAddressForSDP; portNumBits fPortNumForSDP; private: friend class ServerMediaSession; friend class ServerMediaSubsessionIterator; ServerMediaSubsession* fNext; unsigned fTrackNumber; // within an enclosing ServerMediaSession char const* fTrackId; }; These operations may be divided into several categories, one is a playback control operation, including startStream(), pauseStream(), seekStream(), nullSeekStream(), setStreamScale(), deleteStream() and testScaleFactor(); the other is obtained for performing I/O operations FramedSource and RTPSink the getStreamSource() and getRTPSinkandRTCP(). ServerMediaSubsession The class provides implementations of common operations for several subsessions, including mainly for generating track ids in the form of strings trackId(), for setting the SDP server address and port number setServerAddressAndPortForSDP(), and for generating SDP lines for subsessions rangeSDPLine(): ServerMediaSubsession::ServerMediaSubsession(UsageEnvironment& env) : Medium(env), fParentSession(NULL), fServerAddressForSDP(0), fPortNumForSDP(0), fNext(NULL), fTrackNumber(0), fTrackId(NULL) { } ServerMediaSubsession::~ServerMediaSubsession() { delete[] (char*)fTrackId; Medium::close(fNext); } char const* ServerMediaSubsession::trackId() { if (fTrackNumber == 0) return NULL; // not yet in a ServerMediaSession if (fTrackId == NULL) { char buf[100]; sprintf(buf, \"track%d\", fTrackNumber); fTrackId = strDup(buf); } return fTrackId; } . . . . . . void ServerMediaSubsession::setServerAddressAndPortForSDP(netAddressBits addressBits, portNumBits portBits) { fServerAddressForSDP = addressBits; fPortNumForSDP = portBits; } char const* ServerMediaSubsession::rangeSDPLine() const { // First, check for the special case where we support seeking by 'absolute' time: char* absStart = NULL; char* absEnd = NULL; getAbsoluteTimeRange(absStart, absEnd); if (absStart != NULL) { char buf[100]; if (absEnd != NULL) { sprintf(buf, \"a=range:clock=%s-%s\\r\\n\", absStart, absEnd); } else { sprintf(buf, \"a=range:clock=%s-\\r\\n\", absStart); } return strDup(buf); } if (fParentSession == NULL) return NULL; // If all of our parent's subsessions have the same duration // (as indicated by \"fParentSession->duration() >= 0\"), there's no \"a=range:\" line: if (fParentSession->duration() >= 0.0) return strDup(\"\"); // Use our own duration for a \"a=range:\" line: float ourDuration = duration(); if (ourDuration == 0.0) { return strDup(\"a=range:npt=0-\\r\\n\"); } else { char buf[100]; sprintf(buf, \"a=range:npt=0-%.3f\\r\\n\", ourDuration); return strDup(buf); } } These operations are relatively concise and will not be described here. For many other interfaces that operate on a single stream, the ServerMediaSubsession class simply provides an empty default implementation: void ServerMediaSubsession::pauseStream(unsigned /*clientSessionId*/, void* /*streamToken*/) { // default implementation: do nothing } void ServerMediaSubsession::seekStream(unsigned /*clientSessionId*/, void* /*streamToken*/, double& /*seekNPT*/, double /*streamDuration*/, u_int64_t& numBytes) { // default implementation: do nothing numBytes = 0; } void ServerMediaSubsession::seekStream(unsigned /*clientSessionId*/, void* /*streamToken*/, char*& absStart, char*& absEnd) { // default implementation: do nothing (but delete[] and assign \"absStart\" and \"absEnd\" to NULL, to show that we don't handle this) delete[] absStart; absStart = NULL; delete[] absEnd; absEnd = NULL; } void ServerMediaSubsession::nullSeekStream(unsigned /*clientSessionId*/, void* /*streamToken*/, double streamEndTime, u_int64_t& numBytes) { // default implementation: do nothing numBytes = 0; } void ServerMediaSubsession::setStreamScale(unsigned /*clientSessionId*/, void* /*streamToken*/, float /*scale*/) { // default implementation: do nothing } float ServerMediaSubsession::getCurrentNPT(void* /*streamToken*/) { // default implementation: return 0.0 return 0.0; } FramedSource* ServerMediaSubsession::getStreamSource(void* /*streamToken*/) { // default implementation: return NULL return NULL; } void ServerMediaSubsession::deleteStream(unsigned /*clientSessionId*/, void*& /*streamToken*/) { // default implementation: do nothing } void ServerMediaSubsession::testScaleFactor(float& scale) { // default implementation: Support scale = 1 only scale = 1; } float ServerMediaSubsession::duration() const { // default implementation: assume an unbounded session: return 0.0; } void ServerMediaSubsession::getAbsoluteTimeRange(char*& absStartTime, char*& absEndTime) const { // default implementation: We don't support seeking by 'absolute' time, so indicate this by setting both parameters to NULL: absStartTime = absEndTime = NULL; } OnDemandServerMediaSubsession realized by a ServerMediaSubsession defined stream operator interface. In order to achieve these operations, some I/O operations are required, such as parsing streaming media files, transceiving RTP/RTCP packets, and so on. These I/O operation due to the different specific types of streaming media sources differ, and therefore not directly in the OnDemandServerMediaSubsession implementation. OnDemandServerMediaSubsession It defines a new virtual function, so as to obtain from the subclass FramedSource and RTPSink objects, to perform I/O operations. OnDemandServerMediaSubsession The specific implementation will not be explained in detail for the time being. In H264VideoFileServerMediaSubsession the class inheritance hierarchy, the FileServerMediaSubsession file name for the maintenance resources, which is defined as follows: class FileServerMediaSubsession: public OnDemandServerMediaSubsession { protected: // we're a virtual base class FileServerMediaSubsession(UsageEnvironment& env, char const* fileName, Boolean reuseFirstSource); virtual ~FileServerMediaSubsession(); protected: char const* fFileName; u_int64_t fFileSize; // if known }; This definition is very simple and its implementation is simple: FileServerMediaSubsession ::FileServerMediaSubsession(UsageEnvironment& env, char const* fileName, Boolean reuseFirstSource) : OnDemandServerMediaSubsession(env, reuseFirstSource), fFileSize(0) { fFileName = strDup(fileName); } FileServerMediaSubsession::~FileServerMediaSubsession() { delete[] (char*)fFileName; } H264VideoFileServerMediaSubsession the main function is to provide means for performing I/O operations FramedSource and RTPSink defined as follows: class H264VideoFileServerMediaSubsession: public FileServerMediaSubsession { public: static H264VideoFileServerMediaSubsession* createNew(UsageEnvironment& env, char const* fileName, Boolean reuseFirstSource); // Used to implement \"getAuxSDPLine()\": void checkForAuxSDPLine1(); void afterPlayingDummy1(); protected: H264VideoFileServerMediaSubsession(UsageEnvironment& env, char const* fileName, Boolean reuseFirstSource); // called only by createNew(); virtual ~H264VideoFileServerMediaSubsession(); void setDoneFlag() { fDoneFlag = ~0; } protected: // redefined virtual functions virtual char const* getAuxSDPLine(RTPSink* rtpSink, FramedSource* inputSource); virtual FramedSource* createNewStreamSource(unsigned clientSessionId, unsigned& estBitrate); virtual RTPSink* createNewRTPSink(Groupsock* rtpGroupsock, unsigned char rtpPayloadTypeIfDynamic, FramedSource* inputSource); private: char* fAuxSDPLine; char fDoneFlag; // used when setting up \"fAuxSDPLine\" RTPSink* fDummyRTPSink; // ditto }; H264VideoFileServerMediaSubsession By implementing createNewStreamSource() and createNewRTPSink() creates and returns FramedSource and RTPSink: FramedSource* H264VideoFileServerMediaSubsession::createNewStreamSource(unsigned /*clientSessionId*/, unsigned& estBitrate) { estBitrate = 500; // kbps, estimate // Create the video source: ByteStreamFileSource* fileSource = ByteStreamFileSource::createNew(envir(), fFileName); if (fileSource == NULL) return NULL; fFileSize = fileSource->fileSize(); // Create a framer for the Video Elementary Stream: return H264VideoStreamFramer::createNew(envir(), fileSource); } RTPSink* H264VideoFileServerMediaSubsession ::createNewRTPSink(Groupsock* rtpGroupsock, unsigned char rtpPayloadTypeIfDynamic, FramedSource* /*inputSource*/) { return H264VideoRTPSink::createNew(envir(), rtpGroupsock, rtpPayloadTypeIfDynamic); } Here returned FramedSource to H264VideoStreamFramer returned RTPSink to H264VideoRTPSink. In addition to this, H264VideoFileServerMediaSubsession the interface implementation of the AUX SDP line is also provided: H264VideoFileServerMediaSubsession::H264VideoFileServerMediaSubsession(UsageEnvironment& env, char const* fileName, Boolean reuseFirstSource) : FileServerMediaSubsession(env, fileName, reuseFirstSource), fAuxSDPLine(NULL), fDoneFlag(0), fDummyRTPSink(NULL) { } H264VideoFileServerMediaSubsession::~H264VideoFileServerMediaSubsession() { delete[] fAuxSDPLine; } static void afterPlayingDummy(void* clientData) { H264VideoFileServerMediaSubsession* subsess = (H264VideoFileServerMediaSubsession*)clientData; subsess->afterPlayingDummy1(); } void H264VideoFileServerMediaSubsession::afterPlayingDummy1() { // Unschedule any pending 'checking' task: envir().taskScheduler().unscheduleDelayedTask(nextTask()); // Signal the event loop that we're done: setDoneFlag(); } static void checkForAuxSDPLine(void* clientData) { H264VideoFileServerMediaSubsession* subsess = (H264VideoFileServerMediaSubsession*)clientData; subsess->checkForAuxSDPLine1(); } void H264VideoFileServerMediaSubsession::checkForAuxSDPLine1() { nextTask() = NULL; char const* dasl; if (fAuxSDPLine != NULL) { // Signal the event loop that we're done: setDoneFlag(); } else if (fDummyRTPSink != NULL && (dasl = fDummyRTPSink->auxSDPLine()) != NULL) { fAuxSDPLine = strDup(dasl); fDummyRTPSink = NULL; // Signal the event loop that we're done: setDoneFlag(); } else if (!fDoneFlag) { // try again after a brief delay: int uSecsToDelay = 100000; // 100 ms nextTask() = envir().taskScheduler().scheduleDelayedTask(uSecsToDelay, (TaskFunc*) checkForAuxSDPLine, this); } } char const* H264VideoFileServerMediaSubsession::getAuxSDPLine(RTPSink* rtpSink, FramedSource* inputSource) { if (fAuxSDPLine != NULL) return fAuxSDPLine; // it's already been set up (for a previous client) if (fDummyRTPSink == NULL) { // we're not already setting it up for another, concurrent stream // Note: For H264 video files, the 'config' information (\"profile-level-id\" and \"sprop-parameter-sets\") isn't known // until we start reading the file. This means that \"rtpSink\"s \"auxSDPLine()\" will be NULL initially, // and we need to start reading data from our file until this changes. fDummyRTPSink = rtpSink; // Start reading the file: fDummyRTPSink->startPlaying(*inputSource, afterPlayingDummy, this); // Check whether the sink's 'auxSDPLine()' is ready: checkForAuxSDPLine(this); } envir().taskScheduler().doEventLoop(&fDoneFlag); return fAuxSDPLine; } Reward Done. 1.3. Live555 source code analysis series Live555 Source code analysis: Introduction live555 Source code analysis: Infrastructure live555 Source code analysis: MediaSever Wireshark capture packet analysis RTSP/RTP/RTCP Basic working process live555 Source code analysis: RTSPServer live555 Source code analysis: DESCRIBE processing live555 Source code analysis: SETUP processing live555 Source code analysis :PLAY processing live555 Source code analysis: RTSPServer component structure live555 Source code analysis: ServerMediaSession live555 Source code analysis: sub-session SDP line generation live555 Source code analysis: sub-session SETUP live555 Source code analysis: play start "},"Live555 - Live555 source code analysis_subsession SDP line generation.html":{"url":"Live555 - Live555 source code analysis_subsession SDP line generation.html","title":"Live555 - Live555 source code analysis_subsession SDP line generation","keywords":"","body":"1. Live555 source code analysis: sub-session SDP line generation1.1. Live555 source code analysis series1. Live555 source code analysis: sub-session SDP line generation Posted on 2017-09-07 | In live555 Live555 source code analysis: sub-session SDP line generation Live555 source code analysis series As we saw in the previous live555 source code analysis: ServerMediaSession , H264VideoFileServerMediaSubsession the inheritance hierarchy is as follows: In this inheritance hierarchy, ServerMediaSubsession an operation that can be performed on a single subsession of streaming media is defined, which has a life cycle as follows: For achieving these operations is the OnDemandServerMediaSubsession complete, analysis defined herein and class implementation. Let's take a look at the SDP message line that will be used when sdpLines() processing RTSP DESCRIBE messages: char const* OnDemandServerMediaSubsession::sdpLines() { if (fSDPLines == NULL) { // We need to construct a set of SDP lines that describe this // subsession (as a unicast stream). To do so, we first create // dummy (unused) source and \"RTPSink\" objects, // whose parameters we use for the SDP lines: unsigned estBitrate; FramedSource* inputSource = createNewStreamSource(0, estBitrate); if (inputSource == NULL) return NULL; // file not found struct in_addr dummyAddr; dummyAddr.s_addr = 0; Groupsock* dummyGroupsock = createGroupsock(dummyAddr, 0); unsigned char rtpPayloadType = 96 + trackNumber()-1; // if dynamic RTPSink* dummyRTPSink = createNewRTPSink(dummyGroupsock, rtpPayloadType, inputSource); if (dummyRTPSink != NULL && dummyRTPSink->estimatedBitrate() > 0) estBitrate = dummyRTPSink->estimatedBitrate(); setSDPLinesFromRTPSink(dummyRTPSink, inputSource, estBitrate); Medium::close(dummyRTPSink); delete dummyGroupsock; closeStreamSource(inputSource); } fprintf(stderr, \"OnDemandServerMediaSubsession::sdpLines(): %s\\n\", fSDPLines); return fSDPLines; } The steps performed by this function are as follows: Step 1, to call createNewStreamSource() the function to create FramedSource. createNewStreamSource() Functions H264VideoFileServerMediaSubsession are defined: FramedSource* H264VideoFileServerMediaSubsession::createNewStreamSource(unsigned /*clientSessionId*/, unsigned& estBitrate) { estBitrate = 500; // kbps, estimate // Create the video source: ByteStreamFileSource* fileSource = ByteStreamFileSource::createNew(envir(), fFileName); if (fileSource == NULL) return NULL; fFileSize = fileSource->fileSize(); // Create a framer for the Video Elementary Stream: return H264VideoStreamFramer::createNew(envir(), fileSource); } Return FramedSource to ByteStreamFileSource. FramedSource Used to get a single frame in a video stream with an inheritance hierarchy like this: Step 2, call the createGroupsock() function to create Groupsock. Groupsock* OnDemandServerMediaSubsession ::createGroupsock(struct in_addr const& addr, Port port) { fprintf(stderr, \"OnDemandServerMediaSubsession::createGroupsock().\\n\"); // Default implementation; may be redefined by subclasses: return new Groupsock(envir(), addr, port, 255); } In step 3, calculate the RTP payload type. Step 4, call the createNewRTPSink() creation RTPSink, createNewRTPSink() also in H264VideoFileServerMediaSubsession implementation: RTPSink* H264VideoFileServerMediaSubsession ::createNewRTPSink(Groupsock* rtpGroupsock, unsigned char rtpPayloadTypeIfDynamic, FramedSource* /*inputSource*/) { return H264VideoRTPSink::createNew(envir(), rtpGroupsock, rtpPayloadTypeIfDynamic); } Passed in FramedSource has not been used. Return RTPSink toH264VideoRTPSink. H264VideoRTPSink The inheritance hierarchy is shown in the following figure: Step 5, call setSDPLinesFromRTPSink() generation SDP line. The first few steps are preparing for the execution of this step. This function is implemented as follows: void OnDemandServerMediaSubsession ::setSDPLinesFromRTPSink(RTPSink* rtpSink, FramedSource* inputSource, unsigned estBitrate) { fprintf(stderr, \"OnDemandServerMediaSubsession::setSDPLinesFromRTPSink().\\n\"); if (rtpSink == NULL) return; char const* mediaType = rtpSink->sdpMediaType(); unsigned char rtpPayloadType = rtpSink->rtpPayloadType(); AddressString ipAddressStr(fServerAddressForSDP); char* rtpmapLine = rtpSink->rtpmapLine(); char const* rtcpmuxLine = fMultiplexRTCPWithRTP ? \"a=rtcp-mux\\r\\n\" : \"\"; char const* rangeLine = rangeSDPLine(); char const* auxSDPLine = getAuxSDPLine(rtpSink, inputSource); if (auxSDPLine == NULL) auxSDPLine = \"\"; char const* const sdpFmt = \"m=%s %u RTP/AVP %d\\r\\n\" \"c=IN IP4 %s\\r\\n\" \"b=AS:%u\\r\\n\" \"%s\" \"%s\" \"%s\" \"%s\" \"a=control:%s\\r\\n\"; unsigned sdpFmtSize = strlen(sdpFmt) + strlen(mediaType) + 5 /* max short len */ + 3 /* max char len */ + strlen(ipAddressStr.val()) + 20 /* max int len */ + strlen(rtpmapLine) + strlen(rtcpmuxLine) + strlen(rangeLine) + strlen(auxSDPLine) + strlen(trackId()); char* sdpLines = new char[sdpFmtSize]; sprintf(sdpLines, sdpFmt, mediaType, // m= fPortNumForSDP, // m= rtpPayloadType, // m= ipAddressStr.val(), // c= address estBitrate, // b=AS: rtpmapLine, // a=rtpmap:... (if present) rtcpmuxLine, // a=rtcp-mux:... (if present) rangeLine, // a=range:... (if present) auxSDPLine, // optional extra SDP line trackId()); // a=control: delete[] (char*) rangeLine; delete[] rtpmapLine; fSDPLines = strDup(sdpLines); delete[] sdpLines; } In this function, you get the data needed to generate an SDP message and then generate an SDP message. mediaType From VideoRTPSink: char const* VideoRTPSink::sdpMediaType() const { return \"video\"; } It also VideoRTPSink provides the only function of. rtpPayloadType From RTPSink: unsigned char rtpPayloadType() const { return fRTPPayloadType; } In front sdpLines() obtained RTP payload types calculated in creating RTPSink the calculated value will be passed to it. What is returned here is the value calculated earlier. For H.264 video streams, this value is 96. The map line comes from RTPSink: char* RTPSink::rtpmapLine() const { if (rtpPayloadType() >= 96) { // the payload format type is dynamic char* encodingParamsPart; if (numChannels() != 1) { encodingParamsPart = new char[1 + 20 /* max int len */]; sprintf(encodingParamsPart, \"/%d\", numChannels()); } else { encodingParamsPart = strDup(\"\"); } char const* const rtpmapFmt = \"a=rtpmap:%d %s/%d%s\\r\\n\"; unsigned rtpmapFmtSize = strlen(rtpmapFmt) + 3 /* max char len */ + strlen(rtpPayloadFormatName()) + 20 /* max int len */ + strlen(encodingParamsPart); char* rtpmapLine = new char[rtpmapFmtSize]; sprintf(rtpmapLine, rtpmapFmt, rtpPayloadType(), rtpPayloadFormatName(), rtpTimestampFrequency(), encodingParamsPart); delete[] encodingParamsPart; return rtpmapLine; } else { // The payload format is staic, so there's no \"a=rtpmap:\" line: return strDup(\"\"); } } For RFC 3551 to assign a payload type of media type, no map line is required. For a dynamic payload type, the row is required, including the payload type, payload format name, timestamp frequency, etc. When the number of channels is greater than 1, the number of channels is also included. The number of channels comes from MultiFramedRTPSink: MultiFramedRTPSink(UsageEnvironment& env, Groupsock* rtpgs, unsigned char rtpPayloadType, unsigned rtpTimestampFrequency, char const* rtpPayloadFormatName, unsigned numChannels = 1); The payload format name and timestamp frequency are derived from the H264or5VideoRTPSink H.264 video stream, the payload format name is \"H264\", and the timestamp frequency is 90000: H264or5VideoRTPSink ::H264or5VideoRTPSink(int hNumber, UsageEnvironment& env, Groupsock* RTPgs, unsigned char rtpPayloadFormat, u_int8_t const* vps, unsigned vpsSize, u_int8_t const* sps, unsigned spsSize, u_int8_t const* pps, unsigned ppsSize) : VideoRTPSink(env, RTPgs, rtpPayloadFormat, 90000, hNumber == 264 ? \"H264\" : \"H265\"), fHNumber(hNumber), fOurFragmenter(NULL), fFmtpSDPLine(NULL) { Go back setSDPLinesFromRTPSink(). Then there is the range SDP line, which comes from ServerMediaSubsession: char const* ServerMediaSubsession::rangeSDPLine() const { // First, check for the special case where we support seeking by 'absolute' time: char* absStart = NULL; char* absEnd = NULL; getAbsoluteTimeRange(absStart, absEnd); if (absStart != NULL) { char buf[100]; if (absEnd != NULL) { sprintf(buf, \"a=range:clock=%s-%s\\r\\n\", absStart, absEnd); } else { sprintf(buf, \"a=range:clock=%s-\\r\\n\", absStart); } return strDup(buf); } if (fParentSession == NULL) return NULL; // If all of our parent's subsessions have the same duration // (as indicated by \"fParentSession->duration() >= 0\"), there's no \"a=range:\" line: if (fParentSession->duration() >= 0.0) return strDup(\"\"); // Use our own duration for a \"a=range:\" line: float ourDuration = duration(); if (ourDuration == 0.0) { return strDup(\"a=range:npt=0-\\r\\n\"); } else { char buf[100]; sprintf(buf, \"a=range:npt=0-%.3f\\r\\n\", ourDuration); return strDup(buf); } } Final SDP information is required to obtain line AUX SDP, information obtained from the video stream need to parse data by H264VideoFileServerMediaSubsession the getAuxSDPLine() function obtained: char const* H264VideoFileServerMediaSubsession::getAuxSDPLine(RTPSink* rtpSink, FramedSource* inputSource) { if (fAuxSDPLine != NULL) return fAuxSDPLine; // it's already been set up (for a previous client) if (fDummyRTPSink == NULL) { // we're not already setting it up for another, concurrent stream // Note: For H264 video files, the 'config' information (\"profile-level-id\" and \"sprop-parameter-sets\") isn't known // until we start reading the file. This means that \"rtpSink\"s \"auxSDPLine()\" will be NULL initially, // and we need to start reading data from our file until this changes. fDummyRTPSink = rtpSink; // Start reading the file: fDummyRTPSink->startPlaying(*inputSource, afterPlayingDummy, this); // Check whether the sink's 'auxSDPLine()' is ready: checkForAuxSDPLine(this); } envir().taskScheduler().doEventLoop(&fDoneFlag); return fAuxSDPLine; } This function on the first call, will pass RTPSink to start the streaming media file frame data is read, that is calling RTPSink the startPlaying() function. startPlaying() Function performs a long call chain, eventually calling ByteStreamFileSource the doGetNextFrame() function, the call stack as follows: #0 ByteStreamFileSource::doGetNextFrame (this=0x6e4f10) at ByteStreamFileSource.cpp:96 #1 0x00000000004308b4 in FramedSource::getNextFrame (this=0x6e4f10, to=0x7ffff7fd1010 \"\", maxSize=150000, afterGettingFunc=0x4740c2 , afterGettingClientData=0x6e5020, onCloseFunc=0x47424c , onCloseClientData=0x6e5020) at FramedSource.cpp:78 #2 0x0000000000474096 in StreamParser::ensureValidBytes1 (this=0x6e5020, numBytesNeeded=4) at StreamParser.cpp:159 #3 0x0000000000434fe1 in StreamParser::ensureValidBytes (this=0x6e5020, numBytesNeeded=4) at StreamParser.hh:118 #4 0x0000000000434d75 in StreamParser::test4Bytes (this=0x6e5020) at StreamParser.hh:54 #5 0x000000000047918e in H264or5VideoStreamParser::parse (this=0x6e5020) at H264or5VideoStreamFramer.cpp:951 #6 0x0000000000435de9 in MPEGVideoStreamFramer::continueReadProcessing (this=0x6e4710) at MPEGVideoStreamFramer.cpp:159 #7 0x0000000000435d51 in MPEGVideoStreamFramer::doGetNextFrame (this=0x6e4710) at MPEGVideoStreamFramer.cpp:142 #8 0x00000000004308b4 in FramedSource::getNextFrame (this=0x6e4710, to=0x6ff241 \"\", maxSize=100000, afterGettingFunc=0x47c788 , afterGettingClientData=0x6e5540, onCloseFunc=0x43092e , onCloseClientData=0x6e5540) at FramedSource.cpp:78 #9 0x000000000047c2c0 in H264or5Fragmenter::doGetNextFrame (this=0x6e5540) at H264or5VideoRTPSink.cpp:181 #10 0x00000000004308b4 in FramedSource::getNextFrame (this=0x6e5540, to=0x6e69cc \"\", maxSize=100452, afterGettingFunc=0x45d09c , afterGettingClientData=0x6e5220, onCloseFunc=0x45da86 , onCloseClientData=0x6e5220) at FramedSource.cpp:78 #11 0x000000000045d07b in MultiFramedRTPSink::packFrame (this=0x6e5220) at MultiFramedRTPSink.cpp:224 #12 0x000000000045cec8 in MultiFramedRTPSink::buildAndSendPacket (this=0x6e5220, isFirstPacket=1 '\\001') at MultiFramedRTPSink.cpp:199 #13 0x000000000045cd07 in MultiFramedRTPSink::continuePlaying (this=0x6e5220) at MultiFramedRTPSink.cpp:159 #14 0x000000000047bfe0 in H264or5VideoRTPSink::continuePlaying (this=0x6e5220) at H264or5VideoRTPSink.cpp:127 #15 0x0000000000405d2a in MediaSink::startPlaying (this=0x6e5220, source=..., afterFunc=0x422a12 , afterClientData=0x6e4aa0) at MediaSink.cpp:78 #16 0x0000000000422c5f in H264VideoFileServerMediaSubsession::getAuxSDPLine (this=0x6e4aa0, rtpSink=0x6e5220, inputSource=0x6e4710) at H264VideoFileServerMediaSubsession.cpp:92 #17 0x0000000000464cd4 in OnDemandServerMediaSubsession::setSDPLinesFromRTPSink (this=0x6e4aa0, rtpSink=0x6e5220, inputSource=0x6e4710, estBitrate=500) at OnDemandServerMediaSubsession.cpp:456 #18 0x000000000046378b in OnDemandServerMediaSubsession::sdpLines (this=0x6e4aa0) at OnDemandServerMediaSubsession.cpp:76 #19 0x000000000042198b in ServerMediaSession::generateSDPDescription (this=0x6e4900) at ServerMediaSession.cpp:240 ByteStreamFileSource ThedoGetNextFrame() streaming media data to the read start, to achieve this function is as follows: void ByteStreamFileSource::doGetNextFrame() { if (feof(fFid) || ferror(fFid) || (fLimitNumBytesToStream && fNumBytesToStream == 0)) { handleClosure(); return; } #ifdef READ_FROM_FILES_SYNCHRONOUSLY doReadFromFile(); #else if (!fHaveStartedReading) { // Await readable data from the file: envir().taskScheduler().turnOnBackgroundReadHandling(fileno(fFid), (TaskScheduler::BackgroundHandlerProc*)&fileReadableHandler, this); fHaveStartedReading = True; } #endif } For asynchronous read, the register is a read document processing program fileReadableHandler, for synchronous read, it is directly doReadFromFile() read the file data. Back H264VideoFileServerMediaSubsession in getAuxSDPLine(). Implementation of RTPSink the startPlaying() following, it will pass checkForAuxSDPLine(void* clientData) if the end of the check read the video stream metadata: static void checkForAuxSDPLine(void* clientData) { H264VideoFileServerMediaSubsession* subsess = (H264VideoFileServerMediaSubsession*)clientData; subsess->checkForAuxSDPLine1(); } void H264VideoFileServerMediaSubsession::checkForAuxSDPLine1() { nextTask() = NULL; char const* dasl; if (fAuxSDPLine != NULL) { // Signal the event loop that we're done: setDoneFlag(); } else if (fDummyRTPSink != NULL && (dasl = fDummyRTPSink->auxSDPLine()) != NULL) { fAuxSDPLine = strDup(dasl); fDummyRTPSink = NULL; // Signal the event loop that we're done: setDoneFlag(); } else if (!fDoneFlag) { // try again after a brief delay: int uSecsToDelay = 100000; // 100 ms nextTask() = envir().taskScheduler().scheduleDelayedTask(uSecsToDelay, (TaskFunc*) checkForAuxSDPLine, this); } } When this function is executed, if it finds that the aux SDP line has not been acquired, it will register a timer task and continue checking for a while. aux SDP line by RTPSink the auxSDPLine() acquisition, the actual implementation of the function is located in H264VideoRTPSink: char const* H264VideoRTPSink::auxSDPLine() { // Generate a new \"a=fmtp:\" line each time, using our SPS and PPS (if we have them), // otherwise parameters from our framer source (in case they've changed since the last time that // we were called): H264or5VideoStreamFramer* framerSource = NULL; u_int8_t* vpsDummy = NULL; unsigned vpsDummySize = 0; u_int8_t* sps = fSPS; unsigned spsSize = fSPSSize; u_int8_t* pps = fPPS; unsigned ppsSize = fPPSSize; if (sps == NULL || pps == NULL) { // We need to get SPS and PPS from our framer source: if (fOurFragmenter == NULL) return NULL; // we don't yet have a fragmenter (and therefore not a source) framerSource = (H264or5VideoStreamFramer*)(fOurFragmenter->inputSource()); if (framerSource == NULL) return NULL; // we don't yet have a source framerSource->getVPSandSPSandPPS(vpsDummy, vpsDummySize, sps, spsSize, pps, ppsSize); if (sps == NULL || pps == NULL) return NULL; // our source isn't ready } // Set up the \"a=fmtp:\" SDP line for this stream: u_int8_t* spsWEB = new u_int8_t[spsSize]; // \"WEB\" means \"Without Emulation Bytes\" unsigned spsWEBSize = removeH264or5EmulationBytes(spsWEB, spsSize, sps, spsSize); if (spsWEBSize assume our source isn't ready delete[] spsWEB; return NULL; } u_int32_t profileLevelId = (spsWEB[1] To generate SDP lines, SPS frames and PPS frames of video stream data are required. The two frames of data come from two sources, one of which is passed by the caller when the object is constructed: H264or5VideoRTPSink ::H264or5VideoRTPSink(int hNumber, UsageEnvironment& env, Groupsock* RTPgs, unsigned char rtpPayloadFormat, u_int8_t const* vps, unsigned vpsSize, u_int8_t const* sps, unsigned spsSize, u_int8_t const* pps, unsigned ppsSize) : VideoRTPSink(env, RTPgs, rtpPayloadFormat, 90000, hNumber == 264 ? \"H264\" : \"H265\"), fHNumber(hNumber), fOurFragmenter(NULL), fFmtpSDPLine(NULL) { if (vps != NULL) { fVPSSize = vpsSize; fVPS = new u_int8_t[fVPSSize]; memmove(fVPS, vps, fVPSSize); } else { fVPSSize = 0; fVPS = NULL; } if (sps != NULL) { fSPSSize = spsSize; fSPS = new u_int8_t[fSPSSize]; memmove(fSPS, sps, fSPSSize); } else { fSPSSize = 0; fSPS = NULL; } if (pps != NULL) { fPPSSize = ppsSize; fPPS = new u_int8_t[fPPSSize]; memmove(fPPS, pps, fPPSSize); } else { fPPSSize = 0; fPPS = NULL; } } The other is obtained from the data source: class H264or5VideoStreamFramer: public MPEGVideoStreamFramer { public: void getVPSandSPSandPPS(u_int8_t*& vps, unsigned& vpsSize, u_int8_t*& sps, unsigned& spsSize, u_int8_t*& pps, unsigned& ppsSize) const { // Returns pointers to copies of the most recently seen VPS (video parameter set) // SPS (sequence parameter set) and PPS (picture parameter set) NAL units. // (NULL pointers are returned if the NAL units have not yet been seen.) vps = fLastSeenVPS; vpsSize = fLastSeenVPSSize; sps = fLastSeenSPS; spsSize = fLastSeenSPSSize; pps = fLastSeenPPS; ppsSize = fLastSeenPPSSize; } For the case of obtaining SPS frames and PPS frames from the data source, after the data is retrieved from the file, the data is pushed framerSource, and the process of pushing the SPS is as follows: #0 H264or5VideoStreamFramer::saveCopyOfSPS (this=0x6e4710, from=0x6ff241 \"gB\\200*\\332\\001\\020\\017\\036^R\\n\\f\\n\\r\\241Bj\", size=18) at H264or5VideoStreamFramer.cpp:110 #1 0x00000000004798c4 in H264or5VideoStreamParser::parse (this=0x6e5020) at H264or5VideoStreamFramer.cpp:1069 #2 0x0000000000435de9 in MPEGVideoStreamFramer::continueReadProcessing (this=0x6e4710) at MPEGVideoStreamFramer.cpp:159 #3 0x0000000000435db4 in MPEGVideoStreamFramer::continueReadProcessing (clientData=0x6e4710) at MPEGVideoStreamFramer.cpp:155 #4 0x0000000000474249 in StreamParser::afterGettingBytes1 (this=0x6e5020, numBytesRead=150000, presentationTime=...) at StreamParser.cpp:191 #5 0x0000000000474112 in StreamParser::afterGettingBytes (clientData=0x6e5020, numBytesRead=150000, presentationTime=...) at StreamParser.cpp:170 #6 0x000000000043092a in FramedSource::afterGetting (source=0x6e4f10) at FramedSource.cpp:92 #7 0x0000000000431494 in ByteStreamFileSource::doReadFromFile (this=0x6e4f10) at ByteStreamFileSource.cpp:182 #8 0x0000000000431233 in ByteStreamFileSource::fileReadableHandler (source=0x6e4f10) at ByteStreamFileSource.cpp:126 #9 0x0000000000483a49 in BasicTaskScheduler::SingleStep (this=0x6d9c20, maxDelayTime=0) at BasicTaskScheduler.cpp:171 #10 0x00000000004864b4 in BasicTaskScheduler0::doEventLoop (this=0x6d9c20, watchVariable=0x6e4bb0 \"\") at BasicTaskScheduler0.cpp:80 #11 0x0000000000422c9c in H264VideoFileServerMediaSubsession::getAuxSDPLine (this=0x6e4aa0, rtpSink=0x6e5220, inputSource=0x6e4710) at H264VideoFileServerMediaSubsession.cpp:98 #12 0x0000000000464cd4 in OnDemandServerMediaSubsession::setSDPLinesFromRTPSink (this=0x6e4aa0, rtpSink=0x6e5220, inputSource=0x6e4710, estBitrate=500) at OnDemandServerMediaSubsession.cpp:456 #13 0x000000000046378b in OnDemandServerMediaSubsession::sdpLines (this=0x6e4aa0) at OnDemandServerMediaSubsession.cpp:76 #14 0x000000000042198b in ServerMediaSession::generateSDPDescription (this=0x6e4900) at ServerMediaSession.cpp:240 The process of pushing PPS is as follows: #0 H264or5VideoStreamFramer::saveCopyOfPPS (this=0x6e4710, from=0x6ff241 \"h\\316\\006\\342\\332\\001\\020\\017\\036^R\\n\\f\\n\\r\\241Bj\", size=4) at H264or5VideoStreamFramer.cpp:119 #1 0x0000000000479ad9 in H264or5VideoStreamParser::parse (this=0x6e5020) at H264or5VideoStreamFramer.cpp:1090 #2 0x0000000000435de9 in MPEGVideoStreamFramer::continueReadProcessing (this=0x6e4710) at MPEGVideoStreamFramer.cpp:159 #3 0x0000000000435d51 in MPEGVideoStreamFramer::doGetNextFrame (this=0x6e4710) at MPEGVideoStreamFramer.cpp:142 #4 0x00000000004308b4 in FramedSource::getNextFrame (this=0x6e4710, to=0x6ff241 \"h\\316\\006\\342\\332\\001\\020\\017\\036^R\\n\\f\\n\\r\\241Bj\", maxSize=100000, afterGettingFunc=0x47c788 , afterGettingClientData=0x6e5540, onCloseFunc=0x43092e , onCloseClientData=0x6e5540) at FramedSource.cpp:78 #5 0x000000000047c2c0 in H264or5Fragmenter::doGetNextFrame (this=0x6e5540) at H264or5VideoRTPSink.cpp:181 #6 0x00000000004308b4 in FramedSource::getNextFrame (this=0x6e5540, to=0x6e69cc \"gB\\200*\\332\\001\\020\\017\\036^R\\n\\f\\n\\r\\241Bj\", maxSize=100452, afterGettingFunc=0x45d09c , afterGettingClientData=0x6e5220, onCloseFunc=0x45da86 , onCloseClientData=0x6e5220) at FramedSource.cpp:78 #7 0x000000000045d07b in MultiFramedRTPSink::packFrame (this=0x6e5220) at MultiFramedRTPSink.cpp:224 #8 0x000000000045cec8 in MultiFramedRTPSink::buildAndSendPacket (this=0x6e5220, isFirstPacket=0 '\\000') at MultiFramedRTPSink.cpp:199 #9 0x000000000045da83 in MultiFramedRTPSink::sendNext (firstArg=0x6e5220) at MultiFramedRTPSink.cpp:422 #10 0x0000000000486c1b in AlarmHandler::handleTimeout (this=0x6e5760) at BasicTaskScheduler0.cpp:34 #11 0x0000000000484d1e in DelayQueue::handleAlarm (this=0x6d9c28) at DelayQueue.cpp:187 #12 0x0000000000483c4c in BasicTaskScheduler::SingleStep (this=0x6d9c20, maxDelayTime=0) at BasicTaskScheduler.cpp:212 #13 0x00000000004864b4 in BasicTaskScheduler0::doEventLoop (this=0x6d9c20, watchVariable=0x6e4bb0 \"\") at BasicTaskScheduler0.cpp:80 #14 0x0000000000422c9c in H264VideoFileServerMediaSubsession::getAuxSDPLine (this=0x6e4aa0, rtpSink=0x6e5220, inputSource=0x6e4710) at H264VideoFileServerMediaSubsession.cpp:98 #15 0x0000000000464cd4 in OnDemandServerMediaSubsession::setSDPLinesFromRTPSink (this=0x6e4aa0, rtpSink=0x6e5220, inputSource=0x6e4710, estBitrate=500) at OnDemandServerMediaSubsession.cpp:456 #16 0x000000000046378b in OnDemandServerMediaSubsession::sdpLines (this=0x6e4aa0) at OnDemandServerMediaSubsession.cpp:76 #17 0x000000000042198b in ServerMediaSession::generateSDPDescription (this=0x6e4900) at ServerMediaSession.cpp:240 Both SPS and PPS frame data are required to generate SDP lines. H264VideoRTPSink::auxSDPLine() When the SDP line data is not available, it returns null to the caller. For H264VideoFileServerMediaSubsession the checkForAuxSDPLine() purposes, in the case of the SDP can not get, is scheduled to perform a task timer again, waiting for the arrival of a check. In H264VideoRTPSink::auxSDPLine(), if the SPS and PPS data have, then it will first remove Emulation byte of SPS, SPS then calculated Base64 encoded frame data and PPS data frame, and, ultimately SDP line. The process of removing the Emulation bytes in SPS is like this: unsigned removeH264or5EmulationBytes(u_int8_t* to, unsigned toMaxSize, u_int8_t const* from, unsigned fromSize) { unsigned toSize = 0; unsigned i = 0; while (i The so-called Emulation byte is due to the Hx264 stream data, through the 0x00000001 and 0x000001 byte sequences as the segmentation sequence of the frame data, in order to prevent the decoder from misinterpreting such sequences in the encoded frame data as between frames. Split the sequence and force a 0x03 byte to be inserted when two 0x00 bytes of frame data are present. These bytes need to be removed first when calculating Base64 for SPS. H264VideoFileServerMediaSubsession The getAuxSDPLine() after collecting aux SDP line, put it back to the caller OnDemandServerMediaSubsession::setSDPLinesFromRTPSink(). The aux SDP line is usually like this: a=rtpmap:96 H264/90000 a=fmtp:96 packetization-mode=1;profile-level-id=42802A;sprop-parameter-sets=Z0KAKtoBEA8eXlIKDAoNoUJq,aM4G4g== OnDemandServerMediaSubsession::setSDPLinesFromRTPSink() With all the information, the final subsession SDP line is generated. The final subsession SDP line is usually like this: m=video 0 RTP/AVP 96 c=IN IP4 0.0.0.0 b=AS:500 a=rtpmap:96 H264/90000 a=fmtp:96 packetization-mode=1;profile-level-id=42802A;sprop-parameter-sets=Z0KAKtoBEA8eXlIKDAoNoUJq,aM4G4g== a=control:track1 Reward Done. 1.1. Live555 source code analysis series Live555 Source code analysis: Introduction live555 Source code analysis: Infrastructure live555 Source code analysis: MediaSever Wireshark capture packet analysis RTSP/RTP/RTCP Basic working process live555 Source code analysis: RTSPServer live555 Source code analysis: DESCRIBE processing live555 Source code analysis: SETUP processing live555 Source code analysis :PLAY processing live555 Source code analysis: RTSPServer component structure live555 Source code analysis: ServerMediaSession live555 Source code analysis: sub-session SDP line generation live555 Source code analysis: sub-session SETUP live555 Source code analysis: play start "},"Live555 - Live555 source code analysis_Subsession SETUP.html":{"url":"Live555 - Live555 source code analysis_Subsession SETUP.html","title":"Live555 - Live555 source code analysis_Subsession SETUP","keywords":"","body":"1. Live555 Source Code Analysis: Subsession SETUP1.1. Get stream parameters1.2. Settings before playback1.3. Live555 source code analysis series1. Live555 Source Code Analysis: Subsession SETUP Posted on 2017-09-08 | In live555 Live555 Source Code Analysis: Subsession SETUP Get stream parameters Settings before playback Live555 source code analysis series In front live555 source code analysis: sub-session SDP line generates a text, we looked live555 neutron session ServerMediaSubsession lifecycle, and analyzes generated SDP line in more detail sdpLines(), we continue to analyze the life cycle. 1.1. Get stream parameters ServerMediaSubsession The getStreamParameters() functions performed in the RTSP SETUP request invoke, implementation of the function is as follows: void OnDemandServerMediaSubsession ::getStreamParameters(unsigned clientSessionId, netAddressBits clientAddress, Port const& clientRTPPort, Port const& clientRTCPPort, int tcpSocketNum, unsigned char rtpChannelId, unsigned char rtcpChannelId, netAddressBits& destinationAddress, u_int8_t& /*destinationTTL*/, Boolean& isMulticast, Port& serverRTPPort, Port& serverRTCPPort, void*& streamToken) { if (destinationAddress == 0) destinationAddress = clientAddress; struct in_addr destinationAddr; destinationAddr.s_addr = destinationAddress; isMulticast = False; if (fLastStreamToken != NULL && fReuseFirstSource) { // Special case: Rather than creating a new 'StreamState', // we reuse the one that we've already created: serverRTPPort = ((StreamState*)fLastStreamToken)->serverRTPPort(); serverRTCPPort = ((StreamState*)fLastStreamToken)->serverRTCPPort(); ++((StreamState*)fLastStreamToken)->referenceCount(); streamToken = fLastStreamToken; } else { // Normal case: Create a new media source: unsigned streamBitrate; FramedSource* mediaSource = createNewStreamSource(clientSessionId, streamBitrate); // Create 'groupsock' and 'sink' objects for the destination, // using previously unused server port numbers: RTPSink* rtpSink = NULL; BasicUDPSink* udpSink = NULL; Groupsock* rtpGroupsock = NULL; Groupsock* rtcpGroupsock = NULL; if (clientRTPPort.num() != 0 || tcpSocketNum >= 0) { // Normal case: Create destinations portNumBits serverPortNum; if (clientRTCPPort.num() == 0) { // We're streaming raw UDP (not RTP). Create a single groupsock: NoReuse dummy(envir()); // ensures that we skip over ports that are already in use for (serverPortNum = fInitialPortNum;; ++serverPortNum) { struct in_addr dummyAddr; dummyAddr.s_addr = 0; serverRTPPort = serverPortNum; rtpGroupsock = createGroupsock(dummyAddr, serverRTPPort); if (rtpGroupsock->socketNum() >= 0) break; // success } udpSink = BasicUDPSink::createNew(envir(), rtpGroupsock); } else { // Normal case: We're streaming RTP (over UDP or TCP). Create a pair of // groupsocks (RTP and RTCP), with adjacent port numbers (RTP port number even). // (If we're multiplexing RTCP and RTP over the same port number, it can be odd or even.) NoReuse dummy(envir()); // ensures that we skip over ports that are already in use for (portNumBits serverPortNum = fInitialPortNum;; ++serverPortNum) { struct in_addr dummyAddr; dummyAddr.s_addr = 0; serverRTPPort = serverPortNum; rtpGroupsock = createGroupsock(dummyAddr, serverRTPPort); if (rtpGroupsock->socketNum() socketNum() estimatedBitrate() > 0) streamBitrate = rtpSink->estimatedBitrate(); } // Turn off the destinations for each groupsock. They'll get set later // (unless TCP is used instead): if (rtpGroupsock != NULL) rtpGroupsock->removeAllDestinations(); if (rtcpGroupsock != NULL) rtcpGroupsock->removeAllDestinations(); if (rtpGroupsock != NULL) { // Try to use a big send buffer for RTP - at least 0.1 second of // specified bandwidth and at least 50 KB unsigned rtpBufSize = streamBitrate * 25 / 2; // 1 kbps * 0.1 s = 12.5 bytes if (rtpBufSize socketNum(), rtpBufSize); } } // Set up the state of the stream. The stream will get started later: streamToken = fLastStreamToken = new StreamState(*this, serverRTPPort, serverRTCPPort, rtpSink, udpSink, streamBitrate, mediaSource, rtpGroupsock, rtcpGroupsock); } // Record these destinations as being for this client session id: Destinations* destinations; if (tcpSocketNum Add((char const*)clientSessionId, destinations); } This function is mainly used to get the RTP port and RTCP port allocated for the session, as well as the stream token. OnDemandServerMediaSubsession used StreamState to manage input and output components of the bottom layer, and to StreamState object pointer as stream token. When StreamToken session already exists, i.e., fLastStreamToken non-null, returns the requested information directly to the caller. When the session's StreamToken does not yet exist, you need to create the underlying facility for I/O and return the requested information. Here we mainly look at the case where the streaming mode is RTP, and ignore the case where the RTP port number is multiplexed with the RTCP port number. For want to create StreamState situations, creating action mainly through the following steps: The first step is to create FramedSource. In the second step, try to create a pair of groupsocks adjacent to the port number, which are used for RTP and RTCP respectively, where the RTP port number is even and the RTCP port number is odd. Then create an RTP-based groupsock RTPSink. Finally, make some settings for these groupsocks, including clearing the destination address of groupsocks for RTP and RTCP, and increasing the send buffer of groupsock for RTP. } else { // Normal case: We're streaming RTP (over UDP or TCP). Create a pair of // groupsocks (RTP and RTCP), with adjacent port numbers (RTP port number even). // (If we're multiplexing RTCP and RTP over the same port number, it can be odd or even.) NoReuse dummy(envir()); // ensures that we skip over ports that are already in use for (portNumBits serverPortNum = fInitialPortNum;; ++serverPortNum) { struct in_addr dummyAddr; dummyAddr.s_addr = 0; serverRTPPort = serverPortNum; rtpGroupsock = createGroupsock(dummyAddr, serverRTPPort); if (rtpGroupsock->socketNum() socketNum() estimatedBitrate() > 0) streamBitrate = rtpSink->estimatedBitrate(); } The third step, based on the previously created FramedSource, RTP, and RTCP of groupsock and RTPSink so on to create StreamState, and returned to the caller. // Set up the state of the stream. The stream will get started later: streamToken = fLastStreamToken = new StreamState(*this, serverRTPPort, serverRTCPPort, rtpSink, udpSink, streamBitrate, mediaSource, rtpGroupsock, rtcpGroupsock); getStreamParameters() Finally, it will be created Destinations. Destinations encapsulates the client's address, and the RTP and RTCP port numbers. in some get live555 and lookup operations imply semantics created in the absence, as here getStreamParameters(), there GenericMediaServer is lookupServerMediaSession(). 1.2. Settings before playback Then look at the RTSP PLAY request processing, do before playing streaming settings. This includes setStreamScale(), seekStream(), nullSeekStream() and getCurrentNPT() other operations. For the H264VideoFileServerMediaSubsession purposes of implementing these operations are also in the OnDemandServerMediaSubsession middle. setStreamScale() The implementation is as follows: void OnDemandServerMediaSubsession::setStreamScale(unsigned /*clientSessionId*/, void* streamToken, float scale) { // Changing the scale factor isn't allowed if multiple clients are receiving data // from the same source: if (fReuseFirstSource) return; StreamState* streamState = (StreamState*)streamToken; if (streamState != NULL && streamState->mediaSource() != NULL) { setStreamSourceScale(streamState->mediaSource(), scale); } } . . . . . . void OnDemandServerMediaSubsession ::setStreamSourceScale(FramedSource* /*inputSource*/, float /*scale*/) { // Default implementation: Do nothing } setStreamScale() Speed setting for streaming, it will give the real work setStreamSourceScale(), which is OnDemandServerMediaSubsession newly added virtual function, subclasses need to provide actual functionality implemented. For H264VideoFileServerMediaSubsession, it is set to null operation speed of operation of the player. seekStream() The implementation is as follows: void OnDemandServerMediaSubsession::seekStream(unsigned /*clientSessionId*/, void* streamToken, double& seekNPT, double streamDuration, u_int64_t& numBytes) { fprintf(stderr, \"OnDemandServerMediaSubsession::seekStream().\\n\"); numBytes = 0; // by default: unknown // Seeking isn't allowed if multiple clients are receiving data from the same source: if (fReuseFirstSource) return; StreamState* streamState = (StreamState*)streamToken; if (streamState != NULL && streamState->mediaSource() != NULL) { seekStreamSource(streamState->mediaSource(), seekNPT, streamDuration, numBytes); streamState->startNPT() = (float)seekNPT; RTPSink* rtpSink = streamState->rtpSink(); // alias if (rtpSink != NULL) rtpSink->resetPresentationTimes(); } } void OnDemandServerMediaSubsession::seekStream(unsigned /*clientSessionId*/, void* streamToken, char*& absStart, char*& absEnd) { fprintf(stderr, \"OnDemandServerMediaSubsession::seekStream1().\\n\"); // Seeking isn't allowed if multiple clients are receiving data from the same source: if (fReuseFirstSource) return; StreamState* streamState = (StreamState*)streamToken; if (streamState != NULL && streamState->mediaSource() != NULL) { seekStreamSource(streamState->mediaSource(), absStart, absEnd); } } . . . . . . void OnDemandServerMediaSubsession::seekStreamSource(FramedSource* /*inputSource*/, double& /*seekNPT*/, double /*streamDuration*/, u_int64_t& numBytes) { fprintf(stderr, \"OnDemandServerMediaSubsession::seekStreamSource().\\n\"); // Default implementation: Do nothing numBytes = 0; } void OnDemandServerMediaSubsession::seekStreamSource(FramedSource* /*inputSource*/, char*& absStart, char*& absEnd) { fprintf(stderr, \"OnDemandServerMediaSubsession::seekStreamSource().\\n\"); // Default implementation: do nothing (but delete[] and assign \"absStart\" and \"absEnd\" to NULL, to show that we don't handle this) delete[] absStart; absStart = NULL; delete[] absEnd; absEnd = NULL; } seekStream() Used to control the playback progress, their actual functions also need to be implemented by subclasses implementing two newly defined virtual functions. nullSeekStream() The implementation is as follows: void OnDemandServerMediaSubsession::nullSeekStream(unsigned /*clientSessionId*/, void* streamToken, double streamEndTime, u_int64_t& numBytes) { fprintf(stderr, \"OnDemandServerMediaSubsession::nullSeekStream().\\n\"); numBytes = 0; // by default: unknown StreamState* streamState = (StreamState*)streamToken; if (streamState != NULL && streamState->mediaSource() != NULL) { // Because we're not seeking here, get the current NPT, and remember it as the new 'start' NPT: streamState->startNPT() = getCurrentNPT(streamToken); double duration = streamEndTime - streamState->startNPT(); if (duration mediaSource(), duration, numBytes); RTPSink* rtpSink = streamState->rtpSink(); // alias if (rtpSink != NULL) rtpSink->resetPresentationTimes(); } } . . . . . . float OnDemandServerMediaSubsession::getCurrentNPT(void* streamToken) { fprintf(stderr, \"OnDemandServerMediaSubsession::getCurrentNPT().\\n\"); do { if (streamToken == NULL) break; StreamState* streamState = (StreamState*)streamToken; RTPSink* rtpSink = streamState->rtpSink(); if (rtpSink == NULL) break; return streamState->startNPT() + (rtpSink->mostRecentPresentationTime().tv_sec - rtpSink->initialPresentationTime().tv_sec) + (rtpSink->mostRecentPresentationTime().tv_usec - rtpSink->initialPresentationTime().tv_usec)/1000000.0f; } while (0); return 0.0; } . . . . . . void OnDemandServerMediaSubsession ::setStreamSourceDuration(FramedSource* /*inputSource*/, double /*streamDuration*/, u_int64_t& numBytes) { // Default implementation: Do nothing numBytes = 0; } nullSeekStream() When set for long play, also we need to implement new subclass virtual functions, i.e. setStreamSourceDuration() to provide the actual function. getCurrentNPT() Used to get the current NPT time: float OnDemandServerMediaSubsession::getCurrentNPT(void* streamToken) { fprintf(stderr, \"OnDemandServerMediaSubsession::getCurrentNPT().\\n\"); do { if (streamToken == NULL) break; StreamState* streamState = (StreamState*)streamToken; RTPSink* rtpSink = streamState->rtpSink(); if (rtpSink == NULL) break; return streamState->startNPT() + (rtpSink->mostRecentPresentationTime().tv_sec - rtpSink->initialPresentationTime().tv_sec) + (rtpSink->mostRecentPresentationTime().tv_usec - rtpSink->initialPresentationTime().tv_usec)/1000000.0f; } while (0); return 0.0; } This is calculated by using the starting NPT time plus the length of time the RTP session has elapsed. Reward Done. 1.3. Live555 source code analysis series Live555 Source code analysis: Introduction live555 Source code analysis: Infrastructure live555 Source code analysis: MediaSever Wireshark capture packet analysis RTSP/RTP/RTCP Basic working process live555 Source code analysis: RTSPServer live555 Source code analysis: DESCRIBE processing live555 Source code analysis: SETUP processing live555 Source code analysis :PLAY processing live555 Source code analysis: RTSPServer component structure live555 Source code analysis: ServerMediaSession live555 Source code analysis: sub-session SDP line generation live555 Source code analysis: sub-session SETUP live555 Source code analysis: play start "},"Live555 - Live555 source code analysis_play start.html":{"url":"Live555 - Live555 source code analysis_play start.html","title":"Live555 - Live555 source code analysis_play start","keywords":"","body":"1. Live555 source code analysis: play start1.1. RTP packet transmission1.2. RTCP packet reception1.3. RTCP packet transmission1.4. Live555 source code analysis series1. Live555 source code analysis: play start Posted on 2017-09-08 | In live555 Live555 source code analysis: play start RTP packet transmission RTCP packet reception RTCP packet transmission Live555 source code analysis series This article analyzes the process of streaming media playback in live555 and data transmission through RTP/RTCP. As we live555 source code analysis: sub-session SETUP seen, play a streaming media sub-session start from StreamState::startPlaying complete: void OnDemandServerMediaSubsession::startStream(unsigned clientSessionId, void* streamToken, TaskFunc* rtcpRRHandler, void* rtcpRRHandlerClientData, unsigned short& rtpSeqNum, unsigned& rtpTimestamp, ServerRequestAlternativeByteHandler* serverRequestAlternativeByteHandler, void* serverRequestAlternativeByteHandlerClientData) { StreamState* streamState = (StreamState*)streamToken; Destinations* destinations = (Destinations*)(fDestinationsHashTable->Lookup((char const*)clientSessionId)); if (streamState != NULL) { streamState->startPlaying(destinations, clientSessionId, rtcpRRHandler, rtcpRRHandlerClientData, serverRequestAlternativeByteHandler, serverRequestAlternativeByteHandlerClientData); RTPSink* rtpSink = streamState->rtpSink(); // alias if (rtpSink != NULL) { rtpSeqNum = rtpSink->currentSeqNo(); rtpTimestamp = rtpSink->presetNextTimestamp(); } } }s In this function, first find the destination address of the sub-session, i.e. the client's IP address, and a port number of the received RTP / RTCP, and then `StreamState::startPlaying()` start playing, the initial sequence number of the last RTP packet and the time stamp is returned to the initial The caller, that is `RTSPServer`, and the latter, is returned to the client for playback synchronization of the client. `StreamState::startPlaying()` The implementation is like this: void StreamState ::startPlaying(Destinations* dests, unsigned clientSessionId, TaskFunc* rtcpRRHandler, void* rtcpRRHandlerClientData, ServerRequestAlternativeByteHandler* serverRequestAlternativeByteHandler, void* serverRequestAlternativeByteHandlerClientData) { if (dests == NULL) return; if (fRTCPInstance == NULL && fRTPSink != NULL) { // Create (and start) a 'RTCP instance' for this RTP sink: fRTCPInstance = fMaster.createRTCP(fRTCPgs, fTotalBW, (unsigned char*)fMaster.fCNAME, fRTPSink); // Note: This starts RTCP running automatically fRTCPInstance->setAppHandler(fMaster.fAppHandlerTask, fMaster.fAppHandlerClientData); } if (dests->isTCP) { // Change RTP and RTCP to use the TCP socket instead of UDP: if (fRTPSink != NULL) { fRTPSink->addStreamSocket(dests->tcpSocketNum, dests->rtpChannelId); RTPInterface::setServerRequestAlternativeByteHandler(fRTPSink->envir(), dests->tcpSocketNum, serverRequestAlternativeByteHandler, serverRequestAlternativeByteHandlerClientData); // So that we continue to handle RTSP commands from the client } if (fRTCPInstance != NULL) { fRTCPInstance->addStreamSocket(dests->tcpSocketNum, dests->rtcpChannelId); fRTCPInstance->setSpecificRRHandler(dests->tcpSocketNum, dests->rtcpChannelId, rtcpRRHandler, rtcpRRHandlerClientData); } } else { // Tell the RTP and RTCP 'groupsocks' about this destination // (in case they don't already have it): if (fRTPgs != NULL) fRTPgs->addDestination(dests->addr, dests->rtpPort, clientSessionId); if (fRTCPgs != NULL && !(fRTCPgs == fRTPgs && dests->rtcpPort.num() == dests->rtpPort.num())) { fRTCPgs->addDestination(dests->addr, dests->rtcpPort, clientSessionId); } if (fRTCPInstance != NULL) { fRTCPInstance->setSpecificRRHandler(dests->addr.s_addr, dests->rtcpPort, rtcpRRHandler, rtcpRRHandlerClientData); } } if (fRTCPInstance != NULL) { // Hack: Send an initial RTCP \"SR\" packet, before the initial RTP packet, so that receivers will (likely) be able to // get RTCP-synchronized presentation times immediately: fRTCPInstance->sendReport(); } if (!fAreCurrentlyPlaying && fMediaSource != NULL) { if (fRTPSink != NULL) { fRTPSink->startPlaying(*fMediaSource, afterPlayingStreamState, this); fAreCurrentlyPlaying = True; } else if (fUDPSink != NULL) { fUDPSink->startPlaying(*fMediaSource, afterPlayingStreamState, this); fAreCurrentlyPlaying = True; } } } In this function, first create it when RTCPInstance has not been created yet: RTCPInstance* OnDemandServerMediaSubsession ::createRTCP(Groupsock* RTCPgs, unsigned totSessionBW, /* in kbps */ unsigned char const* cname, RTPSink* sink) { // Default implementation; may be redefined by subclasses: return RTCPInstance::createNew(envir(), RTCPgs, totSessionBW, cname, sink, NULL/*we're a server*/); } Ignore the RTP/RTCP packet to go to TCP. Then StreamState::startPlaying() do the right RTP and RTCP of groupsock some settings, add the destination address is a them and did some set RTCPInstance: } else { // Tell the RTP and RTCP 'groupsocks' about this destination // (in case they don't already have it): if (fRTPgs != NULL) fRTPgs->addDestination(dests->addr, dests->rtpPort, clientSessionId); if (fRTCPgs != NULL && !(fRTCPgs == fRTPgs && dests->rtcpPort.num() == dests->rtpPort.num())) { fRTCPgs->addDestination(dests->addr, dests->rtcpPort, clientSessionId); } if (fRTCPInstance != NULL) { fRTCPInstance->setSpecificRRHandler(dests->addr.s_addr, dests->rtcpPort, rtcpRRHandler, rtcpRRHandlerClientData); } } After StreamState::startPlaying() issuing a RTCP packet. if (fRTCPInstance != NULL) { // Hack: Send an initial RTCP \"SR\" packet, before the initial RTP packet, so that receivers will (likely) be able to // get RTCP-synchronized presentation times immediately: fRTCPInstance->sendReport(); } fUDPSink For the case where the streaming mode is RAW UDP, the case of this streaming mode is ignored. Finally executed MediaSink::startPlaying() and set the flag fAreCurrentlyPlaying to indicate that streaming playback has started. 1.1. RTP packet transmission Let's look at how the RTP package is sent out. MediaSink::startPlaying() The function is defined as follows: Boolean MediaSink::startPlaying(MediaSource& source, afterPlayingFunc* afterFunc, void* afterClientData) { // Make sure we're not already being played: if (fSource != NULL) { envir().setResultMsg(\"This sink is already being played\"); return False; } // Make sure our source is compatible: if (!sourceIsCompatibleWithUs(source)) { envir().setResultMsg(\"MediaSink::startPlaying(): source is not compatible!\"); return False; } fSource = (FramedSource*)&source; fAfterFunc = afterFunc; fAfterClientData = afterClientData; return continuePlaying(); } In this function, the stored passed callback parameters and callback, then execution continuePlaying(), continuePlaying() is a pure virtual function, which is implemented by the MediaSink subclasses H264or5VideoRTPSink to achieve: Boolean H264or5VideoRTPSink::continuePlaying() { // First, check whether we have a 'fragmenter' class set up yet. // If not, create it now: if (fOurFragmenter == NULL) { fOurFragmenter = new H264or5Fragmenter(fHNumber, envir(), fSource, OutPacketBuffer::maxSize, ourMaxPacketSize() - 12/*RTP hdr size*/); } else { fOurFragmenter->reassignInputSource(fSource); } fSource = fOurFragmenter; // Then call the parent class's implementation: return MultiFramedRTPSink::continuePlaying(); } In this class, it is primarily H264or5Fragmenter provided streaming media data source, and fSource set H264or5Fragmenter. Here, MultiFramedRTPSink holding the streaming data source FramedSource originally in the H264VideoFileServerMediaSubsession created H264VideoStreamFramer becomes a H264or5Fragmenter, and H264or5Fragmenter is encapsulated H264VideoStreamFramer. Then H264or5VideoRTPSink::continuePlaying() perform MultiFramedRTPSink::continuePlaying() further processing. Boolean MultiFramedRTPSink::continuePlaying() { // Send the first packet. // (This will also schedule any future sends.) buildAndSendPacket(True); return True; } . . . . . . void MultiFramedRTPSink::buildAndSendPacket(Boolean isFirstPacket) { nextTask() = NULL; fIsFirstPacket = isFirstPacket; // Set up the RTP header: unsigned rtpHdr = 0x80000000; // RTP version 2; marker ('M') bit not set (by default; it can be set later) rtpHdr |= (fRTPPayloadTypeenqueueWord(rtpHdr); // Note where the RTP timestamp will go. // (We can't fill this in until we start packing payload frames.) fTimestampPosition = fOutBuf->curPacketSize(); fOutBuf->skipBytes(4); // leave a hole for the timestamp fOutBuf->enqueueWord(SSRC()); // Allow for a special, payload-format-specific header following the // RTP header: fSpecialHeaderPosition = fOutBuf->curPacketSize(); fSpecialHeaderSize = specialHeaderSize(); fOutBuf->skipBytes(fSpecialHeaderSize); // Begin packing as many (complete) frames into the packet as we can: fTotalFrameSpecificHeaderSizes = 0; fNoFramesLeft = False; fNumFramesUsedSoFar = 0; packFrame(); } MultiFramedRTPSink::continuePlaying() Execution MultiFramedRTPSink::buildAndSendPacket(). And MultiFramedRTPSink::buildAndSendPacket() it is in the output buffer constructed RTP header, header fields for which temporarily can not be accurately obtained with space. Then called MultiFramedRTPSink::packFrame(). void MultiFramedRTPSink::packFrame() { // Get the next frame. // First, skip over the space we'll use for any frame-specific header: fCurFrameSpecificHeaderPosition = fOutBuf->curPacketSize(); fCurFrameSpecificHeaderSize = frameSpecificHeaderSize(); fOutBuf->skipBytes(fCurFrameSpecificHeaderSize); fTotalFrameSpecificHeaderSizes += fCurFrameSpecificHeaderSize; // See if we have an overflow frame that was too big for the last pkt if (fOutBuf->haveOverflowData()) { // Use this frame before reading a new one from the source unsigned frameSize = fOutBuf->overflowDataSize(); struct timeval presentationTime = fOutBuf->overflowPresentationTime(); unsigned durationInMicroseconds = fOutBuf->overflowDurationInMicroseconds(); fOutBuf->useOverflowData(); afterGettingFrame1(frameSize, 0, presentationTime, durationInMicroseconds); } else { // Normal case: we need to read a new frame from the source if (fSource == NULL) return; fSource->getNextFrame(fOutBuf->curPtr(), fOutBuf->totalBytesAvailable(), afterGettingFrame, this, ourHandleClosure, this); } } MultiFramedRTPSink::packFrame() Of FramedSource the getNextFrame() obtained frame data, and after obtaining informed frame data. void FramedSource::getNextFrame(unsigned char* to, unsigned maxSize, afterGettingFunc* afterGettingFunc, void* afterGettingClientData, onCloseFunc* onCloseFunc, void* onCloseClientData) { // Make sure we're not already being read: if (fIsCurrentlyAwaitingData) { envir() This function is mainly used to FramedSource set the media stream data to be read where, how much their own address, and a callback function can be read. And ultimately perform doGetNextFrame() the read data. Final data will be ByteStreamFileSource the doGetNextFrame() implementation of scheduling tasks to read, and read from the file. #0 ByteStreamFileSource::doGetNextFrame (this=0x6d8f10) at ByteStreamFileSource.cpp:96 #1 0x000000000043004c in FramedSource::getNextFrame (this=0x6d8f10, to=0x6da9c0 \"(\\243\\203\\367\\377\\177\", maxSize=150000, afterGettingFunc=0x46f6c8 , afterGettingClientData=0x6d91b0, onCloseFunc=0x46f852 , onCloseClientData=0x6d91b0) at FramedSource.cpp:78 ------------------------------------------------------------------------------------------------------------------------------------- #2 0x000000000046f69c in StreamParser::ensureValidBytes1 (this=0x6d91b0, numBytesNeeded=4) at StreamParser.cpp:159 #3 0x00000000004343e5 in StreamParser::ensureValidBytes (this=0x6d91b0, numBytesNeeded=4) at StreamParser.hh:118 #4 0x0000000000434179 in StreamParser::test4Bytes (this=0x6d91b0) at StreamParser.hh:54 #5 0x0000000000471b85 in H264or5VideoStreamParser::parse (this=0x6d91b0) at H264or5VideoStreamFramer.cpp:951 #6 0x000000000043510f in MPEGVideoStreamFramer::continueReadProcessing (this=0x6d9000) at MPEGVideoStreamFramer.cpp:159 #7 0x0000000000435077 in MPEGVideoStreamFramer::doGetNextFrame (this=0x6d9000) at MPEGVideoStreamFramer.cpp:142 #8 0x000000000043004c in FramedSource::getNextFrame (this=0x6d9000, to=0x748d61 \"\", maxSize=100000, afterGettingFunc=0x474cd2 , afterGettingClientData=0x700300, onCloseFunc=0x4300c6 , onCloseClientData=0x700300) at FramedSource.cpp:78 ------------------------------------------------------------------------------------------------------------------------------------- #9 0x000000000047480a in H264or5Fragmenter::doGetNextFrame (this=0x700300) at H264or5VideoRTPSink.cpp:181 #10 0x000000000043004c in FramedSource::getNextFrame (this=0x700300, to=0x7304ec \"\", maxSize=100452, afterGettingFunc=0x45af82 , afterGettingClientData=0x6d92e0, onCloseFunc=0x45b96c , onCloseClientData=0x6d92e0) at FramedSource.cpp:78 ------------------------------------------------------------------------------------------------------------------------------------- #11 0x000000000045af61 in MultiFramedRTPSink::packFrame (this=0x6d92e0) at MultiFramedRTPSink.cpp:224 #12 0x000000000045adae in MultiFramedRTPSink::buildAndSendPacket (this=0x6d92e0, isFirstPacket=1 '\\001') at MultiFramedRTPSink.cpp:199 #13 0x000000000045abed in MultiFramedRTPSink::continuePlaying (this=0x6d92e0) at MultiFramedRTPSink.cpp:159 ------------------------------------------------------------------------------------------------------------------------------------- #14 0x000000000047452a in H264or5VideoRTPSink::continuePlaying (this=0x6d92e0) at H264or5VideoRTPSink.cpp:127 #15 0x0000000000405d2a in MediaSink::startPlaying (this=0x6d92e0, source=..., afterFunc=0x4621f4 , afterClientData=0x6d95b0) at MediaSink.cpp:78 #16 0x00000000004626ea in StreamState::startPlaying (this=0x6d95b0, dests=0x6d9620, clientSessionId=1584618840, rtcpRRHandler=0x407280 , rtcpRRHandlerClientData=0x70ba40, serverRequestAlternativeByteHandler=0x4093a6 , serverRequestAlternativeByteHandlerClientData=0x6ce910) at OnDemandServerMediaSubsession.cpp:576 #17 0x000000000046138d in OnDemandServerMediaSubsession::startStream (this=0x6d8710, clientSessionId=1584618840, streamToken=0x6d95b0, rtcpRRHandler=0x407280 , rtcpRRHandlerClientData=0x70ba40, rtpSeqNum=@0x7fffffffcd76: 0, rtpTimestamp=@0x7fffffffcdc0: 0, serverRequestAlternativeByteHandler=0x4093a6 , serverRequestAlternativeByteHandlerClientData=0x6ce910) at OnDemandServerMediaSubsession.cpp:223 This call stack is deep. It may seem confusing. Live555 actually employed decorator pattern design FramedSource, a FramedSource may be packaged another FramedSource, and provide some additional features, or to optimize performance, or for data analysis or the like. live555 in many FramedSource relationships between classes probably as follows: Above the call stack, mainly based on FramedSource packaging relationship, divided by a dotted line into several different stages. In ByteStreamFileSource the doGetNextFrame() middle, task scheduling reads: void ByteStreamFileSource::doGetNextFrame() { if (feof(fFid) || ferror(fFid) || (fLimitNumBytesToStream && fNumBytesToStream == 0)) { handleClosure(); return; } #ifdef READ_FROM_FILES_SYNCHRONOUSLY doReadFromFile(); #else if (!fHaveStartedReading) { // Await readable data from the file: envir().taskScheduler().turnOnBackgroundReadHandling(fileno(fFid), (TaskScheduler::BackgroundHandlerProc*)&fileReadableHandler, this); fHaveStartedReading = True; } #endif } ByteStreamFileSource::fileReadableHandler() Read the streaming content and notify the caller: void FramedSource::afterGetting(FramedSource* source) { source->nextTask() = NULL; source->fIsCurrentlyAwaitingData = False; // indicates that we can be read again // Note that this needs to be done here, in case the \"fAfterFunc\" // called below tries to read another frame (which it usually will) if (source->fAfterGettingFunc != NULL) { (*(source->fAfterGettingFunc))(source->fAfterGettingClientData, source->fFrameSize, source->fNumTruncatedBytes, source->fPresentationTime, source->fDurationInMicroseconds); } } . . . . . . void ByteStreamFileSource::fileReadableHandler(ByteStreamFileSource* source, int /*mask*/) { if (!source->isCurrentlyAwaitingData()) { source->doStopGettingFrames(); // we're not ready for the data yet return; } source->doReadFromFile(); } void ByteStreamFileSource::doReadFromFile() { // Try to read as many bytes as will fit in the buffer provided (or \"fPreferredFrameSize\" if less) if (fLimitNumBytesToStream && fNumBytesToStream 0 && fPreferredFrameSize 0 && fPreferredFrameSize > 0) { if (fPresentationTime.tv_sec == 0 && fPresentationTime.tv_usec == 0) { // This is the first frame, so use the current time: gettimeofday(&fPresentationTime, NULL); } else { // Increment by the play time of the previous data: unsigned uSeconds = fPresentationTime.tv_usec + fLastPlayTime; fPresentationTime.tv_sec += uSeconds/1000000; fPresentationTime.tv_usec = uSeconds%1000000; } // Remember the play time of this data: fLastPlayTime = (fPlayTimePerFrame*fFrameSize)/fPreferredFrameSize; fDurationInMicroseconds = fLastPlayTime; } else { // We don't know a specific play time duration for this data, // so just record the current time as being the 'presentation time': gettimeofday(&fPresentationTime, NULL); } // Inform the reader that he has data: #ifdef READ_FROM_FILES_SYNCHRONOUSLY // To avoid possible infinite recursion, we need to return to the event loop to do this: nextTask() = envir().taskScheduler().scheduleDelayedTask(0, (TaskFunc*)FramedSource::afterGetting, this); #else // Because the file read was done from the event loop, we can call the // 'after getting' function directly, without risk of infinite recursion: FramedSource::afterGetting(this); #endif } After the data is read, you MultiFramedRTPSink will be notified: #0 MultiFramedRTPSink::afterGettingFrame (clientData=0x6d92e0, numBytesRead=18, numTruncatedBytes=0, presentationTime=..., durationInMicroseconds=0) at MultiFramedRTPSink.cpp:233 --------------------------------------------------------------------------------------------------------------------------- #1 0x00000000004300c2 in FramedSource::afterGetting (source=0x7002c0) at FramedSource.cpp:92 #2 0x0000000000474ca6 in H264or5Fragmenter::doGetNextFrame (this=0x7002c0) at H264or5VideoRTPSink.cpp:263 #3 0x0000000000474dac in H264or5Fragmenter::afterGettingFrame1 (this=0x7002c0, frameSize=18, numTruncatedBytes=0, presentationTime=..., durationInMicroseconds=0) at H264or5VideoRTPSink.cpp:292 #4 0x0000000000474d25 in H264or5Fragmenter::afterGettingFrame (clientData=0x7002c0, frameSize=18, numTruncatedBytes=0, presentationTime=..., durationInMicroseconds=0) at H264or5VideoRTPSink.cpp:279 --------------------------------------------------------------------------------------------------------------------------- #5 0x00000000004300c2 in FramedSource::afterGetting (source=0x6d9000) at FramedSource.cpp:92 #6 0x00000000004351ea in MPEGVideoStreamFramer::continueReadProcessing (this=0x6d9000) at MPEGVideoStreamFramer.cpp:179 #7 0x00000000004350da in MPEGVideoStreamFramer::continueReadProcessing (clientData=0x6d9000) at MPEGVideoStreamFramer.cpp:155 #8 0x000000000046f84f in StreamParser::afterGettingBytes1 (this=0x6d91b0, numBytesRead=150000, presentationTime=...) at StreamParser.cpp:191 #9 0x000000000046f718 in StreamParser::afterGettingBytes (clientData=0x6d91b0, numBytesRead=150000, presentationTime=...) at StreamParser.cpp:170 --------------------------------------------------------------------------------------------------------------------------- #10 0x00000000004300c2 in FramedSource::afterGetting (source=0x6d8f10) at FramedSource.cpp:92 #11 0x0000000000430c2c in ByteStreamFileSource::doReadFromFile (this=0x6d8f10) at ByteStreamFileSource.cpp:182 #12 0x00000000004309cb in ByteStreamFileSource::fileReadableHandler (source=0x6d8f10) at ByteStreamFileSource.cpp:126 We also will callback call stack, according to FramedSource the package relationship, divided into several stages, different stages divided by dotted lines. MultiFramedRTPSink::afterGettingFrame() The function is defined as follows: void MultiFramedRTPSink ::afterGettingFrame(void* clientData, unsigned numBytesRead, unsigned numTruncatedBytes, struct timeval presentationTime, unsigned durationInMicroseconds) { MultiFramedRTPSink* sink = (MultiFramedRTPSink*)clientData; sink->afterGettingFrame1(numBytesRead, numTruncatedBytes, presentationTime, durationInMicroseconds); } In this function call afterGettingFrame1(), afterGettingFrame1() it will be required to call sendPacketIfNecessary(). MultiFramedRTPSink::sendPacketIfNecessary() The definition is as follows: void MultiFramedRTPSink::sendPacketIfNecessary() { if (fNumFramesUsedSoFar > 0) { // Send the packet: #ifdef TEST_LOSS if ((our_random()%10) != 0) // simulate 10% packet loss ##### #endif if (!fRTPInterface.sendPacket(fOutBuf->packet(), fOutBuf->curPacketSize())) { // if failure handler has been specified, call it if (fOnSendErrorFunc != NULL) (*fOnSendErrorFunc)(fOnSendErrorData); } ++fPacketCount; fTotalOctetCount += fOutBuf->curPacketSize(); fOctetCount += fOutBuf->curPacketSize() - rtpHeaderSize - fSpecialHeaderSize - fTotalFrameSpecificHeaderSizes; ++fSeqNo; // for next time } if (fOutBuf->haveOverflowData() && fOutBuf->totalBytesAvailable() > fOutBuf->totalBufferSize()/2) { // Efficiency hack: Reset the packet start pointer to just in front of // the overflow data (allowing for the RTP header and special headers), // so that we probably don't have to \"memmove()\" the overflow data // into place when building the next packet: unsigned newPacketStart = fOutBuf->curPacketSize() - (rtpHeaderSize + fSpecialHeaderSize + frameSpecificHeaderSize()); fOutBuf->adjustPacketStart(newPacketStart); } else { // Normal case: Reset the packet start pointer back to the start: fOutBuf->resetPacketStart(); } fOutBuf->resetOffset(); fNumFramesUsedSoFar = 0; if (fNoFramesLeft) { // We're done: onSourceClosure(); } else { // We have more frames left to send. Figure out when the next frame // is due to start playing, then make sure that we wait this long before // sending the next packet. struct timeval timeNow; gettimeofday(&timeNow, NULL); int secsDiff = fNextSendTime.tv_sec - timeNow.tv_sec; int64_t uSecondsToGo = secsDiff*1000000 + (fNextSendTime.tv_usec - timeNow.tv_usec); if (uSecondsToGo In MultiFramedRTPSink::sendPacketIfNecessary(), the frame data is sent. And if the streaming data transmission has not ended, then, after a data transmission is complete, the timer will dispatch a mission MultiFramedRTPSink::sendNext() to send the data frame again. MultiFramedRTPSink::sendNext() Performing MultiFramedRTPSink::continuePlaying() a similar process, and acquires the next frame transmission. void MultiFramedRTPSink::sendNext(void* firstArg) { MultiFramedRTPSink* sink = (MultiFramedRTPSink*)firstArg; sink->buildAndSendPacket(False); } Of course, not every time you send frame data, you need to get the data directly from the streaming source. In StreamParser the judgment will do, the frame data when needed, it will initiate a streaming media file is read. If you don't need to read the streaming data from the file, you will call back directly: #0 MultiFramedRTPSink::sendPacketIfNecessary (this=0x702140) at MultiFramedRTPSink.cpp:365 #1 0x000000000045b5a4 in MultiFramedRTPSink::afterGettingFrame1 (this=0x702140, frameSize=1444, numTruncatedBytes=0, presentationTime=..., durationInMicroseconds=40000) at MultiFramedRTPSink.cpp:347 #2 0x000000000045afd5 in MultiFramedRTPSink::afterGettingFrame (clientData=0x702140, numBytesRead=1444, numTruncatedBytes=0, presentationTime=..., durationInMicroseconds=40000) at MultiFramedRTPSink.cpp:235 #3 0x00000000004300c2 in FramedSource::afterGetting (source=0x7036d0) at FramedSource.cpp:92 ------------------------------------------------------------------------------------------------------------------------------------ #4 0x0000000000474ca6 in H264or5Fragmenter::doGetNextFrame (this=0x7036d0) at H264or5VideoRTPSink.cpp:263 #5 0x0000000000474dac in H264or5Fragmenter::afterGettingFrame1 (this=0x7036d0, frameSize=53527, numTruncatedBytes=0, presentationTime=..., durationInMicroseconds=40000) at H264or5VideoRTPSink.cpp:292 #6 0x0000000000474d25 in H264or5Fragmenter::afterGettingFrame (clientData=0x7036d0, frameSize=53527, numTruncatedBytes=0, presentationTime=..., durationInMicroseconds=40000) at H264or5VideoRTPSink.cpp:279 #7 0x00000000004300c2 in FramedSource::afterGetting (source=0x701e20) at FramedSource.cpp:92 ------------------------------------------------------------------------------------------------------------------------------------ #8 0x00000000004351ea in MPEGVideoStreamFramer::continueReadProcessing (this=0x701e20) at MPEGVideoStreamFramer.cpp:179 #9 0x0000000000435077 in MPEGVideoStreamFramer::doGetNextFrame (this=0x701e20) at MPEGVideoStreamFramer.cpp:142 ------------------------------------------------------------------------------------------------------------------------------------ #10 0x000000000043004c in FramedSource::getNextFrame (this=0x701e20, to=0x7c3091 \"\\205\\270@\\367\\017\\204?\\017\", , maxSize=100000, afterGettingFunc=0x474cd2 , afterGettingClientData=0x7036d0, onCloseFunc=0x4300c6 , onCloseClientData=0x7036d0) at FramedSource.cpp:78 #11 0x000000000047480a in H264or5Fragmenter::doGetNextFrame (this=0x7036d0) at H264or5VideoRTPSink.cpp:181 ------------------------------------------------------------------------------------------------------------------------------------ #12 0x000000000043004c in FramedSource::getNextFrame (this=0x7036d0, to=0x7aa81c \"|\\205\\270@\\367\\017\\204?\\017\", , maxSize=100452, afterGettingFunc=0x45af82 , afterGettingClientData=0x702140, onCloseFunc=0x45b96c , onCloseClientData=0x702140) at FramedSource.cpp:78 #13 0x000000000045af61 in MultiFramedRTPSink::packFrame (this=0x702140) at MultiFramedRTPSink.cpp:224 #14 0x000000000045adae in MultiFramedRTPSink::buildAndSendPacket (this=0x702140, isFirstPacket=0 '\\000') at MultiFramedRTPSink.cpp:199 #15 0x000000000045b969 in MultiFramedRTPSink::sendNext (firstArg=0x702140) at MultiFramedRTPSink.cpp:422 #16 0x000000000047f165 in AlarmHandler::handleTimeout (this=0x7038a0) at BasicTaskScheduler0.cpp:34 #17 0x000000000047d268 in DelayQueue::handleAlarm (this=0x6cdc28) at DelayQueue.cpp:187 #18 0x000000000047c196 in BasicTaskScheduler::SingleStep (this=0x6cdc20, maxDelayTime=0) at BasicTaskScheduler.cpp:212 Summarize the sending process of RTP packets: OnDemandServerMediaSubsession In execution startStream(), it will launch a streaming media file to read the task, read the file from the work ByteStreamFileSource of doReadFromFile() the Executive. After the file has read some data, MultiFramedRTPSink a callback is obtained afterGetting(), in which the frame data is sent. MultiFramedRTPSink In the callback, if the streaming media data has not been read yet, a timer task is scheduled, and the action of acquiring the frame data is initiated again after a period of time. Repeat steps 2 and 3 until all the data has been sent. 1.2. RTCP packet reception StreamState::startPlaying() By OnDemandServerMediaSubsession::createRTCP() creation RTCPInstance: RTCPInstance* OnDemandServerMediaSubsession ::createRTCP(Groupsock* RTCPgs, unsigned totSessionBW, /* in kbps */ unsigned char const* cname, RTPSink* sink) { fprintf(stderr, \"OnDemandServerMediaSubsession::createRTCP().\\n\"); // Default implementation; may be redefined by subclasses: return RTCPInstance::createNew(envir(), RTCPgs, totSessionBW, cname, sink, NULL/*we're a server*/); } OnDemandServerMediaSubsession::createRTCP() Through the RTCPInstance::createNew() creation: RTCPInstance::RTCPInstance(UsageEnvironment& env, Groupsock* RTCPgs, unsigned totSessionBW, unsigned char const* cname, RTPSink* sink, RTPSource* source, Boolean isSSMSource) : Medium(env), fRTCPInterface(this, RTCPgs), fTotSessionBW(totSessionBW), fSink(sink), fSource(source), fIsSSMSource(isSSMSource), fCNAME(RTCP_SDES_CNAME, cname), fOutgoingReportCount(1), fAveRTCPSize(0), fIsInitial(1), fPrevNumMembers(0), fLastSentSize(0), fLastReceivedSize(0), fLastReceivedSSRC(0), fTypeOfEvent(EVENT_UNKNOWN), fTypeOfPacket(PACKET_UNKNOWN_TYPE), fHaveJustSentPacket(False), fLastPacketSentSize(0), fByeHandlerTask(NULL), fByeHandlerClientData(NULL), fSRHandlerTask(NULL), fSRHandlerClientData(NULL), fRRHandlerTask(NULL), fRRHandlerClientData(NULL), fSpecificRRHandlerTable(NULL), fAppHandlerTask(NULL), fAppHandlerClientData(NULL) { #ifdef DEBUG fprintf(stderr, \"RTCPInstance[%p]::RTCPInstance()\\n\", this); #endif if (fTotSessionBW == 0) { // not allowed! env multicastSendOnly(); // don't receive multicast double timeNow = dTimeNow(); fPrevReportTime = fNextReportTime = timeNow; fKnownMembers = new RTCPMemberDatabase(*this); fInBuf = new unsigned char[maxRTCPPacketSize]; if (fKnownMembers == NULL || fInBuf == NULL) return; fNumBytesAlreadyRead = 0; fOutBuf = new OutPacketBuffer(preferredRTCPPacketSize, maxRTCPPacketSize, maxRTCPPacketSize); if (fOutBuf == NULL) return; if (fSource != NULL && fSource->RTPgs() == RTCPgs) { // We're receiving RTCP reports that are multiplexed with RTP, so ask the RTP source // to give them to us: fSource->registerForMultiplexedRTCPPackets(this); } else { // Arrange to handle incoming reports from the network: TaskScheduler::BackgroundHandlerProc* handler = (TaskScheduler::BackgroundHandlerProc*)&incomingReportHandler; fRTCPInterface.startNetworkReading(handler); } // Send our first report. fTypeOfEvent = EVENT_REPORT; onExpire(this); } . . . . . . RTCPInstance* RTCPInstance::createNew(UsageEnvironment& env, Groupsock* RTCPgs, unsigned totSessionBW, unsigned char const* cname, RTPSink* sink, RTPSource* source, Boolean isSSMSource) { return new RTCPInstance(env, RTCPgs, totSessionBW, cname, sink, source, isSSMSource); } It can be seen in RTCPInstance the constructor, call RTPInterface::startNetworkReading() registers a callback: void RTPInterface ::startNetworkReading(TaskScheduler::BackgroundHandlerProc* handlerProc) { // Normal case: Arrange to read UDP packets: envir().taskScheduler(). turnOnBackgroundReadHandling(fGS->socketNum(), handlerProc, fOwner); // Also, receive RTP over TCP, on each of our TCP connections: fReadHandlerProc = handlerProc; for (tcpStreamRecord* streams = fTCPStreams; streams != NULL; streams = streams->fNext) { // Get a socket descriptor for \"streams->fStreamSocketNum\": SocketDescriptor* socketDescriptor = lookupSocketDescriptor(envir(), streams->fStreamSocketNum); // Tell it about our subChannel: socketDescriptor->registerRTPInterface(streams->fStreamChannelId, this); } } In RTPInterface::startNetworkReading() the RTCP will be registered in the socket and event handlers on the socket to TaskScheduler. live555 It is in this way, be notified when there is RTCP packet arrives, and by RTCPInstance::incomingReportHandler() to handle RTCP packets. 1.3. RTCP packet transmission RTCP packets as required by the RTCPInstance::sendReport() transmission function and the like: void RTCPInstance::sendReport() { #ifdef DEBUG fprintf(stderr, \"sending REPORT\\n\"); #endif // Begin by including a SR and/or RR report: if (!addReport()) return; // Then, include a SDES: addSDES(); // Send the report: sendBuiltPacket(); // Periodically clean out old members from our SSRC membership database: const unsigned membershipReapPeriod = 5; if ((++fOutgoingReportCount) % membershipReapPeriod == 0) { unsigned threshold = fOutgoingReportCount - membershipReapPeriod; fKnownMembers->reapOldMembers(threshold); } } void RTCPInstance::sendBYE() { #ifdef DEBUG fprintf(stderr, \"sending BYE\\n\"); #endif // The packet must begin with a SR and/or RR report: (void)addReport(True); addBYE(); sendBuiltPacket(); } void RTCPInstance::sendBuiltPacket() { #ifdef DEBUG fprintf(stderr, \"sending RTCP packet\\n\"); unsigned char* p = fOutBuf->packet(); for (unsigned i = 0; i curPacketSize(); ++i) { if (i%4 == 0) fprintf(stderr,\" \"); fprintf(stderr, \"%02x\", p[i]); } fprintf(stderr, \"\\n\"); #endif unsigned reportSize = fOutBuf->curPacketSize(); fRTCPInterface.sendPacket(fOutBuf->packet(), reportSize); fOutBuf->resetOffset(); fLastSentSize = IP_UDP_HDR_SIZE + reportSize; fHaveJustSentPacket = True; fLastPacketSentSize = reportSize; } Just like in StreamState::startPlaying() the seen. Reward Done. 1.4. Live555 source code analysis series Live555 Source code analysis: Introduction live555 Source code analysis: Infrastructure live555 Source code analysis: MediaSever Wireshark capture packet analysis RTSP/RTP/RTCP Basic working process live555 Source code analysis: RTSPServer live555 Source code analysis: DESCRIBE processing live555 Source code analysis: SETUP processing live555 Source code analysis :PLAY processing live555 Source code analysis: RTSPServer component structure live555 Source code analysis: ServerMediaSession live555 Source code analysis: sub-session SDP line generation live555 Source code analysis: sub-session SETUP live555 Source code analysis: play start "},"Flutter Framework Analysis 1 - Overview and Window.html":{"url":"Flutter Framework Analysis 1 - Overview and Window.html","title":"Flutter Framework Analysis 1 - Overview and Window","keywords":"","body":"1. Flutter Framework Analysis (1) -- Overview and Window1.1. Foreword1.2. Overview1.2.1. Window1.3. to sum up1. Flutter Framework Analysis (1) -- Overview and Window Flutter Framework Analysis and Analysis Series: \"Flutter Framework Analysis (1) - Overview and Window\" \"Flutter Framework Analysis (2) - Initialization\" \"Flutter Framework Analysis (3) - Widget, Element and RenderObject\" \"Flutter Framework Analysis (4) - Flutter Framework Operation\" \"Flutter Framework Analysis (5) - Animation\" \"Flutter Framework Analysis (6) - Layout\" \"Flutter Framework Analysis (7) - Drawing\" Flutter Framework Analysis (1) -- Overview and Window Foreword Overview Window to sum up 1.1. Foreword After getting familiar with the development of the Flutter app, our curiosity will drive questions about how the Flutter framework works. How does Flutter work? Widget What is it? RenderObject: Is it a ghost? runApp() What happened after that? setState() How is the page refreshed after the call ? To answer these questions, you need to learn the source code of the Flutter framework. For this I will write a series of articles based on source code to analyze the Flutter framework. This article is the first one, mainly to introduce the overview and foundation of the Flutter framework Window. 1.2. Overview How is the Flutter app's page displayed on the screen? What drives the Flutter app to refresh the interface, play animations, and respond to touch events? This process can be described using the following figure. There is a rendering pipeline (Rendering pipeline) in the Flutter framework. This rendering pipeline is driven by the vertical sync signal (Vsync), and the Vsync signal is provided by the system. If your Flutter app is running on Android, then the Vsync signal is the Vsync signal of Android that we are familiar with. When the Vsync signal arrives, the Flutter framework performs a series of actions in the order shown: Animation (Animate), Build, Layout, and Paint, and finally generates a scene (Scene) and sends it to the bottom layer. That Scene will be drawn by the GPU onto the screen. Animate stage: The animation stage is the first stage of the pipeline because the animation changes state with each Vsync signal. Build stage, Flutter, at which the widgets that need to be rebuilt will be rebuilt at this time. That is when we are familiar StatelessWidget.build() or State.build() called. In the Layout phase, the position and size of each display element is determined. This is RenderObject.performLayout() the time when it is called. The Paint phase, RenderObject.paint() when it is called. The above is a rough working process of the entire rendering pipeline. The Flutter app only needs to trigger the rendering pipeline when the state changes. You don't need to re-render the page when your app does nothing. Therefore, the Vsync signal requires the Flutter app to schedule. For example, we all know that if one of your pages needs to be changed, it may be called State.setState(). The call to the Flutter framework will eventually initiate a request to dispatch the Vsync signal to the underlying. Then the bottom layer will drive the rendering pipeline to start working when the Vsync signal arrives, and finally display the new page to the screen. The overall structure of Flutter is shown below: It can be seen that the entire Flutter architecture is divided into two parts. The upper part of the Framework and the underlying Engine part. The Framework part is written in the Dart language and is the main part of this series. The Engine part is implemented in C++. The engine provides support for the framework and is the bridge between the framework and the system (Android/iOS). The Vsync signal that triggers the rendering pipeline is from the engine. The scene after rendering is also sent to the engine for display, and the scheduling of the Vsync signal is also used by the framework to notify the system through the engine. The rendering process is represented by a schematic diagram from the perspective of the framework and engine interaction: The framework notification engine (scheduleFrame) needs to schedule a frame. After the system's Vsync signal arrives, the engine will first call back the _beginFrame function of the framework . At this point, the rendering pipeline of the frame enters the animation stage (Animate) stage. After the animation phase (Animate) phase is completed. The engine will process the microtask queue and then call back the framework's _drawFrame functions. The render pipeline continues to run build, layout, and draw in sequence. After the drawing is finished, the frame call render sends the finished scene to the engine for display to the screen. In the front-end development, we all have a concept of a window for the user interface. The UI of the program we write is contained in the window, which is the root of the framework. The drawing of the interface, the processing of events input by the user, etc. are all managed through the window. Flutter is no exception. The above framework and engine rendering interaction process is also integrated into the window management. So to understand the Flutter framework, you have to start with the window of Flutter. 1.2.1. Window WindowFrom the library in Flutter dart:ui. The relevant source code is in the window.dart middle. First of all, in Flutter, it Windowis a singleton: /// The [Window] singleton. This object exposes the size of the display, the /// core scheduler API, the input event callback, the graphics drawing API, and /// other such core services. final Window window = new Window._(); Window The singleton provides screen size, scheduling interface, input event callback, graphics rendering interface and other core services to the upper layer. In general, the window interface related to the graphical interface in the Flutter engine is provided centrally. Window The api associated with the rendering pipeline is as follows: // The callback after the vcync signal arrives FrameCallback _onBeginFrame; VoidCallback _onDrawFrame; // Request engine to schedule a frame void scheduleFrame() native 'Window_scheduleFrame'; // After the drawing is completed, the scene is sent to the engine display. void render(Scene scene) native 'Window_render'; Note the native keyword behind the function name , indicating that this function is called to the engine layer. Similar to the jni call in Android. In addition to rendering related APIs, window there are some other important APIs listed below: //Touch event callback PointerDataPacketCallback _onPointerDataPacket; // Get the route of the initial page at startup String _defaultRouteName() native 'Window_defaultRouteName'; // Send PlatfromMessage. This is part of the Platform channels mechanism String _sendPlatformMessage(String name, PlatformMessageResponseCallback callback, ByteData data) native 'Window_sendPlatformMessage'; //Callback after receiving the platform message PlatformMessageCallback _onPlatformMessage; There are also APIs related to locale, accessbility that are not listed. 1.3. to sum up At this point, Flutter Window will probably introduce it to everyone. It can be seen that Window it is not complicated. It is basically just a package of interfaces related to the user interface provided on the engine layer. The Flutter framework is based on the Window establishment. If you want, you can Window replace Flutter :) based on setting up your own set of frameworks :). After learning about Flutter's rendering pipeline and window infrastructure. Next, we will use this as a basis to start the journey of the wonderful Flutter framework, so stay tuned. "},"Flutter Framework Analysis 2 - Initialization.html":{"url":"Flutter Framework Analysis 2 - Initialization.html","title":"Flutter Framework Analysis 2 - Initialization","keywords":"","body":"1. Flutter Framework Analysis (2) -- Initialization1.1. Foreword1.2. initialization1.2.1. ensureInitialized()1.2.2. attachRootWidget(app)1.2.3. scheduleWarmUpFrame()1.3. to sum up1. Flutter Framework Analysis (2) -- Initialization Flutter Framework Analysis and Analysis Series: \"Flutter Framework Analysis (1) - Overview and Window\" \"Flutter Framework Analysis (1) - Overview and Window\" \"Flutter Framework Analysis (2) - Initialization\" \"Flutter Framework Analysis (3) - Widget, Element and RenderObject\" \"Flutter Framework Analysis (4) - Flutter Framework Operation\" \"Flutter Framework Analysis (5) - Animation\" \"Flutter Framework Analysis (6) - Layout\" \"Flutter Framework Analysis (7) - Drawing\" Flutter Framework Analysis (2) -- Initialization Foreword initialization ensureInitialized() attachRootWidget(app) scheduleWarmUpFrame() to sum up 1.1. Foreword The previous article \"Flutter Framework Analysis (1) - Overview and Window\" introduces the core rendering pipeline and the most basic of the Flutter framework Window. In this article, we enter from the initialization of the Flutter framework to unveil the cover of Flutter step by step. Students who have written the Flutter program know that the entrance to the Flutter app is a function runApp(). void main() { runApp(MyApp()); } So let's runApp() start with the function and see what happens after this function is called. 1.2. initialization runApp() The function body is located widgets/binding.dart. Long like this: void runApp(Widget app) { WidgetsFlutterBinding.ensureInitialized() ..attachRootWidget(app) ..scheduleWarmUpFrame(); } It can be seen from the name of the function called, it does 3 things, Make sure it WidgetsFlutterBinding is initialized. Where to put your Widget. Then schedule a \"warm-up\" frame. OK, then let's take a look at what these three things have done. 1.2.1. ensureInitialized() First of all, let's take a look at WidgetsFlutterBinding what it is. From the name of this class, it means to bind the Widget and Flutter together. class WidgetsFlutterBinding extends BindingBase with GestureBinding, ServicesBinding, SchedulerBinding, PaintingBinding, SemanticsBinding, RendererBinding, WidgetsBinding { static WidgetsBinding ensureInitialized() { if (WidgetsBinding.instance == null) WidgetsFlutterBinding(); return WidgetsBinding.instance; } } This class inherits from BindingBase and mixes in (Mixin) many other classes, seeing that the names are bindings of different functions. What the static function ensureInitialized() does is return a WidgetsBinding.instance singleton. The various binding classes that are mixed in are also inherited from the abstract class BindingBase. abstract class BindingBase { BindingBase() { ... initInstances(); ... } ... ui.Window get window => ui.window; } With regard to abstract classes BindingBase, you need to understand two places, one is to call the function when it is constructed initInstances(). This function will be implemented by its subclasses, which are the various binding classes of Mixin mentioned above. The specific initialization is implemented internally. The other is to BindingBase have one getter, and the return is window. Remember the window mentioned in \"Flutter Framework Analysis (I) - Overview and Window\") ? That's right, here window is it. Then, can we infer that these bindings are actually the right window package? Come, let's take a look at what these binding classes initInstances() did when they called . The first one is GestureBinding. Gesture binding. mixin GestureBinding on BindingBase implements HitTestable, HitTestDispatcher, HitTestTarget { @override void initInstances() { super.initInstances(); _instance = this; window.onPointerDataPacket = _handlePointerDataPacket; } When calling initInstances(), the main thing to do is to window set up a callback function that sets a gesture. So this binding is mainly responsible for managing gesture events. The second one is ServicesBinding. Service binding mixin ServicesBinding on BindingBase { @override void initInstances() { super.initInstances(); _instance = this; window ..onPlatformMessage = BinaryMessages.handlePlatformMessage; initLicenses(); } This binding is mainly for window the callback that sets the processing of the Platform Message. The third is SchedulerBinding. Schedule bindings. mixin SchedulerBinding on BindingBase, ServicesBinding { @override void initInstances() { super.initInstances(); _instance = this; window.onBeginFrame = _handleBeginFrame; window.onDrawFrame = _handleDrawFrame; SystemChannels.lifecycle.setMessageHandler(_handleLifecycleMessage); } This binding is mainly to window set up onBeginFrame and onDrawFrame callback, recall the article about rendering pipeline when the signal comes when Vsync engine calls back Flutter to start rendering process, which is in two callback SchedulerBinding management. The fourth is PaintingBinding. Draw the binding. mixin PaintingBinding on BindingBase, ServicesBinding { @override void initInstances() { super.initInstances(); _instance = this; _imageCache = createImageCache(); } This binding just creates a picture cache, so I won't go into details. The fifth is SemanticsBinding. Accessibility binding. mixin SemanticsBinding on BindingBase { @override void initInstances() { super.initInstances(); _instance = this; _accessibilityFeatures = window.accessibilityFeatures; } This binding management accessibility feature will not be elaborated. The sixth is RendererBinding. Render the binding. This is a more important class. mixin RendererBinding on BindingBase, ServicesBinding, SchedulerBinding, GestureBinding, SemanticsBinding, HitTestable { @override void initInstances() { super.initInstances(); _instance = this; _pipelineOwner = PipelineOwner( onNeedVisualUpdate: ensureVisualUpdate, onSemanticsOwnerCreated: _handleSemanticsOwnerCreated, onSemanticsOwnerDisposed: _handleSemanticsOwnerDisposed, ); window ..onMetricsChanged = handleMetricsChanged ..onTextScaleFactorChanged = handleTextScaleFactorChanged ..onPlatformBrightnessChanged = handlePlatformBrightnessChanged ..onSemanticsEnabledChanged = _handleSemanticsEnabledChanged ..onSemanticsAction = _handleSemanticsAction; initRenderView(); _handleSemanticsEnabledChanged(); assert(renderView != null); addPersistentFrameCallback(_handlePersistentFrameCallback); _mouseTracker = _createMouseTracker(); } This binding is responsible for managing the rendering process, and there are more things to do during initialization. The first is to instantiate a PipelineOwner class. This class is responsible for managing the rendering pipeline that we have previously said. A window series of callback functions are then set up to handle screen size changes, brightness changes, and so on. Then call initRenderView(). void initRenderView() { assert(renderView == null); renderView = RenderView(configuration: createViewConfiguration(), window: window); renderView.scheduleInitialFrame(); } This function instantiates a RenderView class. RenderView inherited from RenderObject. We all know that this render tree exists in the Flutter framework. This RenderViewis the root node of the render tree. This can be seen by opening the \"Flutter Inspector\". Under the Tab of the \"Render Tree\", this is the red box at the root RenderView. The last call addPersistentFrameCallback adds a callback function. Please remember this callback, the main stage of the rendering pipeline will start in this callback. The seventh is the WidgetsBinding component binding. mixin WidgetsBinding on BindingBase, SchedulerBinding, GestureBinding, RendererBinding, SemanticsBinding { @override void initInstances() { super.initInstances(); _instance = this; buildOwner.onBuildScheduled = _handleBuildScheduled; window.onLocaleChanged = handleLocaleChanged; window.onAccessibilityFeaturesChanged = handleAccessibilityFeaturesChanged; SystemChannels.navigation.setMethodCallHandler(_handleNavigationInvocation); SystemChannels.system.setMessageHandler(_handleSystemMessage); } The initialization of this binding first buildOwner sets a onBuildScheduled callback, remember that the initialization of the rendering binding is instantiated PipelineOwner? This BuildOwner is instantiated in the component binding. It is mainly responsible for managing the reconstruction of the Widget, remembering the two \"owners\". They will be the core classes in the Flutter framework. Then window set up two callbacks, because the relationship with rendering is not big, so I won't elaborate. Finally set the SystemChannels.navigation and SystemChannels.system message handlers. One of these two callbacks is dedicated to routing, and the other is to handle some system events, such as clipboard, vibration feedback, system sound effects, and so on. At this point, the WidgetsFlutterBinding.ensureInitialized() finished running. In general, the window provided APIs are packaged into different Bindings. What we need to focus on is SchedulerBinding, RendererBinding and WidgetsBinding. These three are important to the rendering pipeline. Next, let's take a look runApp() at the second call. 1.2.2. attachRootWidget(app) The code for this function is as follows: void attachRootWidget(Widget rootWidget) { _renderViewElement = RenderObjectToWidgetAdapter( container: renderView, debugShortDescription: '[root]', child: rootWidget ).attachToRenderTree(buildOwner, renderViewElement); } In RendererBinding the initialization mentioned earlier , we got an RenderView instance of the root node of the render tree. RenderView It is inherited from RenderObject, and RenderObject needs to have the corresponding Widget and Element. This is the RenderObjectToWidgetAdapter one in the above code Widget. The corresponding Element is RenderObjectToWidgetElement, since it is to be associated render tree to the root node, then it naturally, is the root element of the tree. From the above analysis we can conclude that: The render binding ( RendererBinding) pipelineOwner holds the root node of the render tree indirectly RenderView. The component binding ( WidgetsBinding) holds the root node of the element tree RenderObjectToWidgetElement. So RenderObjectToWidgetElement how RenderView is it related to it, it is naturally done through a Widget, look at the RenderObjectToWidgetAdapter code: class RenderObjectToWidgetAdapter extends RenderObjectWidget { /// Creates a bridge from a [RenderObject] to an [Element] tree. /// /// Used by [WidgetsBinding] to attach the root widget to the [RenderView]. RenderObjectToWidgetAdapter({ this.child, this.container, this.debugShortDescription }) : super(key: GlobalObjectKey(container)); @override RenderObjectToWidgetElement createElement() => RenderObjectToWidgetElement(this); @override RenderObjectWithChildMixin createRenderObject(BuildContext context) => container; ... } You see, the createElement() return is RenderObjectToWidgetElement, and the createRenderObject return container is to construct the Widget passed in RenderView. And our own MyApp as a child widget exists in it RenderObjectToWidgetAdapter. The last attachToRenderTree thing that is called is the Build phase of the rendering pipeline we said earlier, when we generate the element tree and the render tree based on our own widget. After the Build phase is completed, it is natural to enter the Layout phase and the Paint phase. How to get in? That is runApp the last function call in the middle. 1.2.3. scheduleWarmUpFrame() void scheduleWarmUpFrame() { ... Timer.run(() { ... handleBeginFrame(null); ... }); Timer.run(() { ... handleDrawFrame(); ... }); } In fact, this function will adjust the two functions, that is, before we talk about window when he was two callback functions onBeginFrame and onDrawFrame do? Here is actually the implementation of these two callbacks. Finally, the first frame scene is rendered and sent to the engine display to the screen. The Timer.run() two callbacks used here to run asynchronously are meant to have the opportunity to process the microtask queue before they are called. For the asynchronous execution of Dart code, please refer to my article \"Asynchronous in Flutter/Dart\" We previously said that the rendering pipeline is driven by the Vsync signal, but the above process is runApp() done in it. Did not see where to tell the engine to dispatch a frame. This is because we are doing the initialization of Flutter. In order to save time waiting for the Vsync signal, the rendering process is run directly to make the first frame image. 1.3. to sum up The initialization of the Flutter framework is complete. Incidentally, it also includes a rough flow of the first frame rendering of the Flutter app. The main point of the initialization of the Flutter framework mentioned in this article is the initialization of several bindings. Remember to remember the rendering pipelines and summaries described in the previous article window. The Flutter framework is actually about making a fuss about these two things. To sum up, the main points of this article are so few: 3 important bindings:SchedulerBinding, RendererBinding and WidgetsBinding. 2 \"owner\": PipelineOwner and BuildOwner. The root node of the 2 trees: the root node of the render tree RenderView; the root node of the element tree RenderObjectToWidgetElement. With this foundation in the future, follow-up article we will go analysis Widget, Element and RenderObject the relationship between, and the specific Flutter rendering of how the various stages of the pipeline works. "},"Flutter Framework Analysis 3 - Widget, Element and RenderObject.html":{"url":"Flutter Framework Analysis 3 - Widget, Element and RenderObject.html","title":"Flutter Framework Analysis 3 - Widget, Element and RenderObject","keywords":"","body":"1. Flutter Framework Analysis (3) -- Widget, Element and RenderObject1.1. Foreword1.2. Overview1.3. Widget1.3.1. StatelessWidget1.3.2. StatefulWidget1.3.3. InheritedWidget1.3.4. RenderObjectWidget1.4. Element1.4.1. ComponentElement1.4.2. StatelessElement1.4.3. StatefulElement1.4.4. InheritedElement1.4.5. RenderObjectElement1.5. RenderObject1.6. to sum up1. Flutter Framework Analysis (3) -- Widget, Element and RenderObject Flutter Framework Analysis and Analysis Series: \"Flutter Framework Analysis (1) - Overview and Window\" \"Flutter Framework Analysis (2) - Initialization\" \"Flutter Framework Analysis (3) - Widget, Element and RenderObject\" \"Flutter Framework Analysis (4) - Flutter Framework Operation\" \"Flutter Framework Analysis (5) - Animation\" \"Flutter Framework Analysis (6) - Layout\" \"Flutter Framework Analysis (7) - Drawing\" Flutter Framework Analysis (3) -- Widget, Element and RenderObject Foreword Overview Widget StatelessWidget StatefulWidget State InheritedWidget RenderObjectWidget Element ComponentElement StatelessElement StatefulElement InheritedElement RenderObjectElement RenderObject to sum up 1.1. Foreword The previous two articles on the analysis of the Flutter framework introduced the rendering pipeline, the window and the initialization of the framework. The article goes on to manage at the Flutter app developers more important Widget, Element and RenderObjectsystem. Flutter's philosophy is that Widget. Everything is Widget. Developers are mostly writing a lot when developing the Flutter app Widget. So what is the relationship between the three? How do they work? Let us find out. 1.2. Overview The content of this piece is more and more complicated. In order to prevent everyone from getting lost in the sea of ​​source code, let us briefly give an example to understand this system. void main() { runApp(MyWidget()); } class MyWidget extends StatelessWidget { final String _message = \"Flutter框架分析\"; @override Widget build(BuildContext context) => ErrorWidget(_message); } This example uses Flutter's own ErrorWidget display of our custom sentence: \"Flutter Framework Analysis.\" That's right, this ErrorWidget is the terrible red-yellow yellow message that appears on the screen when your code is out of bug. Let's take a look at the screenshots. It is used here because it is the simplest and least hierarchical one Widget. So that we can understand the Flutter framework and avoid being dismissed by MaterialApp the unfathomable element tree and render tree. After running the above example, open the Flutter Inspector and look at it: As you can see from the above figure, there are three levels of root-> MyWidget-> ErrorWidget. This looks like a widget tree. The root here corresponds to what was said in the previous article RenderObjectToWidgetAdapter. But this is actually an element tree like this: RenderObjectToWidgetElement-> StatelessElement-> LeafRenderObjectElement. Remember what we said in the last article RenderObjectToWidgetElement is the root node of the element tree. Look at the red box above the figure, this root node is the root node holding the render tree RenderView. It is our own child nodes to write MyWidget corresponding StatelessElement. And this element is not held RenderObject. Only the bottom ErrorWidget corresponding one LeafRenderObjectElement holds the second one RenderObject. So the render tree is only two layers: RenderView -> RenderErrorBox. The above is represented by the diagram: The green connecting line in the figure represents the hierarchical relationship of the element tree. The yellow connecting line represents the hierarchical relationship of the render tree. As can be seen from the above example, it Widget is used to describe the corresponding Element description or configuration. The main function Element of the element tree Element is to maintain the tree. The addition, deletion, update, and tree traversal of the node are completed here. Element From all Widget generated. Each Widget will correspond to one Element. But not every Widget/ Element will correspond to one RenderObject. Only when this Widget inherits RenderObjectWidget will there be a corresponding RenderObject. In general, it is the following: Widget Is Element the configuration or description of the pair . The main job of the Flutter app developers is to Widget deal with them. We don't need to care about the maintenance and update of the tree, we just need to focus on Widget the maintenance of the state, which greatly reduces the burden on the developer. Element Responsible for maintaining the element tree. Element I don't care about the specific color, font size, display content, etc. The configuration or description of these UIs, and I don't care about the layout, drawing these things, it just manages its own tree. Element The main work is in the build phase of the render pipeline. RenderObject Responsible for the specific layout and drawing these things. That is, the layout and painting phases of the rendering pipeline. Next we will combine the source code to analyze Widget, Element and RenderObject. 1.3. Widget The base class Widget is very simple @immutable abstract class Widget extends DiagnosticableTree { const Widget({ this.key }); ... @protected Element createElement(); ... } The method createElement() is responsible for instantiating the corresponding one Element. It is implemented by its subclasses. Next, let's look at a few more important subclasses: 1.3.1. StatelessWidget abstract class StatelessWidget extends Widget { /// Initializes [key] for subclasses. const StatelessWidget({ Key key }) : super(key: key); @override StatelessElement createElement() => StatelessElement(this); @protected Widget build(BuildContext context); } StatelessWidget Familiar with the Flutter developers. Its createElement method returns an StatelessElement instance. StatelessWidget There is no RenderObject method of generating . So StatelessWidget just a middle layer, it needs to implement build methods to return children Widget. 1.3.2. StatefulWidget abstract class StatefulWidget extends Widget { @override StatefulElement createElement() => StatefulElement(this); @protected State createState(); } StatefulWidget Very familiar with the Flutter developers. createElement The method returns an StatefulElement instance. The method of createState() constructing this corresponds StatefulWidget to State. StatefulWidget There is no RenderObject method of generating . So StatefulWidget it's just a middle layer, it needs a corresponding State implementation build to return the child Widget. State When StatefulWidget you say it, you can't stop talking State. abstract class State extends Diagnosticable { T get widget => _widget; T _widget; BuildContext get context => _element; StatefulElement _element; bool get mounted => _element != null; void initState() { } void didUpdateWidget(covariant T oldWidget) { } void setState(VoidCallback fn) { final dynamic result = fn() as dynamic; _element.markNeedsBuild(); } void deactivate() { } void dispose() { } Widget build(BuildContext context); void didChangeDependencies() { } } Visible from source, State hold the corresponding Widget and Element. Pay attention to this sentence BuildContext get context => _element;. The input build we entered at the time of the call BuildContext actually returned Element. mounted Used to determine if this State is associated with one of the element trees Element. If you are State not currently in mounted == true the state, you setState() will crash when you call it. The function is initState() used to initialize State. The function is called after didUpdateWidget(covariant T oldWidget) this has State been changed Widget. Yes, the State corresponding Widget instances can be exchanged for as long as they are of the same type. The function setState() is very familiar to us. This function simply executes the incoming callback and then calls it _element.markNeedsBuild(). You see, if this time _element is empty, will there be a problem? So I suggest you setState() use mounted it before you call it. Another point to note is that this function is also a point that triggers the rendering pipeline. I would follow from this point in another article, for everyone to talk about how the rendering pipeline Widget, Element and RenderObject lower operational framework. Function deactivate() in State the corresponding Element after being removed from the tree to call, this may be removed temporarily removed. Function dispose() in State the corresponding Element after being removed from the call tree, the removal is permanently removed. The function build(BuildContext context), everyone is very familiar with, not much to say. The function didChangeDependencies(), when State the dependency changes, is called, and what kind of dependency depends on the text. StatefullWidget and State it may be the most dealing with the developers of the Flutter app. Some details also need to be combined to Element make an in-depth understanding. 1.3.3. InheritedWidget InheritedWidget Neither is it StatefullWidget nor StatelessWidget. It is used to pass data down. In InheritedWidget sub-node under the can by calling BuildContext.inheritFromWidgetOfExactType() to get this InheritedWidget. Its createElement() function returns one InheritedElement. abstract class InheritedWidget extends ProxyWidget { const InheritedWidget({ Key key, Widget child }) : super(key: key, child: child); @override InheritedElement createElement() => InheritedElement(this); @protected bool updateShouldNotify(covariant InheritedWidget oldWidget); } 1.3.4. RenderObjectWidget RenderObjectWidget Used for configuration RenderObject. Its createElement() function returns RenderObjectElement. It is implemented by its subclasses. Relative to the other mentioned above Widget. There is one more createRenderObject() method here . Used to instantiate RenderObject. abstract class RenderObjectWidget extends Widget { const RenderObjectWidget({ Key key }) : super(key: key); @override RenderObjectElement createElement(); @protected RenderObject createRenderObject(BuildContext context); @protected void updateRenderObject(BuildContext context, covariant RenderObject renderObject) { } @protected void didUnmountRenderObject(covariant RenderObject renderObject) { } } RenderObjectWidget Just a configuration, when the configuration changes need to be applied to the existing RenderObject one, the Flutter framework will call updateRenderObject() to set the new configuration to the corresponding one RenderObject. RenderObjectWidget There are three more important subclasses: LeafRenderObjectWidget The Widget node of this configuration is at the bottom of the tree, it has no children. Correspondence LeafRenderObjectElement. SingleChildRenderObjectWidget, only one child. Correspondence SingleChildRenderObjectElement. MultiChildRenderObjectWidget There are multiple children. Correspondence MultiChildRenderObjectElement. 1.4. Element Element Forms the element tree. The main thing that this class is doing is to maintain this tree. FromWidget the analysis of the above, we can see that it seems that each special one Widget will have a corresponding one Element. Especially for RenderObjectWidget. If I have one XXXRenderObjectWidget, it createElement() usually returns one XXXRenderObjectElement. For the sake of simplicity. Our analysis is limited to a few basic ones Element. First look at the base class Element. abstract class Element extends DiagnosticableTree implements BuildContext { Element _parent; Widget _widget; BuildOwner _owner; dynamic _slot; void visitChildren(ElementVisitor visitor) { } Element updateChild(Element child, Widget newWidget, dynamic newSlot) { } void mount(Element parent, dynamic newSlot) { } void unmount() { } void update(covariant Widget newWidget) { } @protected Element inflateWidget(Widget newWidget, dynamic newSlot) { ... final Element newChild = newWidget.createElement(); newChild.mount(this, newSlot); return newChild; } void markNeedsBuild() { if (dirty) return; _dirty = true; owner.scheduleBuildFor(this); } void rebuild() { if (!_active || !_dirty) return; performRebuild(); } @protected void performRebuild(); } Element Hold the current Widget one BuildOwner. This BuildOwner was WidgetsBinding instantiated in the previous one. Element is a tree structure that holds the parent node _parent. Set _slot by the parent Element, the purpose is to tell the current Element location of the parent node. Because the Element base class does not know how the child class will manage the child node. So the function visitChildren() is implemented by a subclass to traverse the child node. The function is updateChild() more important to update a child node. There are four cases for updates: The new Widget is empty, and the old Widget is empty. Then I will not do it. New Widget is empty, old is Widget not empty. This Element was removed. New is Widget not empty, old Widget is empty. Then call inflateWidget() this Wiget to instantiate one for the configuration Element. New is Widget not empty, old is Widget not empty. Call the update() function updater Element. update() Functions are implemented by subclasses. After the new Element instantiation is called, it will be called mount() to add itself to the element tree. Called when you want to remove unmount(). The function is markNeedsBuild() used to mark Elementthe \"dirty\" state. Indicates that this Element needs to be rebuilt when rendering the next frame . The functionrebuild() is called during the build phase of the render pipeline. The concrete reconstruction is implemented in the function performRebuild() and by the Element subclass. Widget There are some more important subclasses, and Element there are some more important subclasses. 1.4.1. ComponentElement ComponentElement indicates that this Element is currently used to combine other Element ones. abstract class ComponentElement extends Element { ComponentElement(Widget widget) : super(widget); Element _child; @override void performRebuild() { Widget built; built = build(); _child = updateChild(_child, built, slot); } Widget build(); } ComponentElement inherited from Element. Is an abstract class. _child is its child. performRebuild() is called in the function build() to instantiate one Widget. build() Functions are implemented by their subclasses. 1.4.2. StatelessElement StatelessElement Corresponding Widget is what we are familiar with StatelessWidget. class StatelessElement extends ComponentElement { @override Widget build() => widget.build(this); @override void update(StatelessWidget newWidget) { super.update(newWidget); _dirty = true; rebuild(); } } Its build() function is called directly StatelessWidget.build(). Now you know where you are written StatelessWidget and build() where it is called. And you see, the build() function's input is this. We all know that the input parameters of this function should be of BuildContext type. This entry is actually this StatelessElement. 1.4.3. StatefulElement StatefulElement Corresponding Widget is what we are familiar with StatefulWidget. class StatefulElement extends ComponentElement { /// Creates an element that uses the given widget as its configuration. StatefulElement(StatefulWidget widget) : _state = widget.createState(), super(widget) { _state._element = this; _state._widget = widget; } @override Widget build() => state.build(this); @override void _firstBuild() { final dynamic debugCheckForReturnedFuture = _state.initState() _state.didChangeDependencies(); super._firstBuild(); } @override void deactivate() { _state.deactivate(); super.deactivate(); } @override void unmount() { super.unmount(); _state.dispose(); _state._element = null; _state = null; } @override void didChangeDependencies() { super.didChangeDependencies(); _state.didChangeDependencies(); } } In the StatefulElement construction time can call the corresponding StatefulWidget the createState() function. That State is to say, it is instantiated at StatefulElement the time of instantiation. And the State instance will be StatefulElement held by this instance. From here you can also see why StatefulWidget the state is managed separately, State and a new one may be StatefulWidget created each time it is refreshed , but the State instance is unchanged. build() The function call is familiar to us, State.build(this) and now you know where State the build() function is called. And you see, the build() function's input is this. We all know that the input parameters of this function should be of BuildContext type. This entry is actually this StatefulElement. We all know that State has a state, and the corresponding callback function will be called when the state changes. These callback functions are actually StatefulElement called inside. In the function _firstBuild() where calls State.initState() and State.didChangeDependencies(). deactivate() Called in the function State.deactivate(). unmount() Called in the function State.dispose(). didChangeDependencies() Called in the function State.didChangeDependencies(). 1.4.4. InheritedElement InheritedElement The corresponding Widget is InheritedWidget. The internal implementation is mainly to maintain the child Element that has dependencies on it Map, and to call the Element corresponding didChangeDependencies() callback when needed. The code is not posted here. If you are interested, you can look at the source code yourself. 1.4.5. RenderObjectElement RenderObjectElement The corresponding Widget is RenderObjectWidget. abstract class RenderObjectElement extends Element { RenderObject _renderObject; @override void mount(Element parent, dynamic newSlot) { super.mount(parent, newSlot); _renderObject = widget.createRenderObject(this); attachRenderObject(newSlot); _dirty = false; } @override void unmount() { super.unmount(); widget.didUnmountRenderObject(renderObject); } @override void update(covariant RenderObjectWidget newWidget) { super.update(newWidget); widget.updateRenderObject(this, renderObject); _dirty = false; } @override void performRebuild() { widget.updateRenderObject(this, renderObject); _dirty = false; } @protected void insertChildRenderObject(covariant RenderObject child, covariant dynamic slot); @protected void moveChildRenderObject(covariant RenderObject child, covariant dynamic slot); @protected void removeChildRenderObject(covariant RenderObject child); } The function mount() is called RenderObjectWidget.createRenderObject() to instantiate when the function is called RenderObject. Function update() and performRebuild()is invoked calls RenderObjectWidget.updateRenderObject(). unmount() Called when the function is called RenderObjectWidget.didUnmountRenderObject(). 1.5. RenderObject RenderObject Responsible for rendering the layout and painting phases of the pipeline. The render tree is also maintained. The maintenance method for the render tree is from the base class AbstractNode. Here we focus on some of the methods associated with rendering pipelines. abstract class RenderObject extends AbstractNode with DiagnosticableTreeMixin implements HitTestTarget { void markNeedsLayout() { ... } void markNeedsPaint() { ... } void layout(Constraints constraints, { bool parentUsesSize = false }) { ... if (sizedByParent) { performResize(); } ... performLayout(); ... } void performResize(); void performLayout(); void paint(PaintingContext context, Offset offset) { } } markNeedsLayout() Marking this RenderObject requires re-layout. markNeedsPaint Marking this RenderObject requires redrawing. These two functions are only marked. After the markup, the Flutter framework dispatches a frame and does the layout and drawing after the next Vsync signal arrives. The real layout is done in the function layout(). This function will make a judgment if it sizedByParent is true. Will be called performResize(). Indicates that RenderObject the size of this is determined only by its parent node. Then it will be called to performLayout() do the layout. performResize() And subclasses that performLayout() are needed RenderObject to implement. 1.6. to sum up Widget, Element and the RenderObject system is the core of the Flutter framework. It Element needs to be understood. The build phase in Flutter's rendering pipeline is primarily to maintain Element nodes in the updated element tree . Only by understanding the Element element tree, is the real master of the Flutter framework. This article is just some static instructions. In the next article I will try to analyze how the Flutter framework works from the perspective of the dynamic operation of the rendering pipeline. "},"Flutter Framework Analysis 4 - Flutter Framework Operation.html":{"url":"Flutter Framework Analysis 4 - Flutter Framework Operation.html","title":"Flutter Framework Analysis 4 - Flutter Framework Operation","keywords":"","body":"1. Flutter Framework Analysis (4) -- Flutter Framework Operation1.1. Foreword1.2. Before scheduling1.3. After Vsync arrives1.3.1. onBeginFrame1.3.2. onDrawFrame1.3.3. Build phase1.4. to sum up1. Flutter Framework Analysis (4) -- Flutter Framework Operation Flutter Framework Analysis and Analysis Series: \"Flutter Framework Analysis (1) - Overview and Window\" \"Flutter Framework Analysis (2) - Initialization\" \"Flutter Framework Analysis (3) - Widget, Element and RenderObject\" \"Flutter Framework Analysis (4) - Flutter Framework Operation\" \"Flutter Framework Analysis (5) - Animation\" \"Flutter Framework Analysis (6) - Layout\" \"Flutter Framework Analysis (7) - Drawing\" Flutter Framework Analysis (4) -- Flutter Framework Operation Foreword Before scheduling After Vsync arrives onBeginFrame onDrawFrame Build phase to sum up 1.1. Foreword The previous articles introduced the rendering pipeline window, initialization Widget, Element and RenderObject architecture of the Flutter framework . Among themWidget, the introduction of Element and RenderObject is mainly a static description. After understanding these technical points, in this article we will introduce how the Flatter framework works by dynamically running. As you can see from the rendering pipeline introduced earlier, this process can be roughly divided into two operations. The first paragraph is State.setState() to request a frame from the engine, the second paragraph is the Vsync signal after the rendering pipeline begins to reconstruct a new frame and finally sent to the engine to display. Let's first look at what the first paragraph of the Flutter framework did. 1.2. Before scheduling Look at it first State.setState() void setState(VoidCallback fn) { final dynamic result = fn() as dynamic; _element.markNeedsBuild(); } Element The markNeedsBuild() function that will be called here . void markNeedsBuild() { if (!_active) return; if (dirty) return; _dirty = true; owner.scheduleBuildFor(this); } Element First look at whether it is active or not. If it is not, it will return directly. If it is a \"dirty\" state, it will return directly. If it is not, then it will put this state and then call BuildOwner the scheduleBuildFor() function. This BuildOwner we introduced before, its The instance is built at WidgetsBinding initialization time. Each Element will holdBuildOwner a reference. Set by the time when his father is Element at mount. void scheduleBuildFor(Element element) { if (element._inDirtyList) { _dirtyElementsNeedsResorting = true; return; } if (!_scheduledFlushDirtyElements && onBuildScheduled != null) { _scheduledFlushDirtyElements = true; onBuildScheduled(); } _dirtyElements.add(element); element._inDirtyList = true; } BuildOwner A_dirtyElements list will be maintained , and all those marked as \"dirty\" element will be added. Will be called before this onBuildScheduled(). This function is WidgetsBinding set when it is initialized BuildOwner, and the corresponding one is WidgetsBinding._handleBuildScheduled(). void _handleBuildScheduled() { ensureVisualUpdate(); } It will be called here ensureVisualUpdate(). This function is defined in the SchedulerBinding Lane void ensureVisualUpdate() { switch (schedulerPhase) { case SchedulerPhase.idle: case SchedulerPhase.postFrameCallbacks: scheduleFrame(); return; case SchedulerPhase.transientCallbacks: case SchedulerPhase.midFrameMicrotasks: case SchedulerPhase.persistentCallbacks: return; } } The function ensureVisualUpdate() will determine the current state of the schedule, if it is in idle(idle) or postFrameCallbacks running state scheduleFrame(). Other states return directly. The following three states are exactly when the rendering pipeline is running. void scheduleFrame() { if (_hasScheduledFrame || !_framesEnabled) return; window.scheduleFrame(); _hasScheduledFrame = true; } scheduleFrame() We saw familiarity in the function window. This is where the engine is notified to dispatch a frame. _hasScheduledFrame Flags are placed after scheduling to avoid duplicate requests. The other flag _framesEnabled is the status of the current app, or whether the life cycle it is allowed to refresh the interface. There are four states: resumed, inactive, paused and suspending. resumed: app is visible and can respond to user input. inactive: app can't respond to user input, such as popping up a system dialog on Android. paused: app is not visible to the user. suspending: app hangs?? This state looks like Android and iOS are not reported. _framesEnabled Only resumed and inactive state only for the true . In other words, the Flutter framework will only refresh the page in these two states. So far, the first phase, that is, the work before the schedule is finished. It seems to be relatively simple, mainly to put the need to rebuild Element into the _dirtyElements list. Next, the Flutter framework will wait for the engine callback frame after the Vsync signal arrives. This is the second thing to do. 1.3. After Vsync arrives We have previously said that after the Vsync signal arrives, engin will call back window the two callback functions in sequence : onBeginFrame() and onDrawFrame(). These two callbacks are SchedulerBinding set when the initialization is done window. The corresponding is SchedulerBinding.handleBeginFrame() and SchedulerBinding.handleDrawFrame(). 1.3.1. onBeginFrame This callback will go straight SchedulerBinding.handleBeginFrame(). void handleBeginFrame(Duration rawTimeStamp) { ... _hasScheduledFrame = false; try { // TRANSIENT FRAME CALLBACKS _schedulerPhase = SchedulerPhase.transientCallbacks; final Map callbacks = _transientCallbacks; _transientCallbacks = {}; callbacks.forEach((int id, _FrameCallbackEntry callbackEntry) { if (!_removedIds.contains(id)) _invokeFrameCallback(callbackEntry.callback, _currentFrameTimeStamp, callbackEntry.debugStack); }); _removedIds.clear(); } finally { _schedulerPhase = SchedulerPhase.midFrameMicrotasks; } } This function mainly calls the \"Transient\" callback function in turn. These callback functions are set before scheduling SchedulerBinding. Here, \"Transient\" means temporary, or one-time. The reason is that these callback functions will only be called once. Notice that the code _transientCallbacks is set to empty Map. If you want to call again in the next frame, you need to reset the callback in advance. These callbacks are mainly related to animation. This is the first stage in the rendering pipeline, the animation (Animate) stage. After the animation, I will write an article to analyze the animation mechanism from the perspective of the framework. _schedulerPhase The state before running the callback is set to SchedulerPhase.transientCallbacks. After the callback is processed, the status is updated to SchedulerPhase.midFrameMicrotasks mean that the microtask queue will be processed next. After processing the microtask, the engine will then callback onDrawFrame(). 1.3.2. onDrawFrame This callback will go straight SchedulerBinding.handleDrawFrame(). void handleDrawFrame() { try { // PERSISTENT FRAME CALLBACKS _schedulerPhase = SchedulerPhase.persistentCallbacks; for (FrameCallback callback in _persistentCallbacks) _invokeFrameCallback(callback, _currentFrameTimeStamp); // POST-FRAME CALLBACKS _schedulerPhase = SchedulerPhase.postFrameCallbacks; final List localPostFrameCallbacks = List.from(_postFrameCallbacks); _postFrameCallbacks.clear(); for (FrameCallback callback in localPostFrameCallbacks) _invokeFrameCallback(callback, _currentFrameTimeStamp); } finally { _schedulerPhase = SchedulerPhase.idle; _currentFrameTimeStamp = null; } } In handleDrawFrame order processing in the two types of callback, a class called \"Persistent\" callback, and the other is called \"Post-Frame\" callback. \"Persistent\" literally means permanent. Such callbacks cannot be cancelled once registered. Mainly used to drive the rendering pipeline. The build, layout, and paint phases of the render pipeline are all in one of the callbacks. The \"Post-Frame\" callback is mainly a type of call after the new frame is rendered. This type of callback will only be called once. The _schedulerPhase status changes to before the \"Persistent\" callback is run SchedulerPhase.persistentCallbacks. The _schedulerPhase status changes to before the \"Post-Frame\" callback is run SchedulerPhase.postFrameCallbacks. The final state changes to SchedulerPhase.idle. Here we mainly focus on a \"Persistent\" callback: WidgetsBinding.drawFrame(). This function is RendererBinding added to the \"Persistent\" callback at initialization time. void drawFrame() { try { if (renderViewElement != null) buildOwner.buildScope(renderViewElement); super.drawFrame(); buildOwner.finalizeTree(); } finally { ... } } This will be called first buildOwner.buildScope(renderViewElement). Its input parameter renderViewElement is the root node of the element tree. At this point, the rendering pipeline enters the build phase. Next called super.drawFrame(). This function is defined in RendererBinding it. void drawFrame() { pipelineOwner.flushLayout(); pipelineOwner.flushCompositingBits(); pipelineOwner.flushPaint(); renderView.compositeFrame(); // this sends the bits to the GPU pipelineOwner.flushSemantics(); // this also sends the semantics to the OS. } It can be seen that the baton of pipelineOwner the rendering pipeline has been passed to the hand, and the rendering pipeline enters the layout phase and the paint phase. This article will not be described in detail in the last two stages. Here everyone knows that after the drawing is completed, the Flutter framework will eventually call window.render(scene) the new frame data into the engine display to the screen. The last call buildOwner.finalizeTree();. The purpose of this function is to clean up Element nodes that are no longer needed . After the element tree is updated, some nodes may no longer need to be mounted on the tree, finalizeTree() and these nodes and their child nodes will be unmounted . 1.3.3. Build phase void buildScope(Element context, [VoidCallback callback]) { try { _scheduledFlushDirtyElements = true; _dirtyElements.sort(Element._sort); _dirtyElementsNeedsResorting = false; int dirtyCount = _dirtyElements.length; int index = 0; while (index Remember to Element put BuildOwner the _dirtyElements list that needs to be updated as \"dirty\" and put it in the list before scheduling the frame . Here, Flutter will first order the list according to the depth. because Element the child nodes are also reconstructed when rebuilding, so if the parent node and the child nodes are both \"dirty\", first rebuilding the parent node avoids repeated reconstruction of the child nodes. The order is to traverse the_dirtyElements list. Called in turn Element.rebuild(). This function will be called again Element.performRebuild(). We Element said earlier that it was performRebuild() implemented by its subclasses. Our previous starting point was State.setState(). Then take a look at StatefulElement how to do it. It's performRebuild() in its parent class ComponentElement: void performRebuild() { Widget built; built = build(); try { _child = updateChild(_child, built, slot); } catch (e, stack) { ... } } Recall ComponentElement. This build() function will eventually be called State.build(). The return is our own instantiation Widget. Get this new Widget call updateChild(). Element We introduced updateChild() this function before when we talked about it . From the increase, deletion, change of such a few cases, for MyWidget, from the State.setState() over is a change. This will be called child.update(newWidget);. This update() function is Element implemented by each subclass. Here we only list a few typical ones. StatefulElement And StatelessElement the update() function will eventually call the base class Element's rebuild() function. It seems to be in a circle. . . RenderObjectElement The update() function is simpler void update(covariant RenderObjectWidget newWidget) { super.update(newWidget); widget.updateRenderObject(this, renderObject); _dirty = false; } The update is just a call RenderObjectWidget.updateRenderObject(). This function was introduced before, just set the new configuration to the existing one RenderObject. Go back to the question of the circle above. The key to clarifying the call relationship here is to figure out whether it Element is working on yourself or on the child. Suppose we have such a three-layer element tree for update reconstruction. Father(StatefulElement) Child(StatefulElement) Grandson(LeafRenderObjectElement) Then from the parent node, the calling sequence is as follows: Parent.rebuild() ---> parent.performRebuild() ---> parent.updateChild() ---> sub.update() ---> sub.rebuild() ---> sub.performRebuild() ---> child.updateChild() ---> sun.update(). It can be seen that the build process is to Element update the child nodes one by one from the nodes that need to be reconstructed . Until the leaf node is encountered. At this point, the build phase of the render pipeline is finished. Next, the pipelineOwner layout and the paint phase are started by the driver. These two stages are left to be introduced to you later. 1.4. to sum up This article starts with the State.setState() functions we are familiar with and gives an overview of how the Flutter framework runs the rendering pipeline. In general, its runtime is divided into two phases, before scheduling the engine to the engine and after the Vsync signal arrives at the engine callback to the Flatter frame. The rest of the space is based on the update Element as an example of what the rendering pipeline has done during the build phase. Due to space limitations, there are no more Element new additions and deletions. If you are interested, you can look at the source directly to find out the relevant information. "},"Flutter Framework Analysis 5 - Animation.html":{"url":"Flutter Framework Analysis 5 - Animation.html","title":"Flutter Framework Analysis 5 - Animation","keywords":"","body":"1. Flutter Frame Analysis (5) -- Animation1.1. Foreword1.2. example1.3. analysis1.4. to sum up1. Flutter Frame Analysis (5) -- Animation Flutter Framework Analysis and Analysis Series: \"Flutter Framework Analysis (1) - Overview and Window\" \"Flutter Framework Analysis (2) - Initialization\" \"Flutter Framework Analysis (3) - Widget, Element and RenderObject\" \"Flutter Framework Analysis (4) - Flutter Framework Operation\" \"Flutter Framework Analysis (5) - Animation\" \"Flutter Framework Analysis (6) - Layout\" \"Flutter Framework Analysis (7) - Drawing\" Flutter Frame Analysis (5) -- Animation Foreword example analysis to sum up 1.1. Foreword The first four articles introduce the full picture of the Flutter framework, and I believe that everyone has an overall understanding of the Flatter framework. This series of articles is always described around the various stages of the rendering pipeline's operation. We know that the first thing that runs after the Vsync signal comes is the Animate phase. This phase is run from window the onBeginFrame function called back from the engine . Then this article will introduce the basic principles of animation of the Flutter framework. 1.2. example The so-called animation is actually a series of continuously changing pictures displayed in a very short time frame by frame, which is an animation in the eyes of the human eye. Here we give a simple example to explain how to run an animation in Flutter: import 'package:flutter/material.dart'; void main() { runApp(MaterialApp(home: LogoAnim())); } class LogoAnim extends StatefulWidget { _LogoAnimState createState() => _LogoAnimState(); } class _LogoAnimState extends State with SingleTickerProviderStateMixin { Animation animation; AnimationController controller; @override void initState() { super.initState(); controller = AnimationController(duration: const Duration(seconds: 2), vsync: this); animation = Tween(begin: 0, end: 300).animate(controller) ..addListener(() { setState(() { }); }); controller.forward(from: 0); } @override Widget build(BuildContext context) { return Center( child: Container( margin: EdgeInsets.symmetric(vertical: 10), height: animation.value, width: animation.value, child: FlutterLogo(), ), ); } void dispose() { controller.dispose(); super.dispose(); } } This animation is a Flutter logo that displays a small to large gradient on the phone screen. From the above code we can see that there are a few things to do to implement an animation in Flutter. The first thing to apply animation Widget is StatefulWidget. It has Stateto be mixed in ( mixin) SingleTickerProviderStateMixin. In order initState() to add animation-related initialization, here we instantiate two classes AnimationController and Animation. When instantiating, AnimationController we passed in two parameters, one is the duration of the animation, the other is State itself, here is actually used to mix in SingleTickerProviderStateMixin. When instantiating another one Animation, we first instantiate one Tween. This class actually represents a linear change from minimum to maximum. So when you instantiate, you need to pass in the start and end values. Then call animate() and pass in the previous one controller. This call will return the Animation instance we need . Obviously we need to know the message when the properties of the animation change, so here we will register the callback by ..addListener() giving the Animation instance. This callback only does one thing, and that is called setState() to update the UI. The last is to call controller.forward() to start the animation. Note build() that we widgetused it in the function when we built it animation.value. So the chain here is that the animation will be called after receiving the callback setState(), and setState will build() be rebuilt after the last article we know in the construction phase of the rendering pipeline Widget. When the reconstruction was completed, it was used after the change animation.value. This one frame by one frame loop, our animation is moving. Finally dispose(), remember to call the controller.dispose() release resource when you are at the end . Next, let's dive into the Flutter source to see how the animation works. 1.3. analysis First let's take a look at the mix State in SingleTickerProviderStateMixin. mixin SingleTickerProviderStateMixin on State implements TickerProvider { Ticker _ticker; @override Ticker createTicker(TickerCallback onTick) { _ticker = Ticker(onTick, debugLabel: 'created by $this'); return _ticker; } @override void didChangeDependencies() { if (_ticker != null) _ticker.muted = !TickerMode.of(context); super.didChangeDependencies(); } } This mixup actually does one thing, implement createTicker() to instantiate a Ticker class. In another function didChangeDependencies(), there is such a line of code _ticker.muted = !TickerMode.of(context);. This line of code means State whether it is mute its own when the animated dependency in the element tree changes _ticker. One scene is that when the animation of the current page is still playing, the user navigates to another page, and the animation of the current page does not need to be played again. Otherwise, the animation may continue to play when the page is switched back, and the control place is Here, pay attention to TickerMode.of(context) this way, we will see it in many places in the Flutter framework, basically InheritedWidget the way to find the corresponding one from the ancestors of the element tree . Ticker As the name implies, it is to provide a vsync signal to the animation. Let's take a look at the source code. class Ticker { TickerFuture _future; bool get muted => _muted; bool _muted = false; set muted(bool value) { if (value == muted) return; _muted = value; if (value) { unscheduleTick(); } else if (shouldScheduleTick) { scheduleTick(); } } bool get isTicking { if (_future == null) return false; if (muted) return false; if (SchedulerBinding.instance.framesEnabled) return true; if (SchedulerBinding.instance.schedulerPhase != SchedulerPhase.idle) return true; return false; } bool get isActive => _future != null; Duration _startTime; TickerFuture start() { _future = TickerFuture._(); if (shouldScheduleTick) { scheduleTick(); } if (SchedulerBinding.instance.schedulerPhase.index > SchedulerPhase.idle.index && SchedulerBinding.instance.schedulerPhase.index _animationId != null; @protected bool get shouldScheduleTick => !muted && isActive && !scheduled; void _tick(Duration timeStamp) { _animationId = null; _startTime ??= timeStamp; _onTick(timeStamp - _startTime); if (shouldScheduleTick) scheduleTick(rescheduling: true); } @protected void scheduleTick({ bool rescheduling = false }) { _animationId = SchedulerBinding.instance.scheduleFrameCallback(_tick, rescheduling: rescheduling); } @protected void unscheduleTick() { if (scheduled) { SchedulerBinding.instance.cancelFrameCallbackWithId(_animationId); _animationId = null; } } } It can be seen that the Ticker main thing is to do something like controlling a timer, having start() and stop() and mute. Also records your current status isTicking. What we need to pay attention to is scheduleTick() this function: @protected void scheduleTick({ bool rescheduling = false }) { _animationId = SchedulerBinding.instance.scheduleFrameCallback(_tick, rescheduling: rescheduling); } You see, here I ran to what we said in the previous article SchedulerBinding. Ticker The callback function that will be passed when dispatching here _tick. int scheduleFrameCallback(FrameCallback callback, { bool rescheduling = false }) { scheduleFrame(); _nextFrameCallbackId += 1; _transientCallbacks[_nextFrameCallbackId] = _FrameCallbackEntry(callback, rescheduling: rescheduling); return _nextFrameCallbackId; } Ticker The callback function _tick was added when scheduling one frame transientCallbacks. From the previous analysis of the rendering pipeline, we know that it transientCallbacks will be executed once window in the onBeginFrame callback after the vsync signal arrives . This means that you are now in the animation Animate phase of the render pipeline . Then let's take a look Ticker at _tick what the callback function does: void _tick(Duration timeStamp) { _animationId = null; _startTime ??= timeStamp; _onTick(timeStamp - _startTime); if (shouldScheduleTick) scheduleTick(rescheduling: true); } Here _onTick is the Ticker incoming time when instantiating . _onTick After being called, Ticker if you find that your task has not been completed yet, you must continue to beat, then schedule a new frame. So the power of watching animation is actually from the vsync signal. So what is this _onTick again? This function is Ticker passed in when instantiated . From the above analysis, we know that Ticker the instantiation is done at TickerProvider.createTicker() the time of the call . Who is going to call this function? Yes AnimationController. AnimationController({ double value, this.duration, this.debugLabel, this.lowerBound = 0.0, this.upperBound = 1.0, this.animationBehavior = AnimationBehavior.normal, @required TickerProvider vsync, }) : _direction = _AnimationDirection.forward { _ticker = vsync.createTicker(_tick); _internalSetValue(value ?? lowerBound); } Can be seen in its constructor createTicker(), the parameters passed in are _ticker. Then look _ticker. void _tick(Duration elapsed) { _lastElapsedDuration = elapsed; final double elapsedInSeconds = elapsed.inMicroseconds.toDouble() / Duration.microsecondsPerSecond; _value = _simulation.x(elapsedInSeconds).clamp(lowerBound, upperBound); if (_simulation.isDone(elapsedInSeconds)) { _status = (_direction == _AnimationDirection.forward) ? AnimationStatus.completed : AnimationStatus.dismissed; stop(canceled: false); } notifyListeners(); _checkStatusChanged(); } Do this in the callback, calculate and update the new value based on the timestamp after the vsync arrives. The calculation here is one _simulation. Why are you calling this name? Because this is used to simulate the change of the motion state of an object under different external forces at different points in time, this is also the essence of animation. After the new value is calculated, it is called notifyListeners() to notify the observers. Also remember in the initial example that we animation will pass the ..addListener() added callback after instantiation ? Here the callback will be called, which setState() will be called. The next step is the build phase of the render pipeline. You may have questions when you see this, and things are AnimationController done , what is the example Tween used to do? From AnimationController the constructor we can see that it only controls between [0.0, 1.0], which means that no matter how the animation moves, it only outputs values ​​between 0.0 and 1.0 at any time, but our animation has a rotation angle. , color gradients, graphic changes, and more complex combinations, obviously we have to find a way to convert the value between 0.0 and 1.0 into the angle, position, color, transparency, etc. we need, this conversion is done by various kinds Animation, As the example says Tween, its task fades the value from 0 to 300 during the animation. How to do it? After instantiation Tween we will call animate() and pass in the AnimationController instance. Animation animate(Animation parent) { return _AnimatedEvaluation(parent, this); } You see, the entrance is one Animation, here is AnimationController. The argument is one Animation. This completes the change from [0.0, 1.0] to any type. How do you change it? This change is actually happening when it is worthwhile. The above example will call this when it State.build() is constructed in the function . This is actually called .widget animation.value getter _AnimatedEvaluation.value @override T get value => _evaluatable.evaluate(parent); _evaluatable It is a Tween, parent is a AnimationController. So, this conversion is Tween done by yourself, and only if it knows what output it needs. T evaluate(Animation animation) => transform(animation.value); Going transform() inside again @override T transform(double t) { if (t == 0.0) return begin; if (t == 1.0) return end; return lerp(t); } See the scope limit? The real conversion is lerp() done again . @protected T lerp(double t) { return begin + (end - begin) * t; } Very simple linear interpolation. You have to understand what the Tween animation in Flutter is doing. Just grasp what it does in your own transform() function. From the above, you can Tween actually do the animation of linear interpolation. Tween Is linear interpolation, then if I want to engage in non-linear interpolation animation? Then use it CurvedAnimation. Flutter has a large variety of linear interpolation animations and non-linear interpolation animations. You can even define your own nonlinear animations by simply rewriting the transformation functions: import 'dart:math'; class ShakeCurve extends Curve { @override double transform(double t) => sin(t * pi * 2); } Ok, the animation in the framework of the Flutter is analyzed here first. 1.4. to sum up This article is the fifth in a series of articles on the Flutter framework analysis. This series of articles is mainly based on Flutter's rendering pipeline as a clue to analyze its operation. This article is mainly aimed at the animation stage of the rendering pipeline, from a low-level perspective on the animation mechanism of Flutter. I hope everyone has a basic understanding of Flutter's animation. All kinds of dazzling animation related widgets on this are derived on the basis of this, the so-called Daosheng, one life two, two students three, three things. If you master the Tao, you will not be confused by all things. "},"Flutter Framework Analysis 6 - Layout.html":{"url":"Flutter Framework Analysis 6 - Layout.html","title":"Flutter Framework Analysis 6 - Layout","keywords":"","body":"1. Flutter Frame Analysis (6) -- Layout1.1. Foreword1.2. Overview1.3. analysis1.3.1. BoxConstraints1.4. Layout example1.5. to sum up1. Flutter Frame Analysis (6) -- Layout Flutter Framework Analysis and Analysis Series: \"Flutter Framework Analysis (1) - Overview and Window\" \"Flutter Framework Analysis (2) - Initialization\" \"Flutter Framework Analysis (3) - Widget, Element and RenderObject\" \"Flutter Framework Analysis (4) - Flutter Framework Operation\" \"Flutter Framework Analysis (5) - Animation\" \"Flutter Framework Analysis (6) - Layout\" \"Flutter Framework Analysis (7) - Drawing\" Flutter Frame Analysis (6) -- Layout Foreword Overview analysis BoxConstraints Layout example to sum up 1.1. Foreword The previous article introduced the animation (animate) and build phase of the Flutter rendering pipeline. This article will introduce you to the layout stage of the rendering pipeline in conjunction with the Flutter source. 1.2. Overview Like other frameworks like Android, iOS, h5, etc., the frame needs to determine the position and size (size) of each element in the page before the page is drawn. For an element in a page, if it contains a child element, the layout of the child element is determined by the parent element after knowing the size of the child element. So as long as the size and position of the child elements are determined, the layout is complete. The layout of the Flutter frame uses the Box constraints model. The layout process is shown below: The tree in the figure is the render tree. Each node is one RenderObject. Starting from the root node, each parent node initiates the layout process of the child node Constraints, which is passed in at startup , that is, \"constraint\". Flutter uses the most box constraints. The box constraint contains 4 fields: maximum width ( maxWidth) minimum width ( minWidth) maximum height ( maxHeight) and minimum height ( minHeight). Once the child node layout is complete, it will determine its size ( size). size Contains two fields: width ( width) and height ( height). The parent node can obtain the size of the child node when the child node layout is completed. ( size) The overall layout flow can be described as one on the next, that is, the constraint is passed from top to bottom, and the upper one refers to the size from bottom to top. In this way, Flutter's layout process only needs to traverse the render tree. How the specific layout process works, we analyze it further by analyzing the source code. 1.3. analysis Recalling \"Flutter Framework Analysis (4) - Flutter Framework Run\" we know that after the vsync signal arrives, the render pipeline starts, and window the onDrawFrame() function in the engine callback . This function runs Flutter's \"Persistence FRAME CALLBACKS\". The build, layout, and paint phases of the render pipeline are all in this callback, WidgetsBinding.drawFrame(). This function is added to the \"Persistent\" callback when the RendererBinding is initialized. void drawFrame() { try { if (renderViewElement != null) buildOwner.buildScope(renderViewElement); super.drawFrame(); buildOwner.finalizeTree(); } finally { ... } } This line buildOwner.buildScope(renderViewElement) in the code is the build phase of the render pipeline. In this part we explain in \"Flutter Framework Analysis (4) - Operation of the Flutter Framework\". The next function super.drawFrame() will come to the RendererBinding middle. void drawFrame() { pipelineOwner.flushLayout(); pipelineOwner.flushCompositingBits(); pipelineOwner.flushPaint(); renderView.compositeFrame(); // this sends the bits to the GPU pipelineOwner.flushSemantics(); // this also sends the semantics to the OS. } The first call inside pipelineOwner.flushLayout() is the layout phase of this article. Ok, let's start from here. Let's take a look PipelineOwner.flushLayout(). void flushLayout() { while (_nodesNeedingLayout.isNotEmpty) { final List dirtyNodes = _nodesNeedingLayout; _nodesNeedingLayout = []; for (RenderObject node in dirtyNodes..sort((RenderObject a, RenderObject b) => a.depth - b.depth)) { if (node._needsLayout && node.owner == this) node._layoutWithoutResize(); } } } This will iterate over the dirtyNodes array. What is placed in this array is the need to re-layout RenderObject. dirtyNodes Sort the array according to its depth in the render tree before traversing . The ordering here is the same as the sorting of the element tree we encountered during the build phase. The upper nodes are prioritized after sorting. Because the child nodes are recursively processed during the layout, if the upper nodes are processed first, the subsequent lower nodes of the layout are avoided. It will then be called RenderObject._layoutWithoutResize() to let the node do the layout itself. void _layoutWithoutResize() { try { performLayout(); markNeedsSemanticsUpdate(); } catch (e, stack) { ... } _needsLayout = false; markNeedsPaint(); } In RenderObject it, the function performLayout() needs its subclass to implement itself. Because of the variety of layouts, subclasses need to be personalized to implement their own layout logic. After the layout is complete, its own _needsLayout flag is set to false. Looking back at the previous function, it will be called in the loop body, only if it _needsLayout is . We know that layout in Flutter, rendering is done by. Most page elements use box constraints. There is a subclass that handles this layout. Most of Flutter is ultimately rendered by subclasses. There is a definition of the pair in the comments in the source code. true _layoutWithoutResize() RenderObject RenderBox Widget RenderBox |A render object in a 2D Cartesian coordinate system.| - Translated is a render object in a two-dimensional Cartesian coordinate system. Each box has a size property. Contains height and width. Each box has its own coordinate system with the coordinates (0,0) in the upper left corner. The coordinates of the lower right corner are (width, height). abstract class RenderBox extends RenderObject { ... Size _size; ... } When we write the Flutter app, we set the size of the component when it is created Widget, and the size or similar configuration is passed in. For example, the following Widget we have specified that its size is 100x100; Container(width: 100, height: 100)； Because the layout is done in the RenderObject inside, here is more specific RenderBox. So how is the size of this 100x100 delivered to RenderBox it? RenderBox How is the layout done? Container It is one StatelessWidget. It does not correspond to any of its own RenderObject. According to the parameters passed in the construction, Container it will eventually return a combination of Align, Padding, ConstrainedBox and so on Widget: Container({ Key key, this.alignment, this.padding, Color color, Decoration decoration, this.foregroundDecoration, double width, double height, BoxConstraints constraints, this.margin, this.transform, this.child, }) : decoration = decoration ?? (color != null ? BoxDecoration(color: color) : null), constraints = (width != null || height != null) ? constraints?.tighten(width: width, height: height) ?? BoxConstraints.tightFor(width: width, height: height) : constraints, super(key: key); final BoxConstraints constraints; @override Widget build(BuildContext context) { Widget current = child; if (child == null && (constraints == null || !constraints.isTight)) { current = LimitedBox( maxWidth: 0.0, maxHeight: 0.0, child: ConstrainedBox(constraints: const BoxConstraints.expand()), ); } if (alignment != null) current = Align(alignment: alignment, child: current); final EdgeInsetsGeometry effectivePadding = _paddingIncludingDecoration; if (effectivePadding != null) current = Padding(padding: effectivePadding, child: current); if (decoration != null) current = DecoratedBox(decoration: decoration, child: current); if (foregroundDecoration != null) { current = DecoratedBox( decoration: foregroundDecoration, position: DecorationPosition.foreground, child: current, ); } if (constraints != null) current = ConstrainedBox(constraints: constraints, child: current); if (margin != null) current = Padding(padding: margin, child: current); if (transform != null) current = Transform(transform: transform, child: current); return current; } In this case, one is returned ConstrainedBox. class ConstrainedBox extends SingleChildRenderObjectWidget { ConstrainedBox({ Key key, @required this.constraints, Widget child, }) : assert(constraints != null), assert(constraints.debugAssertIsValid()), super(key: key, child: child); /// The additional constraints to impose on the child. final BoxConstraints constraints; @override RenderConstrainedBox createRenderObject(BuildContext context) { return RenderConstrainedBox(additionalConstraints: constraints); } @override void updateRenderObject(BuildContext context, RenderConstrainedBox renderObject) { renderObject.additionalConstraints = constraints; } } And this Widget corresponding will be created RenderConstrainedBox. Then the specific layout work is done by it, and from the above code, the size of the 100x100 is constraints inside. class RenderConstrainedBox extends RenderProxyBox { RenderConstrainedBox({ RenderBox child, @required BoxConstraints additionalConstraints, }) : _additionalConstraints = additionalConstraints, super(child); BoxConstraints _additionalConstraints; @override void performLayout() { if (child != null) { child.layout(_additionalConstraints.enforce(constraints), parentUsesSize: true); size = child.size; } else { size = _additionalConstraints.enforce(constraints).constrain(Size.zero); } } } RenderConstrainedBox Inherited from RenderProxyBox. And RenderProxyBox then inherited from RenderBox. Here we see the performLayout() implementation. When there is a child node, the child.layout() request child node is called to make the layout. The constraints on the child node are passed in when calling constraints. This will pass the 100x100 constraint. Set your own size to the size of the child node after the child node layout is complete. When there is no child node, the constraint is converted to the size setting for itself. Let's take a look child.layout(). This function is in the RenderObject class: void layout(Constraints constraints, { bool parentUsesSize = false }) { RenderObject relayoutBoundary; if (!parentUsesSize || sizedByParent || constraints.isTight || parent is! RenderObject) { relayoutBoundary = this; } else { final RenderObject parent = this.parent; relayoutBoundary = parent._relayoutBoundary; } if (!_needsLayout && constraints == _constraints && relayoutBoundary == _relayoutBoundary) { return; } _constraints = constraints; _relayoutBoundary = relayoutBoundary; if (sizedByParent) { try { performResize(); } catch (e, stack) { ... } } try { performLayout(); markNeedsSemanticsUpdate(); } catch (e, stack) { ... } _needsLayout = false; markNeedsPaint(); } This function is longer and more critical. The first thing to do is to be sure relayoutBoundary. There are several conditions in it: parentUsesSize: Whether the parent component needs the size of the child component, this is the input parameter when calling, the default is false. sizedByParent: This is an RenderObject attribute that indicates RenderObject whether the current layout is only affected by RenderObject the constraints given by the parent . The default is false. Subclasses can be returned if needed true. For example RenderErrorBox. When our Flutter app goes wrong, the interface on the screen with the yellow background is rendered by it. constraints.isTight: Represents whether the constraint is a strict constraint. This means that only one size is allowed. The last condition is whether the father node is RenderObject. When any of the above conditions are met, it relayoutBoundary is itself, otherwise it takes the parent node relayoutBoundary. Next is another judgment. If the current node does not need to be re-arranged, the constraint has not changed, relayoutBoundary and there is no change and it returns directly. That is to say, starting from this node, the sub-nodes underneath it need not be re-arranged. This will have a performance boost. Then there is another judgment, if it sizedByParent is true, it will be called performResize(). This function will calculate the current RenderObject size based only on the constraints . When this function is called, it is usually performLayout() not possible to change the size in the next function. performLayout() It is the place where most nodes do layout. Different RenderObject will have different implementations. Finally mark the current node needs to be redrawn. The layout process is recursive. The top nodes are superimposed with different constraints. The child nodes calculate their size according to the constraints. If necessary, the parent node will get the size of the child nodes for further processing after the child node layout is completed. That is what we said at the beginning. layout() When we call we need to pass in the constraint, then let's see what happens to this constraint: abstract class Constraints { bool get isTight; bool get isNormalized; } This is an abstract class with only two getter. isTight It is the strict constraint we said before. Because Flutter is mainly a box constraint. So let's look at Constraints the subclasses:BoxConstraints 1.3.1. BoxConstraints class BoxConstraints extends Constraints { const BoxConstraints({ this.minWidth = 0.0, this.maxWidth = double.infinity, this.minHeight = 0.0, this.maxHeight = double.infinity, }); final double minWidth; final double maxWidth; final double minHeight; final double maxHeight; ... } The box constraint has 4 attributes, maximum width, minimum width, maximum height and minimum height. The different combinations of these four attributes constitute different constraints. When the maximum constraint and the minimum constraint are the same in an axial direction, then this axial direction is considered to be tightly constrained. BoxConstraints.tight(Size size) : minWidth = size.width, maxWidth = size.width, minHeight = size.height, maxHeight = size.height; const BoxConstraints.tightFor({ double width, double height, }) : minWidth = width != null ? width : 0.0, maxWidth = width != null ? width : double.infinity, minHeight = height != null ? height : 0.0, maxHeight = height != null ? height : double.infinity; BoxConstraints tighten({ double width, double height }) { return BoxConstraints(minWidth: width == null ? minWidth : width.clamp(minWidth, maxWidth), maxWidth: width == null ? maxWidth : width.clamp(minWidth, maxWidth), minHeight: height == null ? minHeight : height.clamp(minHeight, maxHeight), maxHeight: height == null ? maxHeight : height.clamp(minHeight, maxHeight)); } When the minimum constraint in a certain axis direction is 0.0, then this axis direction is considered to be loose. BoxConstraints.loose(Size size) : minWidth = 0.0, maxWidth = size.width, minHeight = 0.0, maxHeight = size.height; BoxConstraints loosen() { assert(debugAssertIsValid()); return BoxConstraints( minWidth: 0.0, maxWidth: maxWidth, minHeight: 0.0, maxHeight: maxHeight, ); } When the value of the maximum constraint in an axial direction is smaller than double.infinity this, the constraint of this axial direction is limited. bool get hasBoundedWidth => maxWidth maxHeight When the value of the maximum constraint in the direction of an axis is equal double.infinity, the constraint of this axis direction is unlimited. If the maximum and minimum constraints are both double.infinity, the constraint of this axis direction is exbanding. const BoxConstraints.expand({ double width, double height, }) : minWidth = width != null ? width : double.infinity, maxWidth = width != null ? width : double.infinity, minHeight = height != null ? height : double.infinity, maxHeight = height != null ? height : double.infinity; Finally, the node needs to convert the constraint to size when laying out. The dimensions obtained here are considered to satisfy the constraints. Size constrain(Size size) { Size result = Size(constrainWidth(size.width), constrainHeight(size.height)); return result; } double constrainWidth([ double width = double.infinity ]) { return width.clamp(minWidth, maxWidth); } double constrainHeight([ double height = double.infinity ]) { return height.clamp(minHeight, maxHeight); } 1.4. Layout example We know that the root node of the render tree is RenderView. In the RendererBinding creation RenderViewtime will pass a ViewConfiguration type of configuration parameters: void initRenderView() { assert(renderView == null); renderView = RenderView(configuration: createViewConfiguration(), window: window); renderView.scheduleInitialFrame(); } ViewConfiguration Defined as follows, including a size attribute and a device pixel scale attribute: @immutable class ViewConfiguration { const ViewConfiguration({ this.size = Size.zero, this.devicePixelRatio = 1.0, }); final Size size; final double devicePixelRatio; } ViewConfiguration The instance is createViewConfiguration() created by a function : ViewConfiguration createViewConfiguration() { final double devicePixelRatio = window.devicePixelRatio; return ViewConfiguration( size: window.physicalSize / devicePixelRatio, devicePixelRatio: devicePixelRatio, ); } It can be seen that the size is taken by the physical pixel size of the window divided by the device pixel ratio. On Nexus 5, the physical pixel size of the full-screen window ( window.physicalSize) is 1080x1776. The device pixel ratio ( window.devicePixelRatio) is 3.0. The final ViewConfiguration of the size property to 360x592. Then let's see how RenderView to do the layout: @override void performLayout() { _size = configuration.size; if (child != null) child.layout(BoxConstraints.tight(_size)); } The root node generates a strict box constraint based on the configured size. In the case of the Nexus 5, the constraint is that the maximum width and the minimum width are both 360, and the maximum height and minimum height are both layout() Pass this strict constraint when calling the child node . If we want to display a 100x100 rectangle in the center of the screen, the code is as follows: runApp(Center(child: Container(width: 100, height: 100, color: Color(0xFFFF9000),))); After running, the render tree structure is as follows: RenderView The child nodes are one RenderPositionedBox. Its layout function is as follows: @override void performLayout() { if (child != null) { child.layout(constraints.loosen(), parentUsesSize: true); size = constraints.constrain(Size(shrinkWrapWidth ? child.size.width * (_widthFactor ?? 1.0) : double.infinity, shrinkWrapHeight ? child.size.height * (_heightFactor ?? 1.0) : double.infinity)); alignChild(); } } Here constraints comes from the root node RenderView. We have analyzed before, this is a strict constraint of 360x592. When the child node is called, layout() it will give the child node a new constraint. This constraint is a new constraint after loosening its strict constraint. That is, the constraint to the child node is [0-360]x[0-592] . And set it parentUsesSize to true. Next is the child nodes RenderConstrainedBox to layout: @override void performLayout() { if (child != null) { child.layout(_additionalConstraints.enforce(constraints), parentUsesSize: true); size = child.size; } else { size = _additionalConstraints.enforce(constraints).constrain(Size.zero); } } Here again RenderDecoratedBox, the layout function of the child node is called. What is the constraint on the child node? _additionalConstraints From the size we gave us in Container the 100x100 set. From the foregoing analysis, this is a strict constraint. The parent node gives [0-360]x[0-592]. enforce() Generate a new constraint by calling the function: BoxConstraints enforce(BoxConstraints constraints) { return BoxConstraints( minWidth: minWidth.clamp(constraints.minWidth, constraints.maxWidth), maxWidth: maxWidth.clamp(constraints.minWidth, constraints.maxWidth), minHeight: minHeight.clamp(constraints.minHeight, constraints.maxHeight), maxHeight: maxHeight.clamp(constraints.minHeight, constraints.maxHeight), ); } As can be seen from the above code, the new constraint is a strict constraint of 100x100. Finally we came to the RenderDecoratedBox layout of the leaf node ( ): @override void performLayout() { if (child != null) { child.layout(constraints, parentUsesSize: true); size = child.size; } else { performResize(); } } Because it is a leaf node, it has no children, so it is a else branch, called performResize(): @override void performResize() { size = constraints.smallest; } The default layout when there are no children is to make yourself as small as possible under the current constraints. So the size obtained here is 100x100; At this point, the \"look\" process of the layout process is complete. It can be seen that this process is the constraint that the parent node generates to the child node according to its own configuration, and then lets the child node do the layout according to the constraints of the parent node. After \"getting it done\", then it should be \"one on\". Go back to the parent node of the leaf node RenderConstrainedBox: child.layout(_additionalConstraints.enforce(constraints), parentUsesSize: true); size = child.size; I didn't do it, set the size of my child to my size, how old I am. Going up again, it’s up to RenderPositionedBox: child.layout(constraints.loosen(), parentUsesSize: true); size = constraints.constrain(Size(shrinkWrapWidth ? child.size.width * (_widthFactor ?? 1.0) : double.infinity, shrinkWrapHeight ? child.size.height * (_heightFactor ?? 1.0) : double.infinity)); alignChild(); Here shrinkWrapWidth and shrinkWrapHeight both false. The constraint is a strict constraint of 360x592, so the final size is 360x592. And the child node is 100x100, then you need to know where to put the child node inside, so call alignChild() void alignChild() { _resolve(); final BoxParentData childParentData = child.parentData; childParentData.offset = _resolvedAlignment.alongOffset(size - child.size); } The alignment of the child node inside the parent node is Alignment determined by the alignment . class Alignment extends AlignmentGeometry { const Alignment(this.x, this.y) final double x; final double y; @override double get _x => x; @override double get _start => 0.0; @override double get _y => y; /// The top left corner. static const Alignment topLeft = Alignment(-1.0, -1.0); /// The center point along the top edge. static const Alignment topCenter = Alignment(0.0, -1.0); /// The top right corner. static const Alignment topRight = Alignment(1.0, -1.0); /// The center point along the left edge. static const Alignment centerLeft = Alignment(-1.0, 0.0); /// The center point, both horizontally and vertically. static const Alignment center = Alignment(0.0, 0.0); /// The center point along the right edge. static const Alignment centerRight = Alignment(1.0, 0.0); /// The bottom left corner. static const Alignment bottomLeft = Alignment(-1.0, 1.0); /// The center point along the bottom edge. static const Alignment bottomCenter = Alignment(0.0, 1.0); /// The bottom right corner. static const Alignment bottomRight = Alignment(1.0, 1.0); It contains two floating point coefficients inside. By combining these two coefficients, we can define some common alignments, such as the upper left corner Alignment(-1.0, -1.0). The top is centered Alignment(0.0, -1.0). In the upper right corner is Alignment(1.0, -1.0). The vertical levels we use are all centered Alignment(0.0, 0.0). From then how Alignment to calculate the offset it be? Above, we see that by the Alignment.alongOffset(size - child.size) call. Offset alongOffset(Offset other) { final double centerX = other.dx / 2.0; final double centerY = other.dy / 2.0; return Offset(centerX + x * centerX, centerY + y * centerY); } The input parameter is the size of the parent node minus the size of the child node, that is, the space left by the parent node. Take the excess length and then divide by 2 to get the median. Then each of the median values ​​is Alignment multiplied by the median value to get the offset. Is it very clever? Our example is that the vertical level is centered, x and y both are 0. So the available offset is [130,246]. Going back alignChild(), after getting the offset, the parent node will childParentData.offset save this offset to the child node by setting it. This offset is used in subsequent drawing passes. Finally, I returned to the root node RenderView. So far, the “one-on-one” of the layout process has been completed. It can be seen that the second half of the process parent node may determine its size according to the size of the child node, and it is also possible to determine the position of the child node within the child node according to the size of the child node and its own size. 1.5. to sum up This article introduces the layout stage of the Flutter rendering pipeline. The layout phase is mainly to master the \"one-on-one\" process. The next step is to pass the constraint layer down, and the upper layer is the upper layer. This article does not introduce too much of the details of the various layouts, as long as you master the layout process, which specific layout is how to achieve only need to consult the corresponding RenderObject source code. "},"Flutter Framework Analysis 7 - Drawing.html":{"url":"Flutter Framework Analysis 7 - Drawing.html","title":"Flutter Framework Analysis 7 - Drawing","keywords":"","body":"1. Flutter Frame Analysis (7) -- Drawing1.1. Foreword1.2. Overview1.2.1. Layer1.3. analysis1.3.1. pipelineOwner.flushCompositingBits()1.3.2. pipelineOwner.flushPaint()1.3.3. renderView.compositeFrame()1.4. to sum up1. Flutter Frame Analysis (7) -- Drawing Flutter Framework Analysis and Analysis Series: \"Flutter Framework Analysis (1) - Overview and Window\" \"Flutter Framework Analysis (2) - Initialization\" \"Flutter Framework Analysis (3) - Widget, Element and RenderObject\" \"Flutter Framework Analysis (4) - Flutter Framework Operation\" \"Flutter Framework Analysis (5) - Animation\" \"Flutter Framework Analysis (6) - Layout\" \"Flutter Framework Analysis (7) - Drawing\" Flutter Frame Analysis (7) -- Drawing Foreword Overview Layer analysis pipelineOwner.flushCompositingBits() pipelineOwner.flushPaint() renderView.compositeFrame() to sum up 1.1. Foreword This article will introduce you to the painting phase of the final step of the rendering pipeline in conjunction with the Flutter source. The content of this article may be far from the framework knowledge that you need to know to develop the Flutter app. The place that may need attention at present is RepaintBoundary this Widget, and its corresponding RenderObject is RenderRepaintBoundary. The Widget role of this in the introduction of the rendering pipeline drawing stage I believe that everyone will have a clearer understanding. 1.2. Overview We all know that the render tree in the Flutter framework is responsible for layout and rendering. At the time of rendering, Flutter will traverse the RenderObject subtrees that need to be redrawn to draw one by one. The Flutter app page we saw on the screen was actually composed of different layers of compsite. These layers are organized in the form of trees, another important tree we saw in Flutter: the layer tree. The above image is a schematic diagram of the Flutter frame rendering mechanism. The content in the green box above can be considered as the focus of this series of articles. That is where the Flutter frame rendering pipeline runs. It can be seen that the entire rendering pipeline is running in the UI thread, driven by the Vsync signal, and the layer tree is output after the frame rendering is completed. The layer tree is sent to the engine. The engine dispatches the layer tree to the GPU thread, composing the layer tree in the GPU thread, and then rendering it to the GPU display by the Skia 2D rendering engine. The layer tree is mentioned here because the final output of the rendering pipeline drawing stage we are about to analyze is such a layer tree. So the drawing phase is not as simple as calling a paint() function, but many places involve the management of the layer tree. 1.2.1. Layer The layers in Flutter are Layer represented by classes . abstract class Layer extends AbstractNode with DiagnosticableTreeMixin { @override ContainerLayer get parent => super.parent; Layer get nextSibling => _nextSibling; Layer _nextSibling; Layer get previousSibling => _previousSibling; Layer _previousSibling; } A class Layer is an abstract class, and the RenderObject same, inherited from AbstractNode. Indicates that it is also a tree structure. The attribute parent represents its parent node and the type is ContainerLayer. This class inherits from Layer. Only ContainerLayer layers of types and their subclasses can have children, and other types of Layer subclasses are leaf layers. nextSibling and previousSibling a front and a rear sibling node of the same layer, the layer that is used by children who are doubly linked list of storage. class ContainerLayer extends Layer { Layer _firstChild; Layer _lastChild; void append(Layer child) { adoptChild(child); child._previousSibling = lastChild; if (lastChild != null) lastChild._nextSibling = child; _lastChild = child; _firstChild ??= child; } void _removeChild(Layer child) { if (child._previousSibling == null) { _firstChild = child._nextSibling; } else { child._previousSibling._nextSibling = child.nextSibling; } if (child._nextSibling == null) { _lastChild = child.previousSibling; } else { child.nextSibling._previousSibling = child.previousSibling; } child._previousSibling = null; child._nextSibling = null; dropChild(child); } void removeAllChildren() { Layer child = firstChild; while (child != null) { final Layer next = child.nextSibling; child._previousSibling = null; child._nextSibling = null; dropChild(child); child = next; } _firstChild = null; _lastChild = null; } } ContainerLayer added header and tail two child node properties and provides methods for adding and deleting child nodes. ContainerLayer Subclasses OffsetLayer, ClipRectLayer and so on. The leaf type of the layer has TextureLayer, PlatformViewLayer, PerformanceOverlayLayer, PictureLayer and so on, most RenderObject of the drawn target layers in the frame are PictureLayer. class PictureLayer extends Layer { final Rect canvasBounds; ui.Picture _picture; } The attribute canvasBounds represents the boundary of the layer canvas, but this attribute is suggestive. The attribute picture comes from the dart:ui library. 1.3. analysis Going back to the drawFrame() function we are familiar with , the pipelineOwner.flushLayout() rendering pipeline enters the paint phase after the call is completed. void drawFrame() { pipelineOwner.flushLayout(); pipelineOwner.flushCompositingBits(); pipelineOwner.flushPaint(); renderView.compositeFrame(); // this sends the bits to the GPU pipelineOwner.flushSemantics(); // this also sends the semantics to the OS. } The first call to the drawing phase is pipelineOwner.flushCompositingBits(). 1.3.1. pipelineOwner.flushCompositingBits() This call is used to update RenderObject the _needsCompositing flag bits in the render tree . Before we introduce this call, let's first understand some RenderObject of the flags. bool _needsCompositing: The logo itself or a child node has a composite layer. If the current node needs to be synthesized, then all ancestor nodes also need to be synthesized. bool _needsCompositingBitsUpdate: Flags whether the current node needs to be updated _needsCompositing. This flag is set by the markNeedsCompositingBitsUpdate() function below . bool get isRepaintBoundary => false;: Flags whether the current node is redrawn from the parent node. When this flag is set true, the child node does not necessarily need to be redrawn when the parent node is redrawn. Similarly, the parent node does not necessarily need to be redrawn when it is redrawn. This flag is true the RenderObject root node of the render tree RenderView, we are familiar RenderRepaintBoundary, TextureBox and so on. bool get alwaysNeedsCompositing => false;: Flags whether the current node always needs to be composited. This flag true means that the current node will always open a composite layer when it is drawn. For example TextureBox, and what we are familiar with showing runtime performance RenderPerformanceOverlay. In the construction phase of the rendering pipeline, in some cases the nodes in the render tree need to be re-updated _needsCompositing, such as the addition and deletion of nodes in the render tree. This tagging is done by a function markNeedsCompositingBitsUpdate(). void markNeedsCompositingBitsUpdate() { if (_needsCompositingBitsUpdate) return; _needsCompositingBitsUpdate = true; if (parent is RenderObject) { final RenderObject parent = this.parent; if (parent._needsCompositingBitsUpdate) return; if (!isRepaintBoundary && !parent.isRepaintBoundary) { parent.markNeedsCompositingBitsUpdate(); return; } } if (owner != null) owner._nodesNeedingCompositingBitsUpdate.add(this); } This call will look up from the current node and set the _needsCompositingBitsUpdate flag bits of all parent nodes true. Until you or the parent node isRepaintBoundary is true. Finally, I will add myself to PipelineOwnerthe _nodesNeedingCompositingBitsUpdate list. The function call pipelineOwner.flushCompositingBits() is used to process this list. flushCompositingBits() The source code is as follows: void flushCompositingBits() { _nodesNeedingCompositingBitsUpdate.sort((RenderObject a, RenderObject b) => a.depth - b.depth); for (RenderObject node in _nodesNeedingCompositingBitsUpdate) { if (node._needsCompositingBitsUpdate && node.owner == this) node._updateCompositingBits(); } _nodesNeedingCompositingBitsUpdate.clear(); } First sort the list _nodesNeedingCompositingBitsUpdate by the depth of the nodes in the tree. Then traversing the call node._updateCompositingBits() void _updateCompositingBits() { if (!_needsCompositingBitsUpdate) return; final bool oldNeedsCompositing = _needsCompositing; _needsCompositing = false; visitChildren((RenderObject child) { child._updateCompositingBits(); if (child.needsCompositing) _needsCompositing = true; }); if (isRepaintBoundary || alwaysNeedsCompositing) _needsCompositing = true; if (oldNeedsCompositing != _needsCompositing) markNeedsPaint(); _needsCompositingBitsUpdate = false; } What this does is look down from the current node, if a child node isRepaintBoundary is true or alwaysNeedsCompositing is true it set _needsCompositing to true. If the child node has this flag true, then the flag of the parent node will also be set to true. If _needsCompositing a change has occurred, the markNeedsPaint() notification render pipeline will be called and the RenderObject redraw will need to be redrawn. Why do you want to redraw it? The reason is that the layer where the RenderObject is located may have changed. 1.3.2. pipelineOwner.flushPaint() The function flushPaint() handles _nodesNeedingPaint the nodes that were previously added to the list . RenderObject Called when something needs to be redrawn markNeedsPaint() void markNeedsPaint() { if (_needsPaint) return; _needsPaint = true; if (isRepaintBoundary) { if (owner != null) { owner._nodesNeedingPaint.add(this); owner.requestVisualUpdate(); } } else if (parent is RenderObject) { final RenderObject parent = this.parent; parent.markNeedsPaint(); } else { if (owner != null) owner.requestVisualUpdate(); } } The markNeedsPaint() first thing the function does is set its own flag bit _needsPaint to true. Then it will look up the nearest one isRepaintBoundary for true the ancestor node. Until you find such a node, the node will be added to this _nodesNeedingPaint list, that is to say, not any one needs to be repainted RenderObject will be added to this list, but up looking until you find the nearest one isRepaintBoundary to true take into This list, in other words, is only isRepaintBoundary for true this type of node in this list . That is to say, the starting point of redrawing starts from \"repainting the boundary\". void flushPaint() { try { final List dirtyNodes = _nodesNeedingPaint; _nodesNeedingPaint = []; // Sort the dirty nodes in reverse order (deepest first). for (RenderObject node in dirtyNodes..sort((RenderObject a, RenderObject b) => b.depth - a.depth)) { if (node._needsPaint && node.owner == this) { if (node._layer.attached) { PaintingContext.repaintCompositedChild(node); } else { node._skippedPaintingOnLayer(); } } } } finally { ... } } When dealing with nodes that need to be redrawn, these nodes will be sorted first. It should be noted that, flushLayout() unlike the previous sorting, the sorting here is the node with deep depth. In the loop body, it will determine whether the current node's _layer properties are in attached the state. If it _layer.attached is true, call to PaintingContext.repaintCompositedChild(node); do the drawing, otherwise the call node._skippedPaintingOnLayer() will set itself and _needsPaint all the nodes between the upper drawing boundaries true. This will be drawn directly the next time it _layer.attached changes true. It can also be seen from the above code that redrawing the boundary is equivalent to doing the block processing of Flutter's drawing. The redrawing starts from the upper layer redrawing the boundary to the lower layer redrawing the boundary, and RenderObject both need to be redrawn. Outside the boundary, you may not need to redraw, which is also a performance consideration, try to avoid unnecessary drawing. So how to make reasonable arrangements RepaintBoundary is one of the directions we need to consider when doing the performance optimization of the Flutter app. The _layer attribute here is the layer we said before. This attribute RenderObject has a value only if it is drawn . The general RenderObject property is null. static void _repaintCompositedChild( RenderObject child, { bool debugAlsoPaintedParent = false, PaintingContext childContext, }) { if (child._layer == null) { child._layer = OffsetLayer(); } else { child._layer.removeAllChildren(); } childContext ??= PaintingContext(child._layer, child.paintBounds); child._paintWithContext(childContext, Offset.zero); childContext.stopRecordingIfNeeded(); } The layer property that the function _repaintCompositedChild() will check first RenderObject. If it is empty, create a new OffsetLayer instance. If the layer already exists, clear the child. If not PaintingContext, create a new one and let it start drawing. Let's take a look at PaintingContext this class first : class PaintingContext extends ClipContext { @protected PaintingContext(this._containerLayer, this.estimatedBounds) final ContainerLayer _containerLayer; final Rect estimatedBounds; PictureLayer _currentLayer; ui.PictureRecorder _recorder; Canvas _canvas; @override Canvas get canvas { if (_canvas == null) _startRecording(); return _canvas; } void _startRecording() { _currentLayer = PictureLayer(estimatedBounds); _recorder = ui.PictureRecorder(); _canvas = Canvas(_recorder); _containerLayer.append(_currentLayer); } void stopRecordingIfNeeded() { if (!_isRecording) return; _currentLayer.picture = _recorder.endRecording(); _currentLayer = null; _recorder = null; _canvas = null; } The PaintingContext literal meaning of the class is the drawing context, and its property _containerLayer is the container layer, which comes from the constructor. That PaintingContext is, it is associated with the container layer. Then there is PictureLayer the type of _currentLayer property, ui.PictureRecorder the type of _recorder property and we are familiar with Canvas the type of property _canvas. The function _startRecording() instantiates these properties. _recorder Used to record drawing commands and _canvas bind a recorder. Finally, it _currentLayer will be added as a child node _containerLayer. There will be an end when there is a start, which is stopRecordingIfNeeded() used to end the recording of the current drawing. At the end, the drawn Picture values will be assigned to the current one PictureLayer.picture. Once you have PaintingContext it, you can call to RenderObject._paintWithContext() start drawing. This function will be called directly to the familiar one RenderObject.paint(context, offset). We know that the function paint() is RenderObject implemented by the subclass itself. From the previous source analysis we know that the starting point for drawing is \"draw the boundary\". Here we take a familiar \"draw boundary\", RenderRepaintBoundary for example, to take a look at the drawing process, its implementation of the drawing function in the RenderProxyBoxMixin class: @override void paint(PaintingContext context, Offset offset) { if (child != null) context.paintChild(child, offset); } This call is back to PaintingContext the paintChild() method: void paintChild(RenderObject child, Offset offset) { if (child.isRepaintBoundary) { stopRecordingIfNeeded(); _compositeChild(child, offset); } else { child._paintWithContext(this, offset); } } This will check if the child node is drawing the boundary. If it is not, it is normal drawing, then call _paintWithContext() it down and continue PictureLayer drawing to the current one . If so, stop the current drawing first. Then call _compositeChild(child, offset); void _compositeChild(RenderObject child, Offset offset) { if (child._needsPaint) { repaintCompositedChild(child, debugAlsoPaintedParent: true); } child._layer.offset = offset; appendLayer(child._layer); } If the sub-draw boundary is marked as needing to be redrawn, then it is called repaintCompositedChild() to regenerate the layer and redraw. If this sub-draw boundary is notmarked as needing to be redrawn, the rebuild layer and redraw are skipped. Finally, you only need to add the sublayer to the current container layer. The above is the drawing process when the child nodes are drawing the boundary. If the child nodes are ordinary ones RenderObject? Here is an example of the drawing of the Flutter app error control: void _compositeChild(RenderObject child, Offset offset) { if (child._needsPaint) { repaintCompositedChild(child, debugAlsoPaintedParent: true); } child._layer.offset = offset; appendLayer(child._layer); } This looks like a normal drawing, we will use PaintingContext the canvas canvasfrom the drawing to draw the rectangle, draw the text and so on. As can be seen from the previous analysis, the drawing here is done on one PictureLayer layer. So far pipelineOwner.flushPaint(); this function is called and ran over, through analysis we can know, it is mainly drawn work done in this function. Next, let's take a look at the last important function call of the drawing process: 1.3.3. renderView.compositeFrame() Here renderView is the root node of the render tree we said earlier. This function call mainly sends the entire layer tree generator scene to the engine for display. void compositeFrame() { try { final ui.SceneBuilder builder = ui.SceneBuilder(); final ui.Scene scene = layer.buildScene(builder); if (automaticSystemUiAdjustment) _updateSystemChrome(); _window.render(scene); scene.dispose(); } finally { Timeline.finishSync(); } } ui.SceneBuilder() Finally call the Native method SceneBuilder_constructor. This means that the ui.SceneBuilder instance was created by the engine. The next step is to call the layer.buildScene(builder) method, which returns an ui.Scene instance. Since compositeFrame() the caller of the method is renderView. So here layer is renderView the attribute from which we said earlier that only the boundary node is drawn layer. So the root node renderView of the render tree is also a drawing boundary. So layer where did this come from? In the article \"Flutter Framework Analysis (2) - Initialization\" we have said that during the framework initialization process, renderView the first frame will be dispatched: void scheduleInitialFrame() { scheduleInitialLayout(); scheduleInitialPaint(_updateMatricesAndCreateNewRootLayer()); owner.requestVisualUpdate(); } Layer _updateMatricesAndCreateNewRootLayer() { _rootTransform = configuration.toMatrix(); final ContainerLayer rootLayer = TransformLayer(transform: _rootTransform); rootLayer.attach(this); return rootLayer; } void scheduleInitialPaint(ContainerLayer rootLayer) { _layer = rootLayer; owner._nodesNeedingPaint.add(this); } In the method _updateMatricesAndCreateNewRootLayer(), we see that one is instantiated here TransformLayer. TransformLayer inherited from OffsetLayer. Matrix4 The parameters of the type are required to be constructed transform. This Matrix4 is actually the Matrix same thing we saw in Android . Represents matrix transformation. Here transform comes from what we have said before ViewConfiguration, it is to convert the device pixel ratio into a matrix form. In the end, this layer connection is over renderView. So here TransformLayer is actually the root node of the layer tree. Go back to our drawing process. layer.buildScene(builder); This call we naturally go TransformLayer there to find, but this method is the parent class OffsetLayer inside, we are all of the layers to operate from the beginning of this call, eventually converted to layer tree scene scene: ui.Scene buildScene(ui.SceneBuilder builder) { List temporaryLayers; updateSubtreeNeedsAddToScene(); addToScene(builder); final ui.Scene scene = builder.build(); return scene; } The function call updateSubtreeNeedsAddToScene(); will traverse the layer tree to set the _subtreeNeedsAddToScene flag bit. If there are any sub-layers to add or delete, the sub-layer and its ancestor layer will be _subtreeNeedsAddToScene marked. Then call addToScene(builder); @override @override ui.EngineLayer addToScene(ui.SceneBuilder builder, [ Offset layerOffset = Offset.zero ]) { _lastEffectiveTransform = transform; final Offset totalOffset = offset + layerOffset; if (totalOffset != Offset.zero) { _lastEffectiveTransform = Matrix4.translationValues(totalOffset.dx, totalOffset.dy, 0.0) ..multiply(_lastEffectiveTransform); } builder.pushTransform(_lastEffectiveTransform.storage); addChildrenToScene(builder); builder.pop(); return null; // this does not return an engine layer yet. } builder.pushTransform will call to the engine layer. This is equivalent to telling the engine that I want to add a transform layer. Then call to addChildrenToScene(builder) add the sub-layer to the scene, and then push the transformation layer of the previous stack onto the stack. void addChildrenToScene(ui.SceneBuilder builder, [ Offset childOffset = Offset.zero ]) { Layer child = firstChild; while (child != null) { if (childOffset == Offset.zero) { child._addToSceneWithRetainedRendering(builder); } else { child.addToScene(builder, childOffset); } child = child.nextSibling; } } This is the call to traverse the add sublayer. Mainly still called down layer by layer addToScene(). Different layers of this method will have different implementations. For the container class layer, the main thing is to do three things: 1. Add the effect of your own layer and then push the stack, 2. Add the sublayer, 3. Stack . After all layers have been processed. Going back renderView.compositeFrame(), it will be visible that the scene that was processed will be _window.render(scene); sent to the engine for display. At this point, the paint phase of the render pipeline is finished. Wait, it seems that something is missing. In the process of analyzing and drawing, we see that the main call pipelineOwner.flushCompositingBits() is to update the _needsCompositing flag of the node in the render tree . But we all finished the process, and it seems that we have not seen where the logo is used. This flag is definitely used where it is, otherwise we have to use such a big update to use it? Go back and study the code... Some of this flag will be used RenderObject in its paint() function, and it is reflected in PaintingContext the call of these functions: void pushClipRect(bool needsCompositing, Offset offset, Rect clipRect, PaintingContextCallback painter, { Clip clipBehavior = Clip.hardEdge }) { final Rect offsetClipRect = clipRect.shift(offset); if (needsCompositing) { pushLayer(ClipRectLayer(clipRect: offsetClipRect, clipBehavior: clipBehavior), painter, offset, childPaintBounds: offsetClipRect); } else { clipRectAndPaint(offsetClipRect, clipBehavior, offsetClipRect, () => painter(this, offset)); } } void pushClipRRect(bool needsCompositing, Offset offset, Rect bounds, RRect clipRRect, PaintingContextCallback painter, { Clip clipBehavior = Clip.antiAlias }) { final Rect offsetBounds = bounds.shift(offset); final RRect offsetClipRRect = clipRRect.shift(offset); if (needsCompositing) { pushLayer(ClipRRectLayer(clipRRect: offsetClipRRect, clipBehavior: clipBehavior), painter, offset, childPaintBounds: offsetBounds); } else { clipRRectAndPaint(offsetClipRRect, clipBehavior, offsetBounds, () => painter(this, offset)); } } void pushClipPath(bool needsCompositing, Offset offset, Rect bounds, Path clipPath, PaintingContextCallback painter, { Clip clipBehavior = Clip.antiAlias }) { final Rect offsetBounds = bounds.shift(offset); final Path offsetClipPath = clipPath.shift(offset); if (needsCompositing) { pushLayer(ClipPathLayer(clipPath: offsetClipPath, clipBehavior: clipBehavior), painter, offset, childPaintBounds: offsetBounds); } else { clipPathAndPaint(offsetClipPath, clipBehavior, offsetBounds, () => painter(this, offset)); } } void pushTransform(bool needsCompositing, Offset offset, Matrix4 transform, PaintingContextCallback painter) { final Matrix4 effectiveTransform = Matrix4.translationValues(offset.dx, offset.dy, 0.0) ..multiply(transform)..translate(-offset.dx, -offset.dy); if (needsCompositing) { pushLayer( TransformLayer(transform: effectiveTransform), painter, offset, childPaintBounds: MatrixUtils.inverseTransformRect(effectiveTransform, estimatedBounds), ); } else { canvas ..save() ..transform(effectiveTransform.storage); painter(this, offset); canvas ..restore(); } } needsCompositing As the parameters of these functions, we can see from the code its main function is to control these types of special drawing operations of the specific implementation, if needsCompositing is true, then, will be called pushLayer, the parameters we had seen various layers void pushLayer(ContainerLayer childLayer, PaintingContextCallback painter, Offset offset, { Rect childPaintBounds }) { stopRecordingIfNeeded(); appendLayer(childLayer); final PaintingContext childContext = createChildContext(childLayer, childPaintBounds ?? estimatedBounds); painter(childContext, offset); childContext.stopRecordingIfNeeded(); } @protected PaintingContext createChildContext(ContainerLayer childLayer, Rect bounds) { return PaintingContext(childLayer, bounds); } The process is basically the same as adding a layer when we redraw it. And if it needsCompositing is false, then it is canvas a variety of changes. If you are interested, you can go and see the source code. I won't go into details here. 1.4. to sum up So far, the paint phase of the Flutter frame rendering pipeline has been analyzed. The drawing process is not as straightforward as the previous build, layout process, just traverse the element tree or the render tree. Another tree, layer tree, layer tree appears in the render phase. The entire drawing process is a process of converting the render tree into a suitable layer tree and finally generating a scene. Finally, on the basis of understanding the rendering process, it is recommended that you take a look at this video from Google engineers: Learn more about Flutter's high-performance graphics rendering. I believe that after reading this video, you will have a better understanding of the rendering of the Flutter framework and some performance issues you may encounter. "}}